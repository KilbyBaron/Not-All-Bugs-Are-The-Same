Summary,Issue key,Issue id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Component/s,Component/s,Component/s,Component/s,Component/s,Due Date,Votes,Labels,Labels,Labels,Labels,Description,Environment,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,Σ Original Estimate,Σ Remaining Estimate,Σ Time Spent,Security Level,Outward issue link (Blocker),Outward issue link (Cloners),Outward issue link (Duplicate),Outward issue link (Incorporates),Outward issue link (Incorporates),Outward issue link (Incorporates),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Regression),Outward issue link (Regression),Outward issue link (Required),Outward issue link (Required),Outward issue link (Required),Outward issue link (Required),Outward issue link (Required),Outward issue link (Supercedes),Outward issue link (Supercedes),Outward issue link (dependent),Outward issue link (dependent),Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Custom field (Attachment count),Custom field (Blog - New Blog Administrators),Custom field (Blog - New Blog PMC),Custom field (Blog - Write access),Custom field (Blog Administrator?),Custom field (Blogs - Admin for blog),Custom field (Blogs - Email Address),Custom field (Blogs - Existing Blog Access Level),Custom field (Blogs - Existing Blog Name),Custom field (Blogs - New Blog Write Access),Custom field (Blogs - Username),Custom field (Bug Category),Custom field (Bugzilla - Email Notification Address),Custom field (Bugzilla - List of usernames),Custom field (Bugzilla - PMC Name),Custom field (Bugzilla - Project Name),Custom field (Bugzilla Id),Custom field (Change Category),Custom field (Complexity),Custom field (Date of First Response),Custom field (Discovered By),Custom field (Docs Text),Custom field (Enable Automatic Patch Review),Custom field (Epic Link),Custom field (Existing GitBox Approval),Custom field (External issue ID),Custom field (External issue URL),Custom field (Git Notification Mailing List),Custom field (Git Repository Import Path),Custom field (Git Repository Name),Custom field (Git Repository Type),Custom field (GitHub Options),Custom field (Github Integration),Custom field (Github Integrations - Other),Custom field (Global Rank),Custom field (INFRA - Subversion Repository Path),Custom field (Initial Confluence Contributors),Custom field (Last public comment date),Custom field (Machine Readable Info),Custom field (New-TLP-TLPName),Custom field (Priority),Custom field (Project),Custom field (Protected Branch),Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Severity),Custom field (Severity),Custom field (Space Description),Custom field (Space Key),Custom field (Space Name),Custom field (Test and Documentation Plan),Custom field (Testcase included),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
MetadataLocationObtainer directly updates serverSideIteratorList of ScannerOptions,ACCUMULO-2188,12688697,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,vickyuec,vickyuec,vickyuec,14/Jan/14 08:46,07/Apr/15 15:39,13/Mar/19 22:01,07/Apr/15 15:39,,,,,,,,1.7.0,,,,,,,,,0,,,,,"In lookupTablets method, this class creates a ScannerOptions object and directly updates the serverSideIteratorList field instead of calling addScanIterator, thereby getting serverSideIteratorList and serverSideIteratorOptions out-of-sync. It's not a major issue currently, but MetadataLocationObtainer shouldn't make assumptions about ScannerOptions.",,"Commit b2aa0f86e426809cf952aa914545cdfe1c8f7c2b in accumulo's branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b2aa0f8 ]

ACCUMULO-2188 Use addScanIterator instead of modifying internal field
;07/Apr/15 15:39;jira-bot;600",,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,14/Jan/14 08:58;vickyuec;ACCUMULO-2188.v1.patch.txt;https://issues.apache.org/jira/secure/attachment/12622817/ACCUMULO-2188.v1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2015-04-06 03:20:54.44,,,no_permission,,,,,,,,,,,,367716,,,Mon Apr 06 03:20:54 UTC 2015,,,,,,0|i1rdrz:,368023,,,,,,,,14/Jan/14 08:58;vickyuec;Attached patch.,"06/Apr/15 03:20;elserj;Sorry for the delay, I'll try to take a look at this tmrw.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"AddFilesWithMissingEntries needs to just find abandoned files, or be deleted",ACCUMULO-2381,12696007,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ctubbsii,ecn,ecn,19/Feb/14 16:49,18/Dec/14 20:56,13/Mar/19 22:01,18/Dec/14 20:56,1.6.0,,,,,,,1.6.2,1.7.0,,,,,,,,0,,,,,"The usefulness of the AddFilesWithMissingEntries utility is questionable.

#) it's very dangerous: it updates the metadata table of online tablets without checking or warning users
#) there's no use case for wanting to re-incorporate abandoned metadata files for the metadata table
#) the primary use case for this utility is to find abandoned files
#) the list of files must fit in RAM, which probably requires changing jvm options on large systems
#) the quality and stability of accumulo has improved to the point where having these sorts of crazy fix-it utilities is more trouble than they are worth
#) as noted in ACCUMULO-2077, it does not work on multi-volume systems

It would be nice to look for abandoned files, and it might even be worth doing in the GC on a continuous basis. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-27 18:16:21.64,,,no_permission,,,,,,,,,,,,374484,,,Thu Dec 18 20:56:03 UTC 2014,,,,,,0|i1sj7z:,374784,,,,,,,,"27/Feb/14 18:16;kturner;For the case of finding and listing unused files, delete entries in the metadata table should be considered.  The current utility does not do this.  For the case of adding unreferenced files back, there may be cases where you would want to ignore delete entries.","27/Mar/14 19:47;elserj;From Eric Newton, ""I think that AddFilesWithMissingEntries should be removed, without a deprecation cycle.""

Taking that with what Keith said, I would be in favor of removing the utility in its current state and creating a new utiliity that does just what Keith described. ","28/Mar/14 17:54;ctubbsii;I'm not necessarily advocating for keeping this around, but I will say that it recently made a colleague happy (on 1.4) to have this utility around to help recover from an HDFS corruption, so it has at least some utility. However, I agree that it's a bit dangerous in its current state, especially that it does not prompt or inform the user as it goes.",18/Dec/14 20:56;ctubbsii;Deleted the problematic file.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE on deep copied dumped memory iterator,ACCUMULO-1628,12660939,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,kturner,kturner,31/Jul/13 17:00,19/Nov/14 17:13,13/Mar/19 22:01,19/Nov/14 17:06,1.4.0,1.5.0,,,,,,1.5.2,1.6.1,1.7.0,,,,,,,0,,,,,"Accumulo may dump memory while a scan is running and transparently switch iterators from memory to file.  If an iterator calls deepcopy after this happens, then seek will fail on the deep copy.

{noformat}

java.lang.NullPointerException
	at org.apache.accumulo.server.tabletserver.InMemoryMap$MemoryDataSource.iterator(InMemoryMap.java:349)
	at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.seek(SourceSwitchingIterator.java:163)
{noformat}",,"Commit 30a0ca3e81e5e27f870f8d5fad40f589a959feff in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=30a0ca3 ]

ACCUMULO-1628 made InMemoryMap iterator deepCopy work after delete
;25/Aug/14 16:09;jira-bot;600","Commit 30a0ca3e81e5e27f870f8d5fad40f589a959feff in accumulo's branch refs/heads/1.6.1-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=30a0ca3 ]

ACCUMULO-1628 made InMemoryMap iterator deepCopy work after delete
;25/Aug/14 16:10;jira-bot;600","Commit 30a0ca3e81e5e27f870f8d5fad40f589a959feff in accumulo's branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=30a0ca3 ]

ACCUMULO-1628 made InMemoryMap iterator deepCopy work after delete
;25/Aug/14 16:10;jira-bot;600","Commit 7699e1f43c4ee51bfa4be1e9e73ea722f934a3d6 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7699e1f ]

ACCUMULO-1628 Fixes issue after previous changes which interrupted a deep-copy

Pushes the interrupt flag from the SourceSwitchingIterator down to the
FileManager and InMemoryMap. This should avoid passing the interrupt
into a deep copy which isn't supported. Adds some more tests which
previously caused the edge case which is now fixed.

Signed-off-by: Josh Elser <elserj@apache.org>
;12/Sep/14 07:46;jira-bot;600","Commit 7699e1f43c4ee51bfa4be1e9e73ea722f934a3d6 in accumulo's branch refs/heads/1.6.1-SNAPSHOT from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7699e1f ]

ACCUMULO-1628 Fixes issue after previous changes which interrupted a deep-copy

Pushes the interrupt flag from the SourceSwitchingIterator down to the
FileManager and InMemoryMap. This should avoid passing the interrupt
into a deep copy which isn't supported. Adds some more tests which
previously caused the edge case which is now fixed.

Signed-off-by: Josh Elser <elserj@apache.org>
;12/Sep/14 07:46;jira-bot;600","Commit 7699e1f43c4ee51bfa4be1e9e73ea722f934a3d6 in accumulo's branch refs/heads/master from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7699e1f ]

ACCUMULO-1628 Fixes issue after previous changes which interrupted a deep-copy

Pushes the interrupt flag from the SourceSwitchingIterator down to the
FileManager and InMemoryMap. This should avoid passing the interrupt
into a deep copy which isn't supported. Adds some more tests which
previously caused the edge case which is now fixed.

Signed-off-by: Josh Elser <elserj@apache.org>
;12/Sep/14 07:46;jira-bot;600",,,,,,,,,,,,,,,,,,0,3600,,,0,3600,,,,,,,,,,,,,,,,,,,,,,15/Aug/14 16:08;kturner;ACCUMULO-1628-1.5.2-SNAPSHOT-1.patch;https://issues.apache.org/jira/secure/attachment/12662090/ACCUMULO-1628-1.5.2-SNAPSHOT-1.patch,25/Aug/14 16:16;kturner;ACCUMULO-1628-1.5.2-SNAPSHOT-2.patch;https://issues.apache.org/jira/secure/attachment/12664161/ACCUMULO-1628-1.5.2-SNAPSHOT-2.patch,09/Sep/14 16:17;kturner;ACCUMULO-1628-1.5.2-SNAPSHOT-3.patch;https://issues.apache.org/jira/secure/attachment/12667437/ACCUMULO-1628-1.5.2-SNAPSHOT-3.patch,14/Aug/14 19:07;kturner;ACCUMULO-1628-1.patch;https://issues.apache.org/jira/secure/attachment/12661768/ACCUMULO-1628-1.patch,29/Aug/14 21:46;kturner;ACCUMULO-1628-SET_INTR.patch;https://issues.apache.org/jira/secure/attachment/12665435/ACCUMULO-1628-SET_INTR.patch,11/Feb/14 16:49;benpopp;bpopp-ACCUMULO-1628.log;https://issues.apache.org/jira/secure/attachment/12628254/bpopp-ACCUMULO-1628.log,,,,,,,6.0,,,,,,,,,,,,,,,,,,,2014-01-08 00:41:51.098,,,no_permission,,,,,,,,,,,,341128,,,Wed Nov 19 17:06:02 UTC 2014,,,,,,0|i1mu1r:,341446,,,,,,,,"08/Jan/14 00:41;mdrob;[~kturner] - is this a 1.6.0 change, or something that gets pushed to 1.6.1 & 1.7.0?","11/Feb/14 16:40;benpopp;I saw a similar issue today and [~cmccubbin] & [~jvines@gmail.com] pointed me at this issue. I was running concurrent reads & writes on a single node dev environment with accumulo 1.5.0.  i was using the java IMM, not native. 

full log attached as bpopp-ACCUMULO-1628.log... excerpt below: 

{noformat}
2014-02-11 11:20:26,947 [tabletserver.TabletServer] WARN : exception while doing multi-scan 
java.lang.NullPointerException
	at org.apache.accumulo.server.tabletserver.InMemoryMap$MemoryDataSource.iterator(InMemoryMap.java:427)
	at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.seek(SourceSwitchingIterator.java:163)
	at org.apache.accumulo.core.iterators.WrappingIterator.seek(WrappingIterator.java:101)
	at org.apache.accumulo.core.iterators.SkippingIterator.seek(SkippingIterator.java:37)
{noformat} 

",11/Feb/14 21:40;elserj;What's the plan for this -- I'm planning to cut another RC tmrw for 1.5.1. Is this something that's going to tried to be squeezed into 1.5.1? Is 1.5.2 acceptable?,"12/Feb/14 17:32;ecn;It's not a blocker, I wouldn't wait on it.","11/Aug/14 16:17;vines;FYI, this still occurs and it presents as itself as an NPE coming up through continueMultiScan.

Maybe this can be handled by changing the switched flag ot a shared object so taht way all clones know when it flips?
","12/Aug/14 15:18;vines;Actually, the common case for this coming up is SourceSwitchingIterator.seek(), which calls InMemorymap.iterator as long as it doesn't already have an iterator.

It then goes on and calls readNext(true), and the first thing it does there is {code}(!onlySwitchAfterRow && switchSource()) || initialSeek{code}

if onlySwitchAfterRow is false, then switchSource() is guaranteed to be called, which I believe will handle this issue. maybe if we force switchSource() to be called when initialSeek is true and work around the InMemoryMap.iterator call in seek() we can avoid this issue entirely. Or maybe just incorporate a switchSource() call into seek.",12/Aug/14 16:22;elserj;[~vines] do you have an updated stack trace you can provide? It looks like the original one has shifted a little.,"12/Aug/14 16:35;vines;Bottom of it {code}Caused by: java.lang.NullPointerException
at org.apache.accumulo.tserver.InMemoryMap$MemoryDataSource.iterator(InMemoryMap.java:547)
at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.seek(SourceSwitchingIterator.java:163)
at org.apache.accumulo.core.iterators.WrappingIterator.seek(WrappingIterator.java:101)
at org.apache.accumulo.core.iterators.SkippingIterator.seek(SkippingIterator.java:37)
at org.apache.accumulo.core.iterators.WrappingIterator.seek(WrappingIterator.java:101)
at org.apache.accumulo.core.iterators.system.MultiIterator.seek(MultiIterator.java:105)
at org.apache.accumulo.core.iterators.WrappingIterator.seek(WrappingIterator.java:101)
at org.apache.accumulo.core.iterators.system.StatsIterator.seek(StatsIterator.java:64)
at org.apache.accumulo.core.iterators.WrappingIterator.seek(WrappingIterator.java:101)
at org.apache.accumulo.core.iterators.system.DeletingIterator.seek(DeletingIterator.java:67)
at org.apache.accumulo.core.iterators.WrappingIterator.seek(WrappingIterator.java:101)
at org.apache.accumulo.core.iterators.SkippingIterator.seek(SkippingIterator.java:37)
at org.apache.accumulo.core.iterators.system.ColumnFamilySkippingIterator.seek(ColumnFamilySkippingIterator.java:123)
at org.apache.accumulo.core.iterators.WrappingIterator.seek(WrappingIterator.java:101)
at org.apache.accumulo.core.iterators.Filter.seek(Filter.java:64)
at org.apache.accumulo.core.iterators.WrappingIterator.seek(WrappingIterator.java:101)
at org.apache.accumulo.core.iterators.Filter.seek(Filter.java:64)
at org.apache.accumulo.core.iterators.system.SynchronizedIterator.seek(SynchronizedIterator.java:55){code}",14/Aug/14 19:07;kturner;[~vines] would you be able to take this patch for a test drive?,15/Aug/14 18:03;vines;I'm trying to put together a test bench to recreate it similar to the cases we saw in the wild,25/Aug/14 16:16;kturner;uploaded final patch that was posted to RB ,"28/Aug/14 16:06;vines;{code}java.lang.RuntimeException: Calling setInterruptFlag on a deep copy is not supported
at org.apache.accumulo.core.file.rfile.RFile$Reader.setInterruptFlag(RFile.java:1007)
at org.apache.accumulo.tserver.MemKeyConversionIterator.setInterruptFlag(InMemoryMap.java:182)
at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.switchSource(SourceSwitchingIterator.java:148)
at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.readNext(SourceSwitchingIterator.java:112)
at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.seek(SourceSwitchingIterator.java:168)
at org.apache.accumulo.core.iterators.WrappingIterator.seek(WrappingIterator.java:101)
at or
g.apache.accumulo.core.iterators.SkippingIterator.seek(SkippingIterator.java:37)
{code}

[~parkjsung] has been seeing this issue in a 1.6.0 with this patch backported. I have a strong feeling it's due to this patch",28/Aug/14 17:42;kturner;[~vines] I'll take a look,29/Aug/14 21:46;kturner;[~vines]  I was able to reproduce the bug you are seeing in a unit test.  I attached {{ACCUMULO-1628-SET_INTR.patch}} with the changes to the unit test.  This definitely related to the changes I made.   I am going to look into fixing it.,"09/Sep/14 16:17;kturner;Another attempt   ACCUMULO-1628-1.5.2-SNAPSHOT-3.patch is relative to ACCUMULO-1628-1.5.2-SNAPSHOT-2.patch.  I am going to merge this patch forward locally and try running the ITs in 1.6.

[~vines] if you have a chance to kick the tires on this patch, it would be appreciated.","11/Sep/14 00:12;elserj;I took at look at the patch and ran some tests with it. I'm content with it.

[~kturner], did your ITs finish? Can we commit this and move forward?",12/Sep/14 07:47;elserj;Keith told me that he did run all ITs in 1.6 with the changes. I ran them myself as well.,"18/Nov/14 20:34;vines;I think this has recurred in 1.6.0 in a different with the patch you included.

{code}2014-11-14 22:08:12,745 [tserver.InMemoryMap] ERROR: Failed to create mem dump file
java.io.EOFException
        at java.io.DataInputStream.readByte(DataInputStream.java:267)
        at org.apache.accumulo.core.file.rfile.RelativeKey.fastSkip(RelativeKey.java:314)
        at org.apache.accumulo.core.file.rfile.RFile$LocalityGroupReader._seek(RFile.java:748)
        at org.apache.accumulo.core.file.rfile.RFile$LocalityGroupReader.seek(RFile.java:607)
        at org.apache.accumulo.core.iterators.system.LocalityGroupIterator.seek(LocalityGroupIterator.java:142)
        at org.apache.accumulo.core.file.rfile.RFile$Reader.seek(RFile.java:979)
        at org.apache.accumulo.core.iterators.WrappingIterator.seek(WrappingIterator.java:101)
        at org.apache.accumulo.tserver.MemKeyConversionIterator.seek(InMemoryMap.java:168)
        at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator._switchNow(SourceSwitchingIterator.java:171)
        at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.switchNow(SourceSwitchingIterator.java:179)
        at org.apache.accumulo.tserver.InMemoryMap$MemoryIterator.switchNow(InMemoryMap.java:647)
        at org.apache.accumulo.tserver.InMemoryMap$MemoryIterator.access$900(InMemoryMap.java:601)
        at org.apache.accumulo.tserver.InMemoryMap.delete(InMemoryMap.java:746)
        at org.apache.accumulo.tserver.Tablet$TabletMemory.finalizeMinC(Tablet.java:327)
        at org.apache.accumulo.tserver.Tablet.minorCompact(Tablet.java:2068)
        at org.apache.accumulo.tserver.Tablet.access$4300(Tablet.java:170)
        at org.apache.accumulo.tserver.Tablet$MinorCompactionTask.run(Tablet.java:2134)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:744){code}

We have an installation that is large enough with high ingest and query that is triggering it regularly. I'm currently working on acquiring the datanode logs on the other end, but the footprint and conditions for this are near identical to the original cases we were seeing the old stack traces occur in.","18/Nov/14 23:51;vines;Additonal info: no related errors as far as I can tell in the dfs datanode logs.

The error message is not correct. It says it failed to create the mem dump file, but the exception occurs after it has been created. The exception occurs in the MemoryIterator.switchNow() call for one, where it goes through each MI and switches them. Under the hood, this causes them to seek in the mem dump file.

Initial thought was when it fails it just prevents the IMM from clearing out. However, we then see exceptions afterward coming out of the full iterator stack. I have yet to determine if it's in the iterator that attempted to switch, iterators which already had switched, or the iterators which had not switched.","19/Nov/14 04:16;ecn;I'm having some difficulty parsing that comment, and I feel it might be very important.  Can you edit, or rephrase?  Thanks!","19/Nov/14 15:41;vines;Edited, hopefully for clarity","19/Nov/14 16:09;vines;After looking at the code more deeply, I think the only one left erroring is the one that failed to switch. One way to defend is to get it seeked before updating teh SSI's source and iter fields.","19/Nov/14 17:05;elserj;[~vines] since this issue did get released in 1.5.2 and 1.6.1, can we open up a new issue to track things and link it to this one? I don't want the fact that a change did make it into those released version get lost because it happened to be a partial fix.",19/Nov/14 17:06;vines;Sure,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
!METADATA table merge hangs,ACCUMULO-1264,12642070,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,ecn,ecn,11/Apr/13 17:02,31/Jul/14 16:34,13/Mar/19 22:01,19/Apr/13 15:57,,,,,,,,1.5.0,,,master,,,,,,0,15_qa_bug,,,,"Created many splits in the !METADATA table, and tried to merge a few of them: the merge never completed.",,"Commit 53fcb5262acaac244ef38a1e20c60c2750fef07c in accumulo's branch refs/heads/1.6.1-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=53fcb52 ]

ACCUMULO-1264 move !METADATA file delete markers

Description: Move the !METADATA file delete markers out of the
  !METADATA table and to the root table on upgrade.
Author: Eric Newton
Ref: ACCUMULO-2988

Modified from commit 5416eef
;31/Jul/14 16:34;jira-bot;600","Commit 53fcb5262acaac244ef38a1e20c60c2750fef07c in accumulo's branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=53fcb52 ]

ACCUMULO-1264 move !METADATA file delete markers

Description: Move the !METADATA file delete markers out of the
  !METADATA table and to the root table on upgrade.
Author: Eric Newton
Ref: ACCUMULO-2988

Modified from commit 5416eef
;31/Jul/14 16:34;jira-bot;600",,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,ACCUMULO-1143,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-11 21:04:06.468,,,no_permission,,,,,,,,,,,,322484,,,Fri Apr 19 12:17:13 UTC 2013,,,,,,0|i1jn1r:,322829,,,,,,,,"11/Apr/13 20:12;ecn;If the delete section of the !METADATA table goes offline, earlier sections cannot be chopped.

Ugh.
","11/Apr/13 21:04;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #184 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/184/])
    ACCUMULO-1264 tweak the scan range when looking for !METADATA tablet consistency check; add !METADATA table merge/split to the randomwalk test (Revision 1467012)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/state/MergeStats.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/AddSplits.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Merge.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MetaSplitTest.java
","11/Apr/13 21:08;hudson;Integrated in Accumulo-1.5 #73 (See [https://builds.apache.org/job/Accumulo-1.5/73/])
    ACCUMULO-1264 tweak the scan range when looking for !METADATA tablet consistency check; add !METADATA table merge/split to the randomwalk test (Revision 1467010)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/state/MergeStats.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/AddSplits.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Merge.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/MetaSplitTest.java
","11/Apr/13 21:12;hudson;Integrated in Accumulo-Trunk #826 (See [https://builds.apache.org/job/Accumulo-Trunk/826/])
    ACCUMULO-1264 tweak the scan range when looking for !METADATA tablet consistency check; add !METADATA table merge/split to the randomwalk test (Revision 1467012)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/state/MergeStats.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/AddSplits.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Merge.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MetaSplitTest.java
","12/Apr/13 16:43;ecn;On a new instance, this hangs indefinitely:

{noformat}
shell> merge -t !METADATA -b 012345 -e 02468
{noformat}

","12/Apr/13 17:01;hudson;Integrated in Accumulo-1.5 #75 (See [https://builds.apache.org/job/Accumulo-1.5/75/])
    ACCUMULO-1264 fix edge case when looking at the root tablet (Revision 1467350)
ACCUMULO-1264 put delete markers for the METADATA table into the root tablet (Revision 1467312)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/state/MergeStats.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/MetaSplitTest.java

ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/Constants.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilterTest.java
","12/Apr/13 17:02;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #186 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/186/])
    ACCUMULO-1264 fix edge case when looking at the root tablet (Revision 1467351)
ACCUMULO-1264 put delete markers for the METADATA table into the root tablet (Revision 1467331)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/state/MergeStats.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MetaSplitTest.java

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/Constants.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilterTest.java
* /accumulo/trunk/src
","12/Apr/13 17:06;hudson;Integrated in Accumulo-Trunk #828 (See [https://builds.apache.org/job/Accumulo-Trunk/828/])
    ACCUMULO-1264 fix edge case when looking at the root tablet (Revision 1467351)
ACCUMULO-1264 put delete markers for the METADATA table into the root tablet (Revision 1467331)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/state/MergeStats.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MetaSplitTest.java

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/Constants.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilterTest.java
* /accumulo/trunk/src
","12/Apr/13 17:10;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #74 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/74/])
    ACCUMULO-1264 fix edge case when looking at the root tablet (Revision 1467350)
ACCUMULO-1264 put delete markers for the METADATA table into the root tablet (Revision 1467312)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/state/MergeStats.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/MetaSplitTest.java

ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/Constants.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilterTest.java
","12/Apr/13 20:00;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #187 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/187/])
    ACCUMULO-1264 need a separate batchwriter for the root tablet (Revision 1467385)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/src
","12/Apr/13 20:12;hudson;Integrated in Accumulo-Trunk #829 (See [https://builds.apache.org/job/Accumulo-Trunk/829/])
    ACCUMULO-1264 need a separate batchwriter for the root tablet (Revision 1467385)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/src
","12/Apr/13 20:23;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #75 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/75/])
    ACCUMULO-1264 need a separate batchwriter for the root tablet (Revision 1467383)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
","12/Apr/13 20:34;hudson;Integrated in Accumulo-1.5 #76 (See [https://builds.apache.org/job/Accumulo-1.5/76/])
    ACCUMULO-1264 need a separate batchwriter for the root tablet (Revision 1467383)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
","15/Apr/13 21:27;kturner;[~ecn] is there an upgrade issue with these changes? I took a quick look at the changes, and I do not think there is an issue.  In !METADATA table from 1.4, metadata table deletes will be in old range. But that does not matter since the code that removes candidates still scans the entire metadata table tablet range?","15/Apr/13 22:33;kturner;Thinking about upgrade a bit more, will the metadata delete entries from 1.4 be deleted?","17/Apr/13 00:30;hudson;Integrated in Accumulo-Trunk #833 (See [https://builds.apache.org/job/Accumulo-Trunk/833/])
    ACCUMULO-1264 add a little upgrade to move !METDATA file deletion markers to the root tablet (Revision 1468577)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/trunk/src
",19/Apr/13 12:17;ecn;See ACCUMULO-1293,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support upgrading from 1.4 to 1.5,ACCUMULO-1010,12630010,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,ctubbsii,ctubbsii,30/Jan/13 22:07,31/Jul/14 16:34,13/Mar/19 22:01,25/Mar/13 22:27,,,,,,,,1.5.0,,,,,,,,,0,,,,,"Need to review changes made to structure of data in zookeeper in metadata table to identify any upgrade issues.  Need to test upgrade.
",,"Commit 3beaa5a2bab83e4ff2e189db03b038c32e78a85c in accumulo's branch refs/heads/1.6.1-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3beaa5a ]

ACCUMULO-1010 Support upgrades from 1.4 to 1.5

Description: Add steps necessary to move a zk from 1.4 state to 1.5.
  This leaves it in a good state to be picked up by the rest of the
  1.6 upgrade path.
Author: kturner
Ref: ACCUMULO-2988

Cherry picking caused a huge mess and it was simpler to manually select
the parts of the upgrade code that we needed based on the 1.5.1 tag.

Gathered from commits 317c669, aa6b4309, and 8811859.
;31/Jul/14 16:33;jira-bot;600","Commit 3beaa5a2bab83e4ff2e189db03b038c32e78a85c in accumulo's branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3beaa5a ]

ACCUMULO-1010 Support upgrades from 1.4 to 1.5

Description: Add steps necessary to move a zk from 1.4 state to 1.5.
  This leaves it in a good state to be picked up by the rest of the
  1.6 upgrade path.
Author: kturner
Ref: ACCUMULO-2988

Cherry picking caused a huge mess and it was simpler to manually select
the parts of the upgrade code that we needed based on the 1.5.1 tag.

Gathered from commits 317c669, aa6b4309, and 8811859.
;31/Jul/14 16:34;jira-bot;600",,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-30 22:20:19.669,,,no_permission,,,,,,,,,,,,310506,,,Wed May 08 22:56:45 UTC 2013,,,,,,0|i1hl5b:,310851,,,,,,,,"30/Jan/13 22:20;vines;I don't think inter-trunk compatibility needs to be a concern, only 1.4.x -> 1.5.0 compatibility.","03/Feb/13 21:21;ctubbsii;I agree. The inter-trunk upgrade was what motivated me to make this ticket, but the ticket's focus should be on ensuring the upgrade from 1.4.x goes smoothly.",09/Feb/13 02:03;kturner;Made the ticket more general,09/Feb/13 02:13;kturner;Starting 1.5 when 1.4 was not shutdown cleanly does not seem to be working.,"09/Feb/13 04:24;hudson;Integrated in Accumulo-Trunk #719 (See [https://builds.apache.org/job/Accumulo-Trunk/719/])
    ACCUMULO-635 ACCUMULO-1010 got basic upgrade and upgrade test script working... (Revision 1444313)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/Constants.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/test/system/upgrade_test.sh
","09/Feb/13 04:32;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #77 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/77/])
    ACCUMULO-635 ACCUMULO-1010 got basic upgrade and upgrade test script working... (Revision 1444313)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/Constants.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/test/system/upgrade_test.sh
","11/Feb/13 16:29;kturner;When attemting a dirty upgrade, i did not have the 1.4 walogs dir set for the 1.5 config.  After setting that I am seeing the following error when testing upgrade.   

{noformat}
2013-02-11 11:18:05,269 [tabletserver.TabletServer] WARN : exception trying to assign tablet !0;!0<< /root_tablet
java.lang.RuntimeException: java.io.IOException: java.lang.ArrayIndexOutOfBoundsException
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1452)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1299)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1141)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1129)
        at org.apache.accumulo.server.tabletserver.TabletServer$AssignmentHandler.run(TabletServer.java:2505)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at org.apache.accumulo.server.tabletserver.TabletServer$ThriftClientHandler$3.run(TabletServer.java:1864)
Caused by: java.io.IOException: java.lang.ArrayIndexOutOfBoundsException
        at org.apache.accumulo.server.tabletserver.log.TabletServerLogger.recover(TabletServerLogger.java:424)
        at org.apache.accumulo.server.tabletserver.TabletServer.recover(TabletServer.java:3391)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1420)
        ... 6 more
Caused by: java.lang.ArrayIndexOutOfBoundsException
        at org.apache.accumulo.core.data.Mutation$SimpleReader.readBytes(Mutation.java:158)
        at org.apache.accumulo.core.data.Mutation.newDeserializeColumnUpdate(Mutation.java:518)
        at org.apache.accumulo.core.data.Mutation.deserializeColumnUpdate(Mutation.java:473)
        at org.apache.accumulo.core.data.Mutation.getUpdates(Mutation.java:452)
        at org.apache.accumulo.server.tabletserver.Tablet$2.receive(Tablet.java:1423)
        at org.apache.accumulo.server.tabletserver.log.SortedLogRecovery.playbackMutations(SortedLogRecovery.java:235)
        at org.apache.accumulo.server.tabletserver.log.SortedLogRecovery.recover(SortedLogRecovery.java:128)
        at org.apache.accumulo.server.tabletserver.log.TabletServerLogger.recover(TabletServerLogger.java:422)
        ... 8 more
{noformat}

This can reproduced by running ""test/system/upgrade_test.sh dirty"".    I am going to look into this.  If anyone knows anything let me know.","11/Feb/13 23:25;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #83 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/83/])
    ACCUMULO-1010 fixed bug in mutation that was preventing upgrade of accumulo 1.4 to 1.5. (Revision 1444984)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/Mutation.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/data/MutationTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/data/ServerMutation.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/DfsLogger.java
","11/Feb/13 23:38;hudson;Integrated in Accumulo-Trunk #725 (See [https://builds.apache.org/job/Accumulo-Trunk/725/])
    ACCUMULO-1010 fixed bug in mutation that was preventing upgrade of accumulo 1.4 to 1.5. (Revision 1444984)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/Mutation.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/data/MutationTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/data/ServerMutation.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/DfsLogger.java
","25/Mar/13 23:43;hudson;Integrated in Accumulo-Trunk #800 (See [https://builds.apache.org/job/Accumulo-Trunk/800/])
    ACCUMULO-1010 removed logger zookeeper entries during upgrade (Revision 1460921)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
","25/Mar/13 23:47;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #51 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/51/])
    ACCUMULO-1010 removed logger zookeeper entries during upgrade (Revision 1460920)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
","25/Mar/13 23:48;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #159 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/159/])
    ACCUMULO-1010 removed logger zookeeper entries during upgrade (Revision 1460921)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
","08/May/13 22:31;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #104 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/104/])
    ACCUMULO-1010 ACCUMULO-1380 update upgrade section and API section in README (Revision 1480408)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/README
","08/May/13 22:34;hudson;Integrated in Accumulo-1.5 #102 (See [https://builds.apache.org/job/Accumulo-1.5/102/])
    ACCUMULO-1010 ACCUMULO-1380 update upgrade section and API section in README (Revision 1480408)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/README
","08/May/13 22:52;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #214 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/214/])
    ACCUMULO-1010 ACCUMULO-1380 update upgrade section and API section in README (Revision 1480414)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","08/May/13 22:56;hudson;Integrated in Accumulo-Trunk #856 (See [https://builds.apache.org/job/Accumulo-Trunk/856/])
    ACCUMULO-1010 ACCUMULO-1380 update upgrade section and API section in README (Revision 1480414)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need a way to configure TNonblockingServer.maxReadBufferBytes to prevent OOMs from network misbehavour,ACCUMULO-2360,12694811,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,vines,vines,vines,12/Feb/14 19:00,12/Jun/14 18:18,13/Mar/19 22:01,12/Feb/14 19:26,1.5.0,,,,,,,1.5.1,1.6.0,,master,tserver,,,,,0,,,,,"1.5.0 introduced GENERAL_MAX_MESSAGE_SIZE (ACCUMULO-1141), a parameter to set the maximum frame size for the TFramedTransport. However, there is an underlying frame (I think this is a glossary conflict) read in TNonblockingServer that can still cause OOM errors if erroneously connected to (telnet, netcat, etc.), creating a stack trace as such

{code}2014-02-12 10:26:40,439 [util.TServerUtils$THsHaServer] ERROR: run() exiting due to uncaught error
java.lang.OutOfMemoryError: Java heap space
        at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)
        at java.nio.ByteBuffer.allocate(ByteBuffer.java:329)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.read(AbstractNonblockingServer.java:338)
        at org.apache.thrift.server.AbstractNonblockingServer$AbstractSelectThread.handleRead(AbstractNonblockingServer.java:202)
        at org.apache.thrift.server.TNonblockingServer$SelectAcceptThread.select(TNonblockingServer.java:198)
        at org.apache.thrift.server.TNonblockingServer$SelectAcceptThread.run(TNonblockingServer.java:154){code}

I believe if we set maxReadBufferBytes to the server arguments, it will filter appropriately. The only decision I'm not sure about is if we should recycle the max message property or have a separate one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2367,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-12 19:25:10.685,,,no_permission,,,,,,,,,,,,373319,,,Wed Feb 12 19:26:07 UTC 2014,,,,,,0|i1sc2f:,373620,,,,,,,,"12/Feb/14 19:21;vines;I think reusing the same property makes the most sense here, since I think this property was the original hope of that property. We can revisit that property if we decide it doesn't make sense as at the transport frame level (as opposed to server socket frame).","12/Feb/14 19:25;jira-bot;Commit 1b41177b04428971bceb68774624ad4271e541c1 in branch refs/heads/1.5.1-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1b41177 ]

ACCUMULO-2360 adding TNonblockingServer.maxReadBufferBytes setting
","12/Feb/14 19:25;jira-bot;Commit 1b41177b04428971bceb68774624ad4271e541c1 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1b41177 ]

ACCUMULO-2360 adding TNonblockingServer.maxReadBufferBytes setting
","12/Feb/14 19:26;jira-bot;Commit 1b41177b04428971bceb68774624ad4271e541c1 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1b41177 ]

ACCUMULO-2360 adding TNonblockingServer.maxReadBufferBytes setting
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Various system test pieces missing ACCUMULO_CONF_DIR,ACCUMULO-1925,12680917,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,busbey,busbey,busbey,24/Nov/13 07:53,29/Apr/14 16:45,13/Mar/19 22:01,25/Nov/13 15:35,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"It looks like 1.6.0-SNAPSHOT and master missed the fixes for ACCUMULO-1658 in the merge process.

unfortunately, this means e.g. the agitator for the continuous ingest test can't run.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,24/Nov/13 07:57;busbey;ACCUMULO-1925.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12615498/ACCUMULO-1925.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-11-25 15:34:50.542,,,no_permission,,,,,,,,,,,,360182,,,Mon Nov 25 18:37:15 UTC 2013,,,,,,0|i1q39r:,360481,,,,,,,,"24/Nov/13 07:57;busbey;Attaching a patch that uses cherry-pick to essentially redo the merge of ACCUMULO-1658 from 1.5.1-SNAPSHOT to 1.6.0-SNAPSHOT.

It should apply cleanly to 1.6.0-SNAPSHOT and merge forward to master.","25/Nov/13 15:34;jira-bot;Commit 919691010835462f1dff42ee097a2f6cddf4e76b in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9196910 ]

ACCUMULO-1925 ensure system tests respect ACCUMULO_CONF_DIR.

(cherry-picked from commit 422aaaa7c35de07c280d496e489fbab541edeea3)

Reason: Tests
Author: Ryan Fishel <ryan.fishel@cloudera.com>
Author: John Vines <jvines@gmail.com>

Conflicts:
	test/system/auto/TestUtils.py
	test/system/continuous/start-stats.sh

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","25/Nov/13 18:37;jira-bot;Commit 919691010835462f1dff42ee097a2f6cddf4e76b in branch refs/heads/1.6.0-SNAPSHOT from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9196910 ]

ACCUMULO-1925 ensure system tests respect ACCUMULO_CONF_DIR.

(cherry-picked from commit 422aaaa7c35de07c280d496e489fbab541edeea3)

Reason: Tests
Author: Ryan Fishel <ryan.fishel@cloudera.com>
Author: John Vines <jvines@gmail.com>

Conflicts:
	test/system/auto/TestUtils.py
	test/system/continuous/start-stats.sh

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"In Test module, org.apache.accumulo.test.functional.FunctionalTestUtils is missing license header.",ACCUMULO-1538,12655514,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,medined,medined,medined,30/Jun/13 17:12,28/Apr/14 19:35,13/Mar/19 22:01,30/Jun/13 17:44,,,,,,,,1.6.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-30 17:43:55.521,,,no_permission,,,,,,,,,,,,335789,,,Sun Jun 30 17:44:48 UTC 2013,,,,,,0|i1lx6f:,336113,,,,,,,,"30/Jun/13 17:43;jira-bot;Commit 1498163 from [~medined]
[ https://svn.apache.org/r1498163 ]

ACCUMULO-1538 - add missing license header",30/Jun/13 17:44;medined;SVN#1498163. Added license header to file.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Encrypted WALogs seem to be excessively buffering,ACCUMULO-1998,12683859,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,vines,supermallen,supermallen,10/Dec/13 15:52,14/Apr/14 21:17,13/Mar/19 22:01,16/Jan/14 22:45,,,,,,,,1.6.0,,,,,,,,,0,,,,,"The reproduction steps around this are a little bit fuzzy but basically we ran a moderate workload against a 1.6.0 server.  Encryption happened to be turned on but that doesn't seem to be germane to the problem.  After doing a moderate amount of work, Accumulo is refusing to start up, spewing this error over and over to the log:

{noformat}
2013-12-10 10:23:02,529 [tserver.TabletServer] WARN : exception while doing multi-scan 
java.lang.RuntimeException: java.io.IOException: Failed to open hdfs://10.10.1.115:9000/accumulo/tables/!0/table_info/A000042x.rf
	at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler$LookupTask.run(TabletServer.java:1125)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.IOException: Failed to open hdfs://10.10.1.115:9000/accumulo/tables/!0/table_info/A000042x.rf
	at org.apache.accumulo.tserver.FileManager.reserveReaders(FileManager.java:333)
	at org.apache.accumulo.tserver.FileManager.access$500(FileManager.java:58)
	at org.apache.accumulo.tserver.FileManager$ScanFileManager.openFiles(FileManager.java:478)
	at org.apache.accumulo.tserver.FileManager$ScanFileManager.openFileRefs(FileManager.java:466)
	at org.apache.accumulo.tserver.FileManager$ScanFileManager.openFiles(FileManager.java:486)
	at org.apache.accumulo.tserver.Tablet$ScanDataSource.createIterator(Tablet.java:2027)
	at org.apache.accumulo.tserver.Tablet$ScanDataSource.iterator(Tablet.java:1989)
	at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.seek(SourceSwitchingIterator.java:163)
	at org.apache.accumulo.tserver.Tablet.lookup(Tablet.java:1565)
	at org.apache.accumulo.tserver.Tablet.lookup(Tablet.java:1672)
	at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler$LookupTask.run(TabletServer.java:1114)
	... 6 more
Caused by: java.io.FileNotFoundException: File does not exist: /accumulo/tables/!0/table_info/A000042x.rf
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.fetchLocatedBlocks(DFSClient.java:2006)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1975)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.<init>(DFSClient.java:1967)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:735)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:165)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:436)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getBCFile(CachableBlockFile.java:256)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.access$000(CachableBlockFile.java:143)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader$MetaBlockLoader.get(CachableBlockFile.java:212)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getBlock(CachableBlockFile.java:313)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getMetaBlock(CachableBlockFile.java:367)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getMetaBlock(CachableBlockFile.java:143)
	at org.apache.accumulo.core.file.rfile.RFile$Reader.<init>(RFile.java:825)
	at org.apache.accumulo.core.file.rfile.RFileOperations.openReader(RFileOperations.java:79)
	at org.apache.accumulo.core.file.DispatchingFileFactory.openReader(FileOperations.java:119)
	at org.apache.accumulo.tserver.FileManager.reserveReaders(FileManager.java:314)
	... 16 more
{noformat}

Here's some other pieces of context:

HDFS contents:

{noformat}
ubuntu@ip-10-10-1-115:/data0/logs/accumulo$ hadoop fs -lsr /accumulo/tables/
drwxr-xr-x   - accumulo hadoop          0 2013-12-10 00:32 /accumulo/tables/!0
drwxr-xr-x   - accumulo hadoop          0 2013-12-10 01:06 /accumulo/tables/!0/default_tablet
drwxr-xr-x   - accumulo hadoop          0 2013-12-10 10:49 /accumulo/tables/!0/table_info
-rw-r--r--   5 accumulo hadoop       1698 2013-12-10 00:34 /accumulo/tables/!0/table_info/F0000000.rf
-rw-r--r--   5 accumulo hadoop      43524 2013-12-10 01:53 /accumulo/tables/!0/table_info/F000062q.rf
drwxr-xr-x   - accumulo hadoop          0 2013-12-10 00:32 /accumulo/tables/+r
drwxr-xr-x   - accumulo hadoop          0 2013-12-10 10:45 /accumulo/tables/+r/root_tablet
-rw-r--r--   5 accumulo hadoop       2070 2013-12-10 10:45 /accumulo/tables/+r/root_tablet/A0000738.rf
drwxr-xr-x   - accumulo hadoop          0 2013-12-10 00:33 /accumulo/tables/1
drwxr-xr-x   - accumulo hadoop          0 2013-12-10 00:33 /accumulo/tables/1/default_tablet
{noformat}

ZooKeeper entries

{noformat}
[zk: localhost:2181(CONNECTED) 6] get /accumulo/371cfa3e-fe96-4a50-92e9-da7572589ffa/root_tablet/dir 
hdfs://10.10.1.115:9000/accumulo/tables/+r/root_tablet
cZxid = 0x1b
ctime = Tue Dec 10 00:32:56 EST 2013
mZxid = 0x1b
mtime = Tue Dec 10 00:32:56 EST 2013
pZxid = 0x1b
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 54
numChildren = 0
{noformat}

I'm going to preserve the state of this machine in HDFS for a while but not forever, so if there are other pieces of context people need, let me know.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1481,,,,,,,,,,,,,,31/Dec/13 22:53;vines;0001-ACCUMULO-1998-Working-around-the-cipher-s-buffer-by-.patch;https://issues.apache.org/jira/secure/attachment/12620993/0001-ACCUMULO-1998-Working-around-the-cipher-s-buffer-by-.patch,20/Dec/13 00:34;vines;0001-ACCUMULO-1998-forcing-Buffered-crypto-stream-to-flus.patch;https://issues.apache.org/jira/secure/attachment/12619708/0001-ACCUMULO-1998-forcing-Buffered-crypto-stream-to-flus.patch,03/Jan/14 20:06;vines;0001-ACCUMULO-1998.patch;https://issues.apache.org/jira/secure/attachment/12621377/0001-ACCUMULO-1998.patch,20/Dec/13 01:01;vines;0002-ACCUMULO-1998-forcing-Buffered-crypto-stream-to-flus.patch;https://issues.apache.org/jira/secure/attachment/12619719/0002-ACCUMULO-1998-forcing-Buffered-crypto-stream-to-flus.patch,03/Jan/14 22:37;vines;0002-ACCUMULO-1998.patch;https://issues.apache.org/jira/secure/attachment/12621394/0002-ACCUMULO-1998.patch,20/Dec/13 01:25;vines;0003-ACCUMULO-1998-forcing-Buffered-crypto-stream-to-flus.patch;https://issues.apache.org/jira/secure/attachment/12619724/0003-ACCUMULO-1998-forcing-Buffered-crypto-stream-to-flus.patch,20/Dec/13 01:55;vines;0004-ACCUMULO-1998-forcing-Buffered-crypto-stream-to-flus.patch;https://issues.apache.org/jira/secure/attachment/12619728/0004-ACCUMULO-1998-forcing-Buffered-crypto-stream-to-flus.patch,,,,,,7.0,,,,,,,,,,,,,,,,,,,2013-12-10 15:54:44.252,,,no_permission,,,,,,,,,,,,362931,,,Tue Jan 21 16:06:25 UTC 2014,,,,,,0|i1qk7b:,363237,,,,,,,,10/Dec/13 15:54;vines;It is concerning that both +r and !0 have files in them. What is going on here?!,10/Dec/13 23:12;vines;I totally spaced and mixed up the metadata table (!0) with the root table (+r)...,"11/Dec/13 15:55;supermallen;Here's more of a precise breakdown.  The exception looks like this now:

{noformat}
2013-12-11 15:46:30,871 [thrift.ProcessFunction] ERROR: Internal error processing startMultiScan
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.io.IOException: Failed to open hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf
	at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.continueMultiScan(TabletServer.java:1429)
	at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.startMultiScan(TabletServer.java:1381)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
	at com.sun.proxy.$Proxy10.startMultiScan(Unknown Source)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$startMultiScan.getResult(TabletClientService.java:2252)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$startMultiScan.getResult(TabletClientService.java:2236)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
	at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
	at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.io.IOException: Failed to open hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf
	at org.apache.accumulo.tserver.TabletServer$ScanTask.get(TabletServer.java:754)
	at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.continueMultiScan(TabletServer.java:1416)
	... 18 more
Caused by: java.lang.RuntimeException: java.io.IOException: Failed to open hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf
	at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler$LookupTask.run(TabletServer.java:1125)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	... 5 more
Caused by: java.io.IOException: Failed to open hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf
	at org.apache.accumulo.tserver.FileManager.reserveReaders(FileManager.java:333)
	at org.apache.accumulo.tserver.FileManager.access$500(FileManager.java:58)
	at org.apache.accumulo.tserver.FileManager$ScanFileManager.openFiles(FileManager.java:478)
	at org.apache.accumulo.tserver.FileManager$ScanFileManager.openFileRefs(FileManager.java:466)
	at org.apache.accumulo.tserver.FileManager$ScanFileManager.openFiles(FileManager.java:486)
	at org.apache.accumulo.tserver.Tablet$ScanDataSource.createIterator(Tablet.java:2027)
	at org.apache.accumulo.tserver.Tablet$ScanDataSource.iterator(Tablet.java:1989)
	at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.seek(SourceSwitchingIterator.java:163)
	at org.apache.accumulo.tserver.Tablet.lookup(Tablet.java:1565)
	at org.apache.accumulo.tserver.Tablet.lookup(Tablet.java:1672)
	at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler$LookupTask.run(TabletServer.java:1114)
	... 6 more
Caused by: java.io.FileNotFoundException: File does not exist: /accumulo/tables/!0/table_info/A00002gy.rf
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.fetchLocatedBlocks(DFSClient.java:2006)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1975)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.<init>(DFSClient.java:1967)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:735)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:165)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:436)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getBCFile(CachableBlockFile.java:256)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.access$000(CachableBlockFile.java:143)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader$MetaBlockLoader.get(CachableBlockFile.java:212)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getBlock(CachableBlockFile.java:313)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getMetaBlock(CachableBlockFile.java:367)
	at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getMetaBlock(CachableBlockFile.java:143)
	at org.apache.accumulo.core.file.rfile.RFile$Reader.<init>(RFile.java:825)
	at org.apache.accumulo.core.file.rfile.RFileOperations.openReader(RFileOperations.java:79)
	at org.apache.accumulo.core.file.DispatchingFileFactory.openReader(FileOperations.java:119)
	at org.apache.accumulo.tserver.FileManager.reserveReaders(FileManager.java:314)
	... 16 more
{noformat}

Scanning the root tablet shows the following entries:

{noformat}
root@accumulo accumulo.root> scan
!0;~ file:hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf []    8652,1763
!0;~ file:hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/F000063o.rf []    66848,35747
!0;~ last:142e00c604d0053 []    10.10.1.155:9997
!0;~ loc:142e00c604d0063 []    10.10.1.155:9997
!0;~ srv:compact []    7
!0;~ srv:dir []    hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info
!0;~ srv:flush []    122
!0;~ srv:lock []    tservers/10.10.1.155:9997/zlock-0000000000$142e00c604d0063
!0;~ srv:time []    L39138
!0;~ ~tab:~pr []    \x00
!0< file:hdfs://10.10.1.155:9000/accumulo/tables/!0/default_tablet/A00002gx.rf []    1518,3
!0< last:142e00c604d000d []    10.10.1.155:9997
!0< loc:142e00c604d0063 []    10.10.1.155:9997
!0< srv:compact []    6
!0< srv:dir []    hdfs://10.10.1.155:9000/accumulo/tables/!0/default_tablet
!0< srv:flush []    122
!0< srv:lock []    tservers/10.10.1.155:9997/zlock-0000000000$142e00c604d0063
!0< srv:time []    L12
!0< ~tab:~pr []    \x01~
root@accumulo accumulo.root> 
{noformat}


So we looked for where this missing file (A00002gy.rf) got created.  Back up in the tserver logs is this:

{noformat}
2013-12-11 05:31:55,701 [tserver.Tablet] DEBUG: Starting MajC !0;~< (NORMAL) [hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/F00002gv.rf, hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00000fi.rf] --> hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf_tmp  []
2013-12-11 05:31:55,937 [tserver.TabletServer] DEBUG: ScanSess tid 10.10.1.155:58190 !0 0 entries in 0.10 secs, nbTimes = [98 98 98.00 1]
2013-12-11 05:31:56,208 [util.TServerUtils] INFO : Decreasing server thread pool size on TabletServer to 20
2013-12-11 05:31:56,246 [tserver.TabletServer] DEBUG: MultiScanSess 10.10.1.155:60638 2 entries in 0.01 secs (lookup_time:0.00 secs tablets:1 ranges:1)
2013-12-11 05:31:56,333 [tserver.Compactor] DEBUG: Compaction !0;~< 20,974 read | 1,763 written | 42,979 entries/sec |  0.488 secs
2013-12-11 05:31:56,345 [tserver.Tablet] DEBUG: MajC finish lock 0.00 secs
2013-12-11 05:31:56,345 [tserver.Tablet] TABLET_HIST: !0;~< MajC [hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/F00002gv.rf, hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00000fi.rf] --> hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf
{noformat}

Then it got major compacted away here:

{noformat}
2013-12-11 05:36:56,907 [tserver.Tablet] DEBUG: Major compaction plan: [hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf, hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/F00005yj.rf] propogate deletes : false
2013-12-11 05:36:56,907 [tserver.Tablet] DEBUG: MajC initiate lock 0.00 secs, wait 0.00 secs
2013-12-11 05:36:56,908 [tserver.Tablet] DEBUG: Starting MajC !0;~< (NORMAL) [hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf, hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/F00005yj.rf] --> hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00005ym.rf_tmp  []
2013-12-11 05:36:57,080 [tserver.Compactor] DEBUG: Compaction !0;~< 37,692 read | 0 written | 269,228 entries/sec |  0.140 secs
2013-12-11 05:36:57,085 [tserver.Tablet] DEBUG: MajC finish lock 0.00 secs
2013-12-11 05:36:57,085 [tserver.Tablet] TABLET_HIST: !0;~< MajC [hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf, hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/F00005yj.rf] --> hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00005ym.rf
{noformat}

The garbage collector decided to collect it:

{noformat}
2013-12-11 05:41:56,870 [gc.SimpleGarbageCollector] DEBUG: Deleting hdfs://10.10.1.155:9000/accumulo/tables/!0/default_tablet/A00002gx.rf
2013-12-11 05:41:56,870 [gc.SimpleGarbageCollector] DEBUG: Deleting hdfs://10.10.1.155:9000/accumulo/tables/!0/default_tablet/F00005yk.rf
2013-12-11 05:41:56,874 [gc.SimpleGarbageCollector] DEBUG: Deleting hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/F00005yj.rf
2013-12-11 05:41:56,883 [gc.SimpleGarbageCollector] DEBUG: Deleting hdfs://10.10.1.155:9000/accumulo/tables/!0/table_info/A00002gy.rf
2013-12-11 05:41:56,956 [gc.SimpleGarbageCollector] INFO : Number of data file candidates for deletion: 4
2013-12-11 05:41:56,956 [gc.SimpleGarbageCollector] INFO : Number of data file candidates still in use: 0
2013-12-11 05:41:56,956 [gc.SimpleGarbageCollector] INFO : Number of successfully deleted data files: 4
2013-12-11 05:41:56,956 [gc.SimpleGarbageCollector] INFO : Number of data files delete failures: 0
2013-12-11 05:41:56,957 [gc.SimpleGarbageCollector] INFO : Collect cycle took 0.29 seconds
{noformat}

So what happened with {{A00005ym.rf}}, which supposedly replaced {{A00002gy.rf}}?

The namenode seems to think it was created and closed.  But no other Hadoop log mentions it:

{noformat}
[root@ip-10-10-1-155 hadoop]# pwd
/data0/logs/hadoop

[root@ip-10-10-1-155 hadoop]# grep A00005ym.rf *
hadoop-hadoop-namenode-ip-10-10-1-155.log:2013-12-11 05:36:57,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /accumulo/tables/!0/table_info/A00005ym.rf_tmp. blk_-5468581853400342461_1318
hadoop-hadoop-namenode-ip-10-10-1-155.log:2013-12-11 05:36:57,068 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /accumulo/tables/!0/table_info/A00005ym.rf_tmp from client DFSClient_NONMAPREDUCE_-1463880682_12
hadoop-hadoop-namenode-ip-10-10-1-155.log:2013-12-11 05:36:57,068 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /accumulo/tables/!0/table_info/A00005ym.rf_tmp is closed by DFSClient_NONMAPREDUCE_-1463880682_12

[root@ip-10-10-1-155 hadoop]#
{noformat}

So somewhere between the major compaction finishing and the root tablet's information being updated, something went wrong.  There are no other obvious exceptions or errors in the logs.
","11/Dec/13 16:17;supermallen;Oh, another hint!  After reading over those log snippets, I noticed that the Hadoop logs only talk up {{A00005ym.rf_tmp}}, and not {{A00005ym.rf}}.  It looks like perhaps the renaming did not occur correctly?

Or, perhaps this is nothing.  Here's similar output for the file that did exist (at least for a time):

{noformat}
[root@ip-10-10-1-155 hadoop]# grep A00002gy.rf *
hadoop-hadoop-namenode-ip-10-10-1-155.log:2013-12-11 05:31:56,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /accumulo/tables/!0/table_info/A00002gy.rf_tmp. blk_-8014878588999673973_1314
hadoop-hadoop-namenode-ip-10-10-1-155.log:2013-12-11 05:31:56,246 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /accumulo/tables/!0/table_info/A00002gy.rf_tmp from client DFSClient_NONMAPREDUCE_-1463880682_12
hadoop-hadoop-namenode-ip-10-10-1-155.log:2013-12-11 05:31:56,246 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /accumulo/tables/!0/table_info/A00002gy.rf_tmp is closed by DFSClient_NONMAPREDUCE_-1463880682_12
[root@ip-10-10-1-155 hadoop]# 
{noformat}",12/Dec/13 19:18;kturner;[~supermallen] were you able to reproduce this yesterday?  How many tservers did you have? Were tservers restarted during this test?  Some other things useful to look would be when and where the root tablet was assigned.   Also could look in the root tablets walogs and try to find the mutations related to these files.   ,"12/Dec/13 19:25;supermallen;[~keith_turner] I reproduced, kind of. Unfortunately it's amazingly inconsistent. I have only one t-server running, and they are not restarted during the course of testing.  When I see it again I'll do some of the digging you suggest.

Also I just saw [ACCUMULO-2006|https://issues.apache.org/jira/browse/ACCUMULO-2006] come through, so I am wondering if it's related.","13/Dec/13 14:54;ecn;[~supermallen] they are probably not related, since this is failing *after* a tablet is assigned.  [ACCUMULO-2006|https://issues.apache.org/jira/browse/ACCUMULO-2006] fails to assign tablets, so no errors occur at the tserver.","19/Dec/13 22:17;vines;Encrypted WALOGs. Those are the issue. They seem buffer more than non-encrypted ones.

Steps to validate this issue-
Start with non-encrypted Accumulo. Run start-here.sh. Wait for metadata tablets to come online. Kill hard with stop-here.sh (hit control+c once). Then run bin/accumulo org.apache.accumulo.tserver.logger.LogReader /accumulo/wal/localhost+9997/<TheOnlyLogFileHere>. You will see tens of lines of output for root tablet writes, maybe metadata tablet writes as well.
Blow away non-encrypted accumulo and replace site.xml with a crypto enabled one. Run start-here.sh. Wait for metadata tablets to come online. Kill hard with stop-here.sh. Run the same command against the new walog file. Observe how empty it is.

The originally reported error manifests itself in this situation-
1. File gets written, leading to a metadata/root table update
2. File gets MajC away, leading to a meta/root table removal
3. File gets deleted by gc
4. Tserver hosting tablet goes down hard
5. walogs replay, but only event 1 is present, not event 2
6. tablet now thinks is now referencing it's old file","20/Dec/13 00:34;vines;So this solutions seems too simple. I'm worried about the repurcussions of flushing before syncing because the flush() will clear out the buffered crypto stream, but then it will keep flushing. Depending on the underlying filesystems, it may do nothing or it may keep flushing.",20/Dec/13 01:01;vines;This second patch wraps the output stream provided to the crypto stuff to make sure flush() calls never go into the FSDataOutputStream. This should mitigate concerns,20/Dec/13 01:25;vines;Third rendition. Buffer needs to be closed when the logFile is being closed as well.,20/Dec/13 01:55;vines;Fourth rendition - just need to close the encryptingLogFile and everything else will flow through.,20/Dec/13 18:11;vines;This still leaves the possibility of the cipher block being unwritten when the write returns to the client. I have another idea...,"31/Dec/13 22:53;vines;This patch is more comprehensive then the others, as it actually deals with the buffering in the cipher stream. The issue is that this buffer does not clear on flush(). So the solution I've incorporated is manually padding on flush(). This allows flush() semantics to make sure the entire stream is clear. Then, I had the DfsLogger explicitly flush after every write() to ensure the crypto stream is clear. I have another stream in there which catches this flush and doesn't propogate it to ensure functionality doesn't get weird. I'm gonna push this in a few days if I hear no objections.","31/Dec/13 23:03;elserj;So you pad the cipher stream to get it to flush to ensure that you don't lose data (or have old data reintroduced)? Have you noticed any sort of performance change in this? I assume the flush()'s in a real system are far enough between one another that it's not terrible? That, and if you don't have super small buffers?","31/Dec/13 23:25;vines;Yes.

This technique adds 4 bytes written per flush /when a 1k buffer fills. This
only occurs when using the default crypto module and should have no impact
on unencrypted performance, as it will just introduce a noop. However, for
the walogs, this will be called for every walog entry. I have not actually
done performance testing though as this was to provide correct behavior,
not adjust performance characteristics.

Sent from my phone, please pardon the typos and brevity.

","31/Dec/13 23:34;elserj;bq. should have no impact on unencrypted performance, as it will just introduce a noop

I figured as much.

bq. I have not actually done performance testing though as this was to provide correct behavior, not adjust performance characteristics.

Ok, I was mostly curious as to whether or not this affected things when using the default crypto module. Would be interested to hear when you get there :)","02/Jan/14 18:29;vines;This patch still isn't sufficient. testKeyEncryptionAndCheckThatFileCannotBeReadWithoutKEK will sometimes fail with an OOM exception when the encrypted bytes come to an outlandish size. Additionally, it breaks handling for partial writes.","03/Jan/14 20:06;vines;Revised version. We now expect a max block size. I also refactored the buffered input stream to not put everything in memory, rather it will keep maxBlocksize. Additionally, have a checkfor a partially written cipher block.","03/Jan/14 22:37;vines;One more go at it, simplified the blockinput stream to deal with a reading issue. I've been slamming Accumulo up and down and have yet to see any issues pop up again.","08/Jan/14 20:57;jira-bot;Commit 443cba7a7a3838b547880f1c49f2a9e0128692cd in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=443cba7 ]

ACCUMULO-1998

All encrypted walog events are now individual blocked on disk. This leads to an additional maxBlockSize parameter (mostly to handle OOM from mismatched crypto). Additionally, because of this behavior, as well as PKCS5 behavior, I have turned off all padding on the default crypto configs and padding should not be used as it can cause data loss in walogs. I have hammered 5 instances on and off every minute for 22 hours and counting with no related issues, so I deem it a fix.
","08/Jan/14 20:57;jira-bot;Commit 443cba7a7a3838b547880f1c49f2a9e0128692cd in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=443cba7 ]

ACCUMULO-1998

All encrypted walog events are now individual blocked on disk. This leads to an additional maxBlockSize parameter (mostly to handle OOM from mismatched crypto). Additionally, because of this behavior, as well as PKCS5 behavior, I have turned off all padding on the default crypto configs and padding should not be used as it can cause data loss in walogs. I have hammered 5 instances on and off every minute for 22 hours and counting with no related issues, so I deem it a fix.
",08/Jan/14 20:58;vines;read my commit for an explanation of how this was resolved.,16/Jan/14 00:02;vines;Seems there are some corner cases involving failed flushes that are causing buffer overflow excpetions in the blockwriter. Working on fixing these.,"16/Jan/14 22:44;jira-bot;Commit 9ba06ff2d515d982b47b4f121a14bb5a98a024f0 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9ba06ff ]

ACCUMULO-1998 Resolving corner cases around blocked output stream behavior and migration
","17/Jan/14 21:00;jira-bot;Commit cac60938f08a1ce40bbbc0e89c2d01ee8350fd1a in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cac6093 ]

ACCUMULO-1998 Defense against concurrent write() and close() by relying on DfsLogger output stream interaction
","20/Jan/14 17:31;jira-bot;Commit cac60938f08a1ce40bbbc0e89c2d01ee8350fd1a in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cac6093 ]

ACCUMULO-1998 Defense against concurrent write() and close() by relying on DfsLogger output stream interaction
","21/Jan/14 16:06;jira-bot;Commit 8cfdc1ffc4413f0712f7ecac1ba05f682e96d249 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8cfdc1f ]

ACCUMULO-1998 fix warning about an unclosed resource.","21/Jan/14 16:06;jira-bot;Commit 8cfdc1ffc4413f0712f7ecac1ba05f682e96d249 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8cfdc1f ]

ACCUMULO-1998 fix warning about an unclosed resource.",,,,,,,,,,,,,,,,,,,,,,,,,
Cannot run offline mapreduce over non-default instance.dfs.dir value,ACCUMULO-2234,12690092,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,elserj,elserj,elserj,21/Jan/14 19:30,26/Mar/14 17:13,13/Mar/19 22:01,24/Jan/14 02:17,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"The javadoc for setting up offline scans over RFiles (InputFormatBase.setScanOffline in 1.4 or InputFormatBase.setOfflineTableScan in 1.5) includes a nice little comment to the effect that if a ""non-standard"" directory is used for Accumulo in HDFS (read as, if the default value for instance.dfs.dir), accumulo-site.xml may need to be on the classpath for the mappers.

Best as I can tell, even if accumulo-site.xml is on the classpath, it makes no difference as InputFormatBase is creating a new ZooKeeperInstance which, in turn, will only ever make a DefaultConfiguration and never try to check if an accumulo-site.xml file is available. This would make it impossible for a non-default value for instance.dfs.dir to ever be used.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-22 22:10:10.419,,,no_permission,,,,,,,,,,,,369049,,,Wed Mar 26 17:13:47 UTC 2014,,,,,,0|i1rlxr:,369354,,,,,,,,"22/Jan/14 22:10;jira-bot;Commit 57f9b6cfd30b1b2505efbacd2a5ce391dbcd1e0c in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=57f9b6c ]

ACCUMULO-2234 Provide accumulo-site.xml to Mapper classpath and ensure is used by concrete Instance.
","22/Jan/14 22:10;jira-bot;Commit 57f9b6cfd30b1b2505efbacd2a5ce391dbcd1e0c in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=57f9b6c ]

ACCUMULO-2234 Provide accumulo-site.xml to Mapper classpath and ensure is used by concrete Instance.
","22/Jan/14 22:10;jira-bot;Commit 57f9b6cfd30b1b2505efbacd2a5ce391dbcd1e0c in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=57f9b6c ]

ACCUMULO-2234 Provide accumulo-site.xml to Mapper classpath and ensure is used by concrete Instance.
","22/Jan/14 22:10;jira-bot;Commit 57f9b6cfd30b1b2505efbacd2a5ce391dbcd1e0c in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=57f9b6c ]

ACCUMULO-2234 Provide accumulo-site.xml to Mapper classpath and ensure is used by concrete Instance.
","22/Jan/14 22:11;elserj;Always pull accumulo-site.xml out of ACCUMULO_CONF_DIR and provide it to the ContinuousVerify Tool. Use DistributedCache to ensure that it gets on the Mapper's classpath.

Tested against Apache Hadoop 1.2.1 and 2.2.0.","23/Jan/14 17:27;jira-bot;Commit 9cf94f93685faaccc927e148791d50570bfb2f30 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9cf94f9 ]

ACCUMULO-2234 Fix up formatting for madrob.
","23/Jan/14 18:05;jira-bot;Commit 9cf94f93685faaccc927e148791d50570bfb2f30 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9cf94f9 ]

ACCUMULO-2234 Fix up formatting for madrob.
","23/Jan/14 18:05;jira-bot;Commit 9cf94f93685faaccc927e148791d50570bfb2f30 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9cf94f9 ]

ACCUMULO-2234 Fix up formatting for madrob.
","23/Jan/14 18:05;jira-bot;Commit 9cf94f93685faaccc927e148791d50570bfb2f30 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9cf94f9 ]

ACCUMULO-2234 Fix up formatting for madrob.
","23/Jan/14 20:07;ctubbsii;Implementation should not add a dependency on server configuration files which cannot assumed to be known by the launching process. It should use conn.instanceOperations().getSiteConfiguration() to get the configuration via thrift, without additional classpath dependencies on server configuration files.

Also, is this really a blocker?","23/Jan/14 21:48;elserj;bq. Implementation should not add a dependency on server configuration files which cannot assumed to be known by the launching process. It should use conn.instanceOperations().getSiteConfiguration() to get the configuration via thrift, without additional classpath dependencies on server configuration files.

The *can* be assumed to be known by the launching process as ACCUMULO_CONF_DIR is expected to be set for other continuous ingest tests. Can instance.dfs.dir be pulled from a Connector/Instance without having it specified by the accumulo-site.xml? If so, I was unaware of this.

However, IMO, there is still no downside to this given that this is a system test and expectations on accumulo-site.xml already being present. This works as is -- I would be inclined that you should open a different ticket for this as these changes do successfully satisfy the lack of functionality in such a way that I do not see issue with.

bq. Also, is this really a blocker?

I could not run a required test for released as I should have been able to. So, yes this is a blocker to me. If we say you should be able to do something that affects a release, but it is impossible to do so, that's a blocker. If you don't agree, you have the ability to change the priority of this ticket.","23/Jan/14 22:26;kturner;It seems like using conn.instanceOperations().getSiteConfiguration() would make it much easier for the user to use offline map reduce.   It would just work.   I took a quick look at the OfflineScanner code, it seems like creating a AccumuloConfiguration object thats backed by the contents of conn.instanceOperations().getSiteConfiguration() would be an easy way to make this work.  ","23/Jan/14 22:29;elserj;Precisely. I just came to realization in IRC. Thanks for looking though, Keith.","24/Jan/14 02:15;jira-bot;Commit 66516a0f8900f228294cb8d818e350887937b079 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=66516a0 ]

Revert ""ACCUMULO-2234 Provide accumulo-site.xml to Mapper classpath and ensure is used by concrete Instance.""

This reverts commit 57f9b6cfd30b1b2505efbacd2a5ce391dbcd1e0c.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
	src/server/src/main/java/org/apache/accumulo/server/test/continuous/ContinuousVerify.java
","24/Jan/14 02:15;jira-bot;Commit 36cec4f33b807ccbd9c2979d886eb842aaab2d74 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=36cec4f ]

ACCUMULO-2234 Replace usages of Instance.getConfiguration with the server-side configuration

Pull the site configuration from instanceOperations off of the Connector which gives
us access to the accumulo-site.xml file being used by that instance and alleviates the
need for us to provide it ourselves.
","24/Jan/14 02:15;jira-bot;Commit 66516a0f8900f228294cb8d818e350887937b079 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=66516a0 ]

Revert ""ACCUMULO-2234 Provide accumulo-site.xml to Mapper classpath and ensure is used by concrete Instance.""

This reverts commit 57f9b6cfd30b1b2505efbacd2a5ce391dbcd1e0c.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
	src/server/src/main/java/org/apache/accumulo/server/test/continuous/ContinuousVerify.java
","24/Jan/14 02:15;jira-bot;Commit 36cec4f33b807ccbd9c2979d886eb842aaab2d74 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=36cec4f ]

ACCUMULO-2234 Replace usages of Instance.getConfiguration with the server-side configuration

Pull the site configuration from instanceOperations off of the Connector which gives
us access to the accumulo-site.xml file being used by that instance and alleviates the
need for us to provide it ourselves.
","24/Jan/14 02:15;jira-bot;Commit 66516a0f8900f228294cb8d818e350887937b079 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=66516a0 ]

Revert ""ACCUMULO-2234 Provide accumulo-site.xml to Mapper classpath and ensure is used by concrete Instance.""

This reverts commit 57f9b6cfd30b1b2505efbacd2a5ce391dbcd1e0c.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
	src/server/src/main/java/org/apache/accumulo/server/test/continuous/ContinuousVerify.java
","24/Jan/14 02:15;jira-bot;Commit 36cec4f33b807ccbd9c2979d886eb842aaab2d74 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=36cec4f ]

ACCUMULO-2234 Replace usages of Instance.getConfiguration with the server-side configuration

Pull the site configuration from instanceOperations off of the Connector which gives
us access to the accumulo-site.xml file being used by that instance and alleviates the
need for us to provide it ourselves.
","24/Jan/14 02:15;jira-bot;Commit 36cec4f33b807ccbd9c2979d886eb842aaab2d74 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=36cec4f ]

ACCUMULO-2234 Replace usages of Instance.getConfiguration with the server-side configuration

Pull the site configuration from instanceOperations off of the Connector which gives
us access to the accumulo-site.xml file being used by that instance and alleviates the
need for us to provide it ourselves.
",24/Jan/14 02:17;elserj;Reverted original change and used Connector.instanceOperations.getSiteConfiguration() instead of passing the accumulo-site.xml through to the mapper's classpath,"24/Jan/14 02:34;jira-bot;Commit 6d6ca9d9ef5b4f2fb6245631020cc16c3dcf7051 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6d6ca9d ]

ACCUMULO-2234 Remove a no longer relevant javadoc message.
","24/Jan/14 02:34;jira-bot;Commit 40ef5d426d968f0032a4e2a844c7ffc624db0d7c in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=40ef5d4 ]

ACCUMULO-2234 Remove the hardcoded tables dir and put it with the rest of the constants in core.
","24/Jan/14 02:34;jira-bot;Commit 6d6ca9d9ef5b4f2fb6245631020cc16c3dcf7051 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6d6ca9d ]

ACCUMULO-2234 Remove a no longer relevant javadoc message.
","24/Jan/14 02:34;jira-bot;Commit 40ef5d426d968f0032a4e2a844c7ffc624db0d7c in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=40ef5d4 ]

ACCUMULO-2234 Remove the hardcoded tables dir and put it with the rest of the constants in core.
","24/Jan/14 02:34;jira-bot;Commit 6d6ca9d9ef5b4f2fb6245631020cc16c3dcf7051 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6d6ca9d ]

ACCUMULO-2234 Remove a no longer relevant javadoc message.
","24/Jan/14 02:34;jira-bot;Commit 6d6ca9d9ef5b4f2fb6245631020cc16c3dcf7051 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6d6ca9d ]

ACCUMULO-2234 Remove a no longer relevant javadoc message.
","26/Mar/14 17:12;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
","26/Mar/14 17:13;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
","26/Mar/14 17:13;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
","26/Mar/14 17:13;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
",,,,,,,,,,,,,,,,,,,,,,,
monitor not seeing zookeeper updates,ACCUMULO-1920,12680797,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,ecn,ecn,22/Nov/13 18:34,04/Mar/14 16:46,13/Mar/19 22:01,22/Nov/13 20:02,,,,,,,,1.4.5,1.5.1,1.6.0,monitor,,,,,,0,,,,,"Started RandomWalk test, and didn't see any tables being created.  After selecting a tablet server, I started seeing entries for unknown tables.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-22 20:59:18.713,,,no_permission,,,,,,,,,,,,360062,,,Tue Nov 26 16:04:27 UTC 2013,,,,,,0|i1q2j3:,360361,,,,,,,,"22/Nov/13 20:59;jira-bot;Commit 11acdf86d05ee512c056e846311c1c3fb8d432dd in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=11acdf8 ]

ACCUMULO-1920 should not close shared zookeeper session; clean up unused watcher list
","22/Nov/13 20:59;jira-bot;Commit 11acdf86d05ee512c056e846311c1c3fb8d432dd in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=11acdf8 ]

ACCUMULO-1920 should not close shared zookeeper session; clean up unused watcher list
","25/Nov/13 21:33;jira-bot;Commit f896c9566c9a483bcf7d074efce16b1f1c88ed2c in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f896c95 ]

ACCUMULO-1920 should not close shared zookeeper session; clean up unused watcher list

Conflicts:
	server/src/main/java/org/apache/accumulo/server/monitor/Monitor.java
",25/Nov/13 21:34;elserj;This also affected 1.5.1,"25/Nov/13 21:44;jira-bot;Commit f896c9566c9a483bcf7d074efce16b1f1c88ed2c in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f896c95 ]

ACCUMULO-1920 should not close shared zookeeper session; clean up unused watcher list

Conflicts:
	server/src/main/java/org/apache/accumulo/server/monitor/Monitor.java
","25/Nov/13 21:44;jira-bot;Commit f896c9566c9a483bcf7d074efce16b1f1c88ed2c in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f896c95 ]

ACCUMULO-1920 should not close shared zookeeper session; clean up unused watcher list

Conflicts:
	server/src/main/java/org/apache/accumulo/server/monitor/Monitor.java
","26/Nov/13 16:04;jira-bot;Commit 51dd805097eeca9404b78e5b332c9aebb09c9ed4 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=51dd805 ]

ACCUMULO-1920 fix needs to be in 1.4 branch, too
","26/Nov/13 16:04;jira-bot;Commit 51dd805097eeca9404b78e5b332c9aebb09c9ed4 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=51dd805 ]

ACCUMULO-1920 fix needs to be in 1.4 branch, too
","26/Nov/13 16:04;jira-bot;Commit 51dd805097eeca9404b78e5b332c9aebb09c9ed4 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=51dd805 ]

ACCUMULO-1920 fix needs to be in 1.4 branch, too
","26/Nov/13 16:04;jira-bot;Commit 51dd805097eeca9404b78e5b332c9aebb09c9ed4 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=51dd805 ]

ACCUMULO-1920 fix needs to be in 1.4 branch, too
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
upgrade trunk to thrift 0.9,ACCUMULO-822,12612424,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,,ecn,ecn,18/Oct/12 13:18,26/Feb/14 19:21,13/Mar/19 22:01,18/Oct/12 19:31,,,,,,,,1.5.0,,,,,,,,,0,,,,,should fix two problems identified with 0.8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-18 14:24:11.418,,,no_permission,,,,,,,,,,,,249561,,,Thu Oct 18 20:07:30 UTC 2012,,,,,,0|i0afjr:,58792,,,,,,,,18/Oct/12 14:24;medined;Which two?,18/Oct/12 15:24;ecn;THRIFT-1658 and THRIFT-1474,18/Oct/12 17:43;kturner;also see ACCUMULO-696 and ACCUMULO-701,"18/Oct/12 20:07;hudson;Integrated in Accumulo-Trunk #528 (See [https://builds.apache.org/job/Accumulo-Trunk/528/])
    ACCUMULO-822 update to thrift 0.9.0 (Revision 1399806)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/BatchWriterImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReaderIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchWriter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftScanner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/Writer.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ClientService.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ConfigurationType.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/TableOperation.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/TableOperationExceptionType.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ThriftTableOperationException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/InitialMultiScan.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/InitialScan.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/IterInfo.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/MapFileInfo.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/MultiScanResult.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/ScanResult.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TColumn.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TConstraintViolationSummary.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TKey.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TKeyExtent.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TKeyValue.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TMutation.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TRange.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/UpdateErrors.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/file/rfile/RelativeKey.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/gc/thrift/GCMonitorService.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/gc/thrift/GCStatus.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/gc/thrift/GcCycleStats.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/Compacting.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/DeadServer.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/MasterClientService.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/MasterGoalState.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/MasterMonitorInfo.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/MasterState.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/RecoveryException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/RecoveryStatus.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TableInfo.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TableOperation.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TabletLoadState.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TabletServerStatus.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TabletSplit.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/thrift/AuthInfo.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/thrift/SecurityErrorCode.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/thrift/ThriftSecurityException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/ActionStats.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/ActiveScan.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/ConstraintViolationException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/IteratorConfig.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/NoSuchScanIDException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/NotServingTabletException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/ScanState.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/ScanType.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/TIteratorSetting.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/TabletClientService.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/TabletStats.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/TooManyFilesException.java
* /accumulo/trunk/core/src/main/thrift/thrift.sh
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mock/MockTableOperationsTest.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/problems/ProblemReports.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/continuous/ContinuousStatsCollector.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/functional/BadIteratorMincTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/performance/metadata/MetadataBatchScanTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/randomwalk/shard/DeleteSomeDocs.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/master/TestMergeState.java
* /accumulo/trunk/trace/src/main/java/org/apache/accumulo/cloudtrace/thrift/RemoteSpan.java
* /accumulo/trunk/trace/src/main/java/org/apache/accumulo/cloudtrace/thrift/SpanReceiver.java
* /accumulo/trunk/trace/src/main/java/org/apache/accumulo/cloudtrace/thrift/TInfo.java
* /accumulo/trunk/trace/src/main/java/org/apache/accumulo/cloudtrace/thrift/TestService.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KilledTabletServerSplit functional test fails,ACCUMULO-109,12529853,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,ecn,ecn,02/Nov/11 13:29,21/Feb/14 01:11,13/Mar/19 22:01,18/Nov/11 18:17,,,,,,,,1.3.5-incubating,1.4.0,,tserver,,,,,,0,,,,,"Sometime the test times out.  Looking at the logs, I see

{noformat}
java.lang.RuntimeException: java.lang.IllegalStateException: Existing time 270 >= 270
...
{noformat}


This is just after the recovery of the root tablet.
",./test/system/auto/run.py -t KilledTabletServerSplit ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215712,,,2011-11-02 13:29:57.0,,,,,,0|i07p5z:,42843,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Recent Traces link no longer works,ACCUMULO-1161,12635796,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,vines,ecn,ecn,07/Mar/13 14:30,20/Feb/14 23:11,13/Mar/19 22:01,26/Mar/13 18:46,,,,,,,,,,,monitor,,,,,,0,,,,,"I just get this stack trace:

{noformat}
org.apache.accumulo.core.client.AccumuloSecurityException: Error INSUFFICIENT_PROPERTIES for user null - Unknown security exception
	at org.apache.accumulo.core.security.handler.ZKAuthenticator.login(ZKAuthenticator.java:39)
	at org.apache.accumulo.server.monitor.servlets.trace.Basic.getScanner(Basic.java:80)
	at org.apache.accumulo.server.monitor.servlets.trace.Summary.pageBody(Summary.java:131)
	at org.apache.accumulo.server.monitor.servlets.BasicServlet.doGet(BasicServlet.java:61)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-07 14:33:18.443,,,no_permission,,,,,,,,,,,,316288,,,Wed Mar 27 02:47:31 UTC 2013,,,,,,0|i1ikt3:,316631,,,,,,,,07/Mar/13 14:33;vines;Was this after a pull from last night or from an earlier revision?,"07/Mar/13 14:45;ecn;Pull from this morning, assuming my updated/build/deploy dance is working correctly.",07/Mar/13 15:55;vines;Fresh copy of the example configs?,"07/Mar/13 16:18;ecn;I've pulled in the changes from the examples; still fails.  Also, requiring users to change these properties will break every existing install, which is user-hostile.","07/Mar/13 16:20;vines;Actually, this is because there was a partial change for ACCUMULO-1156. I didn't think it would interfere. Obviously I was mistaken. Once I finish 1156, this will be fine. trace.user and trace.password will still be supported, just deprecated.","07/Mar/13 16:21;vines;The changes in 1156 so far introduced this error. Once 1156 is finished, this should no longer occur.","07/Mar/13 19:36;vines;Correction, this ticket is from me flat out screwing something up.","07/Mar/13 21:54;hudson;Integrated in Accumulo-1.5 #22 (See [https://builds.apache.org/job/Accumulo-1.5/22/])
    ACCUMULO-1161 - neglected how getPropertiesWithPrefix worked. Also, added some debug info to login tokens (Revision 1454085)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/security/handler/ZKAuthenticator.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
","07/Mar/13 22:01;hudson;Integrated in Accumulo-Trunk #767 (See [https://builds.apache.org/job/Accumulo-Trunk/767/])
    ACCUMULO-1161 - neglected how getPropertiesWithPrefix worked. Also, added some debug info to login tokens (Revision 1454106)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/handler/ZKAuthenticator.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
","07/Mar/13 22:03;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #20 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/20/])
    ACCUMULO-1161 - neglected how getPropertiesWithPrefix worked. Also, added some debug info to login tokens (Revision 1454085)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/security/handler/ZKAuthenticator.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
","07/Mar/13 22:05;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #126 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/126/])
    ACCUMULO-1161 - neglected how getPropertiesWithPrefix worked. Also, added some debug info to login tokens (Revision 1454106)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/handler/ZKAuthenticator.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
","08/Mar/13 15:38;ecn;Still not working; I've updated my accumulo-site file, too.","08/Mar/13 18:44;vines;Sorry, the example files weren't brought back up to snuff.","08/Mar/13 19:51;hudson;Integrated in Accumulo-Trunk #771 (See [https://builds.apache.org/job/Accumulo-Trunk/771/])
    ACCUMULO-1161 - sed command to update xml files apparently wasn't right, got missed (Revision 1454494)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-site.xml
","08/Mar/13 19:54;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #130 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/130/])
    ACCUMULO-1161 - sed command to update xml files apparently wasn't right, got missed (Revision 1454494)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-site.xml
","08/Mar/13 19:58;hudson;Integrated in Accumulo-1.5 #26 (See [https://builds.apache.org/job/Accumulo-1.5/26/])
    ACCUMULO-1161 - sed command to update xml files apparently wasn't right, got missed (Revision 1454492)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/512MB/standalone/accumulo-site.xml
","08/Mar/13 20:01;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #24 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/24/])
    ACCUMULO-1161 - sed command to update xml files apparently wasn't right, got missed (Revision 1454492)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/512MB/standalone/accumulo-site.xml
","25/Mar/13 21:00;vines;{code}
org.apache.accumulo.core.client.AccumuloSecurityException: Error INSUFFICIENT_PROPERTIES for user root - Unknown security exception
	at org.apache.accumulo.core.security.handler.ZKAuthenticator.login(ZKAuthenticator.java:42)
	at org.apache.accumulo.server.monitor.servlets.trace.Basic.getScanner(Basic.java:86)
	at org.apache.accumulo.server.monitor.servlets.trace.Summary.pageBody(Summary.java:131)
	at org.apache.accumulo.server.monitor.servlets.BasicServlet.doGet(BasicServlet.java:61)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
{code}","26/Mar/13 00:46;elserj;[~vines] Alright, apparently I was missing, as compared to the 3G native-standalone example, `trace.principal` and incorrectly had `trace.password` instead of `trace.login.password`. Fixing those gets me traces again. Do you see any problems adding a better description (the above kinda sucks)? In my case, perhaps adding something to the core/**/AccumuloSecurityException#getDefaultErrorMessage(SecurityErrorCode) to handle the INSUFFICIENT_PROPERTIES code? Is there a better fix that isn't initially obvious?

Also, do you think it would be good to look for this case and warn them that they are specifying the old property and not the new? I just saw something similar to this in regards to the Hadoop append/sync configuration params.

[~kturner] Can you double check your accumulo-site.xml against one of the examples to see if you are incorrectly setting a property?","26/Mar/13 01:09;vines;Yeah, the error can be clarified there. However, the old property should still work, it's just deprecated. I'll take a look into that tomorrow.","26/Mar/13 13:20;kturner;bq. Can you double check your accumulo-site.xml against one of the examples to see if you are incorrectly setting a property?

Yeah its different, I have trace.user and trace.password.  The example has trace.login.password and trace.principal.
",26/Mar/13 18:46;vines;I checked for the login properties map being null instead of being empty. Tested it and it's all good now.,"27/Mar/13 02:33;hudson;Integrated in Accumulo-Trunk #802 (See [https://builds.apache.org/job/Accumulo-Trunk/802/])
    ACCUMULO-1161 - fixed logic error for backwards compatability. Also, more descriptive error messaging. (Revision 1461266)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/AccumuloSecurityException.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
","27/Mar/13 02:37;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #53 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/53/])
    ACCUMULO-1161 - fixed logic error for backwards compatability. Also, more descriptive error messaging. (Revision 1461265)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/AccumuloSecurityException.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
","27/Mar/13 02:47;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #161 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/161/])
    ACCUMULO-1161 - fixed logic error for backwards compatability. Also, more descriptive error messaging. (Revision 1461266)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/AccumuloSecurityException.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ACCUMULO_LOG_HOST is incorrectly computed,ACCUMULO-2078,12685912,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,elserj,elserj,elserj,20/Dec/13 22:41,05/Feb/14 23:55,13/Mar/19 22:01,21/Dec/13 00:32,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,scripts,,,,,,0,,,,,"I couldn't figure out why I wasn't getting any logforwarding set up on a small cluster. After verifying that DNS was correctly working for FQDN and hostnames, I dug into how the remote log host is configured.

The grep included in all accumulo-env.sh examples will *never* work on a multi-node installation with the example monitor file. Assuming the user will replace ""localhost"" with the hostname of the host running the monitor, this will not work which is extremely misleading.

The reason is because the grep doesn't exclude any whitespace, so, in o.a.a.s.Accumulo, the value will be replaced with the hostname for localhost (which will eat all of the logs intended for the monitor).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-21 00:23:52.638,,,no_permission,,,,,,,,,,,,364931,,,Sat Dec 21 00:32:54 UTC 2013,,,,,,0|i1qwg7:,365231,,,,,,,,"21/Dec/13 00:23;jira-bot;Commit 55827af327c9e04ac010b821e135c56e5d95faaa in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=55827af ]

ACCUMULO-2078 Fix the grep so that the example configurations are properly interpreted.
","21/Dec/13 00:28;jira-bot;Commit 55827af327c9e04ac010b821e135c56e5d95faaa in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=55827af ]

ACCUMULO-2078 Fix the grep so that the example configurations are properly interpreted.
","21/Dec/13 00:31;jira-bot;Commit 55827af327c9e04ac010b821e135c56e5d95faaa in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=55827af ]

ACCUMULO-2078 Fix the grep so that the example configurations are properly interpreted.
",21/Dec/13 00:32;elserj;Added to the grep that sets ACCUMULO_LOG_HOST so that the example configs (and any user generated ones) can deal with empty lines or lines with whitespace only.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to migrate from 1.5.0 to 1.6.0,ACCUMULO-2161,12688099,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,,vines,vines,09/Jan/14 17:03,17/Jan/14 19:20,13/Mar/19 22:01,17/Jan/14 19:20,,,,,,,,1.6.0,,,master,,,,,,0,,,,,"Running start-all results in the following
{code}2014-01-09 12:01:39,468 [server.Accumulo] INFO : Connected to HDFS
Thread ""org.apache.accumulo.master.state.SetGoalState"" died java.lang.reflect.InvocationTargetException
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.accumulo.start.Main$1.run(Main.java:137)
	at java.lang.Thread.run(Thread.java:701)
Caused by: org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /accumulo/19d74712-6e73-4657-82c5-13553709a5f8/masters/goal_state
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:113)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)
	at org.apache.accumulo.fate.zookeeper.ZooUtil.putData(ZooUtil.java:146)
	at org.apache.accumulo.fate.zookeeper.ZooUtil.putPersistentData(ZooUtil.java:126)
	at org.apache.accumulo.fate.zookeeper.ZooReaderWriter.putPersistentData(ZooReaderWriter.java:80)
	at org.apache.accumulo.master.state.SetGoalState.main(SetGoalState.java:44)
	... 6 more
{code}

Furthermore, master reports {code}2014-01-09 12:02:28,495 [master.Master] WARN : Failed to get master lock org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /accumulo/19d74712-6e73-4657-82c5-13553709a5f8/masters/lock/zlock- {code} constantly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-09 17:29:16.313,,,no_permission,,,,,,,,,,,,367105,,,Fri Jan 17 19:20:15 UTC 2014,,,,,,0|i1ra1b:,367415,,,,,,,,09/Jan/14 17:29;kturner;Do you have the same secret configured in accumulo-site.xml for 1.5 and 1.6?,09/Jan/14 17:33;vines;Yes,17/Jan/14 19:20;vines;I was hammering this yesterday and it seems to be good now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to upgrade to new namespaces,ACCUMULO-1976,12683215,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ctubbsii,vines,vines,06/Dec/13 22:53,09/Jan/14 17:30,13/Mar/19 22:01,07/Jan/14 02:28,,,,,,,,1.6.0,,,master,tserver,,,,,1,,,,,"Attempting to start a 1.6.0 on top of 1.5.0 yields-

{code}2013-12-06 17:47:57,228 [master.Master] FATAL: Error performing upgrade
java.lang.IllegalArgumentException: Improper table name format
        at org.apache.accumulo.core.client.impl.Tables.qualify(Tables.java:188)
        at org.apache.accumulo.core.client.impl.Tables.qualified(Tables.java:175)
        at org.apache.accumulo.core.client.impl.Tables.getMap(Tables.java:81)
        at org.apache.accumulo.core.client.impl.Tables.getIdToNameMap(Tables.java:111)
        at org.apache.accumulo.core.client.impl.Tables.getTableName(Tables.java:100)
        at org.apache.accumulo.server.security.AuditedSecurityOperation.getTableName(AuditedSecurityOperation.java:80)
        at org.apache.accumulo.server.security.AuditedSecurityOperation.grantTablePermission(AuditedSecurityOperation.java:379)
        at org.apache.accumulo.master.Master.upgradeZookeeper(Master.java:322)
        at org.apache.accumulo.master.Master.setMasterState(Master.java:267)
        at org.apache.accumulo.master.Master.getMasterLock(Master.java:1849)
        at org.apache.accumulo.master.Master.run(Master.java:1678)
        at org.apache.accumulo.master.Master.main(Master.java:1865)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:622)
        at org.apache.accumulo.start.Main$1.run(Main.java:137)
        at java.lang.Thread.run(Thread.java:701)
{code}

And then things just die. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-07 03:37:53.889,,,no_permission,,,,,,,,,,,,362467,,,Thu Jan 09 17:30:26 UTC 2014,,,,,,0|i1qhav:,362761,,,,,,,,"06/Dec/13 23:38;vines;I manually got it together, and it seems like there is some logic in place for this, but it's incomplete. I believe the two steps I had to do were-
rename table !0's name from !METADATA to metadata in ZK.
create /namespace in the accumulo's instances ZK directory.","07/Dec/13 03:37;ctubbsii;Ah, I didn't realize we were ever reading the metadata table name from ZK, since it's a built-in constant!","09/Dec/13 16:33;mberman;For others trying to do the process manually, in zkCli:

{code}
set /accumulo/{INSTANCE_ID}/tables/!0/name metadata
create /accumulo/{INSTANCE_ID}/namespaces """"
{code}

(note that it's plural ""namespaces"", not singular as in vines's comment)","09/Dec/13 18:11;mberman;(I wish I was allowed to edit my comments...)

also:

{code}
set /accumulo/{INSTANCE_ID}/tables/+r/namespace +accumulo
set /accumulo/{INSTANCE_ID}/tables/!0/namespace +accumulo
{code}","09/Dec/13 18:44;elserj;bq. (I wish I was allowed to edit my comments...)

I'm not sure if there's a reason for it or if it's just an oversight, but the ""Hadoop Permissions"" that we have for the Accumulo project (likely reused so that INFRA doesn't go crazy with new permissions for every ASF project), has empty roles for ""edit own comment"" and ""delete own comment"". ",30/Dec/13 23:44;ctubbsii;I believe I fixed this already. Can anybody confirm it's still an issue?,"30/Dec/13 23:45;ctubbsii;Or, at least, describe their test procedure in more detail so I can reproduce?","07/Jan/14 02:24;jira-bot;Commit ea8fe54145b306310a93e9df65ea5277dff2853e in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ea8fe54 ]

ACCUMULO-1976 Fix upgrade broken by ACCUMULO-2093
","07/Jan/14 02:27;jira-bot;Commit ea8fe54145b306310a93e9df65ea5277dff2853e in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ea8fe54 ]

ACCUMULO-1976 Fix upgrade broken by ACCUMULO-2093
",09/Jan/14 17:30;vines;Currently unable to confirm because migration is broken (ACCUMULO-2161).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide resource cleanup via static utility rather than Instance.close,ACCUMULO-2128,12687069,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,busbey,busbey,02/Jan/14 23:18,07/Jan/14 02:50,13/Mar/19 22:01,07/Jan/14 02:11,,,,,,,,1.4.5,1.5.1,1.6.0,client,,,,,,0,,,,,"After [discussion about the current state of our code base and the need to properly clean up global resources|http://mail-archives.apache.org/mod_mbox/accumulo-dev/201401.mbox/%3CCAGHyZ6JsKn6AuTpD5A6FFbgF1KY1fshGTvbe7rkhnVyRA5Sc%2Bw%40mail.gmail.com%3E], consensus is that we need to provide a work around for now that doesn't rely on API changes.

Later, when we refactor the client api we'll include proper lifecycle management, for now we just need a global utility for unloading.

This ticket needs to revert all commits from the Instance close work: ACCUMULO-1379, ACCUMULO-1697, ACCUMULO-1858, ACCUMULO-2027, ACCUMULO-1889, and ACCUMULO-2105

Also ACCUMULO-1923 can be closed as wontfix with a link here.

Then we need a version of the solution outlined in ACCUMULO-2113 that does not rely on reflection, if possible.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1379,ACCUMULO-1923,ACCUMULO-2113,,03/Jan/14 05:38;jaredwinick;ACCUMULO-2128.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12621254/ACCUMULO-2128.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-01-03 03:47:57.388,,,no_permission,,,,,,,,,,,,366064,,,Tue Jan 07 02:50:57 UTC 2014,,,,,,0|i1r3mf:,366375,,,,,,,,"03/Jan/14 03:47;kturner;I created a non-reflection version of the utility.  Its in the following branch on github which is based off 1.4.5-SNAPSHOT.   [~jaredwinick] I need to add your {{waitForZooKeeperClientThreads()}} method in the CleanUp class I created.  I would like to get this in place before I proceed with pushing to 1.4 and merging forward.   Can you create a patch that adds that method to o.a.a.core.util.CleanUp in the following branch and attach it here?  That way the code will be attributed to you and we can use it in Accumulo.  

https://github.com/keith-turner/accumulo/tree/ACCUMULO-2113

",03/Jan/14 05:38;jaredwinick;Patch to include waitForZooKeeperClientThreads method. Obviously feel free to modify as needed.,03/Jan/14 22:17;busbey;forgot to include ACCUMULO-2010 in the revert list.,"06/Jan/14 18:47;kturner;I have worked out a plan for doing this work.   My overall plan is to revert Instance.close() in all branches.  After thats done I will add the static utility and merge it forward.  I was going to revert in 1.4.5, add the utility in 1.4.5, and then merge all of that forward but I think that could make resolving merge conflicts more complicated.  This would make it harder to review conflicts related to the utility.     

The following commits occurred related to Instance.close() (merge related commits not included in list).  The commits are in the order applied.

{noformat}
commits in 1.6.0-SNAPSHOT

379881e
975e8c0
674fa95
0d0bc46 
ada4180
79d686f
3f6c66e
7da1164

commits in 1.5.1-SNAPSHOT

975e8c0
0d0bc46
ada4180
79d686f

commits in 1.4.5-SNAPSHOT

975e8c0
0d0bc46
ada4180
79d686f
{noformat}

I am thinking of doing the following to revert and then add this utility.  I am breaking up things for 1.6.0-SNAPSHOT in the hopes that all commits for 1.6.0 will leave things in a compiling state.  Also hoping that breaking up the 1.6.0 revert/merge steps will make it more resilient to concurrent commits by other developers.

 # revert 379881e 674fa95 in 1.6.0-SNAPSHOT
 # revert 975e8c0 0d0bc46 ada4180 79d686f in 1.4.5-SNAPSHOT
 # merge 1.4.5-SNAPSHOT to 1.5.1-SNAPSHOT
 # merge 1.5.1-SNAPSHOT to 1.6.0-SNAPSHOT
 # revert 3f6c66e 7da1164 in 1.6.0-SNAPSHOT
 # add utility to 1.4.5-SNAPSHOT
 # merge 1.4.5-SNAPSHOT to 1.5.1-SNAPSHOT
 # merge 1.5.1-SNAPSHOT to 1.6.0-SNAPSHOT
 # merge 1.6.0-SNAPSHOT to master","06/Jan/14 19:02;elserj;I didn't verify myself that you listed all of the necessary commits that need reverting (I trust you there), but the above plan (with those commits specifically) looks right to me.","06/Jan/14 19:32;busbey;I was going to say that all three branches should include 335f693 from ACCUMULO-2010, but now I notice that that patch covered more than just things introduced as a part of the Instance.close stuff.

So now I'm not sure. Better to just handle an unclean revert somewhere else?","06/Jan/14 20:20;jira-bot;Commit 016f3bb10c43f6461c5d41025b0e07b50f1638a2 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=016f3bb ]

ACCUMULO-2128 Revert ""ACCUMULO-1889 found a few more ZooKeeperInstances that are not closed""

This reverts commit 674fa95cacaa9353142071a66006e0ffb65cae94.

Conflicts:
	core/src/main/java/org/apache/accumulo/core/client/mapreduce/AbstractInputFormat.java
","06/Jan/14 20:39;kturner;335f693 is a partial revert of some of the changes made by other commits I am trying to revert.  I don't want to revert 335f693 because that would bring back stuff we are trying to get rid of. 379881e is the same situation.   When I tried to revert 379881e it brought back some calls to instance.close() that were removed.  This was the first thing I tried and I threw it out after reviewing the changes.   335f693 is a bigger change, I will review it to see if anything needs to be done.","07/Jan/14 01:43;jira-bot;Commit 715825b3299fd742d8570971a7f271178b932812 in branch refs/heads/1.4.5-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=715825b ]

ACCUMULO-2128 added utility to cleanup accumulo static resources

Signed-off-by: Keith Turner <kturner@apache.org>
","07/Jan/14 01:43;jira-bot;Commit c94a73f478c91a24e35583d41bb39102461c54fa in branch refs/heads/1.4.5-SNAPSHOT from [~jaredwinick]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c94a73f ]

ACCUMULO-2128 added waitForZooKeeperClientThreads method

Signed-off-by: Keith Turner <kturner@apache.org>
","07/Jan/14 01:44;jira-bot;Commit 8f9fe41751415ab66ddbce6d6dec058999afc1d3 in branch refs/heads/1.4.5-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8f9fe41 ]

ACCUMULO-2128 added test for static clean up utility
","07/Jan/14 01:45;jira-bot;Commit 715825b3299fd742d8570971a7f271178b932812 in branch refs/heads/1.5.1-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=715825b ]

ACCUMULO-2128 added utility to cleanup accumulo static resources

Signed-off-by: Keith Turner <kturner@apache.org>
","07/Jan/14 01:45;jira-bot;Commit c94a73f478c91a24e35583d41bb39102461c54fa in branch refs/heads/1.5.1-SNAPSHOT from [~jaredwinick]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c94a73f ]

ACCUMULO-2128 added waitForZooKeeperClientThreads method

Signed-off-by: Keith Turner <kturner@apache.org>
","07/Jan/14 01:46;jira-bot;Commit 8f9fe41751415ab66ddbce6d6dec058999afc1d3 in branch refs/heads/1.5.1-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8f9fe41 ]

ACCUMULO-2128 added test for static clean up utility
","07/Jan/14 02:06;jira-bot;Commit 715825b3299fd742d8570971a7f271178b932812 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=715825b ]

ACCUMULO-2128 added utility to cleanup accumulo static resources

Signed-off-by: Keith Turner <kturner@apache.org>
","07/Jan/14 02:06;jira-bot;Commit c94a73f478c91a24e35583d41bb39102461c54fa in branch refs/heads/1.6.0-SNAPSHOT from [~jaredwinick]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c94a73f ]

ACCUMULO-2128 added waitForZooKeeperClientThreads method

Signed-off-by: Keith Turner <kturner@apache.org>
","07/Jan/14 02:07;jira-bot;Commit 8f9fe41751415ab66ddbce6d6dec058999afc1d3 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8f9fe41 ]

ACCUMULO-2128 added test for static clean up utility
","07/Jan/14 02:07;jira-bot;Commit c94a73f478c91a24e35583d41bb39102461c54fa in branch refs/heads/master from [~jaredwinick]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c94a73f ]

ACCUMULO-2128 added waitForZooKeeperClientThreads method

Signed-off-by: Keith Turner <kturner@apache.org>
","07/Jan/14 02:08;jira-bot;Commit 8f9fe41751415ab66ddbce6d6dec058999afc1d3 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8f9fe41 ]

ACCUMULO-2128 added test for static clean up utility
","07/Jan/14 02:46;jira-bot;Commit 21b1b1108b6094d9706d1a01125d8e36041b484c in branch refs/heads/1.5.1-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=21b1b11 ]

ACCUMULO-2128 Remove warnings introduced by merge
","07/Jan/14 02:50;jira-bot;Commit 21b1b1108b6094d9706d1a01125d8e36041b484c in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=21b1b11 ]

ACCUMULO-2128 Remove warnings introduced by merge
","07/Jan/14 02:50;jira-bot;Commit 21b1b1108b6094d9706d1a01125d8e36041b484c in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=21b1b11 ]

ACCUMULO-2128 Remove warnings introduced by merge
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Namespaces need to create appropriate exceptions,ACCUMULO-1970,12682984,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ctubbsii,vines,vines,05/Dec/13 20:11,31/Dec/13 23:29,13/Mar/19 22:01,31/Dec/13 23:29,,,,,,,,1.6.0,,,client,,,,,,0,,,,,"The ACCUMULO-802 patch left some very strange spaces in the client API around errors regarding namespaces. Dominantly, they are exceptions masked as generic AccumuloExceptions or NamespaceNotFoundExceptions wrapped in IllegalArgument and RuntimeExceptions. We need consistency and accuracy for these prior to putting out an API for them.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1965,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-05 21:10:12.646,,,no_permission,,,,,,,,,,,,362241,,,Tue Dec 31 23:29:25 UTC 2013,,,,,,0|i1qfwv:,362536,,,,,,,,"05/Dec/13 21:10;busbey;I'd really like to see the TableOperations.create method throw an appropriate NamespaceNotFoundException when someone attempts to use a namespace that doesn't exist. Making the NamespaceNotFoundException extend AccumuloException, then having methods throw it is a good way to do that without causing an incompatible API change for clients.

e.g. adding this to TableOperations.create will be compatible for old clients (because they're already have code to deal with AccumuloException) while allowing new clients to catch the specific subclass if they so desire.

If we want to make the Table related exceptions follow suite by changing them to extend AccumuloException we'll need a deprecation cycle. The move will be binary compatible but might cause problems i.e.

this will still behave as expected:
{code}
public boolean createTableIfNotExists(String table) {
  boolean exists = true;
  try {
    connection.tableOperations().create(table);
  } catch (TableExistsException exception) {
    LOG.debug(""table already existed."");
  } catch (AccumuloException exception) {
    exists = false;
    LOG.error(""unknown problem with accumulo."", exception);
  }
  return exists;
}
{code}

this will only end up running the code in the AccumuloException block:
{code}
public boolean createTableIfNotExists(String table) {
  boolean exists = true;
  try {
    connection.tableOperations().create(table);
  } catch (AccumuloException exception) {
    exists = false;
    LOG.error(""unknown problem with accumulo."", exception);
  } catch (TableExistsException exception) {
    LOG.debug(""table already existed."");
  }
  return exists;
}
{code}

The latter will cause a compiler error when the source is recompiled (which will then prompt rearranging into the former), but without that a client would silently get incorrect behavior.","05/Dec/13 21:15;vines;agreed on deprecation cycles and such. That was a whim, but we can at least start with a good base for namespaces since that's a fresh API.

My only real concern about extending them is I think IDEs will want to simplify the APIs to throw AccumuloException when there are other Exceptions that extend it, but having that enumeration is monumentally helpful to users.","31/Dec/13 23:29;ctubbsii;I believe I've addressed everything in this ticket for 1.6 under ACCUMULO-1965. If there's anything remaining, re-open or new ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.5.1-SNAPHOST fails to run against Hadoop 1.0.4,ACCUMULO-1900,12679490,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,kturner,kturner,15/Nov/13 21:17,12/Dec/13 20:09,13/Mar/19 22:01,12/Dec/13 20:09,,,,,,,,1.5.1,,,,,,,,,0,,,,,Tried running 1.5.1 snapshot against hadoop 1.0.4 and it failed trying to call FileSystem.getDefaultReplication(Path) which does not exist in 1.0.4.  May have been introduced in Hadoop 1.2.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-12 19:29:15.697,,,no_permission,,,,,,,,,,,,358850,,,Thu Dec 12 19:30:10 UTC 2013,,,,,,0|i1puzr:,359140,,,,,,,,"12/Dec/13 19:29;jira-bot;Commit 998648d3ddeebf9295e62ab6069bdd47e96e1420 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=998648d ]

ACCUMULO-1900 use the old deprecated API for 1.0 compatibility
","12/Dec/13 19:29;jira-bot;Commit 7a840dbe91e819fca829dcb28d76324e2dda4082 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7a840db ]

ACCUMULO-1900 code already uses deprecated API
","12/Dec/13 19:30;jira-bot;Commit 998648d3ddeebf9295e62ab6069bdd47e96e1420 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=998648d ]

ACCUMULO-1900 use the old deprecated API for 1.0 compatibility
","12/Dec/13 19:30;jira-bot;Commit 998648d3ddeebf9295e62ab6069bdd47e96e1420 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=998648d ]

ACCUMULO-1900 use the old deprecated API for 1.0 compatibility
","12/Dec/13 19:30;jira-bot;Commit 7a840dbe91e819fca829dcb28d76324e2dda4082 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7a840db ]

ACCUMULO-1900 code already uses deprecated API
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NativeMapIT fails,ACCUMULO-1860,12677997,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ctubbsii,ecn,ecn,07/Nov/13 14:36,06/Dec/13 20:03,13/Mar/19 22:01,06/Dec/13 20:03,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"The changes made for ACCUMULO-658 break the NativeMapIT.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,357372,,,2013-11-07 14:36:00.0,,,,,,0|i1plvr:,357662,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update dependencies to get around classdefnotfound in maven 3.1,ACCUMULO-1952,12682234,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,elserj,elserj,elserj,02/Dec/13 22:04,06/Dec/13 05:19,13/Mar/19 22:01,06/Dec/13 05:19,1.5.0,,,,,,,1.5.1,,,build,,,,,,1,,,,,"Ran into https://cwiki.apache.org/confluence/display/MAVEN/AetherClassNotFound

Initial tests on 1.5.1-SNAPSHOT, changing the maven-dependency-plugin from 2.7 to 2.8 did fix it. Need to investigate more to figure out what exactly should be changed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-05 17:40:05.067,,,no_permission,,,,,,,,,,,,361491,,,Fri Dec 06 05:19:10 UTC 2013,,,,,,0|i1qbbb:,361789,,,,,,,,05/Dec/13 17:40;ctubbsii;Are you using 3.1.0 or 3.1.1? 3.1.0 has bugs which are fixed in 3.1.1.,05/Dec/13 17:57;elserj;3.1.1,"05/Dec/13 18:37;ctubbsii;What was your maven command? I could not reproduce with ""mvn clean package"" with Maven 3.1.1 on Mac OS X 10.8.2

If we need to update to 2.8, I don't think there's any concern doing that. Normally, we pull in these dependencies from the Apache parent pom, but for some reason, this one isn't even defined in the parent pom ([apache-13|http://search.maven.org/remotecontent?filepath=org/apache/apache/13/apache-13.pom]), so we've declared it ourselves in our top-level parent pom.","05/Dec/13 18:39;elserj;Oh, my bad. `mvn dependency:tree`. Didn't realize I was being ambiguous.","05/Dec/13 21:44;ctubbsii;So, it's not actually a problem with the build, just a problem executing a plugin manually?
You could just do:
{code}mvn org.apache.maven.plugins:maven-dependency-plugin:2.8:tree{code}",05/Dec/13 21:50;elserj;But why declare a dependency version that we know doesn't work with the current stable version of maven when there's a new version of that same plugin that does work?,"05/Dec/13 21:59;ctubbsii;Like I said above, I'm fine bumping the version... it makes sense to do so. I was mostly adding the previous comment to document a workaround for 1.5.0.","06/Dec/13 04:09;elserj;bq. I was mostly adding the previous comment to document a workaround for 1.5.0.

Gotcha - I was confused why you were suggesting it :)","06/Dec/13 05:14;jira-bot;Commit b9adbd7d6ed0a69921338e48d899c1693e50ff52 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b9adbd7 ]

ACCUMULO-1952 Update maven-dependency-version to get around upstream changes.
","06/Dec/13 05:18;jira-bot;Commit b9adbd7d6ed0a69921338e48d899c1693e50ff52 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b9adbd7 ]

ACCUMULO-1952 Update maven-dependency-version to get around upstream changes.
","06/Dec/13 05:19;jira-bot;Commit b9adbd7d6ed0a69921338e48d899c1693e50ff52 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b9adbd7 ]

ACCUMULO-1952 Update maven-dependency-version to get around upstream changes.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dfs.datanode.synconclose check is lacking,ACCUMULO-1947,12682179,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,elserj,elserj,elserj,02/Dec/13 17:23,02/Dec/13 22:54,13/Mar/19 22:01,02/Dec/13 22:54,,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,"The dfs configuration checks we now perform to support hdfs WALs includes a check for dfs.datanode.synconclose which informs the datanode to flush to disk when a file is closed instead of lazily writing the block (very important in the case of power failure).

Looking at the actual check, it performs reflection on a CreateFlag class. In Apache Hadoop 1.2.1, this class doesn't exist yet the option for dfs.datanode.synconclose does exist. We should likely just reflect on the constant DFSConfigKeys.DFS_DATANODE_SYNCONCLOSE_KEY or DFSConfigKeys.DFS_DATANODE_SYNCONCLOSE_DEFAULT to determine if that option is present.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-02 22:34:11.992,,,no_permission,,,,,,,,,,,,361436,,,Mon Dec 02 22:54:27 UTC 2013,,,,,,0|i1qazb:,361735,,,,,,,,"02/Dec/13 19:47;elserj;Looks like the current check would incorrectly not warn users on >=hadoop-1.1.1 and 1.2 (the CreateFlag class does not exist, yet the option for DFS_DATANODE_SYNCONCLOSE does exist). Hadoop-1.0.x and Hadoop-1.1.0 don't have the variable defined.","02/Dec/13 22:34;jira-bot;Commit c7fc776562275e417b0497ba47a2a5a212eca04f in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c7fc776 ]

ACCUMULO-1947 Remove forcefully setting the logger in a test with no reset after the test is done.
","02/Dec/13 22:34;jira-bot;Commit cd96f85e0ec24be01d38c3a3dc78380f3b945d0b in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cd96f85 ]

ACCUMULO-1947 Use DfsConfigKeys.DFS_DATANODE_SYNCONCLOSE_KEY instead of the CreateFlag class as a better way to check
whether or not to we warn if the configuration doesn't contain dfs.datanode.synconclose=true
","02/Dec/13 22:54;jira-bot;Commit c7fc776562275e417b0497ba47a2a5a212eca04f in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c7fc776 ]

ACCUMULO-1947 Remove forcefully setting the logger in a test with no reset after the test is done.
","02/Dec/13 22:54;jira-bot;Commit cd96f85e0ec24be01d38c3a3dc78380f3b945d0b in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cd96f85 ]

ACCUMULO-1947 Use DfsConfigKeys.DFS_DATANODE_SYNCONCLOSE_KEY instead of the CreateFlag class as a better way to check
whether or not to we warn if the configuration doesn't contain dfs.datanode.synconclose=true
","02/Dec/13 22:54;jira-bot;Commit c7fc776562275e417b0497ba47a2a5a212eca04f in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c7fc776 ]

ACCUMULO-1947 Remove forcefully setting the logger in a test with no reset after the test is done.
","02/Dec/13 22:54;jira-bot;Commit cd96f85e0ec24be01d38c3a3dc78380f3b945d0b in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cd96f85 ]

ACCUMULO-1947 Use DfsConfigKeys.DFS_DATANODE_SYNCONCLOSE_KEY instead of the CreateFlag class as a better way to check
whether or not to we warn if the configuration doesn't contain dfs.datanode.synconclose=true
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
org.apache.accumulo.proxy.SimpleTest failing,ACCUMULO-1672,12665836,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,mdrob,mdrob,28/Aug/13 01:36,24/Nov/13 00:42,13/Mar/19 22:01,22/Oct/13 17:14,,,,,,,,1.5.1,1.6.0,,proxy,,,,,,0,,,,,"Command executed:
{{mvn clean test -Dtest=org.apache.accumulo.proxy.* -pl proxy -DfailIfNoTests=false -am -T1.0C}}

Output:
{noformat}
-------------------------------------------------------------------------------
Test set: org.apache.accumulo.proxy.SimpleTest
-------------------------------------------------------------------------------
Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 40.618 sec <<< FAILURE!
testTableOperations(org.apache.accumulo.proxy.SimpleTest)  Time elapsed: 1.954 sec  <<< ERROR!
MutationsRejectedException(msg:org.apache.accumulo.core.client.MutationsRejectedException: # constraint violations : 1  security codes: {}  # server errors 0 # exceptions 0)
	at org.apache.accumulo.proxy.thrift.AccumuloProxy$updateAndFlush_result$updateAndFlush_resultTupleScheme.read(AccumuloProxy.java)
	at org.apache.accumulo.proxy.thrift.AccumuloProxy$updateAndFlush_result$updateAndFlush_resultTupleScheme.read(AccumuloProxy.java)
	at org.apache.accumulo.proxy.thrift.AccumuloProxy$updateAndFlush_result.read(AccumuloProxy.java)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
	at org.apache.accumulo.proxy.thrift.AccumuloProxy$Client.recv_updateAndFlush(AccumuloProxy.java:2414)
	at org.apache.accumulo.proxy.thrift.AccumuloProxy$Client.updateAndFlush(AccumuloProxy.java:2399)
	at org.apache.accumulo.proxy.SimpleTest.testTableOperations(SimpleTest.java:949)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{noformat}","git commit id #21f93e3
Ubuntu 13.04

Apache Maven 3.0.5 (r01de14724cdef164cd33c7c8c2fe155faf9602da; 2013-02-19 08:51:28-0500)
Maven home: /opt/apache-maven-3.0.5
Java version: 1.7.0_25, vendor: Oracle Corporation
Java home: /usr/lib/jvm/java-7-oracle/jre
Default locale: en_US, platform encoding: UTF-8
OS name: ""linux"", version: ""3.8.0-26-generic"", arch: ""amd64"", family: ""unix""
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1924,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-08-28 01:48:43.52,,,no_permission,,,,,,,,,,,,345775,,,Fri Sep 20 16:22:25 UTC 2013,,,,,,0|i1nmkv:,346076,,,,,,,,"28/Aug/13 01:48;sonixbp;Mike, 

Is this a random error that keeps popping up or is it something that happens every time you run the tests? ","28/Aug/13 01:58;mdrob;This happens every time I run. I also took off the {{-T}} argument to maven, to let it run in a single thread, and the test failure still occurred.",28/Aug/13 02:11;sonixbp;It looks like a constraint is being removed by number on line 948 and my intuition is telling me that there's either an unexpected constraint already applied to the table or there is an expected constraint that's missing. I'll take a look at this.,"28/Aug/13 03:06;sonixbp;Mike, I'm running it from your commit (21f93e3)

I modified SimpleTest slightly to print the constraints both before and after the removal of the constaint in line 949.

The test appears to pass and the output yields this:
{noformat}
{org.apache.accumulo.examples.simple.constraints.NumericValueConstraint=2, org.apache.accumulo.core.constraints.DefaultKeySizeConstraint=1}
Removing constaint...
{org.apache.accumulo.core.constraints.DefaultKeySizeConstraint=1}
{noformat}

Weird thing is, the first time I ran the test when I checked out that commit, it failed with the exact stack trace you gave but now I can't seem to reproduce it. What are the specs on the machine that's failing?","28/Aug/13 03:13;sonixbp;On my end:

Apache Maven 3.0.4 (r1232337; 2012-01-17 03:44:56-0500)
Maven home: /usr/share/maven
Java version: 1.6.0_51, vendor: Apple Inc.
Java home: /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home
Default locale: en_US, platform encoding: MacRoman
OS name: ""mac os x"", version: ""10.8.4"", arch: ""x86_64"", family: ""mac""","28/Aug/13 03:18;mdrob;git bisect suggests that the bug occurred between {{8622b4d670ecb3fde53022cb6588df649357d2c9}} and {{ae4653287f8e2e20e48e3b43ca3f3bec84d82d9a}}, which is... not helpful.

Currently running this on an Inspiron 5323, so a fairly modest laptop, but it's been getting the job done up until now. I'm not certain how this could be a hardware issue though. Software specs are listed in the ""environment"" description. Let me know if you want me to check which packages are installed for things like thrift, etc.","28/Aug/13 03:22;sonixbp;Just upgraded to Maven 3.0.5 and java 7. Got the error again. But once again, I can't
reproduce.



","28/Aug/13 11:30;ecn;Perhaps flush the os file buffers between runs?

This may be a race condition where the change in zookeeper needs to propagate to all the tservers and this is done asynchronously.

* Ask master to remove the constraint.
* Master updates zookeeper
* Ask tserver to do something
* Tserver gets update from zookeeper


","10/Sep/13 17:57;vines;So that mvn clean test -Dtest=org.apache.accumulo.proxy.* -pl proxy -DfailIfNoTests=false -am -T1.0C works fine for me, but just doing a mvn clean package after building 1.5.1 causes it to consistently fail

Apache Maven 3.0.4
Maven home: /usr/share/maven
Java version: 1.7.0_25, vendor: Oracle Corporation
Java home: /usr/lib/jvm/java-7-openjdk-amd64/jre
Default locale: en_US, platform encoding: UTF-8
OS name: ""linux"", version: ""3.8.0-30-generic"", arch: ""amd64"", family: ""unix""
","10/Sep/13 20:22;jira-bot;Commit 77760cf7e423358883c55119099e11e17122e8cc in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=77760cf ]

ACCUMULO-1672 avoid race condition when setting constraints in proxy test
","10/Sep/13 20:29;kturner;This is a race condition.  I added a step to the test where it list the constraints after setting them.  Listing the constraints reaches out to the tserver and clear the zoo keeper cache.  This seemed better than sleeping, but its still not 100% (like when there are multiple tservers and I think MAC runs 2).","11/Sep/13 01:22;jira-bot;Commit 1ec9f8f8dad7aff2f2fb72bf242e9e63d509df86 in branch refs/heads/master from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1ec9f8f ]

Augmenting Keith's change for ACCUMULO-1672 to set number of TServers to 1
","11/Sep/13 01:39;jira-bot;Commit e80dfc420ae90be818b15d5c3e8b90649332dee8 in branch refs/heads/1.5.1-SNAPSHOT from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e80dfc4 ]

Pulling back ACCUMULO-1672 changes from master.
","11/Sep/13 01:59;mdrob;I feel like there should be a better solution than reducing the number of tservers. Is this race condition something that can happen on a real cluster? I would not feel comfortable telling users that the solution is to not run multiple tablet servers when they just bought several racks of hardware. Alternatively, is it just an artifact of the way the test is structured?","11/Sep/13 02:06;elserj;Also, wearing the Git hat, this is a good example in practice about duplicating commits in the history with git-cherrypick. We'll have 1ec9f8f8dad7aff2f2fb72bf242e9e63d509df86 and e80dfc420ae90be818b15d5c3e8b90649332dee8 in master (after 1.5.1-SNAPSHOT is merged into master) which both apply the same change.

Please try to keep this in mind in the future, [~sonixbp]. Apply to the ""lowest"" version branch and merge up to higher version. Thanks :D","11/Sep/13 02:27;sonixbp;[~mdrob], that's a great question. I was thinking it just to be a product of the test since it's explicitly verifying that the change propagated in a specific block of code. In reality, if the change had not propagated to all tablet servers, it's possible that a write could occur that still applied the constraint as the tablet sever wouldn't have received the update in time. The alternative would be to guarantee the properties update on the table has propagated fully. This would likely have a performance impact but I can't see properties changing on tables very frequently and I'm not sure if this is something that I've ever had happen personally (as most changes I've made to tables in my stack are static operations that are performed in the shell or upon table creation).

[~elserj], sorry about the duplicated commit. I was adding to a commit that was pushed to 1.6.0 and saw that [~vines] needed it in 1.5.1-SNAPSHOT as well. In the future, I will make sure I pull things forwards instead of backwards.","11/Sep/13 02:42;jira-bot;Commit e80dfc420ae90be818b15d5c3e8b90649332dee8 in branch refs/heads/master from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e80dfc4 ]

Pulling back ACCUMULO-1672 changes from master.
",11/Sep/13 02:44;sonixbp;Thanks Josh!,"11/Sep/13 02:50;elserj;No worries, [~sonixbp]. I just wanted to make sure I mentioned it when I saw a case of this happening. I had many discussion with [~kturner] on this exact subject.

FWIW, I took what was already in master. That appeared to be the correct decision given the circumstances :)","12/Sep/13 04:11;sonixbp;[~mdrob] / [~jvines@gmail.com], are you guys at least able to build now?","12/Sep/13 05:26;kturner;bq. The alternative would be to guarantee the properties update on the table has propagated fully. This would likely have a performance impact

Thats correct.  Configuration changes like this are eventually consistent (based on zookeeper watchers).  Do not want every write to Accumulo to do a blocking read to Zookeeper.  If this was a problem for a user we could add an instance operation that reaches out to each tablet server and does a config reload & check.  W/o this test that make config changes are just going to have to deal w/ the eventual consistency of configuration.",13/Sep/13 20:05;billie.rinaldi;I'm still getting SimpleTest failures.  Sometimes.,"14/Sep/13 02:30;sonixbp;Billie,

Is it the MutationsRejectedException or a different exception?



","14/Sep/13 02:47;billie.rinaldi;No, actually.

{noformat}
AccumuloSecurityException(msg:org.apache.accumulo.core.client.AccumuloSecurityException: Error INVALID_INSTANCEID for user  - Unknown security exception)
{noformat}","18/Sep/13 19:42;ecn;Jenkins is also seeing this.  I don't know what's going on here, and I can't reproduce it at all.","18/Sep/13 20:27;jira-bot;Commit fe85c92d29f779dfb25fea8f387398d90c5027a3 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fe85c92 ]

ACCUMULO-1672 try to make table juggling more robust in the face of failure; this is probably not fixing any real problem
","19/Sep/13 03:32;sonixbp;I'm getting this exception now too when building master

AccumuloSecurityException(msg:org.apache.accumulo.core.client.AccumuloSecurityException: Error INVALID_INSTANCEID for user �
                                                                                                                            createTable
                                                                                                                                       �9e35319a-3445-436e-9bb7-67fe378edfcb - Unknown security exception)
","20/Sep/13 16:22;jira-bot;Commit 964b6f6d1bd68e09c3b1ada1b7e7839d51dea95e in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=964b6f6 ]

ACCUMULO-1672 byte buffers use offsets into a backing array
",,,,,,,,,,,,,,,,,,,,,,,,,,
NativeMap Makefile creates incorrect output file for OSX,ACCUMULO-1843,12676998,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,elserj,elserj,elserj,01/Nov/13 03:31,23/Nov/13 01:41,13/Mar/19 22:01,01/Nov/13 03:40,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Unpacked the accumulo-native tarball, built the library and put it under lib/native.

Tabletserver expected a different filename (libNativeMap-Mac_OS_X-x86_64-64.dylib) than the Makefile built (libaccumulo.jnilib).

This previously worked.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-01 03:37:11.727,,,no_permission,,,,,,,,,,,,356374,,,Sat Nov 23 01:41:57 UTC 2013,,,,,,0|i1pfq7:,356662,,,,,,,,"01/Nov/13 03:37;jira-bot;Commit 96b8d23a71252e3d18b03c94c86dd3a307b4845f in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=96b8d23 ]

ACCUMULO-1843 Use the correct name that Platform.getPlatform generates
when building the native map library
","23/Nov/13 01:41;jira-bot;Commit 73114819e85714f56838e2bcf16bf9b5c6c6a397 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7311481 ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Split failed during conditional randomwalk test,ACCUMULO-1867,12678280,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,kturner,kturner,08/Nov/13 18:21,19/Nov/13 14:46,13/Mar/19 22:01,19/Nov/13 14:46,,,,,,,,1.6.0,,,,,,,,,0,,,,,"I left the conditional random walk test running overnight against 1.6.0-SNAPSHOT configured to use two namenodes.   After running for a few hours   a client saw a split operating failand I saw the following corresponding error message in the tserver logs.

{noformat}

2013-11-08 12:31:59,227 [util.FileUtil] DEBUG: Too many indexes (33) to open at once for null null, reducing in tmpDir = /accumulo-1.6/tmp/idxReduce_1116774712
2013-11-08 12:31:59,369 [thrift.ProcessFunction] ERROR: Internal error processing splitTablet
java.lang.IllegalArgumentException: Wrong FS: hdfs://nn2:9001/accumulo-1.6/tables/2/t-0000ew3/F0000ex7.rf, expected: hdfs://nn1:6093
        at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:381)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:129)
        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:154)
        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:427)
        at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getBCFile(CachableBlockFile.java:256)
        at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.access$000(CachableBlockFile.java:143)
        at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader$MetaBlockLoader.get(CachableBlockFile.java:212)
        at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getBlock(CachableBlockFile.java:313)
        at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getMetaBlock(CachableBlockFile.java:367)
        at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getMetaBlock(CachableBlockFile.java:143)
        at org.apache.accumulo.core.file.rfile.RFile$Reader.<init>(RFile.java:825)
        at org.apache.accumulo.core.file.rfile.RFileOperations.openIndex(RFileOperations.java:63)
        at org.apache.accumulo.core.file.DispatchingFileFactory.openIndex(FileOperations.java:66)
        at org.apache.accumulo.server.util.FileUtil.reduceFiles(FileUtil.java:135)
        at org.apache.accumulo.server.util.FileUtil.estimatePercentageLTE(FileUtil.java:207)
        at org.apache.accumulo.tserver.Tablet.split(Tablet.java:3527)
        at org.apache.accumulo.tserver.TabletServer.splitTablet(TabletServer.java:2648)
        at org.apache.accumulo.tserver.TabletServer.access$1600(TabletServer.java:237)
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.splitTablet(TabletServer.java:2095)
        at sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at $Proxy10.splitTablet(Unknown Source)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$splitTablet.getResult(TabletClientService.java:2531)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$splitTablet.getResult(TabletClientService.java:2515)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:159)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:214)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)

{noformat}

nn1 is the default namenode.  The ""Too many indexes"" message may be important.  That message indicates the split code entered special code that handles tablets w/ lots of files.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-08 19:05:25.989,,,no_permission,,,,,,,,,,,,357655,,,Wed Nov 13 18:05:22 UTC 2013,,,,,,0|i1pnmn:,357945,,,,,,,,"08/Nov/13 19:05;busbey;the ""Wrong filesystem"" error happens when an HDFS client is incorrectly configured for writing to a HA set up and they rely on absolute paths. the paths should have nameservices in the path, not particular NameNodes. Otherwise, whenever there is a failover you'll get this kind of error for whatever files have the other namenode in their path.

I don't know why HA HDFS lets you successfully access paths with the current active namenode, since it just makes people catch this kind of error later. :(

Does your cluster have a proper [nameservice configuration|http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/HDFSHighAvailabilityWithQJM.html#Configuration_details]?",13/Nov/13 01:33;kturner;This is a bug related to the changes made in ACCUMULO-118.  I do not think tablets can split when a tablet references files on different namenodes.  ,"13/Nov/13 16:32;ecn;[~busbey] this wasn't an HA configuration.  Accumulo was to configured to use two separate NNs, each with its own namespace.
","13/Nov/13 17:47;jira-bot;Commit 5ded019232528880fa1746134799571abde19a85 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5ded019 ]

ACCUMULO-1867 use the correct file system when reading the indexes of existing files
","13/Nov/13 17:48;jira-bot;Commit 8beeaa6c1f90649d567bca95d60ae6b99399a80b in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8beeaa6 ]

ACCUMULO-1867 use the correct file system when reading the indexes of existing files
","13/Nov/13 18:05;jira-bot;Commit 5ded019232528880fa1746134799571abde19a85 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5ded019 ]

ACCUMULO-1867 use the correct file system when reading the indexes of existing files
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accumulo tarball doesn't include necessary jars,ACCUMULO-1841,12676992,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ctubbsii,elserj,elserj,01/Nov/13 02:54,15/Nov/13 22:02,13/Mar/19 22:01,15/Nov/13 22:02,,,,,,,,1.6.0,,,,,,,,,0,,,,,"At 05d5921c00cc5f71857fcb6c4a173cccc2e40123 on master. Then mvn clean package -Passemble. Un-tar'ed and copied an example config into conf.

Tried to accumulo init and got a NoClassDefFound on o.a.a.s.u.Initialize.

Brief inspection showed none of the new server/* jars in lib",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-01 05:41:02.686,,,no_permission,,,,,,,,,,,,356368,,,Fri Nov 01 05:41:02 UTC 2013,,,,,,0|i1pfov:,356656,,,,,,,,"01/Nov/13 05:41;jira-bot;Commit a974a4ad2c5afda425af41eff08ed2fe0f00d62a in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a974a4a ]

ACCUMULO-1841 Include missing jars in assembly; remove dupe
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
`accumulo init` invokes the wrong class,ACCUMULO-1842,12676997,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,elserj,elserj,elserj,01/Nov/13 03:01,01/Nov/13 03:40,13/Mar/19 22:01,01/Nov/13 03:40,,,,,,,,1.6.0,,,,,,,,,0,,,,,Invoking `accumulo init` attempts to run o.a.a.s.u.Initialize but the class is now o.a.a.s.i.Initialize.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1844,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-01 03:04:29.6,,,no_permission,,,,,,,,,,,,356373,,,Fri Nov 01 03:04:29 UTC 2013,,,,,,0|i1pfpz:,356661,,,,,,,,"01/Nov/13 03:04;jira-bot;Commit e639ac33b0a19252ce04d250717b918558f39014 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e639ac3 ]

ACCUMULO-1842 Fix Main to actually reference the correct class.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LogSorter cannot read WAlogs from 1.5,ACCUMULO-1814,12675542,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,supermallen,ecn,ecn,24/Oct/13 18:54,29/Oct/13 15:00,13/Mar/19 22:01,28/Oct/13 14:12,,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"While working on the upgrade code for 1.6.0-SNAPSHOT, I got a version check failure on reading a 1.5 WAL.

Yikes!
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-998,,,,,,,,,,,,,,29/Oct/13 15:00;bhavanki;ACCUMULO-1814-2.patch;https://issues.apache.org/jira/secure/attachment/12610810/ACCUMULO-1814-2.patch,28/Oct/13 04:24;supermallen;ACCUMULO-1814.patch;https://issues.apache.org/jira/secure/attachment/12610504/ACCUMULO-1814.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-10-24 18:58:32.152,,,no_permission,,,,,,,,,,,,355119,,,Tue Oct 29 15:00:46 UTC 2013,,,,,,0|i1p7zz:,355407,,,,,,,,"24/Oct/13 18:55;ecn;Deserialization code isn't in the nice readHeader() method, either.","24/Oct/13 18:58;jira-bot;Commit 6337c285fba031c0c14ab1a22e81e5c9b3c4c84c in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6337c28 ]

ACCUMULO-1481 create the root table entry in zookeeper, but blocked by ACCUMULO-1814
",25/Oct/13 19:28;supermallen;I'm working on it.,"28/Oct/13 04:23;supermallen;Here's a first pass at a patch.  It doesn't have quite as much testing as I'd like but time and tide seem to be working against me this weekend.  I'm happy to continue to refine this.  I think we should have some unit tests that involve encryption but those are a bit more involved to write (mostly because of the key management aspects).  

The basic thrust of the patch here is that the WALog format changed ever so slightly between 1.6.0 and 1.5.0, but enough that reading it caused problems.  I consolidated the code that reads the headers out of the file into one spot in DFSLogger and had that spot return both the raw input stream and the decrypting input stream, both set to the right spot within the WALog to begin reading K/V pairs out of it.

Opinions welcome.",28/Oct/13 04:24;supermallen;The patch,"28/Oct/13 14:12;jira-bot;Commit 8730d5cef37f301fc3f204a48e6af63c32a4f207 in branch refs/heads/master from [~mallen]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8730d5c ]

ACCUMULO-1814 Fixes WALog reading issue from 1.5

WALogs from 1.5.0 use a slightly different format than WALogs
from 1.6.0.  Consequently, the code to read WALogs from 1.6.0
doesn't work on files from 1.5.0.  I made changes to
DFSLogger to correctly interpret 1.5.0 based log files,
and increments the log version number to 3, so that
the WALog reading code can correctly identify what type of
file we're dealing with.

This may still require more testing especially with encryption
turned on but for now this will do.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",29/Oct/13 14:06;billie.rinaldi;Rat check fails for me on walog-from-16.walog (but not on the 15 version).  Apparently it can't tell it's a binary file.  We could add it to the apache-rat-plugin excludes in the server pom.,29/Oct/13 15:00;bhavanki;I hit the same problem as Billie with the walogs. Here's a quick patch for the server POM.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Do we need to take care of crypto based export control policy?,ACCUMULO-1714,12668488,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,vines,vines,vines,13/Sep/13 14:37,25/Oct/13 21:49,13/Mar/19 22:01,25/Oct/13 21:49,,,,,,,,1.6.0,,,,,,,,,0,,,,,"This came up in ACCUMULO-1009, but also may affect ACCUMULO-998.

Related info:

https://issues.apache.org/jira/browse/TIKA-118
http://www.apache.org/licenses/exports/
http://markmail.org/message/jduwmahz7nfcrzw6
http://www.apache.org/dev/crypto.html

The dev/crypto.html is from the last version in 2010, which has changed based on some legal-discuss items I read.

Initial thoughts are:
ACCUMULO-998 is fine because we do not ship ANY crypto modules with that, just an interface to use them
ACCUMULO-1009 is not fine IF we bundle bouncycastle in with us.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-09 15:16:41.361,,,no_permission,,,,,,,,,,,,348422,,,Fri Oct 25 21:49:28 UTC 2013,,,,,,0|i1o2uf:,348719,,,,,,,,"09/Oct/13 15:16;billie.rinaldi;Can you provide a reference to the legal-discuss items?  Based on the existing document, it seems like ""contain"" or ""designed to use"" crypto would cover ACCUMULO-998 as well, but I'd be happy to take a look at additional guidance.",09/Oct/13 15:20;vines;http://mail-archives.apache.org/mod_mbox/www-legal-discuss/201309.mbox/%3CCADczPYQ_BG%3DvYQ_9WJfNY3t2NzLC5UpbDr0gzWcyLWZsSB6%2Bdw%40mail.gmail.com%3E is the beginning of the email discussion.,"09/Oct/13 16:42;billie.rinaldi;Thanks for starting that discussion.  What I gather from your thread as well as [1] is that we are still using the process outlined on dev/crypto.html.  Also, I note that no one replied to your question as to whether ACCUMULO-998 needs to follow the policy as well, but someone states on the earlier thread ""Note the threshold is -using- that encryption mechanism, not that your code -implements- that cryptographic code.""

[1]: http://mail-archives.apache.org/mod_mbox/www-legal-discuss/201306.mbox/%3C87ehc6b355.fsf@v35516.1blu.de%3E","25/Oct/13 21:44;jira-bot;Commit 9f86320996b3a7c77f9c5cb263246f9fabe56b24 in branch refs/heads/1.5.1-SNAPSHOT from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9f86320 ]

ACCUMULO-1714 - adding necessary README section for crypto
","25/Oct/13 21:48;jira-bot;Commit 9f86320996b3a7c77f9c5cb263246f9fabe56b24 in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9f86320 ]

ACCUMULO-1714 - adding necessary README section for crypto
","25/Oct/13 21:48;jira-bot;Commit c7b810b55b445267680566c96990b7c518a21162 in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c7b810b ]

ACCUMULO-1714 - Adding necessary crypto readme information to the README
","25/Oct/13 21:49;vines;Apache Accumulo has been added to the apache exports page ( http://www.apache.org/licenses/exports/ ), USG has been notified, and we now have the requisite information in our README files.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
single node zookeeper failure kills connected accumulo servers,ACCUMULO-1572,12658010,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,ecn,ecn,16/Jul/13 13:38,22/Oct/13 17:13,13/Mar/19 22:01,22/Oct/13 17:13,1.5.0,,,,,,,1.4.5,1.5.1,1.6.0,master,tserver,,,,,0,,,,,"Drew Thornton writes on the user mailing list:
{quote}
If one zookeeper node is shutdown/fails/whatever and the rest of the ensemble stays up, the tablet servers attached as clients to the shutdown node immediately fail. If one of the clients happens to be the master, the cluster goes down.

Accumulo does not seem to be failing over to the remaining zookeeper nodes, and this causes me to restart the individual tablet servers again.

The zookeeper ensemble is very stable and has plenty of bandwidth/memory/processing, so taking one node down out of five doesn't crash the zookeepers, just the tablet servers...
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-715,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-16 14:48:13.16,,,no_permission,,,,,,,,,,,,338204,,,Tue Sep 03 12:57:32 UTC 2013,,,,,,0|i1mc1r:,338525,,,,,,,,"16/Jul/13 14:48;nocusds;There are two configurations where I have experienced this:

1) The Zookeeper leader is removed from the ensemble and a new leader is elected.
  Result: Master immediately goes down along with the tablet servers.

2) According to http://zookeeper.apache.org/doc/r3.4.5/zookeeperAdmin.html, the leader should not serve clients in 5+ node ensemble (zoo.cfg - leaderServes=no). Accumulo does not seem to anticipate this situation, so perhaps when a node is removed, the clients attempt to reestablish connection at the leader, who is not serving, and they fail. This may appear as two failures in the ensemble.
  Result: Tablet servers die who were clients of the removed node. If the master was one of the clients, then the cluster goes down.

Versions:
Zookeeper 3.4.5 - 5 nodes with 4 processors and 6GB system memory (-Xmx4096m -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC)
CDH 4.3 - MRv1, no YARN - no special configuration
Accumulo 1.5.0 - adjusted for system memory","17/Jul/13 18:10;jira-bot;Commit 333062d27e25ee227365357bdca237b0c6912f68 in branch refs/heads/1.4.4-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=333062d ]

ACCUMULO-1572 ignore connection lost; eventually we'll get an session lost event
","17/Jul/13 18:10;jira-bot;Commit 7b617230979811d0e0ec8fffa6b633b70278c466 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7b61723 ]

ACCUMULO-1572 ignore connection lost; eventually we'll get an session lost event
","17/Jul/13 18:10;jira-bot;Commit 7b617230979811d0e0ec8fffa6b633b70278c466 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7b61723 ]

ACCUMULO-1572 ignore connection lost; eventually we'll get an session lost event
","17/Jul/13 18:12;jira-bot;Commit 388d58c6d02224e76fab77db852258eccc2dab7a in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=388d58c ]

ACCUMULO-1572 integration test
","17/Jul/13 18:16;ecn;Wrote an integration test that reproduced the problem, then eliminated the fail-fast on connection lost.","18/Jul/13 00:34;ecn;Keith, what do you think needs to be resolved?",18/Jul/13 01:45;kturner;We were discussing how connection loss events were handled in a change to zoolock and decided some changes needed to be made.  I think watchingParent can get set to false when it should not.,"26/Aug/13 22:26;kturner;Its confusing that the ticket is not marked for 1.4.4 since a change was made to 1.4.4 under this ticket.   The following change was made for 1.5 and 1.6 but not 1.4 under this ticket.   Its in this change that watchingParent may not be handled properly.  [~ecn] why wasn't the following change made for 1.4?

{noformat}
@@ -349,6 +349,9 @@ public class ZooLock implements Watcher {
       try { // set the watch on the parent node again
         zooKeeper.getStatus(path, this);
         watchingParent = true;
+      } catch (KeeperException.ConnectionLossException ex) {
+        // we can't look at the lock because we aren't connected, but our session is still good
+        log.warn(""lost connection to zookeeper"");
       } catch (Exception ex) {
         if (lock != null || asyncLock != null) {
           lockWatcher.unableToMonitorLockNode(ex);
{noformat}","30/Aug/13 14:59;ecn;[~kturner] I don't know why the change wasn't applied to the 1.4 branch.

From observation, it looks like the loggers still go down when a zookeeper node goes down, even with this fix.  The other servers stay up if they are able to reconnect in a timely fashion.

So this is still not fixed in 1.4.

","30/Aug/13 15:01;jira-bot;Commit 4ed51ecbca7d4120c5c31531ecbebb5d56a7b79f in branch refs/heads/1.4.4-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ed51ec ]

ACCUMULO-1572 apply missing patch; prevent logger from killing itself on a Disconnect event
","03/Sep/13 12:57;jira-bot;Commit 4ed51ecbca7d4120c5c31531ecbebb5d56a7b79f in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ed51ec ]

ACCUMULO-1572 apply missing patch; prevent logger from killing itself on a Disconnect event
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failing tests again hadoop-2.2.0,ACCUMULO-1784,12674388,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,elserj,elserj,17/Oct/13 19:58,18/Oct/13 00:22,13/Mar/19 22:01,18/Oct/13 00:22,1.5.0,,,,,,,1.5.1,1.6.0,,start,,,,,,0,,,,,"A couple of the VFS classloader tests are failing due to dfs.namenode.fs-limits.min-block-size.

{noformat}
org.apache.hadoop.ipc.RemoteException(java.io.IOException): Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 102400 < 1048576
{noformat}

I imagine there may be more down the pipeline from accumulo-start.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-17 22:02:16.476,,,no_permission,,,,,,,,,,,,354010,,,Thu Oct 17 22:11:21 UTC 2013,,,,,,0|i1p17j:,354302,,,,,,,,"17/Oct/13 22:02;jira-bot;Commit b539fa01a57770cbf7313148aa49b872e8220f7d in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b539fa0 ]

ACCUMULO-1784 fix minimum block size complaint for hadoop-2.2.0
","17/Oct/13 22:11;jira-bot;Commit 1b38c037a6c509c64ace9b55f8fe7fc9fb7dac87 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1b38c03 ]

ACCUMULO-1784 fix minimum block size complaint for hadoop-2.2.0

Conflicts:
	start/src/test/java/org/apache/accumulo/test/AccumuloDFSBase.java
","17/Oct/13 22:11;jira-bot;Commit 1b38c037a6c509c64ace9b55f8fe7fc9fb7dac87 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1b38c03 ]

ACCUMULO-1784 fix minimum block size complaint for hadoop-2.2.0

Conflicts:
	start/src/test/java/org/apache/accumulo/test/AccumuloDFSBase.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TServerUtils.startHsHaServer eats maxMessageSize parameter,ACCUMULO-1141,12635063,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,afuchs,afuchs,04/Mar/13 02:13,17/May/13 12:01,13/Mar/19 22:01,07/Mar/13 19:01,,,,,,,,1.5.0,,,rpc,tserver,,,,,0,,,,,"org.apache.accumulo.server.util.TServerUtils.startHsHaServer doesn't do anything with the maxMessageSize parameter, causing the maximum frame size to be about 16MB. This is too small for many mutations, and would greatly restrict the values that are commonly used with Accumulo.

To fix, we need to include a frame size parameter in the TFramedTransport.Factory returned by org.apache.accumulo.core.util.ThriftUtil.transportFactory().",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Mar/13 03:45;afuchs;ACCUMULO-1141.patch;https://issues.apache.org/jira/secure/attachment/12571840/ACCUMULO-1141.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-03-04 17:14:56.292,,,no_permission,,,,,,,,,,,,315556,,,Fri Mar 08 03:08:17 UTC 2013,,,,,,0|i1igaf:,315899,,,,,,,,"04/Mar/13 03:47;afuchs;Looks like the TFramedTransport used to have a default max size of 2G, and it was decreased to 16M in thrift version 0.9.","04/Mar/13 17:14;ecn;""maxFrameSize < Integer.MIN_VALUE""

I believe minFrameSize should not be less than 1.  Otherwise it looks good.
","04/Mar/13 23:17;elserj;I'm curious, what were the performance effects you saw with changing the frame size?","07/Mar/13 21:54;hudson;Integrated in Accumulo-1.5 #22 (See [https://builds.apache.org/job/Accumulo-1.5/22/])
    ACCUMULO-1141 use maxFrameSize (Revision 1454002)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
","07/Mar/13 22:01;hudson;Integrated in Accumulo-Trunk #767 (See [https://builds.apache.org/job/Accumulo-Trunk/767/])
    ACCUMULO-1141 use maxFrameSize (Revision 1454003)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
* /accumulo/trunk/src
","07/Mar/13 22:03;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #20 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/20/])
    ACCUMULO-1141 use maxFrameSize (Revision 1454002)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
","07/Mar/13 22:05;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #126 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/126/])
    ACCUMULO-1141 use maxFrameSize (Revision 1454003)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
* /accumulo/trunk/src
","07/Mar/13 23:12;afuchs;[~elserj]: Mutations over the frame size generated exceptions -- it wasn't so much a performance problem as it was a stability problem. For us, these exceptions resulted in an infinite loop of retries. I'm not sure if that was in our code or in the Accumulo client library.","07/Mar/13 23:25;elserj;bq. Mutations over the frame size generated exceptions

Oh, very interesting. My initial guess was that thrift would chunk the Mutation down to fit within the frame. Perhaps I'll have to go poking through Thrift to understand it a bit better. Thanks!","08/Mar/13 03:08;afuchs;As I understand it, the point of limiting the frame size is to prevent excessive memory allocation by Thrift, perhaps in the case of a DOS attempt. A single message fits into one frame, and the size is sent ahead of time (first 4 bytes) to make sure that the message is fully read from the transport before being executed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bin/config.sh has hard-coded version that isn't updated with the build,ACCUMULO-1384,12646294,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ctubbsii,ctubbsii,ctubbsii,06/May/13 21:01,11/May/13 05:23,13/Mar/19 22:01,08/May/13 22:15,,,,,,,,1.5.0,,,scripts,,,,,,0,,,,,"In ACCUMULO-1271, the version constant for Accumulo was derived from the version of the artifact from the POM, to better automate releases (version is specified in one place, instead of many).

The bin/config.sh script uses the version of Accumulo to find jars. It is not currently derived from the build process and prevents running Accumulo if it is incorrect.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-08 22:31:21.403,,,no_permission,,,,,,,,,,,,326652,,,Sat May 11 05:23:13 UTC 2013,,,,,,0|i1kcqv:,326997,,,,,,,,"06/May/13 21:02;ctubbsii;r1479673 did a localized fix, in the 1.5 branch, but a larger fix needs to be done to avoid updating the version in multiple places.","06/May/13 21:37;ctubbsii;After some further consideration, I think it might be better to simply drop the version part of our jars in the lib/ directory of our binary packaging. There doesn't actually seem to be a need to have it there.","08/May/13 22:31;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #104 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/104/])
    ACCUMULO-1384 strip versions off of filenames in binary distributions and simplify globbing/classpaths throughout configuration (Revision 1480477)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/README
* /accumulo/branches/1.5/bin/accumulo
* /accumulo/branches/1.5/bin/bootstrap_hdfs.sh
* /accumulo/branches/1.5/bin/config.sh
* /accumulo/branches/1.5/bin/stop-all.sh
* /accumulo/branches/1.5/bin/stop-here.sh
* /accumulo/branches/1.5/bin/tdown.sh
* /accumulo/branches/1.5/bin/tool.sh
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/512MB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/vfs-classloader/accumulo-site.xml
* /accumulo/branches/1.5/core/src/main/resources/org/apache/accumulo/core/conf/config.html
* /accumulo/branches/1.5/core/src/test/resources/disabled/conf/accumulo-site.xml
* /accumulo/branches/1.5/docs/combiners.html
* /accumulo/branches/1.5/docs/examples/README.bloom
* /accumulo/branches/1.5/docs/examples/README.combiner
* /accumulo/branches/1.5/docs/examples/README.constraints
* /accumulo/branches/1.5/docs/examples/README.mapred
* /accumulo/branches/1.5/docs/examples/README.maxmutation
* /accumulo/branches/1.5/docs/examples/README.regex
* /accumulo/branches/1.5/docs/examples/README.rowhash
* /accumulo/branches/1.5/docs/examples/README.tabletofile
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/server/src/main/c++/nativeMap/Makefile
* /accumulo/branches/1.5/test/compat/japi-compliance/japi-accumulo-1.5.xml
* /accumulo/branches/1.5/test/src/test/resources/conf/accumulo-site.xml
* /accumulo/branches/1.5/test/system/auto/TestUtils.py
* /accumulo/branches/1.5/test/system/auto/simple/mapreduce.py
* /accumulo/branches/1.5/test/system/bench/lib/Benchmark.py
* /accumulo/branches/1.5/test/system/continuous/agitator.pl
* /accumulo/branches/1.5/test/system/continuous/mapred-setup.sh
","08/May/13 22:34;hudson;Integrated in Accumulo-1.5 #102 (See [https://builds.apache.org/job/Accumulo-1.5/102/])
    ACCUMULO-1384 strip versions off of filenames in binary distributions and simplify globbing/classpaths throughout configuration (Revision 1480477)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/branches/1.5/README
* /accumulo/branches/1.5/bin/accumulo
* /accumulo/branches/1.5/bin/bootstrap_hdfs.sh
* /accumulo/branches/1.5/bin/config.sh
* /accumulo/branches/1.5/bin/stop-all.sh
* /accumulo/branches/1.5/bin/stop-here.sh
* /accumulo/branches/1.5/bin/tdown.sh
* /accumulo/branches/1.5/bin/tool.sh
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/512MB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/vfs-classloader/accumulo-site.xml
* /accumulo/branches/1.5/core/src/main/resources/org/apache/accumulo/core/conf/config.html
* /accumulo/branches/1.5/core/src/test/resources/disabled/conf/accumulo-site.xml
* /accumulo/branches/1.5/docs/combiners.html
* /accumulo/branches/1.5/docs/examples/README.bloom
* /accumulo/branches/1.5/docs/examples/README.combiner
* /accumulo/branches/1.5/docs/examples/README.constraints
* /accumulo/branches/1.5/docs/examples/README.mapred
* /accumulo/branches/1.5/docs/examples/README.maxmutation
* /accumulo/branches/1.5/docs/examples/README.regex
* /accumulo/branches/1.5/docs/examples/README.rowhash
* /accumulo/branches/1.5/docs/examples/README.tabletofile
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/server/src/main/c++/nativeMap/Makefile
* /accumulo/branches/1.5/test/compat/japi-compliance/japi-accumulo-1.5.xml
* /accumulo/branches/1.5/test/src/test/resources/conf/accumulo-site.xml
* /accumulo/branches/1.5/test/system/auto/TestUtils.py
* /accumulo/branches/1.5/test/system/auto/simple/mapreduce.py
* /accumulo/branches/1.5/test/system/bench/lib/Benchmark.py
* /accumulo/branches/1.5/test/system/continuous/agitator.pl
* /accumulo/branches/1.5/test/system/continuous/mapred-setup.sh
","08/May/13 22:52;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #214 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/214/])
    ACCUMULO-1384, ACCUMULO-1389 merged to trunk (Revision 1480486)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/bin/stop-all.sh
* /accumulo/trunk/bin/stop-here.sh
* /accumulo/trunk/bin/tdown.sh
* /accumulo/trunk/bin/tool.sh
* /accumulo/trunk/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/vfs-classloader/accumulo-site.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/resources/org/apache/accumulo/core/conf/config.html
* /accumulo/trunk/core/src/test/resources/disabled/conf/accumulo-site.xml
* /accumulo/trunk/docs/combiners.html
* /accumulo/trunk/docs/examples/README.bloom
* /accumulo/trunk/docs/examples/README.combiner
* /accumulo/trunk/docs/examples/README.constraints
* /accumulo/trunk/docs/examples/README.mapred
* /accumulo/trunk/docs/examples/README.maxmutation
* /accumulo/trunk/docs/examples/README.regex
* /accumulo/trunk/docs/examples/README.rowhash
* /accumulo/trunk/docs/examples/README.tabletofile
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/c++/nativeMap/Makefile
* /accumulo/trunk/src
* /accumulo/trunk/test/compat/japi-compliance/japi-accumulo-1.5.xml
* /accumulo/trunk/test/src/test/resources/conf/accumulo-site.xml
* /accumulo/trunk/test/system/auto/TestUtils.py
* /accumulo/trunk/test/system/auto/simple/mapreduce.py
* /accumulo/trunk/test/system/bench/lib/Benchmark.py
* /accumulo/trunk/test/system/continuous/agitator.pl
* /accumulo/trunk/test/system/continuous/mapred-setup.sh
","08/May/13 22:56;hudson;Integrated in Accumulo-Trunk #856 (See [https://builds.apache.org/job/Accumulo-Trunk/856/])
    ACCUMULO-1384, ACCUMULO-1389 merged to trunk (Revision 1480486)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/bin/stop-all.sh
* /accumulo/trunk/bin/stop-here.sh
* /accumulo/trunk/bin/tdown.sh
* /accumulo/trunk/bin/tool.sh
* /accumulo/trunk/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/vfs-classloader/accumulo-site.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/resources/org/apache/accumulo/core/conf/config.html
* /accumulo/trunk/core/src/test/resources/disabled/conf/accumulo-site.xml
* /accumulo/trunk/docs/combiners.html
* /accumulo/trunk/docs/examples/README.bloom
* /accumulo/trunk/docs/examples/README.combiner
* /accumulo/trunk/docs/examples/README.constraints
* /accumulo/trunk/docs/examples/README.mapred
* /accumulo/trunk/docs/examples/README.maxmutation
* /accumulo/trunk/docs/examples/README.regex
* /accumulo/trunk/docs/examples/README.rowhash
* /accumulo/trunk/docs/examples/README.tabletofile
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/c++/nativeMap/Makefile
* /accumulo/trunk/src
* /accumulo/trunk/test/compat/japi-compliance/japi-accumulo-1.5.xml
* /accumulo/trunk/test/src/test/resources/conf/accumulo-site.xml
* /accumulo/trunk/test/system/auto/TestUtils.py
* /accumulo/trunk/test/system/auto/simple/mapreduce.py
* /accumulo/trunk/test/system/bench/lib/Benchmark.py
* /accumulo/trunk/test/system/continuous/agitator.pl
* /accumulo/trunk/test/system/continuous/mapred-setup.sh
","10/May/13 19:21;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #107 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/107/])
    ACCUMULO-1384: fix typo in setting up the HADOOP_CLASSPATH (Revision 1481126)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/bin/tool.sh
","10/May/13 19:29;hudson;Integrated in Accumulo-1.5 #105 (See [https://builds.apache.org/job/Accumulo-1.5/105/])
    ACCUMULO-1384: fix typo in setting up the HADOOP_CLASSPATH (Revision 1481126)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/bin/tool.sh
","11/May/13 05:18;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #217 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/217/])
    ACCUMULO-1404, ACCUMULO-1384 merge to trunk (Revision 1481250)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src/main/assemblies/bin.xml
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/bin/tool.sh
* /accumulo/trunk/pom.xml
","11/May/13 05:23;hudson;Integrated in Accumulo-Trunk #859 (See [https://builds.apache.org/job/Accumulo-Trunk/859/])
    ACCUMULO-1404, ACCUMULO-1384 merge to trunk (Revision 1481250)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src/main/assemblies/bin.xml
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/bin/tool.sh
* /accumulo/trunk/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tablet fails to load after split fix,ACCUMULO-1235,12640508,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,ecn,ecn,03/Apr/13 13:28,23/Apr/13 01:21,13/Mar/19 22:01,22/Apr/13 16:23,1.4.0,,,,,,,1.4.4,1.5.0,,tserver,,,,,,0,15_qa_bug,,,,"After fixing a split, the metadata table information for the low half of the split is empty, which eventually causes an NPE.

The split appears to be fixed.

{noformat}
2013-04-03 05:25:42,209 [tabletserver.TabletServer] DEBUG: verifying extent 1ya;000019;000018
2013-04-03 05:25:42,211 [util.MetadataTable] WARN : Incomplete split 1ya;000019 attempting to fix
2013-04-03 05:25:42,222 [util.MetadataTable] DEBUG: Prev tablet 1ya;000018 : [] 9223372036854775807 false does not exist, need to create it 000018 000017 0.47058823529411764
2013-04-03 05:25:42,229 [tabletserver.TabletServer] DEBUG: verifying extent 1ya;000019;000017
2013-04-03 05:25:42,234 [tabletserver.TabletServer] DEBUG: Master didn't know 1ya;000019;000018 was split, letting it know about [1ya;000018;000017, 1ya;000019;000018]
2013-04-03 05:25:42,235 [tabletserver.Tablet] DEBUG: Looking at metadata {}
2013-04-03 05:25:42,235 [tabletserver.Tablet] DEBUG: got [] for logs for 1ya;000018;000017
2013-04-03 05:25:42,239 [tabletserver.NativeMap] DEBUG: Allocated native map 0x00002aaab809a790
2013-04-03 05:25:42,240 [tabletserver.TabletServer] WARN : exception trying to assign tablet 1ya;000018;000017 /t-0007dqd
java.lang.NullPointerException
        at org.apache.accumulo.server.tabletserver.TabletTime.getInstance(TabletTime.java:61)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1368)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1300)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1142)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1130)
        at org.apache.accumulo.server.tabletserver.TabletServer$AssignmentHandler.run(TabletServer.java:2512)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
{noformat}
",10-node test cluster running randomwalk test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-03 19:11:17.248,,,no_permission,,,,,,,,,,,,320968,,,Tue Apr 23 01:21:52 UTC 2013,,,,,,0|i1jdof:,321309,,,,,,,,"03/Apr/13 19:11;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #60 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/60/])
    ACCUMULO-1235 load properties if we're loading an unfinished split (Revision 1464119)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.5/test/src/main/resources/log4j.properties
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/TestAccumulo1235.java
","03/Apr/13 19:18;hudson;Integrated in Accumulo-1.5 #62 (See [https://builds.apache.org/job/Accumulo-1.5/62/])
    ACCUMULO-1235 load properties if we're loading an unfinished split (Revision 1464119)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.5/test/src/main/resources/log4j.properties
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/TestAccumulo1235.java
","05/Apr/13 02:11;kturner;I was reviewing the code changes for this tickets.  I think the changes look good, but in the process of the review I noticed ACCUMULO-1243",22/Apr/13 16:23;ecn;The loading of a half-split tablet needed to be cleaned up.,"23/Apr/13 00:59;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #86 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/86/])
    ACCUMULO-1235 added timeout to split recovery unit test (Revision 1470607)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/TestAccumuloSplitRecovery.java
","23/Apr/13 01:08;hudson;Integrated in Accumulo-1.5 #87 (See [https://builds.apache.org/job/Accumulo-1.5/87/])
    ACCUMULO-1235 added timeout to split recovery unit test (Revision 1470607)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/TestAccumuloSplitRecovery.java
","23/Apr/13 01:13;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #198 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/198/])
    ACCUMULO-1235 added timeout to split recovery unit test (Revision 1470609)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/TestAccumuloSplitRecovery.java
","23/Apr/13 01:21;hudson;Integrated in Accumulo-Trunk #840 (See [https://builds.apache.org/job/Accumulo-Trunk/840/])
    ACCUMULO-1235 added timeout to split recovery unit test (Revision 1470609)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/TestAccumuloSplitRecovery.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
delay file garbage collection to survive name node failure,ACCUMULO-919,12624833,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,ecn,ecn,20/Dec/12 15:45,11/Mar/13 15:07,13/Mar/19 22:01,27/Feb/13 18:43,,,,,,,,1.5.0,,,gc,,,,,,0,,,,,"Consider the catastrophic loss of the namenode.

Assuming you have a previous snapshot, you can recover the namenode using another node back to that snapshot.

However, the most recently deleted files will show as corrupt, because the slightly older state will point to blocks that are now gone.

If the gc delayed file collection for a period of time longer than the age of a snapshot, accumulo could be recovered with the snapshot.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-20 16:17:23.216,,,no_permission,,,,,,,,,,,,301341,,,Mon Mar 11 15:07:57 UTC 2013,,,,,,0|i16rsn:,247635,,,,,,,,"20/Dec/12 16:17;kturner;Would enabling HDFS trash feature work just as well?  I have never used it, the property is fs.trash.interval.   Setting this to some multiple of the snapshot time may work.","20/Dec/12 17:19;ecn;Yes, looks like the trash feature is exactly what we need.","08/Jan/13 16:53;ecn;Hmm... it looks to me like the trash is a shell thing, and not built into FileSystem implementations.","08/Jan/13 19:09;hudson;Integrated in Accumulo-Trunk #617 (See [https://builds.apache.org/job/Accumulo-Trunk/617/])
    ACCUMULO-919 delete files using Trash (Revision 1430444)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
","08/Jan/13 20:33;ecn;GC now uses the Trash, if configured.","08/Jan/13 21:16;hudson;Integrated in Accumulo-Trunk #618 (See [https://builds.apache.org/job/Accumulo-Trunk/618/])
    ACCUMULO-919 provide an option to just skip using the trash to delete files (Revision 1430474)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/gc/TestConfirmDeletes.java
","09/Jan/13 21:06;hudson;Integrated in Accumulo-Trunk #622 (See [https://builds.apache.org/job/Accumulo-Trunk/622/])
    ACCUMULO-919 trash emptier lives in the NN, no need to start our own (Revision 1431055)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
","11/Jan/13 18:09;hudson;Integrated in Accumulo-Trunk #629 (See [https://builds.apache.org/job/Accumulo-Trunk/629/])
    ACCUMULO-919 moveToTrash throws an exception if the file does not exists, which is different than the way delete behaves (Revision 1432173)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
","11/Jan/13 19:33;hudson;Integrated in Accumulo-Trunk #630 (See [https://builds.apache.org/job/Accumulo-Trunk/630/])
    ACCUMULO-919 refactor trash to use a local method with the semantics that match delete (Revision 1432219)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
","18/Jan/13 19:26;hudson;Integrated in Accumulo-1.4.x #269 (See [https://builds.apache.org/job/Accumulo-1.4.x/269/])
    ACCUMULO-919 backported to 1.4 branch (Revision 1435288)

     Result = SUCCESS
drew : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
","14/Feb/13 17:32;ecn;WAL file collection doesn't use the Trash.
TServer recovery clean-up doesn't use the Trash.
Root tablet file clean-up doesn't use the Trash.
","14/Feb/13 20:31;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #93 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/93/])
    ACCUMULO-919 use the trash to cleanup root tablet files, recovery files, and WAL (Revision 1446314)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/GarbageCollectWriteAheadLogs.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
","14/Feb/13 20:42;hudson;Integrated in Accumulo-Trunk #735 (See [https://builds.apache.org/job/Accumulo-Trunk/735/])
    ACCUMULO-919 use the trash to cleanup root tablet files, recovery files, and WAL (Revision 1446314)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/GarbageCollectWriteAheadLogs.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
","27/Feb/13 22:47;hudson;Integrated in Accumulo-1.4.x #277 (See [https://builds.apache.org/job/Accumulo-1.4.x/277/])
    ACCUMULO-919 port the Trash updates back to 1.4 (Revision 1450909)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/CoordinateRecoveryTask.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/test/functional/BulkSplitOptimizationTest.java
","11/Mar/13 15:07;hudson;Integrated in Accumulo-1.4.x #279 (See [https://builds.apache.org/job/Accumulo-1.4.x/279/])
    ACCUMULO-919: move recovery files to the trash, too (Revision 1455141)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/CoordinateRecoveryTask.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deadlock possible with log recovery.,ACCUMULO-1077,12633026,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,kturner,kturner,19/Feb/13 19:13,02/Mar/13 05:28,13/Mar/19 22:01,27/Feb/13 23:02,,,,,,,,1.5.0,,,,,,,,,0,,,,,"The master enqueues a FATE operation to start log recovery.  If all FATE threads are busy trying to read the metadata table and the metadata table needs to be recovered then we are stuck.  I think this bug may be new in 1.5, but I am not sure.  Need to check if it exists in 1.4.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-27 22:23:37.743,,,no_permission,,,,,,,,,,,,313522,,,Sat Mar 02 05:28:48 UTC 2013,,,,,,0|i1i3r3:,313867,,,,,,,,"27/Feb/13 22:23;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #2 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/2/])
    ACCUMULO-1077 fixed deadlock w/ walog recovery and made walog recovery retry w/ backoff.... failed log recoveries were not retrying (Revision 1450993)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/LogCloser.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRLogCloser.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRRecoverLease.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/SubmitFileForRecovery.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/log/LogSorter.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
","28/Feb/13 01:36;hudson;Integrated in Accumulo-Trunk #748 (See [https://builds.apache.org/job/Accumulo-Trunk/748/])
    ACCUMULO-1077 fixed deadlock w/ walog recovery and made walog recovery retry w/ backoff.... failed log recoveries were not retrying (Revision 1450994)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/LogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRLogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRRecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/SubmitFileForRecovery.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/LogSorter.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
* /accumulo/trunk/src
","28/Feb/13 02:20;hudson;Integrated in Accumulo-1.5 #3 (See [https://builds.apache.org/job/Accumulo-1.5/3/])
    ACCUMULO-1077 fixed deadlock w/ walog recovery and made walog recovery retry w/ backoff.... failed log recoveries were not retrying (Revision 1450993)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/LogCloser.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRLogCloser.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRRecoverLease.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/SubmitFileForRecovery.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/log/LogSorter.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
","28/Feb/13 02:31;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #107 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/107/])
    ACCUMULO-1077 fixed deadlock w/ walog recovery and made walog recovery retry w/ backoff.... failed log recoveries were not retrying (Revision 1450994)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/LogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRLogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRRecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/SubmitFileForRecovery.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/LogSorter.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
* /accumulo/trunk/src
",28/Feb/13 19:47;ecn;Confirmed by randomwalk tests.  Good catch!,"02/Mar/13 05:28;elserj;I'm a little confused... With the changes to HadoopLogCloser, I tried building against CDH3u5, but got an error because, in CDH3u5, DistributedFileSystem#recoverLease throws NoSuchMethodException. 0.20.205, 1.0.4, 1.1.3, nor 2.0.2-alpha have throws NoSuchMethodException, though.

Modifying the CDH3u5 source gets around the Accumulo compilation issue. I'm not sure there's any good way around it, but perhaps I'm just noting it here.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Configuration secrets exposed via thrift RPC with no authentication,ACCUMULO-1086,12633796,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,ctubbsii,ctubbsii,24/Feb/13 13:40,28/Feb/13 14:21,13/Mar/19 22:01,28/Feb/13 14:21,,,,,,,,1.5.0,,,master,rpc,tserver,,,,0,,,,,"Trace password, keystore passwords, and other sensitive information is available without any authentication whatsoever, in the thrift client service. What's the reason for not requiring authentication here?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-27 20:26:51.907,,,no_permission,,,,,,,,,,,,314291,,,Thu Feb 28 01:36:29 UTC 2013,,,,,,0|i1i8hz:,314636,,,,,,,,"27/Feb/13 20:26;ecn;I've modified the code to hide passwords and require user credentials, which are checked.  No further permissions are required.
","27/Feb/13 20:57;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #106 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/106/])
    ACCUMULO-1086 require some user auth, and filter out passwords (Revision 1450930)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ClientService.java
* /accumulo/trunk/core/src/main/thrift/client.thrift
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
* /accumulo/trunk/src
","27/Feb/13 21:00;hudson;Integrated in Accumulo-1.5 #2 (See [https://builds.apache.org/job/Accumulo-1.5/2/])
    ACCUMULO-1086 require some user auth, and filter out passwords (Revision 1450929)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ClientService.java
* /accumulo/branches/1.5/core/src/main/thrift/client.thrift
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
","27/Feb/13 22:23;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #2 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/2/])
    ACCUMULO-1086 require some user auth, and filter out passwords (Revision 1450929)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ClientService.java
* /accumulo/branches/1.5/core/src/main/thrift/client.thrift
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
","28/Feb/13 01:36;hudson;Integrated in Accumulo-Trunk #748 (See [https://builds.apache.org/job/Accumulo-Trunk/748/])
    ACCUMULO-1086 require some user auth, and filter out passwords (Revision 1450930)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ClientService.java
* /accumulo/trunk/core/src/main/thrift/client.thrift
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stop-all doesn't work: Error BAD_CREDENTIALS for user root,ACCUMULO-1120,12634418,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,vines,ecn,ecn,27/Feb/13 14:58,28/Feb/13 02:31,13/Mar/19 22:01,27/Feb/13 18:11,,,,,,,,1.5.0,,,,,,,,,0,,,,,"{noformat}
$ bin/accumulo admin stopAll
2013-02-27 14:56:14,072 [util.Admin] ERROR: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_CREDENTIALS for user root - Username or Password is Invalid
org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_CREDENTIALS for user root - Username or Password is Invalid
	at org.apache.accumulo.core.client.impl.MasterClient.execute(MasterClient.java:119)
	at org.apache.accumulo.server.util.Admin.stopServer(Admin.java:107)
	at org.apache.accumulo.server.util.Admin.main(Admin.java:95)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.accumulo.start.Main$1.run(Main.java:97)
	at java.lang.Thread.run(Thread.java:662)
Caused by: ThriftSecurityException(user:root, code:BAD_CREDENTIALS)
	at org.apache.accumulo.core.master.thrift.MasterClientService$shutdown_result$shutdown_resultStandardScheme.read(MasterClientService.java:8424)
	at org.apache.accumulo.core.master.thrift.MasterClientService$shutdown_result$shutdown_resultStandardScheme.read(MasterClientService.java:8410)
	at org.apache.accumulo.core.master.thrift.MasterClientService$shutdown_result.read(MasterClientService.java:8360)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
	at org.apache.accumulo.core.master.thrift.MasterClientService$Client.recv_shutdown(MasterClientService.java:312)
	at org.apache.accumulo.core.master.thrift.MasterClientService$Client.shutdown(MasterClientService.java:297)
	at org.apache.accumulo.server.util.Admin$1.execute(Admin.java:110)
	at org.apache.accumulo.server.util.Admin$1.execute(Admin.java:107)
	at org.apache.accumulo.core.client.impl.MasterClient.execute(MasterClient.java:113)
	... 8 more

{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-27 18:11:00.396,,,no_permission,,,,,,,,,,,,314911,,,Thu Feb 28 02:31:12 UTC 2013,,,,,,0|i1icbj:,315255,,,,,,,,27/Feb/13 18:11;vines;CLI no longer has a default password in it,"27/Feb/13 21:00;hudson;Integrated in Accumulo-1.5 #2 (See [https://builds.apache.org/job/Accumulo-1.5/2/])
    ACCUMULO-1120 - credentials now getting properly read (Revision 1450882)

     Result = FAILURE
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/branches/1.5/examples/simple/src/test/java/org/apache/accumulo/examples/simple/dirlist/CountTest.java
* /accumulo/branches/1.5/test/system/auto/TestUtils.py
","27/Feb/13 22:23;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #2 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/2/])
    ACCUMULO-1120 - credentials now getting properly read (Revision 1450882)

     Result = FAILURE
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/branches/1.5/examples/simple/src/test/java/org/apache/accumulo/examples/simple/dirlist/CountTest.java
* /accumulo/branches/1.5/test/system/auto/TestUtils.py
","28/Feb/13 01:36;hudson;Integrated in Accumulo-Trunk #748 (See [https://builds.apache.org/job/Accumulo-Trunk/748/])
    merging changes from 1.5

ACCUMULO-1118 - updating cli's default password to be empty, and some of the tests appropriately
ACCUMULO-1104, ACCUMULO-1093, ACCUMULO-1094, ACCUMULO-1095, ACCUMULO-1099, ACCUMULO-1097, ACCUMULO-1102 - Improve documentation
ACCUMULO-858: Parse Exception During Run of Maven Changes Report Plugin
ACCUMULO-1120 - credentials now getting properly read (Revision 1451008)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_design.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/dirlist/CountTest.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","28/Feb/13 02:31;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #107 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/107/])
    merging changes from 1.5

ACCUMULO-1118 - updating cli's default password to be empty, and some of the tests appropriately
ACCUMULO-1104, ACCUMULO-1093, ACCUMULO-1094, ACCUMULO-1095, ACCUMULO-1099, ACCUMULO-1097, ACCUMULO-1102 - Improve documentation
ACCUMULO-858: Parse Exception During Run of Maven Changes Report Plugin
ACCUMULO-1120 - credentials now getting properly read (Revision 1451008)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_design.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/dirlist/CountTest.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Must kill hdfs processes during testing,ACCUMULO-636,12560691,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,kturner,kturner,14/Jun/12 21:46,26/Feb/13 18:13,13/Mar/19 22:01,26/Feb/13 18:13,,,,,,,,1.5.0,,,,,,,,,0,,,,,"When running continuous ingest and random walk test we also run the agitator perl script which kills accumulo processes.  Now that the loggers are gone and write ahead logs are written directly to HDFS, we need to kill hdfs processes during testing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-06 15:23:23.409,,,no_permission,,,,,,,,,,,,245594,,,Wed Feb 06 23:50:44 UTC 2013,,,,,,0|i06bxr:,34867,,,,,,,,17/Jul/12 15:13;kturner;See HBASE-6401,"06/Feb/13 15:23;hudson;Integrated in Accumulo-Trunk #711 (See [https://builds.apache.org/job/Accumulo-Trunk/711/])
    ACCUMULO-636 randomly kill datanodes (Revision 1442989)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/test/system/continuous/agitator.pl
* /accumulo/trunk/test/system/continuous/continuous-env.sh.example
","06/Feb/13 15:29;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #69 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/69/])
    ACCUMULO-636 randomly kill datanodes (Revision 1442989)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/test/system/continuous/agitator.pl
* /accumulo/trunk/test/system/continuous/continuous-env.sh.example
","06/Feb/13 20:14;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #71 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/71/])
    ACCUMULO-636 need to get HADOOP_PREFIX from env (Revision 1443159)
ACCUMULO-636 randomly shutdown every now and then; license headers (Revision 1443145)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/test/system/continuous/agitator.pl

ecn : 
Files : 
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooLock.java
* /accumulo/trunk/proxy/proxy.properties
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Shutdown.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/StartAll.java
* /accumulo/trunk/test/system/randomwalk/conf/modules/Concurrent.xml
","06/Feb/13 20:20;hudson;Integrated in Accumulo-Trunk #713 (See [https://builds.apache.org/job/Accumulo-Trunk/713/])
    ACCUMULO-636 need to get HADOOP_PREFIX from env (Revision 1443159)
ACCUMULO-636 randomly shutdown every now and then; license headers (Revision 1443145)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/test/system/continuous/agitator.pl

ecn : 
Files : 
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooLock.java
* /accumulo/trunk/proxy/proxy.properties
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Shutdown.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/StartAll.java
* /accumulo/trunk/test/system/randomwalk/conf/modules/Concurrent.xml
","06/Feb/13 23:43;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #72 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/72/])
    ACCUMULO-636 fix read of env var in perl; ugh... perl (Revision 1443214)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/test/system/continuous/agitator.pl
* /accumulo/trunk/test/system/continuous/start-agitator.sh
","06/Feb/13 23:50;hudson;Integrated in Accumulo-Trunk #714 (See [https://builds.apache.org/job/Accumulo-Trunk/714/])
    ACCUMULO-636 fix read of env var in perl; ugh... perl (Revision 1443214)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/test/system/continuous/agitator.pl
* /accumulo/trunk/test/system/continuous/start-agitator.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Randomwalk Config test depends on commons-math,ACCUMULO-1081,12633436,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,elserj,elserj,elserj,21/Feb/13 17:46,22/Feb/13 02:28,13/Mar/19 22:01,21/Feb/13 18:34,1.5.0,,,,,,,1.5.0,,,test,,,,,,0,,,,,"org.apache.accumulo.test.randomwalk.concurrent.Config uses RandomData from commons-math but the module doesn't have commons-math listed as a dependency.

Noticed this when trying to build against CDH3u5 artifacts, e.g. `mvn package -Dhadoop.version=0.20.2-cdh3u5 -Dzookeeper.version=3.3.5-cdh3u5`.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-22 02:27:45.435,,,no_permission,,,,,,,,,,,,313931,,,Fri Feb 22 02:28:04 UTC 2013,,,,,,0|i1i69z:,314276,,,,,,,,21/Feb/13 18:34;elserj;Fixed in 1448760. Perhaps worth noting that I didn't track through why the build against hadoop-1.0.4 works fine.,"21/Feb/13 18:56;elserj;For some closure, hadoop-core-1.0.4 includes commons-math-2.1 as a dependency whereas hadoop-core-0.20.2-cdh3u5 does not which explains what I was seeing.","22/Feb/13 02:27;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #100 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/100/])
    ACCUMULO-1080 make it easy to see when a offline tablet has walogs
ACCUMULO-1081 Add a dependency to commons-math for the configuration randomwalk tests (Revision 1448807)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/FindOfflineTablets.java
* /accumulo/trunk/src
* /accumulo/trunk/test/pom.xml
","22/Feb/13 02:28;hudson;Integrated in Accumulo-Trunk #742 (See [https://builds.apache.org/job/Accumulo-Trunk/742/])
    ACCUMULO-1080 make it easy to see when a offline tablet has walogs
ACCUMULO-1081 Add a dependency to commons-math for the configuration randomwalk tests (Revision 1448807)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/FindOfflineTablets.java
* /accumulo/trunk/src
* /accumulo/trunk/test/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
gc is getting an authentication error,ACCUMULO-1060,12631806,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,vines,ecn,ecn,11/Feb/13 20:36,12/Feb/13 00:51,13/Mar/19 22:01,11/Feb/13 23:49,,,,,,,,1.5.0,,,gc,,,,,,0,,,,,"Just started seeing this. TServers/monitor have no problems authenticating.


{noformat}
Unable to scan metadata table
	java.lang.RuntimeException: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_CREDENTIALS for user !SYSTEM - Username or Password is Invalid
		at org.apache.accumulo.core.client.impl.ScannerIterator.hasNext(ScannerIterator.java:174)
		at org.apache.accumulo.server.util.MetadataTable$LogEntryIterator.hasNext(MetadataTable.java:930)
		at org.apache.accumulo.server.gc.GarbageCollectWriteAheadLogs.removeMetadataEntries(GarbageCollectWriteAheadLogs.java:174)
		at org.apache.accumulo.server.gc.GarbageCollectWriteAheadLogs.collect(GarbageCollectWriteAheadLogs.java:82)
		at org.apache.accumulo.server.gc.SimpleGarbageCollector.run(SimpleGarbageCollector.java:302)
		at org.apache.accumulo.server.gc.SimpleGarbageCollector.main(SimpleGarbageCollector.java:162)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
		at java.lang.reflect.Method.invoke(Method.java:597)
		at org.apache.accumulo.start.Main$1.run(Main.java:97)
		at java.lang.Thread.run(Thread.java:662)
	Caused by: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_CREDENTIALS for user !SYSTEM - Username or Password is Invalid
		at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:474)
		at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:298)
		at org.apache.accumulo.core.client.impl.ScannerIterator$Reader.run(ScannerIterator.java:82)
		at org.apache.accumulo.core.client.impl.ScannerIterator.hasNext(ScannerIterator.java:164)
		... 11 more
	Caused by: ThriftSecurityException(user:!SYSTEM, code:BAD_CREDENTIALS)
		at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$startScan_result$startScan_resultStandardScheme.read(TabletClientService.java:4652)
		at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$startScan_result$startScan_resultStandardScheme.read(TabletClientService.java:4629)
		at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$startScan_result.read(TabletClientService.java:4552)
		at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
		at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_startScan(TabletClientService.java:209)
		at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.startScan(TabletClientService.java:186)
		at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:419)
		... 14 more
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-11 23:49:00.764,,,no_permission,,,,,,,,,,,,312302,,,Tue Feb 12 00:51:56 UTC 2013,,,,,,0|i1hw7z:,312648,,,,,,,,"11/Feb/13 23:49;vines;Got it, there's a token serialization mismatch. Between the refactoring and keeping deprecated methods, there were a few cases throughout the code where the serialized bytes of a SecurityToken were extracted from a Credential and resupplied to a getConnector method. These bytes were then treated as a password, resulting in a mismatch. CredentialHelper.extractToken(Credential) will reassemble a SecurityToken give the canonical class name and serialized version of it. This code is used in the server as well, but only after the token class has been verified as valid by the authenticator.","12/Feb/13 00:35;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #84 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/84/])
    ACCUMULO-1060 - bug found, explanation in comments of ticket (Revision 1444996)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
","12/Feb/13 00:51;hudson;Integrated in Accumulo-Trunk #726 (See [https://builds.apache.org/job/Accumulo-Trunk/726/])
    ACCUMULO-1060 - bug found, explanation in comments of ticket (Revision 1444996)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
encryption changes break diagnostic LogReader,ACCUMULO-1032,12630648,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,ecn,ecn,04/Feb/13 14:53,04/Feb/13 23:59,13/Mar/19 22:01,04/Feb/13 19:45,,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"Trying to debug a continuous ingest test:

{noformat}
$ ./bin/accumulo org.apache.accumulo.server.logger.LogReader /accumulo/wal/some/filename
ava.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.accumulo.start.Main$1.run(Main.java:97)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.UTFDataFormatException: malformed input around byte 542
	at java.io.DataInputStream.readUTF(DataInputStream.java:617)
	at java.io.DataInputStream.readUTF(DataInputStream.java:547)
	at org.apache.accumulo.server.logger.LogFileKey.readFields(LogFileKey.java:51)
	at org.apache.accumulo.server.logger.LogReader.main(LogReader.java:105)
	... 6 more
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-958,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-04 19:17:18.41,,,no_permission,,,,,,,,,,,,311144,,,Mon Feb 04 23:59:54 UTC 2013,,,,,,0|i1hp33:,311491,,,,,,,,"04/Feb/13 15:05;ecn;Reading the magic in the new format might be broken.  It does not protect against some crazy initial value from the old log file format, which might cause it to read the entire file as a single UTF string.",04/Feb/13 15:24;ecn;Changing to a blocker: this is needed this during testing to debug WAL errors,"04/Feb/13 19:17;supermallen;I'll be fixing this today.  Turns out LogReader is the second spot that reads the WAL log files, and I thought there was only one.","04/Feb/13 19:45;ecn;I had to fix it a little bit to do my debugging, so I fixed it myself.","04/Feb/13 19:49;supermallen;OK, thanks Eric.","04/Feb/13 23:07;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #60 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/60/])
    ACCUMULO-1032 move header reading to a utility method and use it in LogReader (Revision 1442303)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/logger/LogReader.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/DfsLogger.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/LogSorter.java
","04/Feb/13 23:59;hudson;Integrated in Accumulo-Trunk #702 (See [https://builds.apache.org/job/Accumulo-Trunk/702/])
    ACCUMULO-1032 move header reading to a utility method and use it in LogReader (Revision 1442303)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/logger/LogReader.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/DfsLogger.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/LogSorter.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Combiners documention could be improved,ACCUMULO-906,12623995,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,ecn,ecn,14/Dec/12 15:36,19/Dec/12 18:15,13/Mar/19 22:01,19/Dec/12 17:21,1.4.0,1.4.1,1.4.2,,,,,1.4.3,1.5.0,,,,,,,,0,,,,,"Goal: sum all the values across all columns.

{noformat}
> createtable animal
> deleteiter -n vers -scan -minc -majc
> setiter -t animal -p 10 -scan -n sum -class org.apache.accumulo.core.iterators.user.SummingCombiner
SummingCombiner interprets Values as Longs and adds them together.  A variety of encodings (variable length, fixed length, or string) are available
----------> set SummingCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.: true
----------> set SummingCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non-alphanum chars using %<hex>.: 
----------> set SummingCombiner parameter lossy, if true, failed decodes are ignored. Otherwise combiner will error on failed decodes (default false): <TRUE|FALSE>: 
----------> set SummingCombiner parameter type, <VARLEN|FIXEDLEN|STRING|fullClassName>: STRING
> insert mammal cow ellie 1
> insert mammal cow nell  1
> insert mammal man eric  1
> scan
expected: mammal dontcare : dontcare 3
{noformat}

Where ""dontcare"" can come back with anything; I just don't care.
But I just get this

{noformat}
mammal cow:ellie []    1
mammal cow:nell []    1
mammal man:eric []    1
{noformat}

I can't get the combiner to come back with a sum of mammals or cows.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-14 17:12:31.829,,,no_permission,,,,,,,,,,,,297895,,,Wed Dec 19 18:15:50 UTC 2012,,,,,,0|i14vwf:,236633,,,,,,,,"14/Dec/12 17:12;billie.rinaldi;Setting ""all"" to true applies the Combiner to every column instead of just specific columns.  So, if you inserted more data:
{noformat}
> insert mammal cow ellie 1
> insert mammal cow ellie 1
> insert mammal cow ellie 1
> insert mammal cow nell  1
> insert mammal cow nell  1
> insert mammal man eric  1
{noformat}
and then scanned with all=true, you should get
{noformat}
mammal cow:ellie []    3
mammal cow:nell []    2
mammal man:eric []    1
{noformat}
We don't currently support combining values across different columns.",19/Dec/12 17:21;ecn;fixed with 1423966.,"19/Dec/12 18:15;hudson;Integrated in Accumulo-Trunk #585 (See [https://builds.apache.org/job/Accumulo-Trunk/585/])
    ACCUMULO-906 clarify the fact that a Combiner only works over different versions (Revision 1423966)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"master is ""leaking"" ZooLock objects",ACCUMULO-766,12608332,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,ecn,ecn,19/Sep/12 21:06,09/Nov/12 16:08,13/Mar/19 22:01,09/Oct/12 22:25,1.4.0,1.4.1,,,,,,1.4.2,1.5.0,,master,,,,,,0,,,,,"Analysing the memory usage of the master, I noticed many ZooLock objects.  1.4e7 of them, in fact.",discovered on a large cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-09 22:25:13.281,,,no_permission,,,,,,,,,,,,245597,,,Fri Nov 09 16:08:41 UTC 2012,,,,,,0|i06byn:,34871,,,,,,,,09/Oct/12 22:25;kturner;ACCUMULO-799 was opened for follow on work for 1.5.,"09/Nov/12 16:08;hudson;Integrated in Accumulo-Trunk #545 (See [https://builds.apache.org/job/Accumulo-Trunk/545/])
    ACCUMULO-766
There is a race condition between checking for a lock
and removing the node that holds the lock.  This causes
a spurious error message in the logs (and monitor). (Revision 1407489)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
don't log the instance.secret,ACCUMULO-800,12611159,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,,ecn,ecn,10/Oct/12 12:13,15/Oct/12 14:22,13/Mar/19 22:01,15/Oct/12 14:18,1.3.6,1.4.1,,,,,,1.4.2,1.5.0,,,,,,,,1,newbie,,,,"Like passwords, logging the instance secret is probably not great for security.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-13 09:03:57.762,,,no_permission,,,,,,,,,,,,246958,,,Mon Oct 15 14:18:35 UTC 2012,,,,,,0|i07xf3:,44181,,,,,,,,"13/Oct/12 09:03;ctubbsii;This seems like a trivial fix, but could be pretty important, so I put it as a blocker for 1.4.2.
[~mdrob], can you identify which specific log message you are referring to?",15/Oct/12 14:18;ecn;fixed in r1397177 and r1397176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tablet locator fails when the metadata table has empty sections,ACCUMULO-806,12611426,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,ecn,ecn,11/Oct/12 20:28,12/Oct/12 00:25,13/Mar/19 22:01,12/Oct/12 00:25,1.4.0,1.4.1,,,,,,1.4.2,1.5.0,,client,,,,,,0,,,,,"After merging a large number of tablets away, the metadata table had several sections without any entries.

Bulk import into the merged section of the table failed, constantly retrying to find the tablet, and failing.",large cluster environment,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-12 00:24:58.46,,,no_permission,,,,,,,,,,,,247788,,,Fri Oct 12 00:24:58 UTC 2012,,,,,,0|i08puv:,48788,,,,,,,,"12/Oct/12 00:24;kturner;I checked in a fix r1397383 and r1397391

You can easily reproduce this problem in the shell.  Below is an example.

{noformat}
root@test15> createtable foo
root@test15 foo> tables -l
!METADATA       =>         !0
foo             =>          2
trace           =>          1
root@test15 foo> insert a cf1 cq1 v1            
root@test15 foo> addsplits -t !METADATA 2;c 2;f 2;j 2;m 2;r
{noformat}

Exit the shell after doing the above because the location of foo's one tablet is cached.  If you start the shell again and scan foo without the patch, it will hang.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
close consistency check failure,ACCUMULO-681,12598181,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,ecn,ecn,ecn,10/Jul/12 13:06,10/Oct/12 12:45,13/Mar/19 22:01,10/Oct/12 12:45,,,,,,,,1.4.2,1.5.0,,,,,,,,0,,,,,"I recently added tablet server admin shutdown to the Concurrent randomwalk test.

After an hour, the following table problem appeared:

{noformat}
10 12:00:21,755 [tabletserver.Tablet] ERROR: Data file in !METADATA differ from in memory data !0;!0<<  
{noformat}

Note that this is the root tablet, so some other process was updating the files behind this server's back; I suspect inconsistent assignment.
",10 node test cluster running randomwalk Concurrent graph,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,245595,,,Wed Oct 10 12:45:08 UTC 2012,,,,,,0|i06by7:,34869,,,,,,,,"10/Jul/12 13:42;ecn;||The files on disk:||
|/root_tablet/A0002pyh.rf|
|/root_tablet/F0002pu6.rf| 
|/root_tablet/F0002qg7.rf| 
|/root_tablet/F0002qg8.rf| 
|/root_tablet/F0002ql1.rf|

||The files in memory:||
|/root_tablet/A0002mqs.rf|
|/root_tablet/F0002mrf.rf|
|/root_tablet/F0002n8x.rf|
|/root_tablet/F0002oda.rf|
|/root_tablet/F0002orh.rf|
|/root_tablet/F0002p03.rf|
|/root_tablet/F0002p3m.rf|
|/root_tablet/F0002p85.rf|
|/root_tablet/F0002p87.rf|
|/root_tablet/F0002pb8.rf|
|/root_tablet/F0002pi1.rf|
|/root_tablet/F0002pu2.rf|
|/root_tablet/F0002pu6.rf|
|/root_tablet/F0002qg7.rf|
|/root_tablet/F0002qg8.rf|
|/root_tablet/F0002ql1.rf|

So, what happened to A0002mqs, for example?

It was created by node3 at 11:58:11:
{noformat}
11:58:11,159 [tabletserver.Tablet] TABLET_HIST: !0;!0<< MajC [/root_tablet/A0002l9z.rf, /root_tablet/F0002la1.rf] --> /root_tablet/A0002mqs.rf
{noformat}

It was major compacted at 12:00:11 by node4:

{noformat}
12:00:11,786 [tabletserver.Tablet] TABLET_HIST: !0;!0<< MajC [/root_tablet/A0002mqs.rf, /root_tablet/F0002mrf.rf, /root_tablet/F0002n8x.rf, /root_tablet/F0002oda.rf, /root_tablet/F0002orh.rf, /root_tablet/F0002p03.rf, /root_tablet/F0002p3m.rf, /root_tablet/F0002p85.rf, /root_tablet/F0002p87.rf, /root_tablet/F0002pb8.rf] --> /root_tablet/C0002pyf.rf
{noformat}

Let's see where the tablet lived between 11:58 and 12:00:

{noformat}
10 11:56:24,664 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node6
10 11:57:04,971 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node6
10 11:57:04,986 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node9
10 11:57:06,991 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node9
10 11:57:07,074 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node12
10 11:57:50,187 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node12
10 11:57:50,301 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node3
10 11:59:04,506 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node3
10 11:59:04,527 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node9
10 11:59:15,736 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node9
10 11:59:15,758 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node10
10 11:59:20,652 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node10
10 11:59:20,713 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node11
10 11:59:24,687 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node11
10 11:59:24,743 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node9
10 11:59:35,354 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node9
10 11:59:35,530 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node11
10 11:59:39,069 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node11
10 11:59:39,117 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node12
10 11:59:39,169 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node12
10 11:59:39,325 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node10
10 11:59:41,532 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node10
10 11:59:41,696 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node9
10 11:59:43,803 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node9
10 11:59:43,903 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node6
10 11:59:58,634 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node6
10 11:59:58,730 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node7
10 12:00:00,676 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node7
10 12:00:00,823 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node10
10 12:00:07,604 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node10
10 12:00:07,668 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node10
10 12:00:07,681 [tabletserver.Tablet] TABLET_HIST: !0;!0<< closed   node10
10 12:00:07,765 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node4
10 12:00:07,783 [tabletserver.Tablet] TABLET_HIST: !0;!0<< opened    node10  <---
{noformat}

Well, the tablet certainly moves around. The double-open seems to be suspicious.
","10/Jul/12 14:17;ecn;Strange... here's the master logs, where the tablet is assigned to node4
{noformat}
10 12:00:02,535 [master.Master] DEBUG: Root Tablet assigning tablet !0;!0<<=192.168.117.11:9997[2383418e9a17f4b]
10 12:00:09,463 [master.Master] DEBUG: Root Tablet assigning tablet !0;!0<<=192.168.117.11:9997[2383418e9a17f4b]
10 12:00:09,548 [master.Master] DEBUG: Root Tablet assigning tablet !0;!0<<=192.168.117.5:9997[2383418e9a17f44]
{noformat}

So, if node10 processed a late message, and saw a cached or unsynched future_location set to itself, it might open the root tablet at the same time as node4.



",10/Oct/12 12:45;ecn;Fixed with r1359764.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Data lost with hdfs write ahead log,ACCUMULO-623,12559619,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,kturner,kturner,06/Jun/12 23:09,07/Aug/12 02:09,13/Mar/19 22:01,16/Jul/12 19:11,,,,,,,,1.5.0,,,,,,,,,0,,,,,"I shut my machine down with Accumulo, Zookeeper, and HDFS running.  When I restarted it, Accumulo failed to recover its write ahead log because it was zero length.  I wondered if this was because I shutdown HDFS so I tried the following on my single node Accumulo instance.

 * start HDFS and zookeeper
 * init & start Accumulo
 * created a table and insert some data
 * pkill -f java
 * restart everything
 * Accumulo fails to start because walog is zero length

Saw excpetions like the following

{noformat}

06 18:58:44,581 [log.SortedLogRecovery] INFO : Looking at mutations from /accumulo/recovery/def72721-5c64-4755-87cc-2e8cfc3002b7 for !0;!0<<
06 18:58:44,590 [tabletserver.TabletServer] WARN : exception trying to assign tablet !0;!0<< /root_tablet
java.lang.RuntimeException: java.io.IOException: java.lang.RuntimeException: Unable to read log entries
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1458)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1295)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1134)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1121)
        at org.apache.accumulo.server.tabletserver.TabletServer$AssignmentHandler.run(TabletServer.java:2477)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:680)
Caused by: java.io.IOException: java.lang.RuntimeException: Unable to read log entries
        at org.apache.accumulo.server.tabletserver.log.TabletServerLogger.recover(TabletServerLogger.java:428)
        at org.apache.accumulo.server.tabletserver.TabletServer.recover(TabletServer.java:3206)
        at org.apache.accumulo.server.tabletserver.Tablet.<init>(Tablet.java:1426)
        ... 6 more
Caused by: java.lang.RuntimeException: Unable to read log entries
        at org.apache.accumulo.server.tabletserver.log.SortedLogRecovery.findLastStartToFinish(SortedLogRecovery.java:125)
        at org.apache.accumulo.server.tabletserver.log.SortedLogRecovery.recover(SortedLogRecovery.java:89)
        at org.apache.accumulo.server.tabletserver.log.TabletServerLogger.recover(TabletServerLogger.java:426)
        ... 8 more

{noformat}

When trying to run LogReader on the files, it prints nothing.  

{noformat}
$ ./bin/accumulo org.apache.accumulo.server.logger.LogReader /accumulo/recovery/def72721-5c64-4755-87cc-2e8cfc3002b7
06 19:04:37,147 [util.NativeCodeLoader] WARN : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
$ ./bin/accumulo org.apache.accumulo.server.logger.LogReader /accumulo/wal/127.0.0.1+40200/def72721-5c64-4755-87cc-2e8cfc3002b7
$ 
{noformat}



","MacOSX, Hadoop 1.0.3, zookeeper 3.3.3",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-08-07 02:09:59.91,,,no_permission,,,,,,,,,,,,246443,,,Tue Aug 07 02:09:59 UTC 2012,,,,,,0|i07m27:,42340,,,,,,,,06/Jun/12 23:11;kturner;The hdfs write ahead log is new in trunk.  This does not affect 1.4.,"14/Jun/12 20:37;kturner;I tried another experiment.  Instead of killing all java processes on my single node instance, I did the following.

 * start HDFS and zookeeper
 * init & start Accumulo
 * created a table and insert some data 
 * kill data node
 * kill all accumulo processes
 * restart datanode
 * restart accumulo
 * recovery fails 

Under this scenario recovery fails differently.  The following is from the tablet server logs, I get an NPE in hdfs client code.

{noformat}
14 16:26:17,253 [log.LogSorter] INFO : Zookeeper references 1 recoveries, attempting locks14 16:26:17,254 [log.LogSorter] DEBUG: Attempting to lock b67eb806-6ef1-4ecc-b739-a4ee90e08086
14 16:26:17,262 [log.LogSorter] INFO : got lock for b67eb806-6ef1-4ecc-b739-a4ee90e08086
14 16:26:17,264 [log.LogSorter] INFO : Copying /accumulo/wal/127.0.0.1+40200/b67eb806-6ef1-4ecc-b739-a4ee90e08086 to /accumulo/recovery/b67eb806-6ef1-4ecc-b739-a4ee90e08086
14 16:26:17,300 [log.LogSorter] ERROR: Unexpected error
java.lang.NullPointerException
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.updateBlockInfo(DFSClient.java:1885)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1858)        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.<init>(DFSClient.java:1834)
        at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:578)        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:154)
        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:427)
        at org.apache.accumulo.server.tabletserver.log.LogSorter.startSort(LogSorter.java:295)
        at org.apache.accumulo.server.tabletserver.log.LogSorter.attemptRecoveries(LogSorter.java:266)
        at org.apache.accumulo.server.tabletserver.log.LogSorter.access$200(LogSorter.java:60)
        at org.apache.accumulo.server.tabletserver.log.LogSorter$1.process(LogSorter.java:204)
        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:530)        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:506)

{noformat}

An update, if I kill accumulo after this and restart HDFS, then I am back to the first problem of a zero length walog file.","14/Jun/12 20:52;kturner;Did the following experiment killing the namenode.  In this case recovery succeeds.

 * start HDFS and zookeeper
 * init & start Accumulo
 * created a table and insert some data 
 * kill name node
 * kill all accumulo processes
 * restart namenode
 * restart accumulo
 * recovery succeeds  ","14/Jun/12 21:39;kturner;I was doing some research looking for HDFS issues, turns out I just need to set dfs.support.append to true in hdfs-site.xml.  After doing this, the previous two scenarios that failed to recover now work.  This needs to be documented in the README.  Since the consequences of not setting this property are so severe, maybe tablet servers and the master should refuse to start unless it is set to true.

The property seems kinda screwy. It enables append which is broken, but also enables sync.",14/Jun/12 22:25;kturner;see HADOOP-8230,"16/Jul/12 17:39;kturner;John V and I were discussing this, one possibility is that a tserver will only start if dfs.durable.sync OR dfs.support.append is set to true.  This is kinda screwy because at some point the property dfs.support.append (which defaults to false) will go away and the property dfs.durable.sync will appear (which defaults to true).  However, I do not think there is a way to determine what a property defaults to in HAdoop, because this is just hardcoded into code that uses the prop.  So a user would need to explicitly set dfs.durable.sync to true in their config even though this is the default.  See HADOOP-8365.","07/Aug/12 02:09;elserj;Interesting, I added some messages in TabletServer to dump those variables on my instance: 'dfs.durable.sync'=false and 'dfs.support.append'=true. I have neither set in my config files.

Cloudera's site (https://ccp.cloudera.com/display/CDHDOC/Incompatible+Changes) states that starting in CDH3u4 dfs.support.append is true by default. Given that I'm on CDH3u3, apparently that's a little off or I stumbled upon tlipcon's magic pixie dust ;)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Data loss possible when tablet killed immediately after recovery,ACCUMULO-444,12545250,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,kturner,kturner,05/Mar/12 23:09,06/Mar/12 16:45,13/Mar/19 22:01,06/Mar/12 16:12,1.3.5-incubating,,,,,,,1.3.6,1.4.0,,tserver,,,,,,0,14_qa_bug,,,,"Came in after a weekend of running test to find the Shard random walk test had lost data in its index table.  After debugging I found the following sequence of events occurred.

 * Mutation X was written to shard index on Tablet T1
 * X was minor compacted to file F1
 * Tablet server serving T1 was killed
 * When T1 came up on another tablet server, it did not know about F1

The above sequence of events indicate that the !METADATA table lost data.  So I started looking into that, and found the following sequence of events.

 * Tablet server T1 serving METADATA tablet MT was killed
 * MT comes up on another tablet server T2
 * Mutation Y is written to MT about file F1 for tablet T1
 * Tablet server T2 is killed.
 * MT comes up in tablet server T3
 * The mutations for MT from T1 are recovered, but not from T2.. therefore Y is lost

There is code that supposed to handle this situation, but its not working... I think this issue exist in 1.3

Data loss is not certain in this situation.  In the scenario above, when MT is loaded on T2 a minor compaction is started.  If the server is killed before this minor compaction completes then data loss will likely occur.

  
","Running random walk, continuous ingest, and agitator on 10 node cluster.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,230436,,,Tue Mar 06 16:45:25 UTC 2012,,,,,,0|i07n5j:,42517,,,,,,,,05/Mar/12 23:13;kturner;I think ACCUMULO-388 would have made this bug show up sooner in testing.  ,"06/Mar/12 16:45;kturner;Posting the tablet server logs that show how this scenario played out.

Below are the logs for tablet server T2

{noformat}
04 04:46:32,613 [log.RemoteLogger] DEBUG: Got new write-ahead log: xxx.xxx.xxx.10:11224/3f729699-6a7b-4ed0-8e41-cd767056a62e
04 04:46:32,615 [log.RemoteLogger] DEBUG: Got new write-ahead log: xxx.xxx.xxx.11:11224/6042d841-0f4f-40a0-b480-1e7d51047982

04 04:50:59,873 [tabletserver.TabletServer] DEBUG: Loading extent: !0;~;!0<
04 04:50:59,877 [util.MetadataTable] INFO : Returning logs [!0;~; 661acb95-8fb9-4ac7-8545-83032f05eb2b (257)] for extent !0;~;!0<
04 04:50:59,877 [tabletserver.Tablet] DEBUG: got [!0;~; 661acb95-8fb9-4ac7-8545-83032f05eb2b (257)] for logs for !0;~;!0<
04 04:50:59,901 [tabletserver.Tablet] INFO : Starting Write-Ahead Log recovery for !0;~;!0<
04 04:50:59,901 [tabletserver.TabletServer] INFO : Looking for /accumulo/recovery/661acb95-8fb9-4ac7-8545-83032f05eb2b.recovered/finished
04 04:50:59,902 [log.SortedLogRecovery] INFO : Looking at mutations from /accumulo/recovery/661acb95-8fb9-4ac7-8545-83032f05eb2b.recovered for !0;~;!0<
04 04:50:59,914 [log.SortedLogRecovery] DEBUG: Found tid, seq 257 9
04 04:50:59,928 [log.SortedLogRecovery] INFO : Scanning for mutations starting at sequence number 10 for tid 257
04 04:51:00,047 [log.SortedLogRecovery] INFO : Recovery complete for /accumulo/recovery/661acb95-8fb9-4ac7-8545-83032f05eb2b.recovered
04 04:51:00,047 [tabletserver.Tablet] INFO : Write-Ahead Log recovery complete for !0;~;!0< (4721 mutations applied, 21111 entries created)
04 04:51:00,047 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 

04 04:51:00,066 [tabletserver.TabletServer] INFO : Adding 2 logs for extent !0;~;!0< as alias 353

04 05:01:25,326 [tabletserver.TabletServer] FATAL: Lost tablet server lock (reason = LOCK_DELETED), exiting.
04 05:08:48,307 [server.Accumulo] INFO : tserver starting
{noformat}

Below is the lost mutation that was written to walog 3f729699-6a7b-4ed0-8e41-cd767056a62e on T2.

{noformat}
MUTATION 353 3
1 mutations:
  7kb;000054
      file:/t-000h69l/F000h8ae.rf [system]:2175897 [] 64826,16582
      srv:time [system]:2175897 [] M1330836309355
      last:335d51be2cb3cc6 [system]:2175897 [] xxx.xxx.xxx.11:9997
      log:xxx.xxx.xxx.10:11224/d1699ae9-04c7-4128-8b9d-a6355af0393a [system]:2175897 [] <deleted>
      log:xxx.xxx.xxx.13:11224/4b28c8e0-8729-4d52-a0a7-e080e03601a0 [system]:2175897 [] <deleted>
      srv:flush [system]:2175897 [] 0
      srv:lock [system]:2175897 [] tservers/xxx.xxx.xxx.11:9997/zlock-0000000001$335d51be2cb3cc6
{noformat}

Below shows that the metadata table was loaded on tablet server T3, and even though it should recover more data is recovers the same amount as when it recovered on T2.  This shows that all data written while the tablet was hosted on T2 was lost.

{noformat}
04 05:01:49,458 [tabletserver.TabletServer] DEBUG: Loading extent: !0;~;!0<
04 05:01:49,460 [util.MetadataTable] INFO : Returning logs [!0;~; 661acb95-8fb9-4ac7-8545-83032f05eb2b (257), !0;~; 3f729699-6a7b-4ed0-8e41-cd767056a62e (353)] for extent !0;~;!0<
04 05:01:49,461 [tabletserver.Tablet] DEBUG: got [!0;~; 661acb95-8fb9-4ac7-8545-83032f05eb2b (257), !0;~; 3f729699-6a7b-4ed0-8e41-cd767056a62e (353)] for logs for !0;~;!0<
04 05:01:49,474 [tabletserver.Tablet] INFO : Starting Write-Ahead Log recovery for !0;~;!0<
04 05:01:49,489 [log.SortedLogRecovery] DEBUG: Found tid, seq 257 9
04 05:01:49,495 [log.SortedLogRecovery] INFO : Looking at mutations from /accumulo/recovery/3f729699-6a7b-4ed0-8e41-cd767056a62e.recovered for !0;~;!0<
04 05:01:49,500 [log.SortedLogRecovery] DEBUG: Found tid, seq 353 3
04 05:01:49,510 [log.SortedLogRecovery] INFO : Scanning for mutations starting at sequence number 10 for tid 257
04 05:01:49,624 [log.SortedLogRecovery] INFO : Recovery complete for /accumulo/recovery/661acb95-8fb9-4ac7-8545-83032f05eb2b.recovered
04 05:01:49,629 [log.SortedLogRecovery] INFO : Scanning for mutations starting at sequence number 10 for tid 353
04 05:01:49,674 [log.SortedLogRecovery] INFO : Recovery complete for /accumulo/recovery/3f729699-6a7b-4ed0-8e41-cd767056a62e.recovered
04 05:01:49,674 [tabletserver.Tablet] INFO : Write-Ahead Log recovery complete for !0;~;!0< (4721 mutations applied, 21111 entries created)
04 05:01:49,674 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Data lost when tablets moving around frequently,ACCUMULO-427,12544293,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,kturner,kturner,kturner,27/Feb/12 19:01,28/Feb/12 18:30,13/Mar/19 22:01,28/Feb/12 18:30,,,,,,,,1.4.0,,,tserver,,,,,,0,14_qa_bug,,,,The shard random walk test failed when verifiy its new index.  This test has two tables a document table and a sharded index table used to find documents.  The test has a node that rebuilds the index from the document table and then verifies that the new and old index are the same.  This verification failed.  The failure was all realted to data loss in one tablet in the new index table.  The data that was lost was read from two tablets in the document table.  None of the lost data appeared in any write ahead logs.  The tablet that lost data was being moved around very frequently during the time of the data loss.  All of the evidence points to a bug in the batch writer or the tablet server code related to writing data.,10 node cluster running random walk test w/ agitation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,229530,,,Mon Feb 27 21:02:41 UTC 2012,,,,,,0|i07n9b:,42534,,,,,,,,27/Feb/12 19:08;kturner;This bug was triggered by ACCUMULO-329,"27/Feb/12 21:02;kturner;Looking at the code, the following sequence of events will result in data loss. 

 * Client starts update session 
 * Tablet A is unloaded
 * Client sends mutation batch 1 to tablet A, which fails
 * Tablet A is loaded
 * Client sends mutation batch 2 tablet A, which succeeds 
 * Tablet A is unloaded
 * Client sends mutation batch 3 to tablet A, which fails

In the above sequence, the failure of batch 1 is forgotten by the current code.  It assumes batch 1 and 2 were successful and that batch 3 was not.

I think this bug was caused by changes made in 1.4, and does not exist in 1.3.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"removing ""throws IOException"" from method breaks backwards compatibility",ACCUMULO-206,12533787,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Blocker,Fixed,billie.rinaldi,afuchs,afuchs,04/Dec/11 15:30,04/Jan/12 16:48,13/Mar/19 22:01,04/Jan/12 16:48,,,,,,,,,,,client,,,,,,0,,,,,"One example of this is the org.apache.accumulo.core.client.ScannerBase.setScanIterators method. In version 1.3.x this has the signature:

{noformat}
public void setScanIterators(int priority, String iteratorClass, String iteratorName) throws IOException;
{noformat}

But, in the 1.4 branch it reads:

{noformat}
public void setScanIterators(int priority, String iteratorClass, String iteratorName);
{noformat}

Code that compiled against 1.3 and attempts to catch that IOException does not compile against 1.4 with this change, giving the following error:

{noformat}
exception java.io.IOException is never thrown in body of corresponding try statement
{noformat}

I think we should maintain the previous signature on this method in the 1.4 release, even if it doesn't throw an exception (especially because it's deprecated). We also need to look for any other cases like this and decide what to do on a case-by-case basis.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-12-09 17:48:04.906,,,no_permission,,,,,,,,,,,,219513,,,Fri Dec 09 17:48:04 UTC 2011,,,,,,0|i07okv:,42748,,,,,,,,09/Dec/11 17:48;billie.rinaldi;fixed that one; let me know if you see any more.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Wikisearch example doesn't work with 1.5 and later,ACCUMULO-2446,12699798,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,milleruntime,busbey,busbey,10/Mar/14 15:59,17/Feb/17 18:36,13/Mar/19 22:01,17/Feb/17 18:36,1.5.0,,,,,,,,,,contrib,wikisearch,,,,,0,,,,,"The Wikisearch contrib was brought up to speed for working against Accumulo 1.4.x under ACCUMULO-1977, but was left with two problems

* the 1.4.5-SNAPSHOT branch has an independent history from master
* master does not currently work with 1.5.x

Implementer should decide if it's easier to merge the 1.4 branch's fixes (namely the subtasks under ACCUMULO-1977) to master or to start a new 1.5 compat branch based on current 1.4",,"Github user milleruntime closed the pull request at:

    https://github.com/apache/accumulo-wikisearch/pull/2
;13/Dec/16 19:11;githubbot;600","GitHub user milleruntime opened a pull request:

    https://github.com/apache/accumulo-wikisearch/pull/3

    Fixes to query for 1.8 Update

    This should satisfy ACCUMULO-2446 so we can close it. There is still a bug in query when you search on terms not in the index.  But I will file this as a separate bug since its working otherwise.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/milleruntime/accumulo-wikisearch master

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/accumulo-wikisearch/pull/3.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #3
    
----
commit eb573a5188c10fc82ddf911f4a0ab892860335d1
Author: Mike Miller <mmiller@apache.org>
Date:   2017-01-04T19:19:33Z

    Fixes to query for 1.8 Update

----
;16/Feb/17 16:01;githubbot;600","Github user asfgit closed the pull request at:

    https://github.com/apache/accumulo-wikisearch/pull/3
;17/Feb/17 18:30;githubbot;600",,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,ACCUMULO-2779,,,,,ACCUMULO-2020,ACCUMULO-2019,ACCUMULO-2017,ACCUMULO-2018,ACCUMULO-1882,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-13 05:03:50.729,,,no_permission,,,,,,,,,,,,378144,,,Wed Feb 15 22:15:21 UTC 2017,,,,,,0|i1t5pr:,378436,,,,,,,,"13/Mar/14 05:03;bills;The histories for the 1.4.5 branch and master of wikisearch weren't too divergent-- they actually did have a common ancestor, and master is now in a merged state. It will build if users opt not to build the tests (for which I have a fix I plan on cleaning up and pushing tomorrow).",06/May/14 17:52;medined;~wslacum did you get a chance to fix the wikisearch tests?,06/May/14 18:54;medined;Ticket 2779 changes the pom.xml files so that the tests run. Not sure if that resolves this ticket as well.,06/May/14 21:46;bills;Commit 1990979 should've had the tests running under both hadoop 1 and hadoop 2. Were they not working for you?,06/May/14 22:27;medined;Please close this ticket. The tests are working.,"07/May/14 00:16;bills;Just for clarity's sake, are they not working for you without the patch for ACCUMULO-2779? ",07/May/14 00:59;medined;I was not able to run the tests because I did not clone the project within an Accumulo project. That's how I discovered the parent-child dependency. So my experience is not relevant.,"15/Feb/17 22:15;ctubbsii;Removed 1.8.0 from fixVersion. 1.8.0 refers to the Accumulo 1.8.0 release version. The fixVersion should reflect the version of Wikisearch in which the issue is fixed. I recommend creating new versions that correspond to Wikisearch versions, of the form ""wikisearch-x.y.z"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Continuous Ingest clients die,ACCUMULO-2388,12696281,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,mdrob,mdrob,20/Feb/14 15:57,03/Jun/16 18:08,13/Mar/19 22:01,16/Jun/15 21:43,,,,,,,,1.6.3,1.7.1,1.8.0,test,tserver,,,,,0,16_qa_bug,,,,"I was running continuous ingest on a 7 node cluster (5 slaves) and after enabling HDFS agitation, my clients died.

{code:title=ingest.err}
Thread ""org.apache.accumulo.test.continuous.ContinuousIngest"" died java.lang.reflect.InvocationTargetException
java.lang.reflect.InvocationTargetException
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.accumulo.start.Main$1.run(Main.java:137)
at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.reflect.UndeclaredThrowableException
at $Proxy9.addMutation(Unknown Source)
at org.apache.accumulo.test.continuous.ContinuousIngest.main(ContinuousIngest.java:212)
... 6 more
Caused by: java.lang.reflect.InvocationTargetException
at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.accumulo.trace.instrument.TraceProxy$2.invoke(TraceProxy.java:43)
... 8 more
Caused by: org.apache.accumulo.core.client.MutationsRejectedException: # constraint violations : 0 security codes: {} # server errors 1 # exceptions 0
at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.checkForFailures(TabletServerBatchWriter.java:537)
at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.addMutation(TabletServerBatchWriter.java:258)
at org.apache.accumulo.core.client.impl.BatchWriterImpl.addMutation(BatchWriterImpl.java:43)
... 12 more
{code}

{code:title=ingest.out}
UUID 1392844086463 f822a6a9-9592-4b3a-ab3b-1c172be20b96
FLUSH 1392844135523 49047 6165 1000000 1000000
FLUSH 1392844165594 30071 7787 2000000 1000000
FLUSH 1392844195875 30281 7816 3000000 1000000
FLUSH 1392844226787 30912 8086 4000000 1000000
FLUSH 1392844257194 30407 7989 5000000 1000000
FLUSH 1392844287518 30324 7743 6000000 1000000
FLUSH 1392844325833 38315 10933 7000000 1000000
FLUSH 1392844364708 38875 7916 8000000 1000000
FLUSH 1392844395818 31110 8104 9000000 1000000
2014-02-19 13:16:57,444 [impl.TabletServerBatchWriter] ERROR: Server side error on tserver1:10011: org.apache.thrift.TApplicationException: Internal error processing applyUpdates
2014-02-19 13:16:57,446 [impl.TabletServerBatchWriter] ERROR: Failed to send tablet server tserver1:10011 its batch : Error on server tserver1:10011
org.apache.accumulo.core.client.impl.AccumuloServerException: Error on server tserver1:10011
at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.sendMutationsToTabletServer(TabletServerBatchWriter.java:937)
at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.access$1600(TabletServerBatchWriter.java:616)
at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter$SendTask.send(TabletServerBatchWriter.java:801)
at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter$SendTask.run(TabletServerBatchWriter.java:765)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
at java.util.concurrent.FutureTask.run(FutureTask.java:138)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.TApplicationException: Internal error processing applyUpdates
at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:71)
at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_closeUpdate(TabletClientService.java:431)
at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.closeUpdate(TabletClientService.java:417)
at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.sendMutationsToTabletServer(TabletServerBatchWriter.java:899)
... 11 more
{code}

{code:title=tserver.log}
2014-02-19 13:16:56,156 [util.TServerUtils$THsHaServer] WARN : Got an IOException in internalRead!
java.io.IOException: Connection reset by peer
at sun.nio.ch.FileDispatcher.read0(Native Method)
at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)
at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:198)
at sun.nio.ch.IOUtil.read(IOUtil.java:171)
at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:243)
at org.apache.thrift.transport.TNonblockingSocket.read(TNonblockingSocket.java:141)
at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.internalRead(AbstractNonblockingServer.java:515)
at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.read(AbstractNonblockingServer.java:355)
at org.apache.thrift.server.AbstractNonblockingServer$AbstractSelectThread.handleRead(AbstractNonblockingServer.java:202)
at org.apache.thrift.server.TNonblockingServer$SelectAcceptThread.select(TNonblockingServer.java:198)
at org.apache.thrift.server.TNonblockingServer$SelectAcceptThread.run(TNonblockingServer.java:154)
{code}

Note that this last message was not propagated to the monitor for some reason, but that is likely a different issue. (I had been seeing other WARN messages show up earlier.)","1.6.0-SNAPSHOT (sha-1: 0da9a56)
cdh4.5.0","Commit 6965fb07c97cd752d6f5415a39e87b9ff3c1ba7e in accumulo's branch refs/heads/1.6 from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6965fb0 ]

ACCUMULO-2388 Make clients retry in case of HoldTimeoutException
;16/Jun/15 21:42;jira-bot;600","Commit 25475d0a3f05093975439084944972cb73827537 in accumulo's branch refs/heads/1.6 from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=25475d0 ]

Merge branch 'ACCUMULO-2388' of github:keith-turner/accumulo into 1.6
;16/Jun/15 21:42;jira-bot;600","Commit 6965fb07c97cd752d6f5415a39e87b9ff3c1ba7e in accumulo's branch refs/heads/1.7 from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6965fb0 ]

ACCUMULO-2388 Make clients retry in case of HoldTimeoutException
;16/Jun/15 21:42;jira-bot;600","Commit 25475d0a3f05093975439084944972cb73827537 in accumulo's branch refs/heads/1.7 from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=25475d0 ]

Merge branch 'ACCUMULO-2388' of github:keith-turner/accumulo into 1.6
;16/Jun/15 21:42;jira-bot;600","Commit 6965fb07c97cd752d6f5415a39e87b9ff3c1ba7e in accumulo's branch refs/heads/master from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6965fb0 ]

ACCUMULO-2388 Make clients retry in case of HoldTimeoutException
;16/Jun/15 21:42;jira-bot;600","Commit 25475d0a3f05093975439084944972cb73827537 in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=25475d0 ]

Merge branch 'ACCUMULO-2388' of github:keith-turner/accumulo into 1.6
;16/Jun/15 21:42;jira-bot;600",,,,,,,,,,,,,,,,,,0,3600,,,0,3600,,,,,,,,,,,,,,,,,,,,,,14/Apr/14 21:15;kturner;ACCUMULO-2388-1.patch;https://issues.apache.org/jira/secure/attachment/12640143/ACCUMULO-2388-1.patch,24/Feb/14 20:52;mdrob;tracer.debug.log;https://issues.apache.org/jira/secure/attachment/12630794/tracer.debug.log,20/Feb/14 17:50;mdrob;tserver1.log;https://issues.apache.org/jira/secure/attachment/12630101/tserver1.log,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2014-02-20 17:03:46.412,,,no_permission,,,,,,,,,,,,374757,,,Thu Jun 18 20:36:24 UTC 2015,,,,,,0|i1skwn:,375057,,,,,,,,20/Feb/14 16:01;mdrob;It's easy to modify the CI client code to retry when faced with a {{MutationsRejectedException}} but I wonder if that would hide other issues that we could find. Probably need to find the code in tserver and make it more robust.,"20/Feb/14 17:03;ecn;[~mdrob] can you post more of tserver1's log?  This traceback is the loss of a connection to a client, and not an error from HDFS.",20/Feb/14 17:50;mdrob;Attaching a larger section of the tserver log.,"20/Feb/14 18:12;ecn;The log shows this tablet server was held, minor compactions were probably hanging.  But there's no errors bubbling up from DFSClient.

Do you know what sort of agitation was going on at this time?  NN or a bunch of DN's?
","20/Feb/14 18:42;mdrob;Looking later in the tserver logs, this line is repeated a bunch:
{{2014-02-20 07:23:22,907 [retry.RetryInvocationHandler] WARN : Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB. Trying to fail over immediately.}}

It only started later, so I didn't catch it at first, but now I am thinking it might be relevant. Actually... It looks like it corresponds quite strongly to NN failover, and doesn't show up until later (because I didn't start NN agitation until later).

So... potentially this has nothing to do with HDFS agitation. That does not make me feel better at all.","20/Feb/14 18:56;elserj;Are you sure you had Accumulo pointed at the correct HDFS config directory? The NameNodeProxies class will try to determine which kind of class to instantiate based on the contents of core-site and hdfs-site. Perhaps it was incorrectly only talking to one of the NNs in your (I'm assuming from other chatter) HA/QJM installation and would fail on renewing a lease when that NN wasn't active?

Edit: nevermind, I re-read your post. My questions are likely irrelevant.","20/Feb/14 20:02;mdrob;Was running again without any agitation, it took about an hour for the first client to die. From the tserver log:

{noformat}
2014-02-20 11:35:33,570 [thrift.ProcessFunction] ERROR: Internal error processing applyUpdates
org.apache.accumulo.tserver.HoldTimeoutException: Commits are held
        at org.apache.accumulo.tserver.TabletServerResourceManager.waitUntilCommitsAreEnabled(TabletServerResourceManager.java:412)
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.flush(TabletServer.java:1556)
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.applyUpdates(TabletServer.java:1535)
        at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at $Proxy16.applyUpdates(Unknown Source)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$applyUpdates.getResult(TabletClientService.java:2347)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$applyUpdates.getResult(TabletClientService.java:2333)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
{noformat}

Nothing interesting before, and a little while later there's a read error because the client died.","20/Feb/14 20:15;elserj;Without any HDFS errors, might you be oversaturating the tservers? I typically found that one CI ingest client can saturate a couple of tservers once majcs really kick off.

Also, have you taken a look at the MinC traces to see if some part of the chain is taking unexpectedly long?","20/Feb/14 20:19;ecn;Can you provide some details about your cluster (drives, virtual vs bare metal)?

What ingest rate are you seeing without agitation?

How big is your IMM?

","20/Feb/14 21:05;mdrob;Physical cluster; 5 slaves + 5 ingest clients; 11 drives/node.
Ingest with 1 clients (since the rest died...) is 150k entries/second which is approx 17 MB/s
IMM = 8G, Tserver Heap = 2G, Total RAM = 48G

Edit: I was looking at the wrong logs, updated the number of ingesters accordingly.",21/Feb/14 16:21;mdrob;Also saw this same error with 1.5.1-rc2,"21/Feb/14 17:02;ecn;150K aggregate?  That is significantly less than I would expect on that kind of hardware.

What's the write rate you are seeing on minor compactions?  The traces have information about the size and times.

Are minor compactions backing up?  What's the rate when the number of tablets per server is ~80?
","21/Feb/14 17:18;mdrob;Neither minors nor majors appear to be backing up. I let the single client continue writing overnight and we're up to ~100 tablets per server currently. The ingest rate is still steady at 150k entries. Actually, steady at 175k, but occasionally dropping to 100k when there is a spike in the number of flushes happening. I did not restart the other clients which died.

Where do I get an aggregate write rate? From the table on the ""Recent Traces"" page:
||Type||Total||Min||Max||Avg||
|majorCompaction	|4	|465ms	|810ms|	612ms|
|minorCompaction|	199|	114ms|7s 709ms|	4s 323ms|

When I drill down into minors, and look at the longest few, here are the details:
||time||entries||size||
|5815|471697|19258626|
|5879|436972|17837345|
|5760|471619|19260212|","21/Feb/14 17:37;mdrob;As an unrelated note, while trying to understand what is going on with the exception handling, I feel like {{TraceProxy.trace}} should not throw {{Throwable}}...

I'll create a separate JIRA for that this afternoon.","21/Feb/14 18:12;elserj;bq.  we're up to ~100 tablets per server currently

Does that mean you didn't presplit your table nor set the split threshold higher than the default 1G?","21/Feb/14 18:37;kturner;If the HoldTimeoutException is whats causing problems, it may be that timing is too tight.   The server code assumes that if the write was held more than general.rpc.timeout that the client has timed out and is no longer interested. Therefore the server code throws exception to abort with the expectation that client will not be impacted.  However if the client has not timed out for some reason, it would see this exception. Maybe change the timeout in TabletServerResourceManager.waitUntilCommitsAreEnabled() to 2x general.rpc.timeout and see if that helps avoid this problem.","24/Feb/14 20:13;mdrob;[~kturner] - looking at the {{waitUntilCommitsAreEnabled}} method, I see that we also ignore {{InterruptedException}} and just continue waiting. Seems like a code smell.

I had another realization on this - I've only seen the error on writes that are traced. After the fixes from ACCUMULO-2390 I see better exceptions in the monitor, and it looks like the commits held are specifically traces - not ingest data. I'm going to fish around in the logs for something concrete and hopefully more useful.","24/Feb/14 20:52;mdrob;Attaching tracer debug log. Doesn't look like there is anything new, unfortunately.","24/Feb/14 23:39;mdrob;Finally caught the moment when things die - before commits are held and all but one of my ingest clients die, I see write rate of about 300k entries per second.","26/Feb/14 20:42;mdrob;Started looking more into the time-out issues, and discovered that I'm not setting {{--batchTimeout}} and it is defaulting to {{Long.MAX_VALUE}}. So the client is _always_ going to still be waiting and the tablet server will never be able to safely abort the operation. At least, I hope that I'm reading these properties correctly.

The longest hold time that I see in the logs is 170s, and my general.rpc.timeout is 120s, so the {{HoldTimeoutException}} makes sense, from a sanity check point of view. Doubling the wait time on the tserver would likely solve the issue here, yes, but I'm worried that's not a stable approach.

The question that remains is how best to prevent ingest clients from dying, now. There may be different short term and long term solutions that are appropriate.
Short term: Let ingest retry the failed mutations. If the tablet server rejects the mutation for whatever reason, and the client is aware of it, then this wouldn't constitute data loss.
Long term: Provide an API for clients to specify their wait time to the servers. Then, tablet servers can more intelligently decide when to abort scans and when not to. Would need to protect the cluster from several poorly configured clients asking for very long hold times. Possibly other availability issues would be present as well.

Thoughts?",26/Feb/14 21:29;kturner;I think having the server double the configured hold time is a good short time solution.  Having clients pass timeout to the server via thrift seems like a good long term solution along with throwing an explicit thrift timeout exception.  The client needs to know this happened so it can differentiate it from an unexpected server side error.,"26/Feb/14 22:12;mdrob;Doubling the hold time in just that one spot doesn't sit quite right with me - I think that is surprising behaviour and I would not want to push that onto an operator ever. What do you think of doubling the underlying property - {{general.rpc.timeout}} - either in this specific case, or even in the default case.","26/Feb/14 23:03;kturner;How will doubling the default value for general.rpc.timeout resolve the issue?  This still leaves the server and client timeout the same, which is the root of the problem.","26/Feb/14 23:15;mdrob;Do the continuous ingest clients read the value for {{general.rpc.timeout}} out of the {{accumulo-site.xml}} or zookeeper? I don't see that happening (not saying that it doesn't, just that I am not aware of it, if it is).

Like I said earlier, I didn't think the client has any notion of time-out, so it will wait forever for a response (well, {{MAX_LONG}}, but close enough). It is also possible I am misinterpreting client values.","27/Feb/14 15:31;kturner;{{TabletServerBatchWriter.MutationWriter.sendMutationsToTabletServer()}} calls the followng method in ThriftUtil.  Which will probably just get the default timeout.  So the client should timeout.  Another possible problem is that the timeout code on the client is not working properly.

{code:java}
class ThriftUtil{
 static public TabletClientService.Client getTServerClient(String address, AccumuloConfiguration conf) throws TTransportException {
    return getClient(new TabletClientService.Client.Factory(), address, Property.GENERAL_RPC_TIMEOUT, conf);
  }
}
{code}","27/Feb/14 16:22;mdrob;Wow, that's pretty buried in the code. Thanks, Keith.

I started a run yesterday with general.rpc.timout=240s in my accumulo-site.xml, and everything seems to be going well. The longest hold time was 215s, and all held commits occurred in the first two hours of ingest. I'm going to try and piece together a time-line to see where things correspond to split/flush/compact and see if I can get more insight into potential issues.","04/Mar/14 14:41;mdrob;I brought the timeout back to the default, but instead of starting the table from scratch I pre-split it into 10 tablets and started a continuous ingest run. None of the clients died under this configuration.","05/Mar/14 23:22;kturner;[~mdrob] what are your thoughts on this for 1.6.0?  I am thinking that if we waiting 2x general.rpc.timeout on the server side might be a good option.  If we do this, may want to consider doing it for 1.4 and 1.5.   ",25/Mar/14 02:26;mdrob;I think we can bump resolving it properly to 1.6.1 since there are workarounds present.,"14/Apr/14 18:21;kturner;I ran continuous ingest on a 20 node AWS cluster using 1.6.0-RC1  and 6 of my 17 ingest clients died with this issue.  About 11 hours after stating 6 of the clients died around the same time because of an internal error on the same tserver.  The tserver had many  {{org.apache.accumulo.tserver.HoldTimeoutException}} around that time. 

{noformat}
[cluster@ip-10-1-2-24 logs]$ grep ""Commits held"" * | egrep [0-9][0-9][0-9][.][0-9][0-9]
tserver_ip-10-1-2-24.ec2.internal.debug.log:2014-04-12 11:08:24,800 [tserver.TabletServerResourceManager] DEBUG: Commits held for 184.93 secs
{noformat}

Looking at the tserver logs it seems that walog writes taking too long were the culprit.  The tablet server ran for hours, but excessively long walog times only occurred around this short period of time.

{noformat}
[cluster@ip-10-1-2-24 logs]$ grep writeTime * | egrep -v ""writeTime:[1-2]?[0-9]?[0-9]?[0-9]?[0-9]m""
tserver_ip-10-1-2-24.ec2.internal.debug.log:2014-04-12 11:03:21,790 [log.TabletServerLogger] DEBUG:  wrote MinC finish  60370: writeTime:39247ms 
tserver_ip-10-1-2-24.ec2.internal.debug.log:2014-04-12 11:08:24,665 [log.TabletServerLogger] DEBUG:  wrote MinC finish  60410: writeTime:58963ms 
tserver_ip-10-1-2-24.ec2.internal.debug.log:2014-04-12 11:08:24,748 [log.TabletServerLogger] DEBUG:  wrote MinC finish  60412: writeTime:58104ms 
tserver_ip-10-1-2-24.ec2.internal.debug.log:2014-04-12 11:08:24,748 [log.TabletServerLogger] DEBUG:  wrote MinC finish  60413: writeTime:57303ms 
tserver_ip-10-1-2-24.ec2.internal.debug.log:2014-04-12 11:08:24,748 [log.TabletServerLogger] DEBUG:  wrote MinC finish  60411: writeTime:58922ms 
{noformat}

{noformat}
[cluster@ip-10-1-2-24 logs]$ grep UpSess tserver_ip-10-1-2-24.ec2.internal.debug.log | egrep -v ""lt=[0-9]?[0-9][.][0-9]""
2014-04-12 11:04:21,370 [tserver.TabletServer] DEBUG: UpSess 10.1.2.24:41076 16,893 in 113.972s, at=[0 0 0.00 32] ft=113.917s(pt=0.005s lt=113.564s ct=0.348s)
2014-04-12 11:04:21,528 [tserver.TabletServer] DEBUG: UpSess 10.1.2.18:45239 25,402 in 114.076s, at=[0 0 0.00 32] ft=113.998s(pt=0.009s lt=113.485s ct=0.504s)
2014-04-12 11:04:34,246 [tserver.TabletServer] DEBUG: UpSess 10.1.2.14:34925 25,495 in 127.707s, at=[0 0 0.00 32] ft=127.524s(pt=0.008s lt=127.188s ct=0.328s)
2014-04-12 11:05:12,730 [tserver.TabletServer] DEBUG: UpSess 10.1.2.27:47808 41,559 in 110.530s, at=[0 1 0.03 32] ft=110.297s(pt=0.027s lt=109.579s ct=0.691s)
2014-04-12 11:05:12,731 [tserver.TabletServer] DEBUG: UpSess 10.1.2.16:36129 42,009 in 110.808s, at=[0 0 0.00 32] ft=110.699s(pt=0.027s lt=109.802s ct=0.870s)
2014-04-12 11:05:13,091 [tserver.TabletServer] DEBUG: UpSess 10.1.2.19:38228 41,187 in 114.117s, at=[0 1 0.03 32] ft=114.022s(pt=0.050s lt=113.574s ct=0.398s)
2014-04-12 11:05:39,362 [tserver.TabletServer] DEBUG: UpSess 10.1.2.22:37561 41,799 in 124.262s, at=[0 0 0.00 32] ft=124.169s(pt=0.019s lt=123.414s ct=0.736s)
2014-04-12 11:06:41,348 [tserver.TabletServer] DEBUG: UpSess 10.1.2.17:57689 33,547 in 130.710s, at=[0 1 0.06 32] ft=130.631s(pt=0.014s lt=130.119s ct=0.498s)
2014-04-12 11:06:53,563 [tserver.TabletServer] DEBUG: UpSess 10.1.2.14:35186 33,503 in 146.692s, at=[0 1 0.03 32] ft=146.587s(pt=0.017s lt=146.300s ct=0.270s)
2014-04-12 11:06:58,482 [tserver.TabletServer] DEBUG: UpSess 10.1.2.18:45239 33,394 in 156.948s, at=[0 1 0.03 32] ft=156.845s(pt=0.017s lt=156.575s ct=0.253s)
2014-04-12 11:07:05,899 [tserver.TabletServer] DEBUG: UpSess 10.1.2.13:40356 41,804 in 226.959s, at=[0 1 0.03 32] ft=226.786s(pt=0.020s lt=226.168s ct=0.598s)
2014-04-12 11:07:06,025 [tserver.TabletServer] DEBUG: UpSess 10.1.2.16:36129 7,962 in 113.265s, at=[0 1 0.03 32] ft=113.243s(pt=0.002s lt=113.082s ct=0.159s)
2014-04-12 11:07:06,044 [tserver.TabletServer] DEBUG: UpSess 10.1.2.19:38228 8,314 in 111.536s, at=[0 0 0.00 32] ft=111.497s(pt=0.003s lt=111.318s ct=0.176s)
2014-04-12 11:07:06,143 [tserver.TabletServer] DEBUG: UpSess 10.1.2.27:47808 16,831 in 110.390s, at=[0 0 0.00 32] ft=110.359s(pt=0.005s lt=110.081s ct=0.273s)
2014-04-12 11:07:14,716 [tserver.TabletServer] DEBUG: UpSess 10.1.2.23:54944 8,485 in 138.654s, at=[0 0 0.00 32] ft=138.638s(pt=0.003s lt=138.596s ct=0.039s)
2014-04-12 11:08:25,465 [tserver.TabletServer] DEBUG: UpSess 10.1.2.24:41076 41,923 in 244.077s, at=[0 1 0.03 32] ft=243.878s(pt=78.546s lt=164.889s ct=0.443s)
2014-04-12 11:08:25,891 [tserver.TabletServer] DEBUG: UpSess 10.1.2.20:41926 41,910 in 235.374s, at=[0 1 0.03 32] ft=235.277s(pt=98.752s lt=135.996s ct=0.529s)
2014-04-12 11:08:25,891 [tserver.TabletServer] DEBUG: UpSess 10.1.2.29:41553 41,691 in 228.196s, at=[0 1 0.03 32] ft=228.041s(pt=107.973s lt=119.670s ct=0.398s)
2014-04-12 11:08:26,307 [tserver.TabletServer] DEBUG: UpSess 10.1.2.15:50332 42,013 in 228.612s, at=[0 0 0.00 32] ft=228.434s(pt=118.835s lt=109.381s ct=0.218s)
{noformat}

Since this was running on AWS maybe these walog hiccups are expected, not sure.   In any case the clients should not error.  I am going to retry w/ setting  {{general.rpc.timout=240s}} in {{accumulo-site.xml}}","14/Apr/14 18:33;mdrob;By increasing the tserver rpc timeout, we're not really doing anything to address the issue. It deals with the proximal cause of clients dying, but eventually somebody will reach the point where 4 minutes is not enough due to the load on their cluster and up it goes again. Does increasing the rpc timeout have adverse affects on anything else? Like causing servers to hold on to more requests in memory?

I feel like we should build some retry capability into clients for this. Probably would be good to do it inside of the [Batch]Scanner implementation so that users don't even need to worry about it. I remember discussing the possibility of scanners that could advertise their own timeout, did that ever get a JIRA filed? If not, it should.","14/Apr/14 21:10;kturner;bq. I feel like we should build some retry capability into clients for this.

I agree, this is the long term solution.   The batch writer should handle this situation transparently.   It would probably be best if when the server suspected the client had timed out that it threw a specific thrift exception for this case.  What if, anything should be done for the short term?

bq.  Does increasing the rpc timeout have adverse affects on anything else? Like causing servers to hold on to more requests in memory?

Yes, it could certainly increase memory used.  I will attach a patch to outline the short term work around I was thinking about. Maybe its too risky because it along w/ ACCUMULO-1905 may lead to too much memory used to  buffer incoming data.  Also it does not prevent this issue from occurring, just reduces the probability that it will occur.     Another possibility for the short term is to list this as a known issue in the release notes w/ recommendations for working around.

Maybe ACCUMULO-2668 will speed up walogs and decrease the probability this situation will occur.  I am thinking of trying that patch w/ my next run instead of increasing general.rpc.timoute.  


","15/Apr/14 13:41;mdrob;bq. Another possibility for the short term is to list this as a known issue in the release notes w/ recommendations for working around.
+1","16/Apr/14 17:17;mdrob;Running {{1.6.0-RC2}}, saw this happen with both traces and one of the ingesters again. I believe this build includes ACCUMULO-2668, so that didn't solve the issue.

The ingester died, the tracer is still running.","16/Apr/14 17:42;kturner;I was able to do another run w/ ACCUMULO-2668 and it was successful.  I analyzed all of the tserver logs and still saw some high walog times.  So the potential for the problem I saw previously was still there, it just did not happen to all occur on one node at one time.

{noformat}
[cluster@ip-10-1-2-10 continuous]$ pssh -i -h ingesters.txt 'grep -a ""UpSess"" /opt/accumulo-1.6.0/logs/*tserver* | egrep -a -v ""lt=[0-9]?[0-9][.][0-9]""'
[12] 17:31:55 [SUCCESS] ip-10-1-2-18
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-18.ec2.internal.debug.log:2014-04-15 06:17:24,337 [tserver.TabletServer] DEBUG: UpSess 10.1.2.28:48032 16,975 in 102.868s, at=[0 0 0.00 32] ft=102.667s(pt=0.090s lt=102.317s ct=0.260s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-18.ec2.internal.debug.log:2014-04-15 06:17:38,671 [tserver.TabletServer] DEBUG: UpSess 10.1.2.19:52736 16,842 in 118.418s, at=[0 0 0.00 32] ft=118.355s(pt=0.008s lt=118.178s ct=0.169s)
[17] 17:31:58 [SUCCESS] ip-10-1-2-23
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:36,850 [tserver.TabletServer] DEBUG: UpSess 10.1.2.20:50978 17,092 in 137.192s, at=[0 1 0.03 32] ft=137.122s(pt=0.006s lt=136.790s ct=0.326s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:36,896 [tserver.TabletServer] DEBUG: UpSess 10.1.2.16:38184 24,779 in 137.509s, at=[0 0 0.00 32] ft=137.295s(pt=0.008s lt=136.912s ct=0.375s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:37,429 [tserver.TabletServer] DEBUG: UpSess 10.1.2.21:59812 17,032 in 138.041s, at=[0 0 0.00 32] ft=137.855s(pt=0.013s lt=137.715s ct=0.127s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:39,004 [tserver.TabletServer] DEBUG: UpSess 10.1.2.24:32948 8,003 in 139.603s, at=[0 0 0.00 32] ft=139.400s(pt=0.003s lt=139.190s ct=0.207s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:39,070 [tserver.TabletServer] DEBUG: UpSess 10.1.2.14:37183 16,372 in 139.701s, at=[0 0 0.00 32] ft=139.506s(pt=0.008s lt=139.228s ct=0.270s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:39,071 [tserver.TabletServer] DEBUG: UpSess 10.1.2.27:40775 16,313 in 139.670s, at=[0 1 0.03 32] ft=139.497s(pt=0.012s lt=139.211s ct=0.274s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:39,345 [tserver.TabletServer] DEBUG: UpSess 10.1.2.22:37906 33,858 in 140.193s, at=[0 0 0.00 32] ft=140.124s(pt=0.045s lt=139.540s ct=0.539s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:41,388 [tserver.TabletServer] DEBUG: UpSess 10.1.2.17:39697 33,352 in 142.488s, at=[0 0 0.00 32] ft=142.351s(pt=0.015s lt=141.952s ct=0.384s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:47,494 [tserver.TabletServer] DEBUG: UpSess 10.1.2.15:43946 8,477 in 120.655s, at=[0 1 0.03 32] ft=120.607s(pt=0.002s lt=120.210s ct=0.395s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:47,669 [tserver.TabletServer] DEBUG: UpSess 10.1.2.13:57710 17,033 in 115.454s, at=[0 1 0.03 32] ft=115.211s(pt=0.013s lt=114.630s ct=0.568s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:47,675 [tserver.TabletServer] DEBUG: UpSess 10.1.2.28:44022 16,907 in 116.482s, at=[0 0 0.00 32] ft=116.322s(pt=0.004s lt=115.743s ct=0.575s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:47,784 [tserver.TabletServer] DEBUG: UpSess 10.1.2.29:48898 25,146 in 126.834s, at=[0 0 0.00 32] ft=126.749s(pt=0.007s lt=126.057s ct=0.685s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:50,020 [tserver.TabletServer] DEBUG: UpSess 10.1.2.10:60386 2,533 in 140.164s, at=[0 0 0.00 1] ft=140.155s(pt=0.000s lt=140.129s ct=0.026s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:50,388 [tserver.TabletServer] DEBUG: UpSess 10.1.2.19:43589 16,838 in 132.732s, at=[0 1 0.03 32] ft=132.671s(pt=0.004s lt=132.276s ct=0.391s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:50,503 [tserver.TabletServer] DEBUG: UpSess 10.1.2.25:50677 25,491 in 136.344s, at=[0 0 0.00 32] ft=136.211s(pt=0.016s lt=135.684s ct=0.511s)
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-23.ec2.internal.debug.log:2014-04-15 06:17:53,409 [tserver.TabletServer] DEBUG: UpSess 10.1.2.18:36106 16,961 in 143.786s, at=[0 1 0.06 32] ft=143.719s(pt=0.004s lt=143.373s ct=0.342s)
{noformat}

{noformat}
[cluster@ip-10-1-2-10 continuous]$ pssh -i -h ingesters.txt 'grep -a ""writeTime"" /opt/accumulo-1.6.0/logs/*tserver* | egrep -v ""writeTime:[1-2]?[0-9]?[0-9]?[0-9]?[0-9]m"" '
[4] 17:34:02 [SUCCESS] ip-10-1-2-13
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-13.ec2.internal.debug.log:2014-04-15 06:17:00,243 [log.TabletServerLogger] DEBUG:  wrote MinC finish  64556: writeTime:30902ms 
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-13.ec2.internal.debug.log:2014-04-15 06:17:00,246 [log.TabletServerLogger] DEBUG:  wrote MinC finish  64557: writeTime:30663ms 
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-13.ec2.internal.debug.log:2014-04-15 06:17:03,548 [log.TabletServerLogger] DEBUG:  wrote MinC finish  64558: writeTime:33712ms 
[12] 17:34:02 [SUCCESS] ip-10-1-2-24
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-24.ec2.internal.debug.log:2014-04-16 04:32:31,653 [log.TabletServerLogger] DEBUG:  wrote MinC finish  822843: writeTime:35119ms 
[14] 17:34:02 [SUCCESS] ip-10-1-2-22
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-22.ec2.internal.debug.log:2014-04-15 18:15:27,592 [log.TabletServerLogger] DEBUG:  wrote MinC finish  153363: writeTime:39875ms 
[16] 17:34:02 [SUCCESS] ip-10-1-2-29
/opt/accumulo-1.6.0/logs/tserver_ip-10-1-2-29.ec2.internal.debug.log:2014-04-15 06:21:25,684 [log.TabletServerLogger] DEBUG:  wrote MinC finish  62514: writeTime:50973ms 
{noformat}","17/Apr/14 17:41;jira-bot;Commit 1588315 from kturner@apache.org in branch 'site/trunk'
[ https://svn.apache.org/r1588315 ]

ACCUMULO-2396 added ACCUMULO-2388 to release notes","18/Apr/14 18:49;mdrob;I'm running another CI tests and seeing the
{noformat}
Got an IOException in internalRead!
	java.io.IOException: Connection reset by peer
{noformat}
trace back show up, but none of the clients appeared to die this time.",13/May/15 14:37;kturner;Just ran into this again while testing 1.7.0rc3.  I would like to get it fixed in the next round of bug fix releases.,"13/May/15 15:04;elserj;I was seeing this off and on again too, ACCUMULO-3811","13/May/15 17:06;elserj;Copied from ACCUMULO-3811 because it might be relevant here:

I'm seeing this pretty regularly with DN agitation on, commits held being the cause each time. I am surprised that I'm seeing this little resilience coming out of HDFS:

Big CI picture w/ agitation
{noformat}
20150513 08:58:26 Killing datanode on cn021
20150513 09:08:26 Starting datanode on cn021

2015-05-13 09:08:16,473 [tserver.TabletServer$ThriftClientHandler] ERROR: Commits are held
org.apache.accumulo.tserver.HoldTimeoutException: Commits are held

2015-05-13 09:08:16,479 [impl.TabletServerBatchWriter] ERROR: Server side error on cn022:9997: org.apache.thrift.TApplicationException: Internal error processing closeUpdate
2015-05-13 09:08:16,483 [start.Main] ERROR: Thread 'org.apache.accumulo.test.continuous.ContinuousIngest' died.
{noformat}

Maybe some blocks aren't fully replicated? I'm not sure but I feel like things shouldn't bog down like this.","13/May/15 17:50;kturner;I was not doing any agitation.  I was seeing a lot of error messages from HDFS when writing to walogs stating that it could not replicate to all datanodes.  I was using hadoop 2.7.0.  I am going to try switching to hadoop 2.6, updating Accumulo settings, and restarting test.","13/May/15 18:42;elserj;bq. I was not doing any agitation. I was seeing a lot of error messages from HDFS when writing to walogs stating that it could not replicate to all datanodes. I was using hadoop 2.7.0.

Oh, ok. BTW, are you aware of the ""not for production"" label on Hadoop 2.7.0? I think a 2.7.1 is incoming shortly, but I don't remember if the found issues would have a direct impact on us.",13/May/15 20:34;kturner;I was not aware of that until [~ecn] mentioned it to me earlier today.    ,28/May/15 23:02;ctubbsii;Does this need to be a blocker for 1.6.3?,"29/May/15 21:29;ctubbsii;Since there hasn't been a response, and this has already been punted before, I can't imagine why it should be a blocker for 1.6.3. I'm dropping priority and making it Critical instead. (If somebody objects to lowering priority, please volunteer to provide a timely fix, before moving it back to ""Blocker""; otherwise, I see no reason to permit this to hold up other fixes included in 1.6.3).","12/Jun/15 22:03;githubbot;GitHub user keith-turner opened a pull request:

    https://github.com/apache/accumulo/pull/38

    ACCUMULO-2388 Make clients retry in case of HoldTimeoutException

    To test this patch, I made the following changes and ran the WriteLotsIt and ConditionalWriterIT
    
    ```
    diff --git a/server/tserver/src/main/java/org/apache/accumulo/tserver/TabletServerResourceManager.java b/server/tserver/src/main/java/org/apache/accumulo/tserver/TabletServerResourceManager.java
    index 7c0eedc..4483fe8 100644
    --- a/server/tserver/src/main/java/org/apache/accumulo/tserver/TabletServerResourceManager.java
    +++ b/server/tserver/src/main/java/org/apache/accumulo/tserver/TabletServerResourceManager.java
    @@ -469,6 +469,9 @@ public class TabletServerResourceManager {
       }
     
       void waitUntilCommitsAreEnabled() {
    +    if(Math.random() < .1)
    +      throw new HoldTimeoutException(""test"");
    +
         if (holdCommits) {
           long timeout = System.currentTimeMillis() + conf.getConfiguration().getTimeInMillis(Property.GENERAL_RPC_TIMEOUT);
           synchronized (commitHold) {
    ```

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/keith-turner/accumulo ACCUMULO-2388

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/accumulo/pull/38.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #38
    
----
commit 6965fb07c97cd752d6f5415a39e87b9ff3c1ba7e
Author: Keith Turner <kturner@apache.org>
Date:   2015-06-12T21:47:18Z

    ACCUMULO-2388 Make clients retry in case of HoldTimeoutException

----
","16/Jun/15 21:42;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/accumulo/pull/38
","18/Jun/15 18:35;elserj;Sorry for the belated review. Made some time to look over these changes in light of the near immediate RC after.

I did a quick glance at how the client handles the new thrown Exception from the server, and it does appear to line up with what your comments suggested. I did cringe a bit at it being a hack, but can understand the choice for this solution for patch releases.

It seems like this is another one of those areas in the code where we could seriously benefit from a well-defined retry policy instead of piggy-backing on code which happens to do an implicit retry. It seems like we'd want a specific exception for the ""go away, come back in a little while"" logic. This would eliminate the unnecessary location-cache eviction this change creates. I'd like to see us think about this for 1.8/2.0. Thoughts?","18/Jun/15 20:14;kturner;> This would eliminate the unnecessary location-cache eviction this change creates. I'd like to see us think about this for 1.8/2.0. Thoughts?

I was worried about the cache eviction when I first made the change.  However I am not sure how frequently it will actually occur.   For some fraction of the time when the exception is thrown the client will be gone.  I wish I had more data about what that fraction was.   ","18/Jun/15 20:18;elserj;bq. For some fraction of the time when the exception is thrown the client will be gone. I wish I had more data about what that fraction was. 

Sounds like another good ticket. We don't have any centralized metrics system for the client, do we? We have metrics2 on the server. Not sure if that's the best choice for the client though. Make be better to look at something more self-contained.","18/Jun/15 20:22;kturner;> Sounds like another good ticket. We don't have any centralized metrics system for the client, do we?

I would really like to see info collected from instrumented clients. Seems like it would be very useful info.","18/Jun/15 20:24;elserj;bq. I would really like to see info collected from instrumented clients

Instrumented with what?",18/Jun/15 20:26;kturner;Not sure what it should be instrumented with.,18/Jun/15 20:36;elserj;Filed ACCUMULO-3908
ShutdownTServer FATE step's call() method sits in a loop: should use isReady() instead,ACCUMULO-1259,12641907,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,vickyuec,ecn,ecn,10/Apr/13 19:55,10/Jun/15 23:54,13/Mar/19 22:01,27/Mar/15 02:29,,,,,,,,1.7.0,,,,,,,,,0,,,,,,,"Commit b0e1a81cf205a7b18fc38793a9e712b65c0a2304 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b0e1a81 ]

ACCUMULO-1259 Move waiting for a TabletServer to die from call to isReady.
;27/Mar/15 02:29;jira-bot;600",,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,ACCUMULO-3897,,,,,,,,,,,03/Mar/15 17:22;elserj;0001-ACCUMULO-1259-Wait-asynchronously-for-TServer-to-go-.patch;https://issues.apache.org/jira/secure/attachment/12702202/0001-ACCUMULO-1259-Wait-asynchronously-for-TServer-to-go-.patch,05/Mar/15 18:25;elserj;ACCUMULO-1259.patch;https://issues.apache.org/jira/secure/attachment/12702864/ACCUMULO-1259.patch,13/Feb/14 07:40;vickyuec;ACCUMULO-1259.v1.patch.txt;https://issues.apache.org/jira/secure/attachment/12628692/ACCUMULO-1259.v1.patch.txt,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2014-02-13 07:40:56.271,,,no_permission,,,,,,,,,,,,322322,,,Thu Mar 26 21:57:29 UTC 2015,,,,,,0|i1jm1r:,322667,,,,,,,,13/Feb/14 07:40;vickyuec;Attached patch against 1.5.1-SNAPSHOT. Have created a new MasterRepo derived class for waiting in isReady().,13/Feb/14 07:43;vickyuec;Forgot to mention: tested shutdown on a cluster with 3 Tservers. Brought 2 of them down with this patch one-by-one. Verified all data was still accessible.,"02/Mar/15 23:21;elserj;Marking as fixVersion 1.7.0. It's not a bug, so we should probably avoid putting it in older versions. I'll try to rebase Vikram's old patch and get a current one up.

We could use some tests for it as well.","03/Mar/15 17:22;elserj;Updated patch based on [~vickyuec]'s original patch. Changes I made:

* Original patch didn't cleanly apply against master, applied it by hand.
* Ensures that the force option doesn't wait
* Removes the ShutdownTServerWait class
* Requests that the master only shutdown the tserver once (not repeatedly)
* Doesn't wait if null connection to server is returned (prevent an extra call to {{isReady()}})","05/Mar/15 18:25;elserj;The first patch was really bad. Ran it on my Jenkins, had decent success but a few failures. None jumped out to me as new failures though.","26/Mar/15 21:57;elserj;I'll rebase, test and then apply this since no one had anything to say.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
random walk test is failing,ACCUMULO-1105,12633979,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,25/Feb/13 19:47,12/Mar/15 17:30,13/Mar/19 22:01,01/Mar/13 19:52,,,,,,,,1.5.0,,,,,,,,,0,15_qa_bug,,,,"All random walk tests are failing:

{noformat}
 by: ThriftSecurityException(user:root, code:BAD_CREDENTIALS)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$authenticateUser_result$authenticateUser_resultStandardScheme.read(ClientService.java:8039)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$authenticateUser_result$authenticateUser_resultStandardScheme.read(ClientService.java:8017)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$authenticateUser_result.read(ClientService.java:7961)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$Client.recv_authenticateUser(ClientService.java:333)

{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-25 23:16:54.222,,,no_permission,,,,,,,,,,,,314473,,,Mon Feb 25 23:24:23 UTC 2013,,,,,,0|i1i9m7:,314817,,,,,,,,"25/Feb/13 23:16;hudson;Integrated in Accumulo-Trunk #744 (See [https://builds.apache.org/job/Accumulo-Trunk/744/])
    ACCUMULO-1105 fix issues with random walk tests (Revision 1449883)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/OfflineScanner.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/QueryMetadataTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/State.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/image/Commit.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/image/ImageFixture.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/multitable/Commit.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/multitable/MultiTableFixture.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/AlterTablePerm.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/Authenticate.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/ChangePass.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/DropTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","25/Feb/13 23:24;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #102 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/102/])
    ACCUMULO-1105 fix issues with random walk tests (Revision 1449883)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/OfflineScanner.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/QueryMetadataTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/State.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/image/Commit.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/image/ImageFixture.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/multitable/Commit.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/multitable/MultiTableFixture.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/AlterTablePerm.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/Authenticate.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/ChangePass.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/DropTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
droptable created infinite METADATA scan loop,ACCUMULO-2361,12694835,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,,cmccubbin,cmccubbin,12/Feb/14 20:58,23/Jan/15 21:10,13/Mar/19 22:01,23/Jan/15 21:10,1.5.1,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,"Working with [~vines] on this one...

Setup: Created a couple tables, added some data, then dropped them. The drop hangs and !METADATA (which has ~400 entries) is scanned in what looks like an infinite loop.

The table being dropped loks like this in !METADATA:

{code}
root@sqrrl> scan -b 3 -e 5 -t !METADATA
4;\x00\x00\x06f srv:dir []    /t-00000b6
4;\x00\x00\x06f srv:lock []    tservers/10.10.1.209:9997/zlock-0000000000$144274cd317000b
4;\x00\x00\x06f srv:time []    M0
4;\x00\x00\x06f ~tab:~pr []    \x00
4;\x00\x00\x0C\xCC loc:144274cd3170008 []    10.10.1.107:9997
4;\x00\x00\x0C\xCC srv:dir []    /t-00000bj
4;\x00\x00\x0C\xCC srv:lock []    tservers/10.10.1.209:9997/zlock-0000000000$144274cd317000b
4;\x00\x00\x0C\xCC srv:time []    M0
4;\x00\x00\x0C\xCC ~tab:~pr []    \x01\x00\x00\x06f
4;\x00\x00\x133 srv:dir []    /t-000002h
4;\x00\x00\x133 srv:lock []    tservers/10.10.1.209:9997/zlock-0000000000$144274cd317000b
4;\x00\x00\x133 srv:time []    M0
4;\x00\x00\x133 ~tab:~pr []    \x01\x00\x00\x0C\xCC
{code}

We think this may be the relevant message in the master debug logs:

{code}
2014-02-12 19:13:31,397 [tableOps.CleanUp] DEBUG: Still waiting for table to be deleted: 4 saw inconsistencynull 4;^@^@^L?;^@^@^Ff
2014-02-12 19:13:31,459 [tableOps.CleanUp] DEBUG: Still waiting for table to be deleted: 4 saw inconsistencynull 4;^@^@^L?;^@^@^Ff
2014-02-12 19:13:31,524 [tableOps.CleanUp] DEBUG: Still waiting for table to be deleted: 4 saw inconsistencynull 4;^@^@^L?;^@^@^Ff
2014-02-12 19:13:31,588 [tableOps.CleanUp] DEBUG: Still waiting for table to be deleted: 4 saw inconsistencynull 4;^@^@^L?;^@^@^Ff
2014-02-12 19:13:31,662 [tableOps.CleanUp] DEBUG: Still waiting for table to be deleted: 4 saw inconsistencynull 4;^@^@^L?;^@^@^Ff
2014-02-12 19:13:31,725 [tableOps.CleanUp] DEBUG: Still waiting for table to be deleted: 4 saw inconsistencynull 4;^@^@^L?;^@^@^Ff
2014-02-12 19:13:31,788 [tableOps.CleanUp] DEBUG: Still waiting for table to be deleted: 4 saw inconsistencynull 4;^@^@^L?;^@^@^Ff
2014-02-12 19:13:31,854 [tableOps.CleanUp] DEBUG: Still waiting for table to be deleted: 4 saw inconsistencynull 4;^@^@^L?;^@^@^Ff
2014-02-12 19:13:31,917 [tableOps.CleanUp] DEBUG: Still waiting for table to be deleted: 4 saw inconsistencynull 4;^@^@^L?;^@^@^Ff
...etc
{code}

Graceful accumulo reboot hangs. 

Hard reboot of everything (control-c'd) clears the problem.",accumulo-1.5.0 with sqrrl extensions.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2489,,,,,,,,,,,,,,18/Mar/14 22:55;vines;AccumuloHammerTableCreation.java;https://issues.apache.org/jira/secure/attachment/12635430/AccumuloHammerTableCreation.java,18/Mar/14 22:14;vines;AccumuloHammerTableCreation.java;https://issues.apache.org/jira/secure/attachment/12635416/AccumuloHammerTableCreation.java,18/Feb/14 17:05;cmccubbin;Screen Shot 2014-02-12 at 2.27.11 PM.png;https://issues.apache.org/jira/secure/attachment/12629568/Screen+Shot+2014-02-12+at+2.27.11+PM.png,18/Feb/14 17:05;cmccubbin;Screen Shot 2014-02-12 at 2.28.09 PM.png;https://issues.apache.org/jira/secure/attachment/12629567/Screen+Shot+2014-02-12+at+2.28.09+PM.png,20/Mar/14 16:25;ecn;TableCreationHammerIT.java;https://issues.apache.org/jira/secure/attachment/12635809/TableCreationHammerIT.java,18/Feb/14 17:01;cmccubbin;jstack1.txt;https://issues.apache.org/jira/secure/attachment/12629562/jstack1.txt,18/Feb/14 17:01;cmccubbin;jstack2.txt;https://issues.apache.org/jira/secure/attachment/12629563/jstack2.txt,18/Feb/14 17:01;cmccubbin;jstack3.txt;https://issues.apache.org/jira/secure/attachment/12629561/jstack3.txt,18/Feb/14 17:01;cmccubbin;masterJstack.txt;https://issues.apache.org/jira/secure/attachment/12629564/masterJstack.txt,18/Feb/14 17:01;cmccubbin;masterJstack2.txt;https://issues.apache.org/jira/secure/attachment/12629565/masterJstack2.txt,18/Feb/14 17:01;cmccubbin;masterJstack3.txt;https://issues.apache.org/jira/secure/attachment/12629566/masterJstack3.txt,18/Feb/14 18:19;cmccubbin;short.debug.log;https://issues.apache.org/jira/secure/attachment/12629585/short.debug.log,12.0,,,,,,,,,,,,,,,,,,,2014-02-12 22:18:51.3,,,no_permission,,,,,,,,,,,,373343,,,Fri Jan 23 21:10:36 UTC 2015,,,,,,0|i1sc7r:,373644,,,,,,,,"12/Feb/14 22:18;ecn;Strange.  The master is seeing the first tablet as: {{4;\x00\x00\x0c?;\x00\x00\x06f}} and the first tablet is {{4;\x00\x00\x0c?<}}.  It could be confused by a recent split, but eventually it should see the METADATA table scan you included above (which looks correct).  Maybe there's some caching that isn't getting reset because we're not trying to find the tablets?


","14/Feb/14 21:25;ecn;[~cmccubbin] I'm trying to reproduce the problem in an integration test ... without much luck.

Do you happen to know how long the master was stuck and repeated this message about inconsistency?

I was able to reproduce the message, but it only shows up once.","14/Feb/14 21:41;cmccubbin;Yes, the master was stuck in this lop until I hard-rebooted accumulo. Until I did that accumulo was totally non-responsive to anything. The monitor kept updating but i couldn't insert, add/drop tables, etc.

I'm thinking it must be some kind of race condition, because I've seen this happen a couple of times now but I can't reliably reproduce the effect. 

I have some other information from this instance if you need it, like listscans from the shell and master jstacks.","14/Feb/14 22:01;ecn;I'll take anything you've got.

Could you scan the !METADATA table when the master was locked up on this?","18/Feb/14 14:47;jira-bot;Commit 1a66f3bd851cc171b26c6b9e62c515338207afac in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1a66f3b ]

ACCUMULO-2361 fix missing space in error message
","18/Feb/14 14:58;jira-bot;Commit 1a66f3bd851cc171b26c6b9e62c515338207afac in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1a66f3b ]

ACCUMULO-2361 fix missing space in error message
","18/Feb/14 16:53;jira-bot;Commit 00ff44819bf97063ad04a96c924a2fde0a10bdd6 in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=00ff448 ]

ACCUMULO-2361 IT to reproduce
","18/Feb/14 16:53;jira-bot;Commit 00ff44819bf97063ad04a96c924a2fde0a10bdd6 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=00ff448 ]

ACCUMULO-2361 IT to reproduce
","18/Feb/14 16:53;jira-bot;Commit 00ff44819bf97063ad04a96c924a2fde0a10bdd6 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=00ff448 ]

ACCUMULO-2361 IT to reproduce
","18/Feb/14 16:56;jira-bot;Commit ad9f9c13dce4c9bc635c4645a5bafd04131a33cd in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ad9f9c1 ]

ACCUMULO-2361 made test a functional SimpleIT for 1.6 and later
","18/Feb/14 16:59;ecn;My test can reliably produce the ""saw inconsistency"" message, but the master does not get stuck: it keeps executing the state machine and all my tables get deleted.

If you don't have log messages from this incident, I'm going to close this with ""Cannot reproduce.""
",18/Feb/14 17:01;cmccubbin;Jstacks of master and tserver taken a few seconds apart while the condition was occurring.,18/Feb/14 17:05;cmccubbin;screencaps of server monitor page while this was happening,"18/Feb/14 17:07;cmccubbin;Here's the output of some listscans on the monitor:

{code}
root@sqrrl> listscans
 TABLET SERVER        | CLIENT               | AGE      | LAST     | STATE  | TYPE  | USER    | TABLE   | COLUMNS   | AUTHORIZATIONS      | TABLET    | ITERATORS  | ITERATOR OPTIONS
root@sqrrl> listscans
 TABLET SERVER        | CLIENT               | AGE      | LAST     | STATE  | TYPE  | USER    | TABLE   | COLUMNS   | AUTHORIZATIONS      | TABLET    | ITERATORS  | ITERATOR OPTIONS
root@sqrrl> listscans
 TABLET SERVER        | CLIENT               | AGE      | LAST     | STATE  | TYPE  | USER    | TABLE   | COLUMNS   | AUTHORIZATIONS      | TABLET    | ITERATORS  | ITERATOR OPTIONS
root@sqrrl> listscans
 TABLET SERVER        | CLIENT               | AGE      | LAST     | STATE  | TYPE  | USER    | TABLE   | COLUMNS   | AUTHORIZATIONS      | TABLET    | ITERATORS  | ITERATOR OPTIONS
root@sqrrl> listscans
 TABLET SERVER        | CLIENT               | AGE      | LAST     | STATE  | TYPE  | USER    | TABLE   | COLUMNS   | AUTHORIZATIONS      | TABLET    | ITERATORS  | ITERATOR OPTIONS
     10.10.1.107:9997 |    10.10.1.206:41386 |      3ms |        - |   IDLE | BATCH | !SYSTEM |!METADATA |[loc::, chopped::, log::, ~tab:~pr:, future::] |                     |       N/A |[wholeRows=1000,org.apache.accumulo.core.iterators.user.WholeRowIterator, tabletChange=1001,org.apache.accumulo.server.master.state.TabletStateChangeIterator] | {wholeRows={}, tabletChange={tables=2,1,!0,5, merges=, servers=10.10.1.60:9997[144274cd3170007],10.10.1.209:9997[144274cd317000b],10.10.1.129:9997[144274cd317000a],10.10.1.114:9997[144274cd3170009],10.10.1.107:9997[144274cd3170008]}}
root@sqrrl> listscans
 TABLET SERVER        | CLIENT               | AGE      | LAST     | STATE  | TYPE  | USER    | TABLE   | COLUMNS   | AUTHORIZATIONS      | TABLET    | ITERATORS  | ITERATOR OPTIONS
root@sqrrl> listscans
 TABLET SERVER        | CLIENT               | AGE      | LAST     | STATE  | TYPE  | USER    | TABLE   | COLUMNS   | AUTHORIZATIONS      | TABLET    | ITERATORS  | ITERATOR OPTIONS
     10.10.1.209:9997 |    10.10.1.206:55270 |      1ms |        - |   IDLE | BATCH | !SYSTEM |!METADATA |[loc::, chopped::, log::, ~tab:~pr:, future::] |                     |       N/A |[wholeRows=1000,org.apache.accumulo.core.iterators.user.WholeRowIterator, tabletChange=1001,org.apache.accumulo.server.master.state.TabletStateChangeIterator] | {wholeRows={}, tabletChange={tables=2,1,!0,5, merges=, servers=10.10.1.60:9997[144274cd3170007],10.10.1.209:9997[144274cd317000b],10.10.1.129:9997[144274cd317000a],10.10.1.114:9997[144274cd3170009],10.10.1.107:9997[144274cd3170008]}}
root@sqrrl> 
{code}","18/Feb/14 17:08;jira-bot;Commit e0b8fb0e98c1b38c4fa2e20ae0611e33e07ecba6 in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e0b8fb0 ]

ACCUMULO-2361 clean-up: remove commented code
",18/Feb/14 17:09;cmccubbin;Also to answer your question [~ecn] : We were able to scan the master during this.,"18/Feb/14 17:09;cmccubbin;Oops, I meant we were able to scan !METADATA.","18/Feb/14 17:39;ecn;Any chance you have the master debug logs from this?

I see a shutdown is being requested in the master jstacks.

Did you notice the problem and attempt a shutdown?  Or did you request a shutdown after noticing the problem?
","18/Feb/14 18:18;cmccubbin;I don't think I have a full trace from the master, but I may have a snippet that I made from when it looked like the issue started. 

I had requested a shutdown well after the issue started, that's when I took the jstacks.",18/Feb/14 18:19;cmccubbin;Here's a snip of the debug log...I'm actually not sure if this is from the master or tserver. But this is from right before we started seeing strange behavior.,"18/Feb/14 18:20;ecn;I haven't worked through all the implications, but doing scan during {{prepareMutationsForCommit}} might not work.  Since this is a sqrrl-specific extension, I'm not going to put any more time into it.  Perhaps you can adopt the integration test I added to reproduce the problem with your full code base.
","18/Feb/14 18:20;cmccubbin;And after that, the log is flooded with those ""2014-02-10 12:50:58,338 [tabletserver.TabletServer] DEBUG: Got unloadTablet message from user: !SYSTEM"" messages, one every couple of ms.",18/Feb/14 18:38;ecn;Please reopen if you can reproduce on vanilla Apache Accumulo.,"18/Feb/14 20:01;jira-bot;Commit 491346ac1bc3795f3610d5c16fc209d1421b5a48 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=491346a ]

ACCUMULO-2361 integration test should be int src/test/java
","18/Feb/14 20:06;jira-bot;Commit 8ca088e6a37aa57181aaff63b749a7e7c5deb203 in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8ca088e ]

ACCUMULO-2361 clean-up at the end of the test
","18/Feb/14 20:08;jira-bot;Commit e0b8fb0e98c1b38c4fa2e20ae0611e33e07ecba6 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e0b8fb0 ]

ACCUMULO-2361 clean-up: remove commented code
","18/Feb/14 20:08;jira-bot;Commit 8ca088e6a37aa57181aaff63b749a7e7c5deb203 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8ca088e ]

ACCUMULO-2361 clean-up at the end of the test
","18/Feb/14 20:08;jira-bot;Commit e0b8fb0e98c1b38c4fa2e20ae0611e33e07ecba6 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e0b8fb0 ]

ACCUMULO-2361 clean-up: remove commented code
","18/Feb/14 20:08;jira-bot;Commit 8ca088e6a37aa57181aaff63b749a7e7c5deb203 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8ca088e ]

ACCUMULO-2361 clean-up at the end of the test
","17/Mar/14 21:36;vines;So I'm seeing this again, I think. It is still with sqrrl extensions, but I do believe it's irrelevant. Critical items to note-

Repeatedly seeing {code}2014-03-17 11:13:50,784 [tabletserver.TabletServer] INFO : told to unload tablet that was not being served 3tx;^@^@�;^@^@�"" {code}

Those are actually the same character-
{code}root@ip-10-10-1-20:/data0/logs/accumulo# tail tserver_ip-10-10-1-20.debug.log | grep -a ""not being served"" | tail -n 1 | hexdump -C
00000000  32 30 31 34 2d 30 33 2d  31 37 20 31 36 3a 34 36  |2014-03-17 16:46|
00000010  3a 35 35 2c 34 31 31 20  5b 74 61 62 6c 65 74 73  |:55,411 [tablets|
00000020  65 72 76 65 72 2e 54 61  62 6c 65 74 53 65 72 76  |erver.TabletServ|
00000030  65 72 5d 20 49 4e 46 4f  20 3a 20 74 6f 6c 64 20  |er] INFO : told |
00000040  74 6f 20 75 6e 6c 6f 61  64 20 74 61 62 6c 65 74  |to unload tablet|
00000050  20 74 68 61 74 20 77 61  73 20 6e 6f 74 20 62 65  | that was not be|
00000060  69 6e 67 20 73 65 72 76  65 64 20 33 74 78 3b 00  |ing served 3tx;.|
00000070  00 ef bf bd 3b 00 00 ef  bf bd 0a                 |....;......|
0000007b
{code}

So it's trying to use a key extent with \x00\x00\xef\\xbf\bd as both the end row and prev end row, which is weird enough and MAY be relevent (side question - how is this happening?) and that there's no sign of this \x00\x00\xEF\xBF\xBD tablet in the !METADATA table. - metadata table view-

{code}
root@accumulo !METADATA> scan -b 3tx -e 3txa -c ~tab -t !METADATA -np
3tx;\x00\x00\x06f ~tab:~pr []    \x00
3tx;\x00\x00\x0C\xCC ~tab:~pr []    \x01\x00\x00\x06f
3tx;\x00\x00\x133 ~tab:~pr []    \x01\x00\x00\x0C\xCC
3tx;\x00\x00\x19\x99 ~tab:~pr []    \x01\x00\x00\x133
3tx;\x00\x00  ~tab:~pr []    \x01\x00\x00\x19\x99
3tx;\x00\x00&f ~tab:~pr []    \x01\x00\x00 
3tx;\x00\x00,\xCC ~tab:~pr []    \x01\x00\x00&f
3tx;\x00\x0033 ~tab:~pr []    \x01\x00\x00,\xCC
3tx;\x00\x009\x99 ~tab:~pr []    \x01\x00\x0033
3tx;\x00\x00@ ~tab:~pr []    \x01\x00\x009\x99
3tx;\x00\x00Ff ~tab:~pr []    \x01\x00\x00@
3tx;\x00\x00L\xCC ~tab:~pr []    \x01\x00\x00Ff
3tx;\x00\x00S3 ~tab:~pr []    \x01\x00\x00L\xCC
3tx;\x00\x00Y\x99 ~tab:~pr []    \x01\x00\x00S3
3tx;\x00\x00` ~tab:~pr []    \x01\x00\x00Y\x99
3tx;\x00\x00ff ~tab:~pr []    \x01\x00\x00`
3tx;\x00\x00l\xCC ~tab:~pr []    \x01\x00\x00ff
3tx;\x00\x00s3 ~tab:~pr []    \x01\x00\x00l\xCC
3tx;\x00\x00y\x99 ~tab:~pr []    \x01\x00\x00s3
3tx;\x00\x00\x80 ~tab:~pr []    \x01\x00\x00y\x99
3tx;\x00\x00\x86f ~tab:~pr []    \x01\x00\x00\x80
3tx;\x00\x00\x8C\xCC ~tab:~pr []    \x01\x00\x00\x86f
3tx;\x00\x00\x933 ~tab:~pr []    \x01\x00\x00\x8C\xCC
3tx;\x00\x00\x99\x99 ~tab:~pr []    \x01\x00\x00\x933
3tx;\x00\x00\xA0 ~tab:~pr []    \x01\x00\x00\x99\x99
3tx;\x00\x00\xA6f ~tab:~pr []    \x01\x00\x00\xA0
3tx;\x00\x00\xAC\xCC ~tab:~pr []    \x01\x00\x00\xA6f
3tx;\x00\x00\xB33 ~tab:~pr []    \x01\x00\x00\xAC\xCC
3tx;\x00\x00\xB9\x99 ~tab:~pr []    \x01\x00\x00\xB33
3tx;\x00\x00\xC0 ~tab:~pr []    \x01\x00\x00\xB9\x99
3tx;\x00\x00\xC6f ~tab:~pr []    \x01\x00\x00\xC0
3tx;\x00\x00\xCC\xCC ~tab:~pr []    \x01\x00\x00\xC6f
3tx;\x00\x00\xD33 ~tab:~pr []    \x01\x00\x00\xCC\xCC
3tx;\x00\x00\xD9\x99 ~tab:~pr []    \x01\x00\x00\xD33
3tx;\x00\x00\xE0 ~tab:~pr []    \x01\x00\x00\xD9\x99
3tx;\x00\x00\xE6f ~tab:~pr []    \x01\x00\x00\xE0
3tx;\x00\x00\xEC\xCC ~tab:~pr []    \x01\x00\x00\xE6f
3tx;\x00\x00\xF9\x99 ~tab:~pr []    \x01\x00\x00\xEC\xCC
3tx;\x00\x01 ~tab:~pr []    \x01\x00\x00\xF9\x99
3tx< ~tab:~pr []    \x01\x00\x01
{code}

Tablet server logs-
{code}
2014-03-15 03:25:40,038 [tabletserver.TabletServer] INFO : unloaded 3tx;^@^@�;^@^@ٙ
2014-03-15 03:25:40,038 [tabletserver.Tablet] DEBUG: initiateClose(saveState=false queueMinC=false disableWrites=false) 3tx;^@^@�;^@^@�
2014-03-15 03:25:40,038 [tabletserver.Tablet] DEBUG: completeClose(saveState=false completeClose=true) 3tx;^@^@�;^@^@�
2014-03-15 03:25:40,038 [tabletserver.Tablet] TABLET_HIST: 3tx;^@^@�;^@^@� closed
2014-03-15 03:25:40,038 [tabletserver.TabletServer] DEBUG: Unassigning 3tx;^@^@�;^@^@�@(null,10.10.1.20:9997[1449daf9ff50ddc],null)
2014-03-15 03:25:40,042 [tabletserver.TabletServer] DEBUG: MultiScanSess 10.10.1.20:40511 2 entries in 0.00 secs (lookup_time:0.00 secs tablets:1 ranges:1) 
2014-03-15 03:25:40,043 [tabletserver.TabletServer] INFO : unloaded 3tx;^@^@�;^@^@�
2014-03-15 03:25:40,043 [tabletserver.TabletServer] INFO : told to unload tablet that was not being served 3tx;^@^@�;^@^@�
2014-03-15 03:25:40,043 [tabletserver.TabletServer] INFO : told to unload tablet that was not being served 3tx;^@^@�;^@^@�
{code}

Looks like a race between unassigning and reattempting to unassign, which is something we've fought with in the past.

Bouncing the master does not resolve this.

table loc scan shows
{code}
root@accumulo> scan -b 3tx -e 3txa -c loc -t !METADATA
3tx;\x00\x00\xEC\xCC loc:1449daf9ff50ddc []    10.10.1.20:9997
3tx;\x00\x00\xF9\x99 loc:1449daf9ff50ddc []    10.10.1.20:9997
{code}

Which is strange, since we only see one erroring unassignment but two tablets with locations.

I then bounced the tserver and it resolved itself.
",17/Mar/14 21:40;vines;https://issues.apache.org/jira/browse/ACCUMULO-2489 was spotted while grabbing debug information for this. This could be related to the mystery tablet that the master was trying to unassign?,18/Mar/14 13:40;ecn;Your extensions may not be causing the problem.  Please consider writing a test that demonstrates that it happens without 3rd party code.,"18/Mar/14 22:14;vines;After about 3 hours against 1.5.1, the following code reproduced the issue. This was after a few hundred messages about overlapping ranges. This finally happened when the tserver died, so I killed this process, restarted the tserver, and attempted to drop all of the TABLE tables from the shell.","18/Mar/14 22:55;vines;Easier method, with this code. While the tables are being created, I ran
kill -9 TSERVERPID; bin/start-here.sh; bin/accumulo shell -u root -p secret -e ""droptable -p TABLE.* -f""

After a few iterations (5), it broke the same way.","20/Mar/14 16:25;ecn;Translated [~vines] description into an Integration Test, which fails consistently for me under 1.6.0-SNAPSHOT.",23/Jun/14 16:41;mdrob;[~ecn] - do you still have the IT that you mentioned? Can we commit (and fix) it in a follow on issue?,24/Jun/14 12:54;ecn;The test is {{DeleteTableDuringSplitIT}} and it was committed with 00ff448.,"24/Jun/14 15:24;vines;When was this fixed? I see commits that landed in 1.5.1 and 1.6.0 which add the test, but the only commits against this ticket that actually touch non-test code are adjustments to the logging message.","26/Jun/14 20:36;vines;Reopening because there are no commits against this ticket where this could have been addressed, nor an explanation for it being addressed.",26/Jun/14 20:39;mdrob;If the test is not failing then it sounds like there is nothing to fix...,"26/Jun/14 20:44;vines;If it was fixed when the test was committed, then the fix versions should be 1.5.1 and 1.6.0","21/Aug/14 21:14;elserj;The only ""substantial"" changes that I can find within a month on either side of March 20th are for ACCUMULO-2520. I don't know those changes somehow fixed this.

[~ecn], how's your memory?","23/Jan/15 01:10;ctubbsii;What is going on with this issue? It's still open, has commits against it, but no updates in awhile. The version number seems to keep getting bumped. Is this even still an issue? If no reply, I'm closing it with the fixVersions that [~vines] mentioned (1.5.1 and 1.6.0), because it seems like it was fixed *at least* by then, if not earlier.","23/Jan/15 21:10;ctubbsii;Closing this with fixVersion 1.5.1 and 1.6.0, since no reply, and it appears to have been resolved by those versions.",,,,,,,,,,
found two last locations for the same extent,ACCUMULO-2057,12685451,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,18/Dec/13 20:07,26/Aug/14 15:05,13/Mar/19 22:01,19/Dec/13 21:33,1.5.0,,,,,,,1.4.5,1.5.1,1.6.0,master,tserver,,,,,0,,,,,"Randomwalk testing, and saw this in the master logs:

{noformat}

2013-12-18 19:16:58,335 [state.MetaDataTableScanner] ERROR: java.lang.RuntimeException: org.apache.accumulo.server.master.state.TabletLocationState$BadLocationState
Exception: found two last locations for the same extent a<: ip-10-1-2-26:9997[1430679035c00c6] and ip-10-1-2-14:9997[343067903a7005b]
java.lang.RuntimeException: org.apache.accumulo.server.master.state.TabletLocationState$BadLocationStateException: found two last locations for the same extent a<: 
ip-10-1-2-26:9997[1430679035c00c6] and ip-10-1-2-14:9997[343067903a7005b]
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.fetch(MetaDataTableScanner.java:192)
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.next(MetaDataTableScanner.java:127)
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.next(MetaDataTableScanner.java:1)
        at org.apache.accumulo.master.TabletGroupWatcher.run(TabletGroupWatcher.java:143)
Caused by: org.apache.accumulo.server.master.state.TabletLocationState$BadLocationStateException: found two last locations for the same extent a<: ip-10-1-2-26:9997[1430679035c00c6] and ip-10-1-2-14:9997[343067903a7005b]
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.createTabletLocationState(MetaDataTableScanner.java:169)
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.fetch(MetaDataTableScanner.java:188)
        ... 3 more
2013-12-18 19:16:58,359 [master.Master] ERROR: Error processing table state for store Normal Tablets
java.lang.RuntimeException: scanner closed
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.hasNext(TabletServerBatchReaderIterator.java:212)
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.hasNext(MetaDataTableScanner.java:117)
        at org.apache.accumulo.master.TabletGroupWatcher.run(TabletGroupWatcher.java:143)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-19 20:33:27.278,,,no_permission,,,,,,,,,,,,364528,,,Tue Aug 26 15:05:13 UTC 2014,,,,,,0|i1qtz3:,364828,,,,,,,,"19/Dec/13 19:03;ecn;Reproduced the problem after studying the logs:

* Create a tablet with a few mutations, flush it to give it a location.
* Shutdown the tserver hosting the tablet
* Split the tablet at its new location
* Compact the table: now it has two last locations!
","19/Dec/13 20:33;jira-bot;Commit 2235b5038a85147cae3495d4d0368e0bd9f38098 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2235b50 ]

ACCUMULO-2057 handle multiple last locations gracefully
","19/Dec/13 20:33;jira-bot;Commit 2235b5038a85147cae3495d4d0368e0bd9f38098 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2235b50 ]

ACCUMULO-2057 handle multiple last locations gracefully
","19/Dec/13 20:33;jira-bot;Commit 76842b29458571fdd66e5b3440f7fd0075d10542 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=76842b2 ]

ACCUMULO-2057 handle duplicate last locations gracefully
","19/Dec/13 20:33;jira-bot;Commit 2235b5038a85147cae3495d4d0368e0bd9f38098 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2235b50 ]

ACCUMULO-2057 handle multiple last locations gracefully
","19/Dec/13 20:33;jira-bot;Commit 76842b29458571fdd66e5b3440f7fd0075d10542 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=76842b2 ]

ACCUMULO-2057 handle duplicate last locations gracefully
","19/Dec/13 20:33;jira-bot;Commit fa31b0c844d09ee66d8f1286f6360cbcb9165e1f in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fa31b0c ]

ACCUMULO-2057 handle duplicate last locations gracefully
","19/Dec/13 20:33;jira-bot;Commit 2235b5038a85147cae3495d4d0368e0bd9f38098 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2235b50 ]

ACCUMULO-2057 handle multiple last locations gracefully
","19/Dec/13 20:33;jira-bot;Commit 76842b29458571fdd66e5b3440f7fd0075d10542 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=76842b2 ]

ACCUMULO-2057 handle duplicate last locations gracefully
","19/Dec/13 20:33;jira-bot;Commit fa31b0c844d09ee66d8f1286f6360cbcb9165e1f in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fa31b0c ]

ACCUMULO-2057 handle duplicate last locations gracefully
","19/Dec/13 20:48;jira-bot;Commit 9cae04863ae46bcd47b09ec883d39dc676574a53 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9cae048 ]

ACCUMULO-2057 track lastLocation through a split
","19/Dec/13 20:48;jira-bot;Commit 9cae04863ae46bcd47b09ec883d39dc676574a53 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9cae048 ]

ACCUMULO-2057 track lastLocation through a split
","19/Dec/13 20:51;jira-bot;Commit e11b3338a8719bbc702337038ca6188e9ee9d224 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e11b333 ]

Revert ""ACCUMULO-2057 track lastLocation through a split""

checked in changes for other tickets... need to redo

This reverts commit 9cae04863ae46bcd47b09ec883d39dc676574a53.
","19/Dec/13 20:51;jira-bot;Commit effd3651dffcd7057d3f4580c13d6f03d88d6652 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=effd365 ]

Revert ""ACCUMULO-2057 track lastLocation through a split""

This reverts commit 9cae04863ae46bcd47b09ec883d39dc676574a53.
","19/Dec/13 21:15;jira-bot;Commit e11b3338a8719bbc702337038ca6188e9ee9d224 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e11b333 ]

Revert ""ACCUMULO-2057 track lastLocation through a split""

checked in changes for other tickets... need to redo

This reverts commit 9cae04863ae46bcd47b09ec883d39dc676574a53.
","19/Dec/13 21:15;jira-bot;Commit 6d083e44d18bc01eebe742bb023671760c581ef3 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6d083e4 ]

ACCUMULO-2057 track lastLocation through a split
","19/Dec/13 21:15;jira-bot;Commit 6d083e44d18bc01eebe742bb023671760c581ef3 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6d083e4 ]

ACCUMULO-2057 track lastLocation through a split
","20/Dec/13 16:10;jira-bot;Commit 6bf68ed0d6e725b8866e304fef693c9f6c6f71fe in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6bf68ed ]

ACCUMULO-2057 caused ACCUMULO-2074 ACCUMULO-2075; copy-paste-error
","20/Dec/13 16:10;jira-bot;Commit 551c6507d5f558fe45aad30b2de42dbf5c3005e0 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=551c650 ]

ACCUMULO-2057 caused ACCUMULO-2074 ACCUMULO-2075; copy-paste-error, re-adding the patch from ACCUMULO-2057 back into master
","20/Dec/13 16:10;jira-bot;Commit 551c6507d5f558fe45aad30b2de42dbf5c3005e0 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=551c650 ]

ACCUMULO-2057 caused ACCUMULO-2074 ACCUMULO-2075; copy-paste-error, re-adding the patch from ACCUMULO-2057 back into master
","20/Dec/13 16:10;jira-bot;Commit 6bf68ed0d6e725b8866e304fef693c9f6c6f71fe in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6bf68ed ]

ACCUMULO-2057 caused ACCUMULO-2074 ACCUMULO-2075; copy-paste-error
","26/Jan/14 22:23;ctubbsii;It was [suggested|http://apache-accumulo.1065345.n5.nabble.com/data-loss-around-splits-when-tserver-goes-down-td7275.html] that this bug might have affected 1.5.0 also.

[~ecn], do you know if that's the case? I see commits against other 1.5.x branches, but the fixVersion only says 1.6.0.",15/Aug/14 19:58;zarinah@gmail.com;I also have this error.  My accumulo cluster won't come up.  Is there a work around for this error?   I'm using Accumulo 1.5.,"26/Aug/14 15:05;ecn;[~zarinah@gmail.com] the work around is to delete last locations, which is safe.  If your metadata table comes online, you should be able to do this in the shell:

{noformat}
shell> grant -u root -t !METADATA Table.WRITE
shell> table !METADATA
shell> deletemany -f -c last
{noformat}

If your metadata table does not come up, you might be able to remove the duplicate last locations from the root tablet like this:
{noformat}
shell> table !METADATA
shell> deletemany -f -c last -e !0<
{noformat}

Please seek help on the mailing list if you are not able to get your system up and running.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Regenerate or repair javadocs,ACCUMULO-1532,12654638,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,25/Jun/13 01:18,05/Aug/14 02:04,13/Mar/19 22:01,05/Aug/14 02:04,,,,,,,,,,,docs,,,,,,0,,,,,"We need to regenerate the javadocs for our website using a more recent version of Java, or repair the existing pages.

See http://www.kb.cert.org/vuls/id/225657",,"Commit 1615836 from [~billie.rinaldi] in branch 'site/trunk'
[ https://svn.apache.org/r1615836 ]

ACCUMULO-1532 repaired 1.4 javadocs;05/Aug/14 01:46;jira-bot;600","Commit 1615839 from [~billie.rinaldi] in branch 'site/trunk'
[ https://svn.apache.org/r1615839 ]

ACCUMULO-1532 updated 1.4/apidocs extpaths;05/Aug/14 02:00;jira-bot;600",,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-25 16:42:15.472,,,no_permission,,,,,,,,,,,,334915,,,Fri Jul 18 04:37:03 UTC 2014,,,,,,0|i1lrsn:,335239,,,,,,,,"25/Jun/13 16:42;ctubbsii;I had already run the tool on the maven-site folder with the apidocs, but I didn't realize that the production website was using extpaths for these. I'm not sure why we do that.","25/Jun/13 21:03;billie.rinaldi;It's because the apidocs are so large (>100MB for 1.5.0) that it makes working with the rest of the site (~5MB) unwieldy / annoying.  Also, since they're generated, they shouldn't change under normal circumstances.",29/Oct/13 16:31;elserj;Are we good to close this out or do we still need to do something here?,"29/Oct/13 18:28;billie.rinaldi;No, we still need to replace the javadocs on the website.",29/Oct/13 23:27;ctubbsii;Does anybody know how to update extpaths stuffs?,30/Oct/13 04:57;mdrob;Billie explaining how to do the extpaths - http://markmail.org/message/sshhqiwwmfceediu,"31/Oct/13 15:11;billie.rinaldi;It may be possible to get it down to two commits: delete extpaths, introduce javadocs, publish; add extpaths, delete javadocs, publish.  I haven't tried that, though.",25/Mar/14 21:41;elserj;A more thorough description of how to update extpaths that I made based on Billie's original email: http://accumulo.apache.org/releasing.html#javadocs,18/Jul/14 03:57;mdrob;Is this done?,18/Jul/14 03:59;elserj;You can run the tool against our published javadocs to find out...,18/Jul/14 04:37;ctubbsii;Pretty sure Billie did this for the older docs. I don't think the 1.6.0 docs were ever affected.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Instructions for 1.5 functional tests via mapreduce should specify use of tool.sh,ACCUMULO-2443,12699679,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,hpham,busbey,busbey,09/Mar/14 07:50,30/Jun/14 00:43,13/Mar/19 22:01,30/Jun/14 00:43,1.5.1,,,,,,,1.5.2,,,docs,test,,,,,0,newbie,,,,"The README for 1.5 functional tests claims the tests can be run via MR with the line

{noformat}
./bin/accumulo org.apache.accumulo.test.functional.RunTests --tests \
   /user/hadoop/tests --output /user/hadoop/results
{noformat}

Attempting to do so fails because the Accumulo classes are not properly in the Hadoop classpath.

Instead, the readme shoudl be updated to use $ACCUMULO_HOME/bin/tool.sh, since it will properly set things up to work with MapReduce.

eg:
{noformat}
./bin/tool.sh lib/accumulo-test.jar org.apache.accumulo.test.functional.RunTests --tests tests --output results
{noformat}",,"Commit 9aafd48bee87fdb6d88bf8d3f64f7812c357a3e1 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~hpham@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9aafd48 ]

ACCUMULO-2443: Change README of auto test to say tool.sh instead of accumulo

Signed-off-by: Sean Busbey <busbey@cloudera.com>
;30/Jun/14 00:42;jira-bot;600","Commit 9aafd48bee87fdb6d88bf8d3f64f7812c357a3e1 in accumulo's branch refs/heads/1.6.1-SNAPSHOT from [~hpham@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9aafd48 ]

ACCUMULO-2443: Change README of auto test to say tool.sh instead of accumulo

Signed-off-by: Sean Busbey <busbey@cloudera.com>
;30/Jun/14 00:42;jira-bot;600","Commit 9aafd48bee87fdb6d88bf8d3f64f7812c357a3e1 in accumulo's branch refs/heads/master from [~hpham@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9aafd48 ]

ACCUMULO-2443: Change README of auto test to say tool.sh instead of accumulo

Signed-off-by: Sean Busbey <busbey@cloudera.com>
;30/Jun/14 00:42;jira-bot;600",,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-06-26 17:31:07.29,,,no_permission,,,,,,,,,,,,378026,,,Mon Jun 30 00:43:32 UTC 2014,,,,,,0|i1t4zr:,378318,,,,,,,,"26/Jun/14 17:31;elserj;[~hpham], are you working on this? I'm trying to get an idea of what is currently outstanding for 1.5.2. Thanks.","26/Jun/14 17:56;hpham;Josh - I can work on this this weekend.     Should be just a minor update to the functional tests README.    To confirm:   I should do this for 1.5.2, correct?","26/Jun/14 18:03;elserj;bq. To confirm: I should do this for 1.5.2, correct?

I assume so, but [~busbey] can confirm since he created the issue.","26/Jun/14 18:17;busbey;yup. current 1.5 dev branch.

[~elserj] the merge to 1.6 will almost certainly be -s ours, because the functional framework moved to ITs that don't have a README or a MR runner.","26/Jun/14 18:23;elserj;bq.  the merge to 1.6 will almost certainly be -s ours, because the functional framework moved to ITs that don't have a README or a MR runner.

Yes, of course. I was considering whether we want to still do this for that reason, but decided it's still worthwhile as we haven't put an EOL on 1.5 yet.","29/Jun/14 22:14;hpham;The README for 1.5 functional tests claims the tests can be run via MR with the line
./bin/accumulo org.apache.accumulo.test.functional.RunTests --tests \
   /user/hadoop/tests --output /user/hadoop/results
Attempting to do so fails because the Accumulo classes are not properly in the Hadoop classpath.
Instead, the readme shoudl be updated to use $ACCUMULO_HOME/bin/tool.sh, since it will properly set things up to work with MapReduce.
eg:
./bin/tool.sh lib/accumulo-test.jar org.apache.accumulo.test.functional.RunTests --tests tests --output results",30/Jun/14 00:43;busbey;Thanks Hung!,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Conditional Mutation with 1000 conditions is slow.,ACCUMULO-1859,12677922,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,07/Nov/13 02:57,23/May/14 17:59,13/Mar/19 22:01,13/Nov/13 23:53,,,,,,,,1.6.0,,,client,tserver,,,,,0,,,,,"The random walk test for conditional mutations creates a conditional mutation  with 1000 conditions.  I noticed this was really slow.   

I did some further testing using MiniAccumulo and was seeing times around 1300ms to 1400ms for this operation (the conditions all checked for absence and all data for the tablet was in memory).

I traced the problem down to parsing the iterator config.  Iterating over the table config, filtering non iterator props, and parsing was taking a little more than a 1ms.  I modifed TableConfiguration to cache the iterator props and saw my test times drop to 120ms to 130ms.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1833,,,,,,,,,,,,,,07/Nov/13 03:06;kturner;0001-ACCUMULO-1859-experimental.patch;https://issues.apache.org/jira/secure/attachment/12612518/0001-ACCUMULO-1859-experimental.patch,07/Nov/13 21:50;kturner;0002-ACCUMULO-1859-experimental.patch;https://issues.apache.org/jira/secure/attachment/12612713/0002-ACCUMULO-1859-experimental.patch,08/Nov/13 20:53;kturner;CWPTest.java;https://issues.apache.org/jira/secure/attachment/12612887/CWPTest.java,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2013-11-13 23:52:24.239,,,no_permission,,,,,,,,,,,,357297,,,Thu Nov 14 01:20:27 UTC 2013,,,,,,0|i1plf3:,357587,,,,,,,,07/Nov/13 03:06;kturner;Attached a file showing the experimental changes I made after locating the slow code.,"07/Nov/13 21:50;kturner;I ran this bug to the ground and found that DefaultConfiguration was the culprit.   Its iterator() method could take up to a few milliseconds.  A secondary issue was that each level of the configuration stack was resorting data (each level was taking everything from the parent and putting it into a treemap).  Also, unwanted properties were being sorted.   My second patch addresses all of the issues.   Running the test with the second patch has the same run times as the first patch.  tl;dr The first patch covered up the performance problem w/ caching, the second patch fixed it.",08/Nov/13 18:43;kturner;One thing I never did determine was why DefaultConfiguration.iterator() was so slow.  Looking at the code its probably either the annotation checking its doing and/or resolving the interpolated properties.,08/Nov/13 20:53;kturner;This is the little program I used to do performance testing.,"13/Nov/13 23:52;jira-bot;Commit c32fb19084688ff6c4e2c246c72b9e9783d84915 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c32fb19 ]

ACCUMULO-1859 dramatically sped up iterating over Accumulo configs
","14/Nov/13 01:20;jira-bot;Commit c32fb19084688ff6c4e2c246c72b9e9783d84915 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c32fb19 ]

ACCUMULO-1859 dramatically sped up iterating over Accumulo configs
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Map reduce reading from Accumulo is not running mapper locally,ACCUMULO-395,12542428,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,13/Feb/12 18:11,25/Apr/14 18:57,13/Mar/19 22:01,17/Feb/12 19:43,1.3.5-incubating,,,,,,,1.3.6,1.4.0,,,,,,,,0,14_qa_bug,,,,"Noticed the continuous ingest verification map reduce job was running slow.  Looking into I noticed that scans were not running locally.  Not sure if this is map reduce issue or AccumuloInputFormat issue.  Not only are the scans not local, sometimes a single tablet server will get a lot scans from many mappers overwhelming it.

{noformat}
$ accumulo shell -u root -p xxxx -e ""listscans -np"" 
 TABLET SERVER        | CLIENT               | AGE      | LAST     | STATE  | TYPE  | USER    | TABLE   | COLUMNS   | TABLET    | ITERATORS  | ITERATOR OPTIONS
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.4:59715 |    2m42s |      8ms |   IDLE |SINGLE |    root |      ci |        [] |6;23a0cc;2380ca |        [] | {}
   xxx.xxx.xxx.8:9997 | xxx.xxx.xxx.12:49054 |     5m3s |      7ms |   IDLE |SINGLE |    root |      ci |        [] |6;1ea0a4c;1e80ac |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.9:57157 |    2m27s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;3a00b;39e0bb |        [] | {}
   xxx.xxx.xxx.8:9997 | xxx.xxx.xxx.10:47880 |    2m58s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;0aa0ab;0a80aa |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.9:57101 |    3m12s |    157ms |RUNNING |SINGLE |    root |      ci |        [] |6;04a05f;04805a |        [] | {}
   xxx.xxx.xxx.8:9997 | xxx.xxx.xxx.13:34053 |    6m20s |    180ms |   IDLE |SINGLE |    root |      ci |        [] |6;34a0cd;3480bd |        [] | {}
   xxx.xxx.xxx.8:9997 | xxx.xxx.xxx.10:47862 |    3m18s |     48ms |   IDLE |SINGLE |    root |      ci |        [] |6;3ea08a;3e808f |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.7:42593 |    2m35s |      2ms |RUNNING |SINGLE |    root |      ci |        [] |6;46a0c5;4680c5 |        [] | {}
  xxx.xxx.xxx.13:9997 |  xxx.xxx.xxx.5:34764 |    2m11s |    177ms |   IDLE |SINGLE |    root |      ci |        [] |6;78007;77e07c |        [] | {}
  xxx.xxx.xxx.13:9997 |  xxx.xxx.xxx.8:43458 |    1m51s |    139ms |   IDLE |SINGLE |    root |      ci |        [] |6;3f803b;3f604e |        [] | {}
  xxx.xxx.xxx.13:9997 |  xxx.xxx.xxx.4:40674 |     3m0s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;0ea08b;0e808f |        [] | {}
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.13:49562 |    2m31s |    111ms |RUNNING |SINGLE |    root |      ci |        [] |6;0ba086;0b8086 |        [] | {}
  xxx.xxx.xxx.13:9997 |  xxx.xxx.xxx.8:43274 |    2m38s |     35ms |   IDLE |SINGLE |    root |      ci |        [] |6;57a024;578025 |        [] | {}
  xxx.xxx.xxx.13:9997 |  xxx.xxx.xxx.6:39526 |    5m11s |    133ms |   IDLE |SINGLE |    root |      ci |        [] |6;16a0c9;1680cc |        [] | {}
  xxx.xxx.xxx.13:9997 |  xxx.xxx.xxx.9:40769 |     5m0s |     11ms |   IDLE |SINGLE |    root |      ci |        [] |6;3fa034;3f803b |        [] | {}
  xxx.xxx.xxx.13:9997 |  xxx.xxx.xxx.6:60691 |    2m59s |     11ms |   IDLE |SINGLE |    root |      ci |        [] |6;1ba0dbe;1b80da |        [] | {}
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.10:35987 |     5m4s |     31ms |   IDLE |SINGLE |    root |      ci |        [] |6;72a066;72806a |        [] | {}
  xxx.xxx.xxx.13:9997 |  xxx.xxx.xxx.9:40839 |    3m18s |      8ms |   IDLE |SINGLE |    root |      ci |        [] |6;71a05e;71805b |        [] | {}
  xxx.xxx.xxx.13:9997 |  xxx.xxx.xxx.8:43189 |    4m36s |    135ms |   IDLE |SINGLE |    root |      ci |        [] |6;75a07d;758075 |        [] | {}
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.12:45476 |     2m5s |    112ms |   IDLE |SINGLE |    root |      ci |        [] |6;48007;47e08 |        [] | {}
  xxx.xxx.xxx.13:9997 |  xxx.xxx.xxx.7:33791 |  4s981ms |     85ms |RUNNING |SINGLE |    root |      ci |        [] |6;5f8036;5f6044c |        [] | {}
  xxx.xxx.xxx.10:9997 |  xxx.xxx.xxx.6:38304 |    2m38s |     18ms |   IDLE |SINGLE |    root |      ci |        [] |6;7ea059;7e8058 |        [] | {}
  xxx.xxx.xxx.10:9997 |  xxx.xxx.xxx.5:44152 |     2m3s |      7ms |   IDLE |SINGLE |    root |      ci |        [] |6;6e809f;6e60a8b |        [] | {}
  xxx.xxx.xxx.10:9997 |  xxx.xxx.xxx.5:44058 |    2m23s |      7ms |   IDLE |SINGLE |    root |      ci |        [] |6;7a00d;79e0d7f |        [] | {}
  xxx.xxx.xxx.10:9997 | xxx.xxx.xxx.13:52463 |    2m35s |      6ms |   IDLE |SINGLE |    root |      ci |        [] |6;77a089;778089 |        [] | {}
  xxx.xxx.xxx.10:9997 |  xxx.xxx.xxx.5:44086 |    2m19s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;4a00c;49e0c3 |        [] | {}
   xxx.xxx.xxx.7:9997 | xxx.xxx.xxx.13:43610 |    2m12s |    179ms |   IDLE |SINGLE |    root |      ci |        [] |6;3800b;37e0bf |        [] | {}
   xxx.xxx.xxx.7:9997 | xxx.xxx.xxx.13:55025 |    4m59s |    152ms |   IDLE |SINGLE |    root |      ci |        [] |6;2ba1568;2b815c |        [] | {}
   xxx.xxx.xxx.7:9997 |  xxx.xxx.xxx.6:44613 |  1s520ms |    518ms |RUNNING |SINGLE |    root |      ci |        [] |6;0f802f;0f6047 |        [] | {}
   xxx.xxx.xxx.7:9997 |  xxx.xxx.xxx.9:33954 |    3m23s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;4da0b4;4d80b9 |        [] | {}
   xxx.xxx.xxx.6:9997 | xxx.xxx.xxx.13:57942 |    2m18s |    224ms |   IDLE |SINGLE |    root |      ci |        [] |6;0a00a;09e0a2 |        [] | {}
   xxx.xxx.xxx.6:9997 | xxx.xxx.xxx.13:58004 |     2m9s |    164ms |   IDLE |SINGLE |    root |      ci |        [] |6;68016;67e16c |        [] | {}
   xxx.xxx.xxx.6:9997 | xxx.xxx.xxx.10:57480 |     3m3s |     80ms |RUNNING |SINGLE |    root |      ci |        [] |6;17a0bc;1780bf |        [] | {}
   xxx.xxx.xxx.6:9997 | xxx.xxx.xxx.12:59552 |    1m59s |    145ms |   IDLE |SINGLE |    root |      ci |        [] |6;1880d8;1860cc |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.5:47196 |    2m29s |     15ms |   IDLE |SINGLE |    root |      ci |        [] |6;1a00d;19e0dd |        [] | {}
   xxx.xxx.xxx.6:9997 | xxx.xxx.xxx.13:58101 |    1m39s |     43ms |   IDLE |SINGLE |    root |      ci |        [] |6;4f8035;4f6045 |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.4:36684 |     3m3s |     97ms |   IDLE |SINGLE |    root |      ci |        [] |6;1ca0df;1c80dc |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.9:45627 |    3m15s |      4ms |RUNNING |SINGLE |    root |      ci |        [] |6;07a022;078025 |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.6:37328 |    4m35s |     93ms |   IDLE |SINGLE |    root |      ci |        [] |6;2da0e5;2d80ed |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.4:46787 |    4m24s |    204ms |   IDLE |SINGLE |    root |      ci |        [] |6;39a0c7d;3980c8 |        [] | {}
   xxx.xxx.xxx.5:9997 | xxx.xxx.xxx.12:39133 |    9m18s |    451ms |   IDLE |SINGLE |    root |      ci |        [] |6;25a147;25813c |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.4:46827 |    3m21s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;52a069;528062 |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.8:49713 |    2m29s |      4ms |   IDLE |SINGLE |    root |      ci |        [] |6;2aa18b;2a818b |        [] | {}
  xxx.xxx.xxx.12:9997 | xxx.xxx.xxx.12:55427 |    2m39s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;45a0c6;4580c7 |        [] | {}
  xxx.xxx.xxx.12:9997 |  xxx.xxx.xxx.9:40025 |     6m6s |     66ms |   IDLE |SINGLE |    root |      ci |        [] |6;44a0bf;4480b9 |        [] | {}
  xxx.xxx.xxx.12:9997 |  xxx.xxx.xxx.7:46896 |    4m48s |      5ms |   IDLE |SINGLE |    root |      ci |        [] |6;6ea092;6e809f |        [] | {}
  xxx.xxx.xxx.12:9997 |  xxx.xxx.xxx.5:59397 |    2m26s |    189ms |   IDLE |SINGLE |    root |      ci |        [] |6;5a004;59e048d |        [] | {}
  xxx.xxx.xxx.12:9997 |  xxx.xxx.xxx.8:47096 |    4m33s |      5ms |   IDLE |SINGLE |    root |      ci |        [] |6;6ca11f;6c8117 |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.6:47355 |    3m23s |      8ms |   IDLE |SINGLE |    root |      ci |        [] |6;06a063;068068 |        [] | {}
   xxx.xxx.xxx.4:9997 | xxx.xxx.xxx.12:56529 |    2m11s |      4ms |RUNNING |SINGLE |    root |      ci |        [] |6;1800a;17e0ad |        [] | {}
   xxx.xxx.xxx.4:9997 | xxx.xxx.xxx.12:56401 |    2m48s |     47ms |   IDLE |SINGLE |    root |      ci |        [] |6;15a0bf;1580bd |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.9:44547 |    3m21s |      6ms |   IDLE |SINGLE |    root |      ci |        [] |6;5ea049;5e8043 |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.8:58391 |     5m6s |    236ms |   IDLE |SINGLE |    root |      ci |        [] |6;28a19a;288196 |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.8:60543 |    2m41s |     43ms |   IDLE |SINGLE |    root |      ci |        [] |6;53a069;538068 |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.4:46148 |     3m6s |    235ms |   IDLE |SINGLE |    root |      ci |        [] |6;03a05c;03805e |        [] | {}
   xxx.xxx.xxx.9:9997 | xxx.xxx.xxx.12:52594 |     2m8s |    319ms |   IDLE |SINGLE |    root |      ci |        [] |6;28019;27e198 |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.7:51462 |    2m59s |    115ms |   IDLE |SINGLE |    root |      ci |        [] |6;19a0eb;1980ea |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.5:48253 |     2m5s |    195ms |   IDLE |SINGLE |    root |      ci |        [] |6;6f803a;6f60496 |        [] | {}
   xxx.xxx.xxx.9:9997 | xxx.xxx.xxx.10:43025 |    2m24s |      3ms |   IDLE |SINGLE |    root |      ci |        [] |6;2a018;29e188 |        [] | {}
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,227714,,,Mon Feb 13 21:54:26 UTC 2012,,,,,,0|i07nfz:,42564,,,,,,,,"13/Feb/12 21:54;kturner;I think I found the issues.  The AccumuloInputFormat passes ip address back for InputSplit locations.  I looked at some other InputFormats and noticed they passed back host names.  I made a quick change to pass back hostnames, and now scans are running locally and evenly.

{noformat}
$ accumulo shell -u root -p xxxx -e ""listscans -np"" 
 TABLET SERVER        | CLIENT               | AGE      | LAST     | STATE  | TYPE  | USER    | TABLE   | COLUMNS   | TABLET    | ITERATORS  | ITERATOR OPTIONS
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.13:39186 |     2m4s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;2380ca;2360c5 |        [] | {}
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.13:39138 |    2m14s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;4480b9;4460ba |        [] | {}
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.13:39263 |    1m50s |    162ms |   IDLE |SINGLE |    root |      ci |        [] |6;2a818b;2a618f |        [] | {}
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.13:39377 |    1m28s |      4ms |RUNNING |SINGLE |    root |      ci |        [] |6;7980cf;7960cd |        [] | {}
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.13:39265 |    1m50s |    225ms |   IDLE |SINGLE |    root |      ci |        [] |6;3480bd;3460bbe |        [] | {}
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.13:39302 |    1m47s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;7c808d;7c608f |        [] | {}
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.13:39102 |    2m17s |        - |RUNNING |SINGLE |    root |      ci |        [] |6;1b80da;1b60e7 |        [] | {}
  xxx.xxx.xxx.13:9997 | xxx.xxx.xxx.13:39433 |    1m23s |      2ms |RUNNING |SINGLE |    root |      ci |        [] |6;56802c;56602bc |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.8:41679 |    2m52s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;088038;086031 |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.8:41926 |    2m13s |    249ms |   IDLE |SINGLE |    root |      ci |        [] |6;04004;03e04d |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.8:41838 |    2m24s |      8ms |   IDLE |SINGLE |    root |      ci |        [] |6;32807c;32607ae |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.8:41626 |    2m56s |      2ms |RUNNING |SINGLE |    root |      ci |        [] |6;3880c5;3860c9 |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.8:41548 |    2m59s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;61808a;616088 |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.8:42009 |    1m34s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;54006;53e06c |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.8:41533 |     3m2s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;25813c;256138 |        [] | {}
   xxx.xxx.xxx.8:9997 |  xxx.xxx.xxx.8:41775 |    2m29s |      5ms |   IDLE |SINGLE |    root |      ci |        [] |6;4980be;4960bb |        [] | {}
  xxx.xxx.xxx.10:9997 | xxx.xxx.xxx.10:57988 |     3m0s |    282ms |   IDLE |SINGLE |    root |      ci |        [] |6;29818f;296198 |        [] | {}
  xxx.xxx.xxx.10:9997 | xxx.xxx.xxx.10:58288 |    2m17s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;3e808f;3e609a |        [] | {}
  xxx.xxx.xxx.10:9997 | xxx.xxx.xxx.10:58157 |    2m39s |     12ms |RUNNING |SINGLE |    root |      ci |        [] |6;068068;066072 |        [] | {}
  xxx.xxx.xxx.10:9997 | xxx.xxx.xxx.10:58126 |    2m41s |     67ms |RUNNING |SINGLE |    root |      ci |        [] |6;1580bd;1560c3 |        [] | {}
  xxx.xxx.xxx.10:9997 | xxx.xxx.xxx.10:58074 |    2m48s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;6d80dd;6d60e8f |        [] | {}
  xxx.xxx.xxx.10:9997 | xxx.xxx.xxx.10:57951 |     3m3s |      2ms |RUNNING |SINGLE |    root |      ci |        [] |6;6f803a;6f60496 |        [] | {}
  xxx.xxx.xxx.10:9997 | xxx.xxx.xxx.10:57880 |    3m10s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;1880d8;1860cc |        [] | {}
  xxx.xxx.xxx.10:9997 | xxx.xxx.xxx.10:58389 |    1m53s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;078025;076034 |        [] | {}
   xxx.xxx.xxx.7:9997 |  xxx.xxx.xxx.7:60817 |    2m22s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;60803b;60602d |        [] | {}
   xxx.xxx.xxx.7:9997 |  xxx.xxx.xxx.7:60705 |    2m40s |     29ms |RUNNING |SINGLE |    root |      ci |        [] |6;4d80b9;4d60c2 |        [] | {}
   xxx.xxx.xxx.7:9997 |  xxx.xxx.xxx.7:60901 |    2m16s |    124ms |RUNNING |SINGLE |    root |      ci |        [] |6;4580c7;4560ce |        [] | {}
   xxx.xxx.xxx.7:9997 |  xxx.xxx.xxx.7:60862 |    2m18s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;1480aa;1460a4 |        [] | {}
   xxx.xxx.xxx.7:9997 |  xxx.xxx.xxx.7:60461 |    3m29s |     29ms |RUNNING |SINGLE |    root |      ci |        [] |6;3a80ae;3a60b6 |        [] | {}
   xxx.xxx.xxx.7:9997 |  xxx.xxx.xxx.7:60641 |    2m46s |     82ms |RUNNING |SINGLE |    root |      ci |        [] |6;4c80df;4c60e7 |        [] | {}
   xxx.xxx.xxx.7:9997 |  xxx.xxx.xxx.7:60621 |    2m48s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;1780bf;1760c4 |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.6:45999 |    2m33s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;2480f7;2460ee |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.6:45903 |    2m53s |    133ms |   IDLE |SINGLE |    root |      ci |        [] |6;03805e;036069 |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.6:37971 |     1m5s |      2ms |RUNNING |SINGLE |    root |      ci |        [] |6;6380f7;6360f97 |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.6:45815 |     3m3s |      4ms |RUNNING |SINGLE |    root |      ci |        [] |6;48007;47e08 |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.6:45866 |    2m56s |        - |RUNNING |SINGLE |    root |      ci |        [] |6;0f802f;0f6047 |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.6:46210 |    1m56s |    294ms |   IDLE |SINGLE |    root |      ci |        [] |6;028066;026069 |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.6:46049 |    2m27s |      2ms |RUNNING |SINGLE |    root |      ci |        [] |6;528062;526058 |        [] | {}
   xxx.xxx.xxx.6:9997 |  xxx.xxx.xxx.6:46095 |    2m23s |        - | QUEUED |SINGLE |    root |      ci |        [] |6;5c8069;5c606f |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.5:47861 |    2m44s |    430ms |   IDLE |SINGLE |    root |      ci |        [] |6;748059;74605a |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.5:47802 |    2m53s |    190ms |   IDLE |SINGLE |    root |      ci |        [] |6;538068;53606a |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.5:47751 |    2m56s |    115ms |RUNNING |SINGLE |    root |      ci |        [] |6;64812e;646129 |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.5:47913 |    2m35s |      5ms |   IDLE |SINGLE |    root |      ci |        [] |6;4780a5;4760ac |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.5:48009 |    2m22s |      4ms |   IDLE |SINGLE |    root |      ci |        [] |6;20802a;206025 |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.5:47614 |    3m15s |      2ms |RUNNING |SINGLE |    root |      ci |        [] |6;518026;516032 |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.5:47658 |     3m9s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;0b8086;0b6092 |        [] | {}
   xxx.xxx.xxx.5:9997 |  xxx.xxx.xxx.5:47578 |    3m26s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;1800a;17e0ad |        [] | {}
  xxx.xxx.xxx.12:9997 | xxx.xxx.xxx.12:40908 |    1m27s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;5b8075;5b607d |        [] | {}
  xxx.xxx.xxx.12:9997 | xxx.xxx.xxx.12:47605 |    1m58s |    284ms |   IDLE |SINGLE |    root |      ci |        [] |6;7d8086;7d608b |        [] | {}
  xxx.xxx.xxx.12:9997 | xxx.xxx.xxx.12:40944 |    1m23s |      5ms |RUNNING |SINGLE |    root |      ci |        [] |6;69815a;69615f |        [] | {}
  xxx.xxx.xxx.12:9997 | xxx.xxx.xxx.12:47540 |    2m12s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;058079;05607a |        [] | {}
  xxx.xxx.xxx.12:9997 | xxx.xxx.xxx.12:47412 |    2m29s |      5ms |RUNNING |SINGLE |    root |      ci |        [] |6;2f8049;2f6057 |        [] | {}
  xxx.xxx.xxx.12:9997 | xxx.xxx.xxx.12:41040 |  27s98ms |      2ms |RUNNING |SINGLE |    root |      ci |        [] |6;33808d;33608c |        [] | {}
  xxx.xxx.xxx.12:9997 | xxx.xxx.xxx.12:47505 |    2m15s |    148ms |   IDLE |SINGLE |    root |      ci |        [] |6;22809a;226098 |        [] | {}
  xxx.xxx.xxx.12:9997 | xxx.xxx.xxx.12:47624 |    1m57s |     77ms |RUNNING |SINGLE |    root |      ci |        [] |6;758075;75607a |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.4:54574 |     3m8s |      1ms |RUNNING |SINGLE |    root |      ci |        [] |6;15a0bf;1580bd |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.4:54805 |    2m34s |    213ms |   IDLE |SINGLE |    root |      ci |        [] |6;548069;54606c |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.4:54688 |    2m52s |      4ms |RUNNING |SINGLE |    root |      ci |        [] |6;6280be;6260c1 |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.4:54873 |    2m25s |    310ms |   IDLE |SINGLE |    root |      ci |        [] |6;288196;28619b |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.4:54987 |    2m12s |    267ms |   IDLE |SINGLE |    root |      ci |        [] |6;6c8117;6c611f |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.4:54751 |    2m43s |      5ms |   IDLE |SINGLE |    root |      ci |        [] |6;59804d;596049 |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.4:54549 |    3m11s |      3ms |RUNNING |SINGLE |    root |      ci |        [] |6;1ba0dbe;1b80da |        [] | {}
   xxx.xxx.xxx.4:9997 |  xxx.xxx.xxx.4:55098 |    1m25s |      1ms | QUEUED |SINGLE |    root |      ci |        [] |6;098088;096085 |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.9:35781 |    2m56s |     13ms |   IDLE |SINGLE |    root |      ci |        [] |6;778089;77608f |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.9:36092 |     2m6s |      2ms |RUNNING |SINGLE |    root |      ci |        [] |6;2e80a4;2e60ad |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.9:35884 |    2m46s |    108ms |RUNNING |SINGLE |    root |      ci |        [] |6;678174;67617b |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.9:35822 |    2m53s |    174ms |   IDLE |SINGLE |    root |      ci |        [] |6;7e8058;7e605d |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.9:35740 |    2m59s |     70ms |RUNNING |SINGLE |    root |      ci |        [] |6;4e808d;4e6092 |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.9:35676 |     3m6s |     86ms |RUNNING |SINGLE |    root |      ci |        [] |6;5f8036;5f6044c |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.9:35950 |    2m37s |      4ms |   IDLE |SINGLE |    root |      ci |        [] |6;4680c5;4660ca |        [] | {}
   xxx.xxx.xxx.9:9997 |  xxx.xxx.xxx.9:35638 |     3m9s |    120ms |RUNNING |SINGLE |    root |      ci |        [] |6;78007;77e07c |        [] | {}
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Experimental properties no longer hidden from DefaultConfiguration,ACCUMULO-2460,12700834,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,ctubbsii,ctubbsii,11/Mar/14 21:51,18/Mar/14 18:31,13/Mar/19 22:01,18/Mar/14 18:16,,,,,,,,1.6.0,,,,,,,,,0,api,semantic,,,"DefaultConfiguration now contains experimental properties, which exposes them prominently to users in the API and in other places, such as in the shell. Users may assume they are stable when they are so prominent. Experimental properties should be excluded from the default configuration (equivalent to default value of null).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-14 18:52:47.788,,,no_permission,,,,,,,,,,,,379177,,,Tue Mar 18 18:31:29 UTC 2014,,,,,,0|i1tc2v:,379469,,,,,,,,14/Mar/14 18:52;elserj;Raising priority: doesn't this represent an unintended change in functionality?,15/Mar/14 00:55;kturner;[~ctubbsii] I created a patch to hide experimental props in the shell.  Were you thinking of doing anything more?,15/Mar/14 05:26;ctubbsii;I took at the patch and it looks fine. I guess whether it is sufficient or not depends on whether we consider the properties enumerated in DefaultConfiguration's iterator part of the public API.,15/Mar/14 05:43;busbey;None of our published guidelines for the public api include o.a.a.core.conf.AccumuloConfiguration. So I wouldn't consider anything that comes out of it part of the public API.,"17/Mar/14 23:00;ctubbsii;Okay, then I think Keith's patch is probably sufficient, then.","18/Mar/14 18:09;jira-bot;Commit 3ef67cbeea54f072c901f25f7bc17740cd30f981 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3ef67cb ]

ACCUMULO-2460 hide experimental props in shell
","18/Mar/14 18:10;jira-bot;Commit 3ef67cbeea54f072c901f25f7bc17740cd30f981 in accumulo's branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3ef67cb ]

ACCUMULO-2460 hide experimental props in shell
","18/Mar/14 18:29;jira-bot;Commit 70d472662d5c21c4f571c9501457172745e59a4c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=70d4726 ]

ACCUMULO-2460 removed empty javadoc
","18/Mar/14 18:31;jira-bot;Commit 70d472662d5c21c4f571c9501457172745e59a4c in accumulo's branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=70d4726 ]

ACCUMULO-2460 removed empty javadoc
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
metadata table not assigned after root table is loaded,ACCUMULO-2408,12697381,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,26/Feb/14 14:47,06/Mar/14 20:58,13/Mar/19 22:01,26/Feb/14 19:42,1.4.0,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,1.5.1,1.4.5,1.5.2,1.6.0,master,,,,,,0,16_qa_bug,,,,"During a nightly integration test run, BigRootTableIT failed, timing out after 4 minutes:

{noformat}
java.lang.Exception: test timed out after 240000 milliseconds
	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1033)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1326)
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:282)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.addSplits(TableOperationsImpl.java:437)
	at org.apache.accumulo.test.functional.BigRootTabletIT.test(BigRootTabletIT.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}

Looking at the logs, the root tablet is assigned successfully:

{noformat}
2014-02-26 05:17:09,414 [state.ZooTabletStateStore] DEBUG: Returning root tablet state: +r<<@(tserver1:9997[1446db2884a0002],null,null)
2014-02-26 05:17:09,596 [master.EventCoordinator] INFO : tablet +r<< was loaded on tserver1:9997
{noformat}

No other tablets are assigned for the next four minutes.

The logs are full of ""Failed to bin"" errors:

{noformat}
2014-02-26 05:19:09,613 [impl.ThriftTransportPool] TRACE: Using existing connection to tserver1:9997
2014-02-26 05:19:09,615 [impl.ThriftTransportPool] TRACE: Returned connection tserver1:9997 (120000) ioCount : 562
2014-02-26 05:19:09,615 [metadata.MetadataLocationObtainer] TRACE: tid=28 oid=3448  Got 2 results  from +r<< in 0.002 secs
2014-02-26 05:19:09,615 [impl.TabletLocatorImpl] TRACE: tid=28 oid=3446  Binned 1 ranges for table !0 to 0 tservers in 0.003 secs
2014-02-26 05:19:09,616 [impl.TabletServerBatchReaderIterator] TRACE: Failed to bin 1 ranges, tablet locations were null, retrying in 100ms
{noformat}

There is an IOException, trying to do a batch read

{noformat}
2014-02-26 05:19:09,687 [impl.TabletServerBatchReaderIterator] DEBUG: Server : tserver1:9997 msg : java.net.SocketTimeoutException: 120000 millis timeout while
 waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/192.168.1.2:52818 remote=tserver1/192.168.1.1:9997]
2014-02-26 05:19:09,689 [impl.TabletServerBatchReaderIterator] DEBUG: org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: 120000 millis timeout while waiting
 for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/192.168.1.2:52818 remote=tserver1/192.168.1.1:9997]
java.io.IOException: org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: 120000 millis timeout while waiting for channel to be ready for read. ch : java.nio.
channels.SocketChannel[connected local=/192.168.1.2:52818 remote=tserver1/192.168.1.1:9997]
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:713)
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator$QueryTask.run(TabletServerBatchReaderIterator.java:372)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:744)
Caused by: org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: 120000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/192.168.1.2:52818 remote=tserver1/192.168.1.1:9997]
        at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:129)
        at org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)
        at org.apache.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)
        at org.apache.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)
        at org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)
        at org.apache.accumulo.core.client.impl.ThriftTransportPool$CachedTTransport.readAll(ThriftTransportPool.java:270)
        at org.apache.thrift.protocol.TCompactProtocol.readByte(TCompactProtocol.java:601)
        at org.apache.thrift.protocol.TCompactProtocol.readMessageBegin(TCompactProtocol.java:470)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_startMultiScan(TabletClientService.java:311)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.startMultiScan(TabletClientService.java:291)
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:658)
        ... 7 more
Caused by: java.net.SocketTimeoutException: 120000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/192.168.1.2:52818 remote=tserver1/192.168.1.1:9997]
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:275)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
        at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:127)
        ... 18 more
2014-02-26 05:19:09,693 [impl.TabletServerBatchReaderIterator] TRACE: Failed to execute multiscans against 1 tablets, retrying...
{noformat}

This would appear to be the batch scanner used to read the root table in the master.

The tablet server hosting the root tablet is being successfully scanned more that 24x a second, presumably from clients.

There are no errors in the tserver logs.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-26 19:40:02.493,,,no_permission,,,,,,,,,,,,375855,,,Wed Feb 26 19:42:51 UTC 2014,,,,,,0|i1srnj:,376151,,,,,,,,"26/Feb/14 15:01;ecn;Failure was against hadoop 1.2.:

{noformat}
mvn -Dhadoop.profile=1 -Dhadoop.version=1.2.1 clean verify
{noformat}
",26/Feb/14 15:04;ecn;The tablet server never reported a successful MultiScan.,"26/Feb/14 15:36;ecn;Managed to reproduce this after a dozen runs.  The multiscan request is stuck here:

{noformat}
""ClientPool 11"" daemon prio=10 tid=0x00007f9c14011800 nid=0xf77c in Object.wait() [0x00007f9bf79f7000]
   java.lang.Thread.State: RUNNABLE
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.startMultiScan(TabletServer.java:1355)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at $Proxy9.startMultiScan(Unknown Source)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$startMultiScan.getResult(TabletClientService.java:2252)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$startMultiScan.getResult(TabletClientService.java:2236)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
{noformat}

Which corresponds to this line:

{noformat}
      Map<KeyExtent,List<Range>> batch = Translator.translate(tbatch, new TKeyExtentTranslator(), new Translator.ListTranslator<TRange,Range>(
          new TRangeTranslator()));
{noformat}
",26/Feb/14 15:40;ecn;Seems to be the same issue as ACCUMULO-1861.,"26/Feb/14 16:46;ecn;Here's the stuck stack with ""jstack -m""

{noformat}
----------------- 41937 -----------------
0x000000351f00b43c      __pthread_cond_wait + 0xcc
0x00007f62d031891d      _ZN13ObjectMonitor4waitElbP6Thread + 0x9bd
0x00007f62d00ce23b      _ZN13instanceKlass15initialize_implE19instanceKlassHandleP6Thread + 0x36b
0x00007f62d00ce55a      _ZN13instanceKlass10initializeEP6Thread + 0x6a
0x00007f62d01055f3      _ZN18InterpreterRuntime4_newEP10JavaThreadP19constantPoolOopDesci + 0x153
0x00007f62cc1b0181      * org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.startMultiScan(org.apache.accumulo.trace.thrift.TInfo, org.apache.accumulo.core.security.thrift.TCredentials, java.util.Map, java.util.List, java.util.List, java.util.Map, java.util.List, boolean) bci:221 line:1355 (Interpreted frame)
0x00007f62cc1924e7      <StubRoutines>
0x00007f62d010d465      _ZN9JavaCalls11call_helperEP9JavaValueP12methodHandleP17JavaCallArgumentsP6Thread + 0x365
0x00007f62d010bec8      _ZN9JavaCalls4callEP9JavaValue12methodHandleP17JavaCallArgumentsP6Thread + 0x28
0x00007f62d039e20f      _ZN10Reflection6invokeE19instanceKlassHandle12methodHandle6Handleb14objArrayHandle9BasicTypeS3_bP6Thread + 0x47f
0x00007f62d039efc0      _ZN10Reflection13invoke_methodEP7oopDesc6Handle14objArrayHandleP6Thread + 0x160
0x00007f62d0194af4      JVM_InvokeMethod + 0x224
0x00007f62cc1a4738      * sun.reflect.NativeMethodAccessorImpl.invoke0(java.lang.reflect.Method, java.lang.Object, java.lang.Object[]) bci:0 (Interpreted frame)
0x00007f62cc198233      * sun.reflect.NativeMethodAccessorImpl.invoke(java.lang.Object, java.lang.Object[]) bci:87 line:57 (Interpreted frame)
0x00007f62cc198233      * sun.reflect.DelegatingMethodAccessorImpl.invoke(java.lang.Object, java.lang.Object[]) bci:6 line:43 (Interpreted frame)
0x00007f62cc1988e1      * java.lang.reflect.Method.invoke(java.lang.Object, java.lang.Object[]) bci:57 line:606 (Interpreted frame)
0x00007f62cc198233      * org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(java.lang.Object, java.lang.reflect.Method, java.lang.Object[]) bci:64 line:63 (Interpreted frame)
0x00007f62cc1988e1      * com.sun.proxy.$Proxy9.startMultiScan(org.apache.accumulo.trace.thrift.TInfo, org.apache.accumulo.core.security.thrift.TCredentials, java.util.Map, java.util.List, java.util.List, java.util.Map, java.util.List, boolean) bci:55 (Interpreted frame)
0x00007f62cc1988e1      * org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$startMultiScan.getResult(org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Iface, org.apache.accumulo.core.tabletserver.thrift.TabletClientService$startMultiScan_args) bci:42 line:2252 (Interpreted frame)
0x00007f62cc198233      * org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$startMultiScan.getResult(java.lang.Object, org.apache.thrift.TBase) bci:9 line:2236 (Interpreted frame)
0x00007f62cc198233      * org.apache.thrift.ProcessFunction.process(int, org.apache.thrift.protocol.TProtocol, org.apache.thrift.protocol.TProtocol, java.lang.Object) bci:86 line:39 (Interpreted frame)
0x00007f62cc198058      * org.apache.thrift.TBaseProcessor.process(org.apache.thrift.protocol.TProtocol, org.apache.thrift.protocol.TProtocol) bci:126 line:39 (Interpreted frame)
0x00007f62cc1989fe      * org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(org.apache.thrift.protocol.TProtocol, org.apache.thrift.protocol.TProtocol) bci:37 line:171 (Interpreted frame)
0x00007f62cc1989fe      * org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke() bci:49 line:478 (Interpreted frame)
0x00007f62cc198058      * org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run() bci:74 line:231 (Interpreted frame)
0x00007f62cc198706      * java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) bci:95 line:1145 (Interpreted frame)
0x00007f62cc198058      * java.util.concurrent.ThreadPoolExecutor$Worker.run() bci:5 line:615 (Interpreted frame)
0x00007f62cc198706      * org.apache.accumulo.trace.instrument.TraceRunnable.run() bci:51 line:47 (Interpreted frame)
0x00007f62cc198706      * org.apache.accumulo.core.util.LoggingRunnable.run() bci:4 line:34 (Interpreted frame)
0x00007f62cc198706      * java.lang.Thread.run() bci:11 line:744 (Interpreted frame)
0x00007f62cc1924e7      <StubRoutines>
0x00007f62d010d465      _ZN9JavaCalls11call_helperEP9JavaValueP12methodHandleP17JavaCallArgumentsP6Thread + 0x365
0x00007f62d010bec8      _ZN9JavaCalls4callEP9JavaValue12methodHandleP17JavaCallArgumentsP6Thread + 0x28
0x00007f62d010c197      _ZN9JavaCalls12call_virtualEP9JavaValue11KlassHandleP6SymbolS4_P17JavaCallArgumentsP6Thread + 0x197
0x00007f62d010c2b7      _ZN9JavaCalls12call_virtualEP9JavaValue6Handle11KlassHandleP6SymbolS5_P6Thread + 0x47
0x00007f62d01881c5      _ZL12thread_entryP10JavaThreadP6Thread + 0xe5
0x00007f62d04625ff      _ZN10JavaThread17thread_main_innerEv + 0xdf
0x00007f62d0462705      _ZN10JavaThread3runEv + 0xf5
0x00007f62d032a538      _ZL10java_startP6Thread + 0x108
{noformat}

Reproduced on jdk7.0u51.
","26/Feb/14 16:57;ecn;A bit of googling around found this [report|https://community.oracle.com/message/9646240] which I don't fully understand yet, but seems to be related to a deadlock possible by having multiple threads initializing the static initialisers of a class.","26/Feb/14 19:40;jira-bot;Commit 57b2e5c7751e2df03b65db6decdb932ba8394802 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=57b2e5c ]

ACCUMULO-2408 organize static final members of abstract class to a concrete implementation
","26/Feb/14 19:40;jira-bot;Commit 57b2e5c7751e2df03b65db6decdb932ba8394802 in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=57b2e5c ]

ACCUMULO-2408 organize static final members of abstract class to a concrete implementation
","26/Feb/14 19:40;jira-bot;Commit 0bd62e390b737d66b2734d3890dbd4f3ca846589 in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0bd62e3 ]

ACCUMULO-2408 organize static final members of abstract class to a concrete implementation
","26/Feb/14 19:40;jira-bot;Commit 57b2e5c7751e2df03b65db6decdb932ba8394802 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=57b2e5c ]

ACCUMULO-2408 organize static final members of abstract class to a concrete implementation
","26/Feb/14 19:40;jira-bot;Commit 0bd62e390b737d66b2734d3890dbd4f3ca846589 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0bd62e3 ]

ACCUMULO-2408 organize static final members of abstract class to a concrete implementation
","26/Feb/14 19:40;jira-bot;Commit 4e7251601f9b51318d7e5373468dd852f12d0e0c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4e72516 ]

ACCUMULO-2408 organize static final members of abstract class to a concrete implementation
","26/Feb/14 19:40;jira-bot;Commit 57b2e5c7751e2df03b65db6decdb932ba8394802 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=57b2e5c ]

ACCUMULO-2408 organize static final members of abstract class to a concrete implementation
","26/Feb/14 19:40;jira-bot;Commit 0bd62e390b737d66b2734d3890dbd4f3ca846589 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0bd62e3 ]

ACCUMULO-2408 organize static final members of abstract class to a concrete implementation
","26/Feb/14 19:40;jira-bot;Commit 4e7251601f9b51318d7e5373468dd852f12d0e0c in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4e72516 ]

ACCUMULO-2408 organize static final members of abstract class to a concrete implementation
","26/Feb/14 19:42;ecn;After moving the static final objects to their own class, the test no longer hangs (well, at least 48 out of 48 attempts).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Backup master can miss acquiring lock when primary exits,ACCUMULO-2422,12697816,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,bhavanki,bhavanki,bhavanki,27/Feb/14 22:32,28/Feb/14 20:11,13/Mar/19 22:01,28/Feb/14 20:11,1.5.1,,,,,,,1.5.2,1.6.0,,fate,master,,,,,0,failover,locking,,,"While running randomwalk tests with agitation for the 1.5.1 release, I've seen situations where a backup master that is eligible to grab the master lock continues to wait. When this condition arises and the other master restarts, both wait for the lock without success.

I cannot reproduce the problem reliably, and I think more investigation is needed to see what circumstances could be causing the problem.

h3. Diagnosis and Work Around
This failure condition can occur on start up and on backup/active failover of the Master role. If the follow log entry is the final entry on all Master logs you should restart all Master roles, staggering by a few seconds.

{noformat}
[master.Master] INFO : trying to get master lock
{noformat}

If starting a cluster with multiple Master roles, you should stagger Master role starts by a few seconds.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-28 05:18:20.442,,,no_permission,,,,,,,,,,,,376290,,,Fri Feb 28 20:09:55 UTC 2014,,,,,,0|i1subr:,376586,,,,,,,,"28/Feb/14 05:18;elserj;How long of a timeframe are you talking about here? By your tone, I'm assuming at least seconds, if not minutes? Indefinitely?

Getting jstack's of the masters in this state would be good. Also, you should check the data in zk /accumulo/uuid/masters and any children at /accumulo/uuid/masters/lock/zlock-* to see what's going on there. It's possible that some of the convenience methods that we wrap ZK with have some issue, but it's primarily ZK code there.","28/Feb/14 14:02;bhavanki;Timeframe I observed is indefinitely, or at least until the agitator bounces both masters.

Stack dumps haven't been terribly helpful so far, although I haven't done a lot of testing yet. Looking at the ZK data is more informative. I added a bunch of logging in master for what it sees in ZK and what it decides to do. So far it appears, at least in one case, that the backup master just didn't notice the active master's node getting deleted. I have even more logging in there now, which I'm checking this morning, to see if it gets no event at all, or why it doesn't process it.","28/Feb/14 15:06;bhavanki;I might have figured it out, though I still need to prove it.

The ""losing"" master server sets a ZK watch on the ""winning"" server's lock node, so that when it disappears it can grab the lock. However, ZK watches are only good for _one event_ ([reference|http://zookeeper.apache.org/doc/r3.2.1/zookeeperProgrammers.html#ch_zkWatches]). If something else happens to the node before it is deleted, then an event for that is sent, but no event is sent for its deletion.

Once a master gets a lock, it replaces its lock node's data when it determines its port (see ACCUMULO-1664 and ACCUMULO-1999). This triggers a NodeDataChanged event. Example:

{noformat}
2014-02-27 18:43:15,141 [zookeeper.ZooLock] DEBUG: - type  NodeDataChanged
2014-02-27 18:43:15,141 [zookeeper.ZooLock] DEBUG: - path  /accumulo/cdeab4df-78e3-4c7f-897b-92f4d98f9602/masters/lock/zlock-0000000206
2014-02-27 18:43:15,141 [zookeeper.ZooLock] DEBUG: - state SyncConnected
{noformat}

This event is sent to the other master's watcher, which does nothing with it, and then the watch dies. So, it won't get a NodeDeleted event later to let it grab the lock. The way to fix this is to set a new watch.

This scenario is difficult to create because both masters need to be started almost simultaneously, and the losing watcher must set its watch between when the winning watcher creates its node and replaces its node data. I'm going to try to trigger this by making the winning master delay the replacement.","28/Feb/14 15:14;mdrob;I think I'm missing part of the picture here - so the first master gets the lock, the second master sets up a watch. After the first master dies, and restarts, what prevents it from getting the lock again, since presumably there is no contention for it, right?","28/Feb/14 15:21;bhavanki;What prevents it is that the master ""gets"" the lock if it has the lock node with the lowest sequential number, as assigned by ZooKeeper. So, extending my example above, the first master originally had the lock with node 206. The second master got 207, but noticed that 206 existed already so it set up a watch on it. So far, so good.

Normally, when the first master exits, the second one gets the deletion event and gets the lock. But in this scenario, the second master gets a node-change event instead. It loses the watch and will never be notified again. Now, the first master exits, so all that is left is node 207. The second master doesn't get the lock, it just waits and waits forever.

The first master restarts and gets node 208. It sees that the second master has 207, so it sets up a watch on it, assuming that the second master has the lock. So, it doesn't get the lock either. It waits and waits forever.","28/Feb/14 15:25;ecn;Yep, writing zookeeper clients is tricky stuff.  Excellent work finding the problem!","28/Feb/14 15:40;billie.rinaldi;Looks like good detective work, [~bhavanki].  In ZooLock.lockAsync it seems to check for a NodeDeleted event or expired session, but doesn't reset the watch if it gets another type of event.  If you verify this is the problem, it was introduced in 1.5.1.","28/Feb/14 17:52;jira-bot;Commit 853ed5bb2b2845284057af051a5d71835cfde8f5 in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=853ed5b ]

ACCUMULO-2422 reset watch on non-delete events
","28/Feb/14 17:52;jira-bot;Commit 853ed5bb2b2845284057af051a5d71835cfde8f5 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=853ed5b ]

ACCUMULO-2422 reset watch on non-delete events
","28/Feb/14 17:52;jira-bot;Commit 7d70ef5848cf6b42752ec708e0442d4b7aa98c2f in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7d70ef5 ]

ACCUMULO-2422 reset watch on non-delete events
","28/Feb/14 17:52;jira-bot;Commit 853ed5bb2b2845284057af051a5d71835cfde8f5 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=853ed5b ]

ACCUMULO-2422 reset watch on non-delete events
","28/Feb/14 17:52;jira-bot;Commit 7d70ef5848cf6b42752ec708e0442d4b7aa98c2f in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7d70ef5 ]

ACCUMULO-2422 reset watch on non-delete events
","28/Feb/14 18:14;bhavanki;I think Eric's fix should be fine, but I want to do more testing, and possibly add some logging and refinement.",28/Feb/14 18:28;busbey;Added diagnosis and word  around text.,"28/Feb/14 19:38;bhavanki;Posted a review for refinements to Eric's initial fix. Lotsa logging, and some refinements.","28/Feb/14 20:09;jira-bot;Commit 7eeff02c7cf883765a33575a19d208be30e1e17c in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7eeff02 ]

ACCUMULO-2422 Refine renewal of master lock watcher

The first commit for ACCUMULO-2422 succeeds in renewing the watch on another master's lock
node when needed. This commit refines the solution:

- The renewal was happening even after the master is able to acquire the lock. This led to a
  spurious log error message. This commit skips renewing the watch in that case.
- If the renewal returns a null status, meaning the other master's lock node disappeared, the
  master now immediately tries again to acquire the lock. This matches watch establishment in
  other areas.

A lot of logging at the trace level was added to ZooLock to assist future troubleshooting.
","28/Feb/14 20:09;jira-bot;Commit 7eeff02c7cf883765a33575a19d208be30e1e17c in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7eeff02 ]

ACCUMULO-2422 Refine renewal of master lock watcher

The first commit for ACCUMULO-2422 succeeds in renewing the watch on another master's lock
node when needed. This commit refines the solution:

- The renewal was happening even after the master is able to acquire the lock. This led to a
  spurious log error message. This commit skips renewing the watch in that case.
- If the renewal returns a null status, meaning the other master's lock node disappeared, the
  master now immediately tries again to acquire the lock. This matches watch establishment in
  other areas.

A lot of logging at the trace level was added to ZooLock to assist future troubleshooting.
","28/Feb/14 20:09;jira-bot;Commit 7eeff02c7cf883765a33575a19d208be30e1e17c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7eeff02 ]

ACCUMULO-2422 Refine renewal of master lock watcher

The first commit for ACCUMULO-2422 succeeds in renewing the watch on another master's lock
node when needed. This commit refines the solution:

- The renewal was happening even after the master is able to acquire the lock. This led to a
  spurious log error message. This commit skips renewing the watch in that case.
- If the renewal returns a null status, meaning the other master's lock node disappeared, the
  master now immediately tries again to acquire the lock. This matches watch establishment in
  other areas.

A lot of logging at the trace level was added to ZooLock to assist future troubleshooting.
","28/Feb/14 20:09;jira-bot;Commit 7eeff02c7cf883765a33575a19d208be30e1e17c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7eeff02 ]

ACCUMULO-2422 Refine renewal of master lock watcher

The first commit for ACCUMULO-2422 succeeds in renewing the watch on another master's lock
node when needed. This commit refines the solution:

- The renewal was happening even after the master is able to acquire the lock. This led to a
  spurious log error message. This commit skips renewing the watch in that case.
- If the renewal returns a null status, meaning the other master's lock node disappeared, the
  master now immediately tries again to acquire the lock. This matches watch establishment in
  other areas.

A lot of logging at the trace level was added to ZooLock to assist future troubleshooting.
","28/Feb/14 20:09;jira-bot;Commit 7eeff02c7cf883765a33575a19d208be30e1e17c in accumulo's branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7eeff02 ]

ACCUMULO-2422 Refine renewal of master lock watcher

The first commit for ACCUMULO-2422 succeeds in renewing the watch on another master's lock
node when needed. This commit refines the solution:

- The renewal was happening even after the master is able to acquire the lock. This led to a
  spurious log error message. This commit skips renewing the watch in that case.
- If the renewal returns a null status, meaning the other master's lock node disappeared, the
  master now immediately tries again to acquire the lock. This matches watch establishment in
  other areas.

A lot of logging at the trace level was added to ZooLock to assist future troubleshooting.
","28/Feb/14 20:09;jira-bot;Commit 7eeff02c7cf883765a33575a19d208be30e1e17c in accumulo's branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7eeff02 ]

ACCUMULO-2422 Refine renewal of master lock watcher

The first commit for ACCUMULO-2422 succeeds in renewing the watch on another master's lock
node when needed. This commit refines the solution:

- The renewal was happening even after the master is able to acquire the lock. This led to a
  spurious log error message. This commit skips renewing the watch in that case.
- If the renewal returns a null status, meaning the other master's lock node disappeared, the
  master now immediately tries again to acquire the lock. This matches watch establishment in
  other areas.

A lot of logging at the trace level was added to ZooLock to assist future troubleshooting.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
WALog is slow,ACCUMULO-1905,12679772,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,ecn,ecn,18/Nov/13 17:30,28/Feb/14 00:50,13/Mar/19 22:01,03/Dec/13 17:23,1.5.0,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"I thought that the continuous ingest test was going slower than it used to.  I was getting about 20K k-v/sec on my desktop.

After turning off the WALog, ingest shot up to 200K k-v/sec.  I expected some improvement, but not an order of magnitude.

","hadoop 2.2.0, accumulo 1.6.0, hash 45fbee6937549048c74fe176f201c246de0f5e0a",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1950,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-02 19:53:53.727,,,no_permission,,,,,,,,,,,,359130,,,Fri Feb 28 00:50:12 UTC 2014,,,,,,0|i1pwt3:,359429,,,,,,,,"18/Nov/13 23:31;ecn;Analysis shows that every group sync (using hsync in hadoop 2.2.0), was taking 50-100ms.  If there wasn't enough data buffered in the group, then smallish amounts were being sent.

First, I increased the client batch size, which is hard-coded (to 1<<17 bytes).  This increased the performance to the same level as the plain sync call available in hadoop 1.2.  Also, adding a second client increased the performance since there were now more clients participating in the group sync.

Finally, I put the client buffer setting back down, and increased the size of the session buffer through configuration:

{{root@test> config -s tserver.mutation.queue.max=2M}}

Now, without any code changes, performance is back up to 40K k-v/sec with a single client.

I was using a very small in-memory map (10M), which caused lots of compactions, which, in turn, caused lots of flushed writes to the !METADATA table.  Those writes would push through to the WAL, which always took 50-100ms.

So, after increasing the IMM to 7G, performance was steady at 73K k-v/sec.
","19/Nov/13 00:11;ecn;With two ingesters, and the native map, I'm seeing 140K k-v/sec.",02/Dec/13 19:53;kturner;I think we should document this for 1.6.0,"03/Dec/13 17:21;jira-bot;Commit 39260cb90be7129d91c21a3f85f625f8578ae554 in branch refs/heads/1.5.1-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=39260cb ]

ACCUMULO-1905 added documentation about hsync to tserver.mutation.queue.max
","03/Dec/13 17:21;jira-bot;Commit 39260cb90be7129d91c21a3f85f625f8578ae554 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=39260cb ]

ACCUMULO-1905 added documentation about hsync to tserver.mutation.queue.max
","03/Dec/13 17:27;jira-bot;Commit f1f28be82a2c27ad905d3bde0669b10ab93d4cf5 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f1f28be ]

ACCUMULO-1905 increased tserver.mutation.queue.max default to 1M
","03/Dec/13 21:18;jira-bot;Commit f1f28be82a2c27ad905d3bde0669b10ab93d4cf5 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f1f28be ]

ACCUMULO-1905 increased tserver.mutation.queue.max default to 1M
","27/Feb/14 23:33;kturner;Also seeing this issue when testing 1.5.1-RC3.   On a single node hadoop 2.2.0 system I saw the following approximate aggregate write rates when running test/system/ingest_test.sh.  

|| tserver.mutation.queue.max value || aggregate write rate ||
|| 256K ||  ~40 K mutations/sec ||
|| 1M ||  ~125 K mutations/sec ||
|| 2M ||  ~170 K mutations/sec ||
|| 4M ||  ~200 K mutations/sec ||

This makes me wonder about the 1M default I chose for 1.6.  I was trying to conservative to avoid introducing memory exhaustion that did not previously exist, but the write rates are not what I would expect.",28/Feb/14 00:50;dlmarion;I would be interested to know if Hadoop 2.3 performance is better or worse.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tables.getNamespaces NPE's on missing table ID,ACCUMULO-2087,12686244,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,elserj,elserj,elserj,24/Dec/13 01:33,27/Feb/14 00:29,13/Mar/19 22:01,04/Feb/14 19:28,,,,,,,,1.6.0,,,,,,,,,0,,,,,"If the user provides a tableID which doesn't exist to getNamespace, the implementation will NPE if a table with that ID doesn't exist.

It should throw a proper exception and be noted in the javadoc as such.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-24 03:54:08.021,,,no_permission,,,,,,,,,,,,365217,,,Tue Feb 04 19:28:31 UTC 2014,,,,,,0|i1qy8v:,365522,,,,,,,,"24/Dec/13 02:13;elserj;This gets really nasty, really fast. [~ctubbsii], is this just a hole in the implementation? As I'm working through this, it just looks like concurrent table/namespace operations weren't even considered, as such, the API is just throwing stuff constantly and there's overlap between what should be a table related error and a namespace related error.

Edit: for example, take {{o.a.a.s.c.ServerConfiguration#getTableConfiguration}} calls {{getNamespaceConfigurationForTable}} which makes a {{TableParentConfiguration}} (still not sure what that actually is supposed to do) which ultimately tries to get the namespace for a table ID (which could fail). That entire chain either needs to propagate a TableNotFoundException or a NamespaceNotFound exception, both of which don't really make sense in portions of that call stack.","24/Dec/13 03:06;elserj;NamespaceConfiguration extending AccumuloConfiguration also causes issues due to the inheritance, we'd either have to make AccumuloConfiguration throw a NamespaceNotFoundException or a runtime exception (or nuke the inheritance from AccumuloConfiguration).","24/Dec/13 03:54;jira-bot;Commit 744f06bfbf23f1cf3f8b0f8b785decd04e69842f in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=744f06b ]

ACCUMULO-2087 Check for the null result from zk and throw something slightly more meaningful.
","24/Dec/13 03:55;elserj;I fixed the code so that it won't throw the NPE anymore, but throws an IllegalArgumentException when it can't be handled. This is really a bandaid for 1.6.0 and I think something better should be addressed.

I'll leave this open for some commentary before closing and making a new ticket for >1.6.0.","24/Dec/13 04:08;ctubbsii;Tables is not supposed to be public API. This is just a helper/utility class to read from ZooKeeper. I haven't worked through all of it yet to see the pitfalls of concurrency... but my guess is that Tables is prone to these sorts of issues everywhere. It probably shouldn't throw IllegalArgumentException... it should probably pass the null through instead of making a new String if null, and be handled by the caller.",24/Dec/13 04:13;ctubbsii;Mind if I re-assign this to myself so I can review/clean up these helpers so sensible things propagate?,"24/Dec/13 04:17;elserj;bq. Tables is not supposed to be public API

I know that, but it's still a public static method that was used by tests, so I consider it to have some sensibility.

bq. it should probably pass the null through instead of making a new String if null, and be handled by the caller.

:cringe: I don't really care for that practice, but if that's what the rest of the code is doing.

bq. Mind if I re-assign this to myself

Go for it. That's why I unassigned it from myself. If you come up with something better, feel free to revert the bandaid.","24/Dec/13 05:03;jira-bot;Commit 0d294ad64ed5a12c44e1c33bc5561897e3aef512 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0d294ad ]

ACCUMULO-2087 ACCUMULO-2086 Fixing formatting.
","24/Dec/13 06:19;jira-bot;Commit 744f06bfbf23f1cf3f8b0f8b785decd04e69842f in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=744f06b ]

ACCUMULO-2087 Check for the null result from zk and throw something slightly more meaningful.
","24/Dec/13 06:20;jira-bot;Commit 0d294ad64ed5a12c44e1c33bc5561897e3aef512 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0d294ad ]

ACCUMULO-2087 ACCUMULO-2086 Fixing formatting.
","04/Feb/14 19:28;vines;This issue has been fixed. If you want to do other cleanup in this class, open up a ticket for it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Log recovery fails with IllegalStateException,ACCUMULO-5,12525976,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,05/Oct/11 21:38,21/Feb/14 01:11,13/Mar/19 22:01,07/Oct/11 19:18,,,,,,,,1.3.5-incubating,1.4.0,,,,,,,,0,,,,,"Sometimes a minor compaction will finish successfully, but the process will die before the compaction finish event is written to the write ahead log.  Recovery attempts to handle this case by looking at what files the tablet has and comparing those with compaction start events.  This check is failing because compaction start events have absolute paths and the recovery code passes in table relative paths.  So the absolute paths and relative paths never match up.

When this occurs, the logical time code will throw an illegal state exception because the recovered data was not newer than the existing data.  An exception like the following will occur and the tablet will fail to load.
    
    IllegalStateException: existing time 19867 >= 19866",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,46604,,,2011-10-05 21:38:32.0,,,,,,0|i07pt3:,42947,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Data file in !METADATA differs from in memory data,ACCUMULO-1940,12681599,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,elserj,elserj,27/Nov/13 15:26,11/Feb/14 17:09,13/Mar/19 22:01,11/Dec/13 18:25,1.4.0,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,,1.4.5,1.5.1,1.6.0,test,,,,,,0,16_qa_bug,,,,"Found during CI run with agitation.

Got the first two error messages 5 times (assuming in a retry on failure block):

{noformat}
Failed to do close consistency check for tablet c;79d0ab;7870a
	java.lang.RuntimeException: Data file in !METADATA differ from in memory data c;79d0ab;7870a  {/t-0005h1j/A0005n8k.rf=797350457 19198312, /t-0005h1j/C0005skm.rf=798078368 19322025, /t-0005h1j/C0005tet.rf=89783168 2196349, /t-0005h1j/C0005u20.rf=90979448 2227972, /t-0005h1j/F0005u0v.rf=23410023 582233, /t-0005h1j/F0005u2p.rf=21958551 547159, /t-0005h1j/F0005u3g.rf=14395121 358893}  {/t-0005h1j/A0005n8k.rf=797350457 19198312, /t-0005h1j/C0005skm.rf=798078368 19322025, /t-0005h1j/C0005tet.rf=89783168 2196349, /t-0005h1j/C0005u20.rf=90979448 2227972, /t-0005h1j/F0005u2p.rf=21958551 547159, /t-0005h1j/F0005u3g.rf=14395121 358893}
		at org.apache.accumulo.server.tabletserver.Tablet.closeConsistencyCheck(Tablet.java:2847)
		at org.apache.accumulo.server.tabletserver.Tablet.completeClose(Tablet.java:2780)
		at org.apache.accumulo.server.tabletserver.Tablet.close(Tablet.java:2658)
		at org.apache.accumulo.server.tabletserver.TabletServer$UnloadTabletHandler.run(TabletServer.java:2357)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at java.lang.Thread.run(Thread.java:744)
{noformat}

Then, we logged that we failed the consistency check

{noformat}
Consistency check fails, retrying java.lang.RuntimeException: Failed to do close consistency check for tablet c;79d0ab;7870a
{noformat}

In the end, we gave up and closed it anyways.

{noformat}
Tablet closed consistency check has failed for c;79d0ab;7870a giving up and closing
{noformat}

Before all of this happened, we tried to bring this tablet online after a failure on a new tserver. During the minc as part of the recovery process, we failed to get the lease on the .rf_tmp file we tried to create. We failed this a couple of times, but eventually got the tmp file we needed and the recovery process completed and we could bring the tablet online. The difference between the in-memory version and the !METADATA version was this one flushed rfile that we created during this recovery process.

The problem eventually fixed itself because the tablet was migrated to a different server and we just took what was (correctly) in the !METADATA table.

There still is an unknown issue of how we missed the flush RFile in the DatafileManager's copy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-29 15:59:22.897,,,no_permission,,,,,,,,,,,,360863,,,Wed Dec 11 18:25:16 UTC 2013,,,,,,0|i1q7gf:,361162,,,,,,,,"27/Nov/13 20:17;elserj;I haven't been able to figure out how the DatafileManager got into an inconsistent state. bringMinorCompactionOnline(...) appears to have completed successfully which means that we should have correctly placed an entry for this flush file into the Map. Unless I missed it, there were no other compactions with this tablet either that could have altered the collection of files.",29/Nov/13 15:59;ecn;One possibility for the lost value in DatafileManager is if the tablet is loaded twice.,"29/Nov/13 18:24;jira-bot;Commit 82477f08aa64e2a8a1cf7f6af0db5ce954801ac8 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=82477f0 ]

ACCUMULO-1940 do not expose a new tablet to the memory manager until after it is online
","29/Nov/13 18:24;jira-bot;Commit 82477f08aa64e2a8a1cf7f6af0db5ce954801ac8 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=82477f0 ]

ACCUMULO-1940 do not expose a new tablet to the memory manager until after it is online
","29/Nov/13 18:24;jira-bot;Commit 82477f08aa64e2a8a1cf7f6af0db5ce954801ac8 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=82477f0 ]

ACCUMULO-1940 do not expose a new tablet to the memory manager until after it is online
","29/Nov/13 18:24;jira-bot;Commit 9b6b9cf104ff332cffdd4900d8057557e64e0ec8 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9b6b9cf ]

ACCUMULO-1940 do not expose a new tablet to the memory manager until after it is online
","29/Nov/13 18:24;jira-bot;Commit 82477f08aa64e2a8a1cf7f6af0db5ce954801ac8 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=82477f0 ]

ACCUMULO-1940 do not expose a new tablet to the memory manager until after it is online
","29/Nov/13 18:24;jira-bot;Commit 9b6b9cf104ff332cffdd4900d8057557e64e0ec8 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9b6b9cf ]

ACCUMULO-1940 do not expose a new tablet to the memory manager until after it is online
","29/Nov/13 18:37;ecn;The memory manager can start a minor compaction after it learns of the tablet's existence.  It learns this when the tablet server reports how much memory it is using.  Unfortunately, it does this right after a recovery in the Tablet's constructor.  In this case, the memory manager started a minor compaction before the tablet was online.  This caused the AssignmentManager's minor compaction to fail.  The AssignmentManager reloaded the tablet at a later time, and no data was lost, but the updates to the METADATA table made by the MemoryManager's MinC were not seen until the consistency check.",02/Dec/13 16:12;kturner;The change that removes  the line that informs the tablet server of the tablets memory usage may lead to the tablet server making bad decisions about memory usage.   Instead of doing this maybe the minor compaction after recovery should probably go through the normal checks that prevent concurrent minor compactions.   ,"02/Dec/13 16:47;ecn;It's probably a bad idea to be doing recovery in the ctor, or anything else that leaks ""this"" to other code that assumes that the tablet is fully constructed, like the MM.

The concurrent MinC check worked, but the tablet load failed and retried.  Then there were two Tablet objects in the server at the same time, and each was allowed to update the !METADATA table.
","02/Dec/13 17:47;kturner;bq.  It's probably a bad idea to be doing recovery in the ctor, or anything else that leaks ""this"" to other code that assumes that the tablet is fully constructed, like the MM.

Agreed.  There is another place where this is leaked, but it seems innocuous.  I'll open a ticket for that.

bq. The concurrent MinC check worked, but the tablet load failed and retried. Then there were two Tablet objects in the server at the same time, and each was allowed to update the !METADATA table.

ok, I see where the concurrency check is done now, I did not look deep enough earlier.  The fix looks good, I will open a separate ticket to track the memory mgmt issue.

","02/Dec/13 18:03;kturner;I opened ACCUMULO-1949.  Thinking about this some more, the changes in this ticket did not create that issue.  It existed before, because the notification to the memory manager was not made until after all data was loaded into memory.  Ideally as the tablet is recovered it would block (unless metadata table) if memory is full until other tablets can be flushed.","11/Dec/13 18:10;mdrob;[~ecn]/[~elserj], is this resolved?","11/Dec/13 18:25;elserj;I haven't re-run another multi-day test yet with this fix, but the fix does look good. I'll close for now and can re-open if it happens again.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrading Accumulo with different zookeeper secret causes issues,ACCUMULO-1591,12659086,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,vines,kturner,kturner,22/Jul/13 13:13,30/Jan/14 00:07,13/Mar/19 22:01,30/Jan/14 00:07,1.4.0,,,,,,,1.4.5,,,,,,,,,0,,,,,"A user ran into an issue where they upgraded Accumulo from 1.4.x to 1.4.y.  During the process they changed the zookeeper password.  This resulted in different nodes in zookeeper with different auths and which prevent Accumulo from working properly.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-22 14:51:45.995,,,no_permission,,,,,,,,,,,,339279,,,Thu Jan 30 00:07:27 UTC 2014,,,,,,0|i1mio7:,339599,,,,,,,,"22/Jul/13 13:19;kturner;One possible way to avoid this problem is to make Accumulo server processes all try to read a certain zookeeper node and halt if they can not.  So if node X can not be read, then do not write anything to zookeeper. 

[~vines], will this solution work w/ Curator?  

Depending on the solution we come up with for this problem, it may be worth porting to 1.4 and 1.5.","22/Jul/13 14:51;vines;Curator basically provides a wrapper which simplifies a lot of calls with auto retries, etc. as well as a bunch of recipes for common actions, such as distirbuted locks, distributed atomic values, and caching, among others. So anything that will work with vanilla ZK will work with Curator. I can't think of a better solution, but TBH I'm having issues understanding the problem at hand. Wouldn't it make more sense to just make the update do all updates as a single transaction?","22/Jul/13 15:01;kturner;Here is a more detailed scenario that describes the problem

 # User installs 1.4.1
 # User edits accumulo-site.xml and sets the secret to X
 # User starts 1.4.1
 # User shuts down 1.4.1 
 # User installs 1.4.2
 # Secret is not set in accumulo-site.xml and therefore reverts to default
 # User starts 1.4.2
 # 1.4.2 starts and writes some zookeeper nodes using the default secret
 # 1.4.2 is unable to read nodes written using the secret X
 # 1.4.2 instance will not start up completely
 # User kills 1.4.2 instance
 # User edits accumulo-site.xml and sets the secret to X
 # 1.4.2 still does not start properly because it can not read the nodes written with the default secret
 # User has to go into zookeeper and fix things
","22/Jul/13 15:28;ecn;Assuming that the user knows they are going to change the system password, they can do:

1. Put the new secret in accumulo-site.xml and distribute this file throughout the cluster
2. Run ChangeSecret:
{noformat}
$ ./bin/accumulo org.apache.accumulo.server.util.ChangeSecret --old oldpasswd --new newpassword
{noformat}

The problem here was that the new servers had scribbled data using the new secret, yet could not update things with the old secret.","26/Oct/13 00:17;vines;So where do we stand with this issue? Is it a documentation issue or should we attempt to make future upgrades use ZK transactions? Furthermore, will this issue be present in 1.6 due to the upgrades involved?","30/Oct/13 14:14;kturner;Since this is a bug that impacts 1.4, 1.5, and 1.6 I plan to look into it after the 1.6 feature freeze.","29/Jan/14 23:51;jira-bot;Commit d362d16ac5ce6c7f088d02fe587d82bdedaac98d in branch refs/heads/1.4.5-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d362d16 ]

ACCUMULO-1591 Master and Logger will fail out if secrets mismatch (tserver already does)
","30/Jan/14 00:05;jira-bot;Commit d362d16ac5ce6c7f088d02fe587d82bdedaac98d in branch refs/heads/1.5.1-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d362d16 ]

ACCUMULO-1591 Master and Logger will fail out if secrets mismatch (tserver already does)
","30/Jan/14 00:06;jira-bot;Commit d362d16ac5ce6c7f088d02fe587d82bdedaac98d in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d362d16 ]

ACCUMULO-1591 Master and Logger will fail out if secrets mismatch (tserver already does)
","30/Jan/14 00:06;jira-bot;Commit d362d16ac5ce6c7f088d02fe587d82bdedaac98d in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d362d16 ]

ACCUMULO-1591 Master and Logger will fail out if secrets mismatch (tserver already does)
","30/Jan/14 00:07;vines;Non-issue in 1.5.0+, master lock dir is ACLed so it can't do anything from there on",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TServer should ensure wal settings are valid for underlying FS,ACCUMULO-2266,12691658,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,vines,busbey,busbey,28/Jan/14 16:16,28/Jan/14 22:57,13/Mar/19 22:01,28/Jan/14 22:57,1.5.0,,,,,,,1.5.1,1.6.0,,tserver,,,,,,0,,,,,"ACCUMULO-2264 revealed a problem in how the tserver handles conflicts between its settings and the restrictions of the underlying fs.

In the case of ACCUMULO-2264, if the tserver is configured with a wal block size less than that allowed by HDFS the tserver sits in an infinite loop.

The tserver should probably be checking for the minimum blocksize (the property is dfs.namenode.fs-limits.min-block-size) and then either issuing a WARN/ERROR to the client and using the minimum or failing loudly and refusing to start. I favor the latter.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-4305,ACCUMULO-2264,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-28 22:52:54.707,,,no_permission,,,,,,,,,,,,370403,,,Tue Jan 28 22:57:20 UTC 2014,,,,,,0|i1rubb:,370724,,,,,,,,"28/Jan/14 22:52;jira-bot;Commit 07da9e3f3cf783074a52331e0d3a4fe0ab4e388b in branch refs/heads/1.5.1-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=07da9e3 ]

ACCUMULO-2266 Checking hdfs minimum block size and failing if it clashes with walog max size
","28/Jan/14 22:56;jira-bot;Commit 07da9e3f3cf783074a52331e0d3a4fe0ab4e388b in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=07da9e3 ]

ACCUMULO-2266 Checking hdfs minimum block size and failing if it clashes with walog max size
","28/Jan/14 22:57;jira-bot;Commit 07da9e3f3cf783074a52331e0d3a4fe0ab4e388b in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=07da9e3 ]

ACCUMULO-2266 Checking hdfs minimum block size and failing if it clashes with walog max size
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
start-all.sh does not work for gc and tracer roles when there are multiples given in conf files,ACCUMULO-2152,12687708,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,busbey,busbey,busbey,07/Jan/14 18:59,08/Jan/14 00:42,13/Mar/19 22:01,08/Jan/14 00:42,,,,,,,,1.4.5,,,scripts,,,,,,0,,,,,"When using multiple gc / tracer roles, start-here.sh works properly, but start-all.sh fails to create any.

instead it gives messages as though it is creating just on the first listed host and instead errors out.

{noformat}
-bash-4.1$ cat $ACCUMULO_CONF_DIR/gc
master1.example.com
master2.example.com
-bash-4.1$ ./bin/start-all.sh
Starting tablet servers and loggers ........ done
Starting tablet server on worker1.example.com
Starting logger on worker1.example.com
2014-01-07 10:54:01,938 [server.Accumulo] INFO : Attempting to talk to zookeeper
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH/lib/hadoop/client-0.20/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH/lib/hadoop/client-0.20/slf4j-log4j12.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
2014-01-07 10:54:02,112 [server.Accumulo] INFO : Zookeeper connected and initialized, attemping to talk to HDFS
2014-01-07 10:54:03,110 [server.Accumulo] INFO : Connected to HDFS
Starting master on master1.example.com
Starting master on master2.example.com
Starting gc on master1.example.com
Starting monitor on master1.example.com
Starting tracer on master1.example
-bash-4.1$ ls -lah /var/log/accumulo/
total 124K
drwxr-xr-x   3 accumulo accumulo 4.0K Jan  7 10:54 .
drwxr-xr-x. 22 root     root     4.0K Jan  5 04:46 ..
-rw-rw-r--   1 accumulo accumulo    0 Jan  7 10:54 master2.example.com_master1.example.com.err
-rw-rw-r--   1 accumulo accumulo  107 Jan  7 10:54 master2.example.com_master1.example.com.out
-rw-rw-r--   1 accumulo accumulo  51K Jan  7 10:54 master_master1.example.com.debug.log
-rw-rw-r--   1 accumulo accumulo  425 Jan  7 10:54 master_master1.example.com.err
-rw-rw-r--   1 accumulo accumulo  17K Jan  7 10:54 master_master1.example.com.log
-rw-rw-r--   1 accumulo accumulo    0 Jan  7 10:54 master_master1.example.com.out
-rw-rw-r--   1 accumulo accumulo  13K Jan  7 10:54 monitor_master1.example.com.debug.log
-rw-rw-r--   1 accumulo accumulo  425 Jan  7 10:54 monitor_master1.example.com.err
-rw-rw-r--   1 accumulo accumulo  11K Jan  7 10:54 monitor_master1.example.com.log
-rw-rw-r--   1 accumulo accumulo    0 Jan  7 10:54 monitor_master1.example.com.out
-bash-4.1$ cat /var/log/accumulo/master2.example.com_master1.example.com.out 
Classname master2.example.com not found.  Please make sure you use the wholly qualified package name.
{noformat}

The problem is how we loop over the available gc/tracer roles.

patch en route.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2153,,,,,,,,,,,,,,07/Jan/14 19:05;busbey;ACCUMULO-2152.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12621833/ACCUMULO-2152.1.patch.txt,07/Jan/14 21:04;busbey;ACCUMULO-2152.2.patch.txt;https://issues.apache.org/jira/secure/attachment/12621856/ACCUMULO-2152.2.patch.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2014-01-07 20:31:21.479,,,no_permission,,,,,,,,,,,,366708,,,Tue Jan 07 22:45:07 UTC 2014,,,,,,0|i1r7lb:,367019,,,,,,,,07/Jan/14 19:05;busbey;tested fix by running on a cluster with dual masters/gc/tracers and successfully starting standby versions of same.,"07/Jan/14 20:31;bhavanki;Instead of

{noformat}
for gc in `echo ""$GC""`
{noformat}

this could work:

{noformat}
for gc in $GC
{noformat}

Barring any issues with special characters in the variable, it's cleaner. There may be a good bash idiom for handling this, though, that I just don't know.",07/Jan/14 21:04;busbey;Updated patch based on feedback.,"07/Jan/14 22:37;jira-bot;Commit 9abb725090fd83a7557a53cdc04fbbec26fb92f3 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9abb725 ]

ACCUMULO-2152 fix start-all.sh to properly handle multiple gc/tracer roles.

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Jan/14 22:38;jira-bot;Commit 9abb725090fd83a7557a53cdc04fbbec26fb92f3 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9abb725 ]

ACCUMULO-2152 fix start-all.sh to properly handle multiple gc/tracer roles.

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Jan/14 22:39;jira-bot;Commit a86d1522ba6b9c54ec1d731f28560237dff14261 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a86d152 ]

ACCUMULO-2152 Merge branch '1.4.5-SNAPSHOT' into 1.5.1-SNAPSHOT
","07/Jan/14 22:39;jira-bot;Commit 9abb725090fd83a7557a53cdc04fbbec26fb92f3 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9abb725 ]

ACCUMULO-2152 fix start-all.sh to properly handle multiple gc/tracer roles.

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Jan/14 22:40;jira-bot;Commit a86d1522ba6b9c54ec1d731f28560237dff14261 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a86d152 ]

ACCUMULO-2152 Merge branch '1.4.5-SNAPSHOT' into 1.5.1-SNAPSHOT
","07/Jan/14 22:40;jira-bot;Commit bb14351c6e6b1dda9a9328e925ce2dcddd0a1bfe in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bb14351 ]

ACCUMULO-2152 Merge branch '1.5.1-SNAPSHOT' into 1.6.0-SNAPSHOT
","07/Jan/14 22:41;jira-bot;Commit 9abb725090fd83a7557a53cdc04fbbec26fb92f3 in branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9abb725 ]

ACCUMULO-2152 fix start-all.sh to properly handle multiple gc/tracer roles.

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Jan/14 22:41;jira-bot;Commit a86d1522ba6b9c54ec1d731f28560237dff14261 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a86d152 ]

ACCUMULO-2152 Merge branch '1.4.5-SNAPSHOT' into 1.5.1-SNAPSHOT
","07/Jan/14 22:42;jira-bot;Commit bb14351c6e6b1dda9a9328e925ce2dcddd0a1bfe in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bb14351 ]

ACCUMULO-2152 Merge branch '1.5.1-SNAPSHOT' into 1.6.0-SNAPSHOT
","07/Jan/14 22:42;jira-bot;Commit 5724ac96a3f579afe5fe88789c9e1d948bb3346c in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5724ac9 ]

ACCUMULO-2152 Merge branch '1.6.0-SNAPSHOT'
","07/Jan/14 22:45;bhavanki;While working this ticket, it was noted that the mechanism in 1.4.5-SNAPSHOT for making the gc and tracers files optional is not present in other branches. See ACCUMULO-2153 for pertinent follow-on work. Commits here only resolve the multiple gc / multiple tracer issue in 1.4.5-SNAPSHOT.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GC doesn't advertise its port,ACCUMULO-2142,12687557,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,elserj,elserj,elserj,07/Jan/14 00:14,07/Jan/14 02:45,13/Mar/19 22:01,07/Jan/14 02:45,,,,,,,,1.6.0,,,gc,,,,,,0,,,,,"The monitor expects to use /gc/lock in ZooKeeper to find the host:port that the GC is running on, but the GC doesn't seem to actually put it there. I'm running with a GC port of 0 to let the process choose its own random port

1.6 seems to correctly report that the GC is dead.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-07 02:45:01.998,,,no_permission,,,,,,,,,,,,366558,,,Tue Jan 07 02:45:34 UTC 2014,,,,,,0|i1r6nr:,366869,,,,,,,,"07/Jan/14 00:41;elserj;I was silly for a little bit: I didn't recurse down far enough into the ZK node so I missed the node that actually had the data.

In 1.6 with gc.port.client, I see {{GC_CLIENT=0.0.0.0:0}} whereas 1.5 with the same gives me something reasonable like {{GC_CLIENT=localhost:58622}}. Both are using 'localhost' in the GC file.","07/Jan/14 00:51;elserj;Ok, verified on a clean system: ""GC_CLIENT=localhost:0"" in 1.6","07/Jan/14 02:45;jira-bot;Commit da9e0f40a34b339eaa23093fce1603c98de0d5d9 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=da9e0f4 ]

ACCUMULO-2142 Return the HostAndPort from creating the thrift server

The GC returned the original HostAndPort object instead of the one
returned by TServerUtils, and ultimately the HsHaServer. The problem
here is that TServerUtils is doing some magic to unwind things like
0.0.0.0 as an addr and a port of 0.
","07/Jan/14 02:45;jira-bot;Commit da9e0f40a34b339eaa23093fce1603c98de0d5d9 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=da9e0f4 ]

ACCUMULO-2142 Return the HostAndPort from creating the thrift server

The GC returned the original HostAndPort object instead of the one
returned by TServerUtils, and ultimately the HsHaServer. The problem
here is that TServerUtils is doing some magic to unwind things like
0.0.0.0 as an addr and a port of 0.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bulk random walk test jams,ACCUMULO-2075,12685832,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,20/Dec/13 15:08,23/Dec/13 13:21,13/Mar/19 22:01,20/Dec/13 16:12,,,,,,,,1.6.0,,,master,tserver,,,,,0,,,,,"Running randomwalk Bulk.xml test on a 20-node test cluster.

Garbage collection stops, blocked on compacting metadata table.

Bulk imports fail because tablets have split, but the retries never succeed.

metadata and root tables scan just fine.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-20 16:10:39.197,,,no_permission,,,,,,,,,,,,364934,,,Mon Dec 23 13:21:41 UTC 2013,,,,,,0|i1qwgv:,365234,,,,,,,,"20/Dec/13 16:10;jira-bot;Commit 6bf68ed0d6e725b8866e304fef693c9f6c6f71fe in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6bf68ed ]

ACCUMULO-2057 caused ACCUMULO-2074 ACCUMULO-2075; copy-paste-error
","20/Dec/13 16:10;jira-bot;Commit 551c6507d5f558fe45aad30b2de42dbf5c3005e0 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=551c650 ]

ACCUMULO-2057 caused ACCUMULO-2074 ACCUMULO-2075; copy-paste-error, re-adding the patch from ACCUMULO-2057 back into master
","20/Dec/13 16:10;jira-bot;Commit 6bf68ed0d6e725b8866e304fef693c9f6c6f71fe in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6bf68ed ]

ACCUMULO-2057 caused ACCUMULO-2074 ACCUMULO-2075; copy-paste-error
","20/Dec/13 16:18;Vivek.Nimje@cognizant.com;Please unregister my email id from mailing list.

Thanks
Vivek
",23/Dec/13 13:21;ctubbsii;User was subscribed as a watcher to this ticket. I removed them as requested.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NotSerializableException: com.google.common.net.HostAndPort,ACCUMULO-2056,12685450,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,18/Dec/13 19:59,19/Dec/13 21:32,13/Mar/19 22:01,19/Dec/13 21:32,,,,,,,,1.6.0,,,master,,,,,,0,,,,,"Randomwalking and got this on the master:

{noformat}
2013-12-18 19:16:12,797 [thrift.ProcessFunction] ERROR: Internal error processing shutdownTabletServer
java.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: com.google.common.net.HostAndPort
        at org.apache.accumulo.fate.ZooStore.push(ZooStore.java:301)
        at org.apache.accumulo.fate.AgeOffStore.push(AgeOffStore.java:176)
        at org.apache.accumulo.fate.Fate.seedTransaction(Fate.java:166)
        at org.apache.accumulo.master.Master$MasterClientServiceHandler.shutdownTabletServer(Master.java:860)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at com.sun.proxy.$Proxy16.shutdownTabletServer(Unknown Source)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Processor$shutdownTabletServer.getResult(MasterClientService.java:1934)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Processor$shutdownTabletServer.getResult(MasterClientService.java:1)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.RuntimeException: java.io.NotSerializableException: com.google.common.net.HostAndPort
        at org.apache.accumulo.fate.ZooStore.serialize(ZooStore.java:67)
        at org.apache.accumulo.fate.ZooStore.push(ZooStore.java:297)
        ... 21 more
Caused by: java.io.NotSerializableException: com.google.common.net.HostAndPort
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1183)
        at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
        at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
        at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
        at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
        at org.apache.accumulo.fate.ZooStore.serialize(ZooStore.java:62)
        ... 22 more


{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,364527,,,2013-12-18 19:59:27.0,,,,,,0|i1qtyv:,364827,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broke log-forwarding with monitor binding to 0.0.0.0,ACCUMULO-2065,12685628,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,elserj,elserj,elserj,19/Dec/13 16:54,19/Dec/13 19:41,13/Mar/19 22:01,19/Dec/13 19:41,,,,,,,,1.5.1,1.6.0,,monitor,,,,,,0,,,,,"In specifying the --address 0.0.0.0 for the monitor, that's also what got placed in ZooKeeper which means that external services can't forward their logs.

The easiest is to probably to revert ACCUMULO-1985 changes to pass in the host from conf/monitor, and then add a new option that will override the address when starting the HTTP server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-19 19:07:01.088,,,no_permission,,,,,,,,,,,,364703,,,Thu Dec 19 19:40:38 UTC 2013,,,,,,0|i1qv1r:,365003,,,,,,,,"19/Dec/13 19:07;jira-bot;Commit a480f63958cee884091fa1f0ad3c542fec5c385a in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a480f63 ]

ACCUMULO-2065 Using the hostname for the system running the monitor instead of what was passed via --address.

The only downside here is if DNS is not set up. However, if DNS is not set up, you're likely running on a single box, at
which point localhost is all you need anyways.
","19/Dec/13 19:40;jira-bot;Commit a480f63958cee884091fa1f0ad3c542fec5c385a in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a480f63 ]

ACCUMULO-2065 Using the hostname for the system running the monitor instead of what was passed via --address.

The only downside here is if DNS is not set up. However, if DNS is not set up, you're likely running on a single box, at
which point localhost is all you need anyways.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MiniAccumuloClusterTest failure,ACCUMULO-2025,12685004,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,vines,elserj,elserj,16/Dec/13 17:37,18/Dec/13 20:50,13/Mar/19 22:01,18/Dec/13 20:50,,,,,,,,1.6.0,,,mini,,,,,,0,,,,,"The only way I can see this happening is that both Mutations got the same timestamp at which point the ordering should be arbitrary which means that the CRC=456 was added after the CRC=123. But, even so, this seems to not be adhering to the contract of BatchWriter.flush().

{noformat}
Tests run: 5, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 9.85 sec <<< FAILURE!
test(org.apache.accumulo.minicluster.MiniAccumuloClusterTest)  Time elapsed: 0.498 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[123]> but was:<[456]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test(MiniAccumuloClusterTest.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-16 18:09:24.209,,,no_permission,,,,,,,,,,,,364081,,,Wed Dec 18 20:49:48 UTC 2013,,,,,,0|i1qr7z:,364381,,,,,,,,"16/Dec/13 17:50;elserj;Actually, I thought that this was a random failure, but seems to be consistently happening at 82e2f57abd69e9b78eb10dc6f79d7f1a0e46576f",16/Dec/13 18:09;ecn;Perhaps the Versioning iterator isn't being applied.,"16/Dec/13 18:17;vines;I had pulled the versioning iterator from the namespace at that commit. I tried changing test() (this needs a better name, also) to set limit versions, but no change. I wonder if that functionality got broke though.",16/Dec/13 18:23;vines;Turns out the limit versions flag no longer does anything on create(),"16/Dec/13 18:29;vines;9f827a303e106598b6d43046a3c31cfe1cbf7d7c seems to have clobbered that, I'm putting it back","16/Dec/13 18:35;jira-bot;Commit 73cbdc04654286dfb91bdd7bb0b61507d6c42c01 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=73cbdc0 ]

ACCUMULO-2025 - restored limitVersion doing things it's supposed to do. And mac test() uses it now
","16/Dec/13 18:35;jira-bot;Commit 73cbdc04654286dfb91bdd7bb0b61507d6c42c01 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=73cbdc0 ]

ACCUMULO-2025 - restored limitVersion doing things it's supposed to do. And mac test() uses it now
","16/Dec/13 18:40;elserj;Thanks, [~ecn] [~jvines@gmail.com], you were both quicker than my git-bisect :)","16/Dec/13 23:58;jira-bot;Commit ae20660d8202cf511c5dbd07b164634fa6f32126 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ae20660 ]

ACCUMULO-2035 ACCUMULO-2025 I accidently made limitVersion always true instead of never true. Now proper.

Also split apart the Iterator and Constraints tests in NamespacesIT
","16/Dec/13 23:58;jira-bot;Commit ae20660d8202cf511c5dbd07b164634fa6f32126 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ae20660 ]

ACCUMULO-2035 ACCUMULO-2025 I accidently made limitVersion always true instead of never true. Now proper.

Also split apart the Iterator and Constraints tests in NamespacesIT
",18/Dec/13 20:48;vines;Now fails with a namespace already existing...,"18/Dec/13 20:49;jira-bot;Commit 3743312d6369ff52691fdca03cb4338972823255 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3743312 ]

ACCUMULO-2025 - splitting the tests caused duplicate tables being used. They now use unique tables and namespaces
","18/Dec/13 20:49;jira-bot;Commit 3743312d6369ff52691fdca03cb4338972823255 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3743312 ]

ACCUMULO-2025 - splitting the tests caused duplicate tables being used. They now use unique tables and namespaces
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
illegal state in RestartStressIT,ACCUMULO-1830,12676472,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,29/Oct/13 19:47,16/Dec/13 16:11,13/Mar/19 22:01,16/Dec/13 16:11,,,,,,,,1.6.0,,,master,tserver,,,,,0,,,,,"{noformat}
2013-10-29 15:20:11,125 [state.MetaDataTableScanner] ERROR: java.lang.RuntimeException: org.apache.accumulo.server.master.state.TabletLocationState$BadLocationStateException: found two locations for the same extent 1<: host:50867[14205a7c2a90003] and host:41255[14205a7c2a9000a]
java.lang.RuntimeException: org.apache.accumulo.server.master.state.TabletLocationState$BadLocationStateException: found two locations for the same extent 1<: host[14205a7c2a90003] and host:41255[14205a7c2a9000a]
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.fetch(MetaDataTableScanner.java:189)
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.next(MetaDataTableScanner.java:124)
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.next(MetaDataTableScanner.java:1)
        at org.apache.accumulo.server.master.TabletGroupWatcher.run(TabletGroupWatcher.java:143)
Caused by: org.apache.accumulo.server.master.state.TabletLocationState$BadLocationStateException: found two locations for the same extent 1<: host:50867[14205a7c2a90003] and host:41255[14205a7c2a9000a]
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.createTabletLocationState(MetaDataTableScanner.java:157)
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.fetch(MetaDataTableScanner.java:185)
        ... 3 more
{noformat}

Here's where the test stopped 
{noformat}
java.lang.IllegalStateException: Tablet has multiple locations : 1<
	at org.apache.accumulo.core.metadata.MetadataLocationObtainer.getMetadataLocationEntries(MetadataLocationObtainer.java:233)
	at org.apache.accumulo.core.metadata.MetadataLocationObtainer.lookupTablet(MetadataLocationObtainer.java:118)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl.lookupTabletLocation(TabletLocatorImpl.java:462)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl._locateTablet(TabletLocatorImpl.java:619)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl.locateTablet(TabletLocatorImpl.java:437)
	at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:226)
	at org.apache.accumulo.core.client.impl.ScannerIterator$Reader.run(ScannerIterator.java:84)
	at org.apache.accumulo.core.client.impl.ScannerIterator.hasNext(ScannerIterator.java:177)
	at org.apache.accumulo.test.VerifyIngest.verifyIngest(VerifyIngest.java:162)
	at org.apache.accumulo.test.functional.RestartStressIT.test(RestartStressIT.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}
","on master, 135e67b68592f0d1c7ca69bac318a7ad3ed55831",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1840,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-01 17:18:55.877,,,no_permission,,,,,,,,,,,,355904,,,Fri Dec 13 22:28:33 UTC 2013,,,,,,0|i1pcu7:,356192,,,,,,,,"30/Oct/13 22:09;ecn;Post-test analysis found that the mutations used to remove WAL entries was incorrect, resulting in WALogs being re-run, which re-introduced an old location.
","01/Nov/13 17:18;jira-bot;Commit 16115f000bf9500b38a01462c25ca5458ae1543f in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=16115f0 ]

ACCUMULO-1830 add an integration test that detects the problem
","01/Nov/13 19:11;jira-bot;Commit b64149d782ef521347fb16bfeecc5c7522a6ee7d in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b64149d ]

ACCUMULO-1830 fix WAL to use consistent METADATA entries
","20/Nov/13 21:20;brassard;We saw this behavior in a 1.5.x build and thought it would be useful to share some insight into how we think this occurred for others that may have similar issues.

Here's a breakdown of the events that took place:

{noformat:nopanel=true}
Timeline:

20:15 i.rf created                              // A
20:20 i.rf compacted away to j.rf     
20:25 i.rf deleted and references updated       // B
??:?? Minor compaction cleans up old walogs     // C
??:?? CLUSTER CRASH
22:20 recovery
22:22 missing file (i.rf) reported

In pictures:    
    
            WAL-1                       RootTablet
            +---------------+           +---------------+
        ?   | file:i.rf     |<---[A]--->| file:i.rf     |
       /    |               |        +->| del:file:i.rf |
      /     +---------------+       /   +---------------+
   [C]                             /
      \     WAL-2                [B]
       \    +---------------+    /
        \+-X| del:file:i.rf | <-+
            |               |
            +---------------+

A: 'i' reference written to RootTablet and WAL-1
B: 'i' delete marker written to RootTablet and WAL-2
    - at this point, there is a delete marker in the RootTablet and in a WAL
C: After compaction, Accumulo cleans up WAL-1 and WAL-2 but is 
   interrupted by failure and WAL-1 is left behind
    
{noformat}

When restarted, the 'file:i.rf' record is recovered and added to the RootTablet, which is telling Accumulo that a file exists, even though it was deleted before the crash happened.
    
A lack of atomicity in the cleanup of walogs seems to be the cause of this behavior.","20/Nov/13 23:05;kturner;[~brassard] I looked at the code and saw that MetadataTableUtil.removeUnusedEntries() uses multiple mutations to delete a set of walogs.  It should use one mutation.  Is this code you are talking about?  Not too familiar with this ticket, can you open a new ticket?  Or do you think this one should be reopened?","21/Nov/13 02:53;brassard;[~afuchs] thought that this was a related bug. Maybe he can comment on what this finding warrants.

The tl;dr for the above post is that one walog got left behind. The bad case of this was that it was the put and not the delete. The case where the delete is left behind is mostly a non-issue. 

I haven't referenced the code directly, but I imagine that anything that should be happening atomically and isn't needs to be fixed for this ticket. The code you're talking about seems like a candidate for a fix. ","21/Nov/13 15:16;brassard;[~kturner], it's worth noting that we think that this was fixed with the resolution in this ticket. The main reason for the comment from yesterday was to provide more insight where this sort of behavior could be seen.

Also, we believe that no pertinent data was actually lost in the scenario outlined above. The Accumulo errors may indicate that data is lost, since it reports that an RFile is missing, but the RFile was actually deleted in a safe way.","21/Nov/13 15:16;vines;[~kturner] nah, Luke was just bringing this up to provide clarity on what sort of real life symptoms this bug could expose itself as, for documentation purposes. We got bit a few times by this before we realized that it was actually a live example of this bug.",21/Nov/13 15:27;kturner;ok I will open a bug for the issue w/ MetadataTableUtil.removeUnusedEntries().  ,"25/Nov/13 22:06;vines;So, it was noticed that this fix was only made on master. This is a really nasty bug in 1.5 and I would like to see it fixed in 1.5.1. I attempted to cherry pick the fix itself back and merge it, but wasn't 100% on it. We're testing now, but I'd be happier if [~ecn] could give it a once over.","26/Nov/13 20:20;vines;Revised patch, now the tests pass","27/Nov/13 16:47;vines;Also, the countLogs in the CleanWalIT test never uses  the tableName, it seems.","02/Dec/13 20:29;vines;Removing patches, they just broke things horribly...","13/Dec/13 18:32;ecn;[~brassard] note that this ticket is for a different bug present only in 1.6.0-SNAPSHOT.  However with ACCUMULO-1914, do you consider the problem you described to be fixed?
","13/Dec/13 22:28;vines;Are you sure, [~ecn]? You had marked the ticket as affects 1.4.x and 1.5.x so I had assumed there was potential across all of them.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
examples-simple brings in unprovided zookeeper dependency,ACCUMULO-1942,12681653,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ctubbsii,vines,vines,27/Nov/13 20:40,07/Dec/13 03:58,13/Mar/19 22:01,07/Dec/13 03:58,,,,,,,,1.5.1,,,build,,,,,,0,,,,,"It looks like an added dependency to examples/simple/pom.xml added a compile time zookeeper dependency, which cuases the zookeeper jar to be added to the lib when built. We should fix this prior to 1.5.1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-02 15:02:39.748,,,no_permission,,,,,,,,,,,,360917,,,Sat Dec 07 03:48:14 UTC 2013,,,,,,0|i1q7s7:,361216,,,,,,,,"02/Dec/13 15:02;kturner;[~vines], so this bug does not exist in 1.5.0?","02/Dec/13 15:30;vines;Correct, it was introduced in 1.5.1-SNAPSHOT","07/Dec/13 03:44;jira-bot;Commit 072ed61863bec0ee74d8a95bc82a2c81a0c5db5a in branch refs/heads/1.5.1-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=072ed61 ]

ACCUMULO-1942 Make zookeeper provided in example pom
","07/Dec/13 03:47;jira-bot;Commit 072ed61863bec0ee74d8a95bc82a2c81a0c5db5a in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=072ed61 ]

ACCUMULO-1942 Make zookeeper provided in example pom
","07/Dec/13 03:48;jira-bot;Commit 072ed61863bec0ee74d8a95bc82a2c81a0c5db5a in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=072ed61 ]

ACCUMULO-1942 Make zookeeper provided in example pom
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
large numbers of threads make in-memory updates slow,ACCUMULO-1062,12632105,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,12/Feb/13 22:29,20/Nov/13 05:40,13/Mar/19 22:01,21/Feb/13 14:52,1.4.2,,,,,,,1.4.3,1.5.0,,tserver,,,,,,0,,,,,"Using hundreds of ingest programs, each running several batch writers, ingest would eventually become slow.  Testing (attached) proved that performance fell off as the number of threads increased.
",testing on large clusters,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,12/Feb/13 22:31;ecn;SlamTest.java;https://issues.apache.org/jira/secure/attachment/12569084/SlamTest.java,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-02-12 22:40:01.658,,,no_permission,,,,,,,,,,,,312601,,,Wed Nov 20 05:40:41 UTC 2013,,,,,,0|i1hy2f:,312947,,,,,,,,"12/Feb/13 22:40;kturner;Eric and I were poking at this issue using the test program.  We found the following code in InMemoryMap is causing the performance  problem.

{code:java}
      synchronized (this) {
        // Can not update mutationCount while writes that started before
        // are in progress, this would cause partial mutations to be seen.
        // Also, can not continue until mutation count is updated, because
        // a read may not see a successful write. Therefore writes must
        // wait for writes that started before to finish.
        
        while (kvCount.get() != kv - 1) {
          try {
            wait();
          } catch (InterruptedException ex) {
            // ignored
          }
        }
        kvCount.set(kv + numKVs - 1);
        notifyAll();
      }
{code}","13/Feb/13 20:19;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #90 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/90/])
    ACCUMULO-1062 serialize writes to ensure counts, rather than serializing the return using check/notify for counts (Revision 1445876)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/InMemoryMap.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
","13/Feb/13 20:39;hudson;Integrated in Accumulo-1.4.x #274 (See [https://builds.apache.org/job/Accumulo-1.4.x/274/])
    ACCUMULO-1062 serialize writes to ensure counts, rather than serializing the return using check/notify for counts; merge to 1.4 branch (Revision 1445880)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/tabletserver/InMemoryMap.java
* /accumulo/branches/1.4/src/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
","13/Feb/13 20:47;hudson;Integrated in Accumulo-Trunk #732 (See [https://builds.apache.org/job/Accumulo-Trunk/732/])
    ACCUMULO-1062 serialize writes to ensure counts, rather than serializing the return using check/notify for counts (Revision 1445876)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/InMemoryMap.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
","14/Feb/13 20:31;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #93 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/93/])
    ACCUMULO-1062 2000 threads is a little too much for a unit test (Revision 1446290)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
","14/Feb/13 20:38;hudson;Integrated in Accumulo-1.4.x #275 (See [https://builds.apache.org/job/Accumulo-1.4.x/275/])
    ACCUMULO-1062 2000 threads is a little too much for a unit test; merge to 1.4 branch (Revision 1446291)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src
* /accumulo/branches/1.4/src/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
","14/Feb/13 20:42;hudson;Integrated in Accumulo-Trunk #735 (See [https://builds.apache.org/job/Accumulo-Trunk/735/])
    ACCUMULO-1062 2000 threads is a little too much for a unit test (Revision 1446290)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
","20/Mar/13 23:29;hudson;Integrated in Accumulo-Trunk #790 (See [https://builds.apache.org/job/Accumulo-Trunk/790/])
    ACCUMULO-1062 I suspect large number of threads is making the apache build servers fail our builds (Revision 1459069)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
* /accumulo/trunk/src
","20/Mar/13 23:50;hudson;Integrated in Accumulo-1.5 #45 (See [https://builds.apache.org/job/Accumulo-1.5/45/])
    ACCUMULO-1062 I suspect large number of threads is making the apache build servers fail our builds (Revision 1459068)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
","21/Mar/13 00:11;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #43 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/43/])
    ACCUMULO-1062 I suspect large number of threads is making the apache build servers fail our builds (Revision 1459068)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
","21/Mar/13 04:15;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #149 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/149/])
    ACCUMULO-1062 I suspect large number of threads is making the apache build servers fail our builds (Revision 1459069)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
* /accumulo/trunk/src
","27/Mar/13 14:26;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #162 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/162/])
    ACCUMULO-1062 disabling testParallelWriteSpeed (Revision 1461553)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
* /accumulo/trunk/src
","27/Mar/13 14:35;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #54 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/54/])
    ACCUMULO-1062 disabling testParallelWriteSpeed (Revision 1461552)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
","27/Mar/13 14:40;hudson;Integrated in Accumulo-1.5 #57 (See [https://builds.apache.org/job/Accumulo-1.5/57/])
    ACCUMULO-1062 disabling testParallelWriteSpeed (Revision 1461552)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
","27/Mar/13 14:44;hudson;Integrated in Accumulo-Trunk #803 (See [https://builds.apache.org/job/Accumulo-Trunk/803/])
    ACCUMULO-1062 disabling testParallelWriteSpeed (Revision 1461553)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
* /accumulo/trunk/src
","20/Nov/13 04:46;jira-bot;Commit ae0be1f60db5b3b2493f5816f4481c1b092ae6bf in branch refs/heads/1.4.5-SNAPSHOT from Eric C. Newton
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ae0be1f ]

ACCUMULO-1062 disabling testParallelWriteSpeed

git-svn-id: https://svn.apache.org/repos/asf/accumulo/branches/1.5@1461552 13f79535-47bb-0310-9956-ffa450edef68
","20/Nov/13 05:26;jira-bot;Commit ae0be1f60db5b3b2493f5816f4481c1b092ae6bf in branch refs/heads/1.5.1-SNAPSHOT from Eric C. Newton
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ae0be1f ]

ACCUMULO-1062 disabling testParallelWriteSpeed

git-svn-id: https://svn.apache.org/repos/asf/accumulo/branches/1.5@1461552 13f79535-47bb-0310-9956-ffa450edef68
","20/Nov/13 05:40;jira-bot;Commit ae0be1f60db5b3b2493f5816f4481c1b092ae6bf in branch refs/heads/1.6.0-SNAPSHOT from Eric C. Newton
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ae0be1f ]

ACCUMULO-1062 disabling testParallelWriteSpeed

git-svn-id: https://svn.apache.org/repos/asf/accumulo/branches/1.5@1461552 13f79535-47bb-0310-9956-ffa450edef68
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update HDFS append/sync precondition check for Hadoop 1.2,ACCUMULO-1637,12661576,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,elserj,elserj,elserj,04/Aug/13 02:53,24/Oct/13 19:16,13/Mar/19 22:01,24/Oct/13 19:16,1.5.0,,,,,,,1.5.1,1.6.0,,tserver,,,,,,0,,,,,"Apache Hadoop 1.2.0 ships with the durable sync enabled by default and the support append option marked as obsolete. Because of this, the check inside of TabletServer, meant to ensure that the HDFS WAL can function properly, incorrectly fails as it doesn't know that dfs.durable.sync is on by default.

This can be worked around by specifying the old durable sync property in hdfs-site.xml:

{noformat}
<property>
  <name>dfs.durable.sync</name>
  <value>true</value>
</property>
{noformat}

I'm not sure how to best way to address the differences between the newer and older versions of Hadoop and their differing append support.

Thanks to Carlos Mundi for pointing this out on user@a.a.o

Using this table to track the presence of these variables and their default from hdfs/o/a/h/h/DFSConfigKeys and from the codebase when there is no config parameter for it.
||Version||DFSConfigKeys.DFS_SUPPORT_APPEND_KEY||DFSConfigKeys.DFS_SUPPORT_APPEND_DEFAULT||""dfs.durable.sync""||Specific Configuration Required||
|0.20.205.0|defined|false|not present|yes|
|0.23.x|defined|true|not present|no|
|1.0.x|defined|false|not present|yes|
|1.1.X|not present|absent|implicit ""true""|no|
|1.2.X|not present|absent|implicit ""true""|no|
|2.0.x|defined|true|not present|no|
|2.1.x|defined|true|not present|no|
|2.2.0|defined|true|not present|no|",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,17/Oct/13 16:31;elserj;0001-ACCUMULO-1637-Rework-the-hadoop-append-sync-checks-t.patch;https://issues.apache.org/jira/secure/attachment/12608958/0001-ACCUMULO-1637-Rework-the-hadoop-append-sync-checks-t.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-10-16 02:30:44.341,,,no_permission,,,,,,,,,,,,341765,,,Thu Oct 24 19:16:05 UTC 2013,,,,,,0|i1mxwn:,342071,,,,,,,,"16/Oct/13 02:30;vines;One of the releases since 1.04 added a centralized location for default
properties that you may be able to use.

Sent from my phone, please pardon the typos and brevity.

","16/Oct/13 02:42;ecn;We could just check for dfs.durable.sync first.
","16/Oct/13 02:54;elserj;Currently trying to wrangle an ""accurate"" view on the Apache Hadoops. I don't think I'll be able to make an assessment on what I think we should do until I have a complete picture.

I'm hoping that DFSConfigKeys will be a uniform place I can look for the defaults (or it will at least match what the code might do implicitly, which I found one instance of already).",16/Oct/13 04:11;ctubbsii;The constants in DFSConfigKeys aren't stable between versions.,"16/Oct/13 04:15;elserj;[~jvines@gmail.com] If you have specifics, that'd be awesome.

[~ecn] Do you know of a means to reliably check that?

Alright, I think I get it now (someone correct me if I'm wrong). Brain-dumping before I lose it.

0.20.205.0 and 1.0.x need the parameter 'dfs.support.append' as a means to make sure *sync* actually works (misnomer on the configuration parameter). 1.1.x (and thus 1.2.x as well) remove this misnomer and introduced 'dfs.durable.sync' as a means for users to turn *off* sync when they don't want it (irrelevant for us). If you have dfs.support.append defined in 1.1.. Hadoop2 variants (0.23 and 2.x) all support append properly and sync implicitly.

In other words: 0.20.205.0 and 1.0.x *must* have the 'dfs.support.append' parameter provided to ensure sync occurs when we call it. >=1.1.0 and >=0.23 must *not* have dfs.durable.sync=false configured (although, realistically, we probably don't ever want to see that).

Personally, if someone is still running 0.20.205.0 or 1.0.x, I'm tempted to just say ""shame on you"" through documentation rather than trying to make a runtime check. We could reflect on DFSConfigKeys (handling the absence of DFS_SUPPORT_APPEND_DEFAULT for the 1.1.x line) and then check for the presence of dfs.support.append being true in the Hadoop conf when DFS_SUPPORT_APPEND_DEFAULT is false. We should probably always check that dfs.durable.sync is absent or true when configured. Thoughts?","16/Oct/13 04:17;elserj;bq. The constants in DFSConfigKeys aren't stable between versions.

Right, that was the point of making the table in the description (as I figured was likely the case).","16/Oct/13 14:03;ecn;bq. We could reflect on DFSConfigKeys (handling the absence of DFS_SUPPORT_APPEND_DEFAULT for the 1.1.x line) and then check for the presence of dfs.support.append being true in the Hadoop conf when DFS_SUPPORT_APPEND_DEFAULT is false.

I think that's reasonable.  Thanks for digging into the version/sync details.
",17/Oct/13 16:31;elserj;Initial stab at reworking the append/sync checks for what Accumulo actually needs.,"17/Oct/13 16:44;ecn;Just commit it; this is a much better check than what is there now.

And hoist the constant "" See ACCUMULO-623 and ACCUMULO-1637 for more details."".
",17/Oct/13 16:47;elserj;Good enough. I'll see if I can get back to this later and add some sort of test for the method as well.,"17/Oct/13 16:49;jira-bot;Commit d1243aafc7dfc9d14ccbe7d67f92055e26228221 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d1243aa ]

ACCUMULO-1637 Rework the hadoop append/sync checks trying to match what
Hadoop is doing internally by default.
","17/Oct/13 16:49;jira-bot;Commit 685cc4a70d87fd7eda56538fb381a8347b4e56e3 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=685cc4a ]

ACCUMULO-1637 Lifting the ticket message into its own string constant
","17/Oct/13 17:08;jira-bot;Commit d1243aafc7dfc9d14ccbe7d67f92055e26228221 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d1243aa ]

ACCUMULO-1637 Rework the hadoop append/sync checks trying to match what
Hadoop is doing internally by default.
","17/Oct/13 17:08;jira-bot;Commit 685cc4a70d87fd7eda56538fb381a8347b4e56e3 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=685cc4a ]

ACCUMULO-1637 Lifting the ticket message into its own string constant
","17/Oct/13 23:45;jira-bot;Commit 18bcd14ca8020e969b9881c44cc3c565471cae5b in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=18bcd14 ]

ACCUMULO-1637 Missed a usage of the DFSConfigKeys constant that might
not always be present.
","17/Oct/13 23:47;jira-bot;Commit 18bcd14ca8020e969b9881c44cc3c565471cae5b in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=18bcd14 ]

ACCUMULO-1637 Missed a usage of the DFSConfigKeys constant that might
not always be present.
","18/Oct/13 01:45;jira-bot;Commit 0987628299165740230de132f85b3c63789ad584 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0987628 ]

ACCUMULO-1637 Add tests for append/sync conf check

Added in a few tests, given a hadoop-1.0.4 dependency, that make sure we
fail when appropriate. Had to change the access control on the method in
TabletServer as well as throwing an exception instead of directly
calling System.exit() to make a more easily testable method.
","18/Oct/13 02:02;jira-bot;Commit 0987628299165740230de132f85b3c63789ad584 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0987628 ]

ACCUMULO-1637 Add tests for append/sync conf check

Added in a few tests, given a hadoop-1.0.4 dependency, that make sure we
fail when appropriate. Had to change the access control on the method in
TabletServer as well as throwing an exception instead of directly
calling System.exit() to make a more easily testable method.
","18/Oct/13 02:02;jira-bot;Commit e498ebb802f7f07827b8f0c0a067f8536322b692 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e498ebb ]

Merge branch '1.5.1-SNAPSHOT'

Conflicts:
	server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java

ACCUMULO-1637 Expanding the tests to account for the VolumeManager
changes in 1.6
",18/Oct/13 15:24;elserj;Borked a test,"18/Oct/13 15:54;jira-bot;Commit 957676e681c46044e9b46f172b8ab96bfdc6715a in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=957676e ]

ACCUMULO-1637 Removing some bad tests that aren't portable across hadoop
versions.
","18/Oct/13 16:02;jira-bot;Commit 957676e681c46044e9b46f172b8ab96bfdc6715a in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=957676e ]

ACCUMULO-1637 Removing some bad tests that aren't portable across hadoop
versions.
",24/Oct/13 18:11;elserj;Found that the previous check is also in the code run during `accumulo init`,"24/Oct/13 19:16;jira-bot;Commit ab6779c30c0308b5905e894c74fce24f6aca7679 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ab6779c ]

ACCUMULO-1637 Update the HDFS configuration check in VolumnManagerImpl
from the one in TabletServer.

Looks like I missed the movement of the configuration validation code in
1.6.0 from TabletServer to VolumeManagerImpl. Updated the check, and
fixed the unit test to invoke the correct code.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
delete mutations not working through the Proxy,ACCUMULO-1800,12675029,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,22/Oct/13 14:11,22/Oct/13 15:26,13/Mar/19 22:01,22/Oct/13 14:30,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,,proxy,,,,,,0,,,,,"Aru Sahni writes:

{quote}
I'm new to Accumulo and am still trying to wrap my head around its ways. To further that challenge, I'm using Pyaccumulo, which doesn't present much in terms of available reference material.

Right now I'm trying to understand how Accumulo manages record (key-value pair) deletions.

conn = Accumulo(host, port, user, password)
table = 'test_table'
conn.create_table(table)
writer = conn.create_batch_writer(table)
mut = Mutation('mut_01')
mut.put(cf='item', cq='name', value='car')
writer.add_mutation(mut)
writer.close()
conn.close()

Will generate a record (found via a shell scan):

mut_01 item:name []    car

However the subsequent mutation...

writer = conn.create_batch_writer(table)
mut = Mutation('mut_01')
mut.put(cf='item', cq='name', is_delete=True)
writer.add_mutation(mut)
writer.close()

Results in:

mut_01 item:name []

How should one expect the deleted row to be represented? That record sticks around even after I force a compaction of the table.  I was expecting it to not show up in any iterators, or at least provide an easy way to see if the cell has been deleted.
{quote}

[~ecn] has confirmed the problem.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-22 14:20:45.961,,,no_permission,,,,,,,,,,,,354651,,,Tue Oct 22 15:26:48 UTC 2013,,,,,,0|i1p547:,354940,,,,,,,,"22/Oct/13 14:20;jira-bot;Commit ffd16c7adbfd99f7acbba08ad9934acd5c80a7df in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ffd16c7 ]

ACCUMULO-1800 fix deletes, added test
","22/Oct/13 14:24;jira-bot;Commit ffd16c7adbfd99f7acbba08ad9934acd5c80a7df in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ffd16c7 ]

ACCUMULO-1800 fix deletes, added test
","22/Oct/13 14:24;jira-bot;Commit 3143b9c5ed639818dd8d8349237815b54f5c1a6a in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3143b9c ]

ACCUMULO-1800 fix deletes, added test
","22/Oct/13 14:29;jira-bot;Commit ffd16c7adbfd99f7acbba08ad9934acd5c80a7df in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ffd16c7 ]

ACCUMULO-1800 fix deletes, added test
","22/Oct/13 14:29;jira-bot;Commit 3143b9c5ed639818dd8d8349237815b54f5c1a6a in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3143b9c ]

ACCUMULO-1800 fix deletes, added test
","22/Oct/13 14:29;jira-bot;Commit 8ec4cb840aff77bba3f3dc2e1b98a1c4de7c89ab in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8ec4cb8 ]

ACCUMULO-1800 fix deletes, added test
","22/Oct/13 15:26;busbey;For future searchers, [workaround per Eric|http://mail-archives.apache.org/mod_mbox/accumulo-user/201310.mbox/%3CCADxc9BmJzWkt3pyvEv%2BunXethJ%3DEzXkEKvQEm-MT8BZcExmqow%40mail.gmail.com%3E]

bq. If you set the timestamp on your mutation (to the current time in millis) it should work.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
unload of METADATA default_tablet with merging minor compactions can lockup,ACCUMULO-1143,12635161,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,ecn,ecn,04/Mar/13 17:10,11/Sep/13 20:36,13/Mar/19 22:01,11/Sep/13 20:36,1.4.0,,,,,,,1.5.0,1.5.1,,tserver,,,,,,0,15_qa_bug,,,,Unloading the default tablet of the !METADATA table can result in a merging minor compaction.  This results in a delete marker for the unneeded resulting file.  The delete marker goes into the default tablet of !METADATA.  Which is offline while it performs its final minor compaction.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-04 22:05:08.553,,,no_permission,,,,,,,,,,,,315654,,,Wed Sep 11 20:36:22 UTC 2013,,,,,,0|i1igw7:,315997,,,,,,,,"04/Mar/13 17:59;ecn;An easy fix is to not do merging minor compactions on the metadata table.

Alternatively, we could move the delete markers for the METADATA table into the root tablet.
","04/Mar/13 22:05;kturner;I am thinking the best long term solution is to write delete markers for the METADATA table into the root tablet.  This fix will avoid possible future bugs.  

Not doing merging minor compactions for the metadata table may not involve any code changes.   Setting table.file.max to a large number for the !METADATA table should disable merging minor compactions.  Could possibly make init do this.",04/Mar/13 22:10;kturner;Move this to 1.6 since modifying table.file.max for metadata table is an easy workaround if this actually occurs on a system not running random walk.,"11/Sep/13 20:36;ecn;We fixed this twice: once by writing !METADATA delete entries to the root tablet in 1.5, and by separating the root tablet to its own table in 1.6.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bench testing shows that the NN loses the WAL,ACCUMULO-1685,12666920,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,04/Sep/13 16:53,11/Sep/13 12:49,13/Mar/19 22:01,05/Sep/13 15:27,,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"Doing bench testing; I build accumulo:

{noformat}
$ mvn -Pnative package -DskipTests
{noformat}

I go into the assembly area and configure and run accumulo

{noformat}
$ cd assemble/target/accumulo-1.6.0-SNAPSHOT-dev/accumulo-1.6.0-SNAPSHOT
$ cp ~/conf/* conf
$ hadoop fs -rmr /accumulo
Moved to trash: hdfs://somehost:9000/accumulo
$ ( echo test ; echo Y ; echo secret ; echo secret ) | ./bin/accumulo init
$ 2013-09-04 12:23:51,558 [util.Initialize] INFO : Hadoop Filesystem is hdfs://somehost:9000
2013-09-04 12:23:51,559 [util.Initialize] INFO : Accumulo data dirs are [hdfs://somehost:9000/accumulo]
2013-09-04 12:23:51,559 [util.Initialize] INFO : Zookeeper server is localhost:2181
2013-09-04 12:23:51,559 [util.Initialize] INFO : Checking if Zookeeper is available. If this hangs, then you need to make sure zookeeper is running
Instance name : test
Instance name ""test"" exists. Delete existing entry from zookeeper? [Y/N] : Y
Enter initial password for root (this may not be applicable for your security setup): ******
Confirm initial password for root: ******
$ ./bin/start-all.sh 
Starting monitor on localhost
Starting tablet servers .... done
Starting tablet server on localhost
2013-09-04 12:26:24,545 [server.Accumulo] INFO : Attempting to talk to zookeeper
2013-09-04 12:26:24,675 [server.Accumulo] INFO : Zookeeper connected and initialized, attemping to talk to HDFS
2013-09-04 12:26:24,679 [server.Accumulo] INFO : Connected to HDFS
Starting master on localhost
Starting garbage collector on localhost
Starting tracer on localhost
{noformat}

Next, create a table

{noformat}
$ ./bin/accumulo shell -u root -p secret
2013-09-04 12:27:01,628 [shell.Shell] WARN : Specifying a raw password is deprecated.

Shell - Apache Accumulo Interactive Shell
- 
- version: 1.6.0-SNAPSHOT
- instance name: test
- instance id: 1967c1ec-cc0f-439b-b4da-4029debd16e3
- 
- type 'help' for a list of available commands
- 
root@test> createtable t
root@test t> 
{noformat}

Then I checked the tserver log for the write-ahead log created for this update to the root table:

{noformat}
$ fgrep -a /wal/ logs/tserver_*.debug.log
2013-09-04 12:26:27,130 [log.DfsLogger] DEBUG: Got new write-ahead log: localhost+9997/hdfs://rd6ul-14706v.tycho.ncsc.mil:9000/accumulo/wal/localhost+9997/1dd2727f-1de9-417b-a5a2-e56f7d8020a9
2013-09-04 12:26:58,264 [tabletserver.Tablet] DEBUG: Logs for memory compacted: !!R<< localhost+9997/hdfs://somehost:9000/accumulo/wal/localhost+9997/1dd2727f-1de9-417b-a5a2-e56f7d8020a9
{noformat}

Now, let's check for the file:

{noformat}
$ hadoop fs -ls hdfs://somehost:9000/accumulo/wal/localhost+9997/1dd2727f-1de9-417b-a5a2-e56f7d8020a9
ls: Cannot access hdfs://somehost:9000/accumulo/wal/localhost+9997/1dd2727f-1de9-417b-a5a2-e56f7d8020a9: No such file or directory.
{noformat}

What?

Check the NN logs:

{noformat}
$ fgrep 1dd2727f /some/log/dir/hadoop-ecnewt2-local-namenode-somehost.log 
2013-09-04 12:26:27,075 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /accumulo/wal/localhost+9997/1dd2727f-1de9-417b-a5a2-e56f7d8020a9. blk_-6011963215434912690_971163
2013-09-04 12:26:27,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.fsync: file /accumulo/wal/localhost+9997/1dd2727f-1de9-417b-a5a2-e56f7d8020a9 for DFSClient_-787226921
{noformat}

So, the NN seems to be making the file, but it's not there when we go to look!

Here's my hdfs-site.xml file:

{noformat}
<?xml version=""1.0""?>
<?xml-stylesheet type=""text/xsl"" href=""configuration.xsl""?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
  <property>
      <name>dfs.replication</name>
      <value>1</value>
  </property>
  <property>
      <name>dfs.name.dir</name>
      <value>/local/ecn/data/hadoop/nn</value>
  </property>
  <property>
      <name>dfs.data.dir</name>
      <value>/disk01/data/hadoop/dn,/disk02/data/hadoop/dn,/disk03/data/hadoop/dn</value>
  </property>
  <property>
      <name>dfs.support.append</name>
      <value>true</value>
  </property>
  <property>
      <name>dfs.data.synconclose</name>
      <value>true</value>
  </property>
</configuration>
{noformat}

I have written an integration test that I dumped into RestartIT.java, but that doesn't seem to fail in same way.","Hadoop 1.0.4, single node dev't system",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-04 16:55:00.617,,,no_permission,,,,,,,,,,,,346857,,,Wed Sep 11 12:49:46 UTC 2013,,,,,,0|i1nt87:,347157,,,,,,,,"04/Sep/13 16:55;jira-bot;Commit e7855b8477694d120f228f2b2747e72a826c52c4 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e7855b8 ]

ACCUMULO-1685 fixed the logger in VolumeManagerImpl and added an integration test in an attempt to reproduce bench-test
",04/Sep/13 17:01;vines;Any reason not to port this to 1.5.1?,"04/Sep/13 17:11;ecn;The integration tests and VolumeManager are new in 1.6.

BTW, I cannot reproduce the error when using 1.5.
","04/Sep/13 17:39;ecn;It's the GC:

{noformat}
2013-09-04 13:38:20,353 [util.MetadataTableUtil] INFO : Setting range to (-inf,~ : [] 9223372036854775807 false)
2013-09-04 13:38:20,358 [gc.GarbageCollectWriteAheadLogs] INFO : 1 log entries scanned in 0.02 seconds
2013-09-04 13:38:20,364 [gc.GarbageCollectWriteAheadLogs] DEBUG: Removing WAL for offline server hdfs://somehost:9000/accumulo/wal/localhost+9997/ffb89027-b28f-4509-9a72-c3d08d1f31ac
{noformat}

Ugh!
","05/Sep/13 15:23;jira-bot;Commit ff02d20db00dfa00929365e1b7befc5ebb91f76f in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ff02d20 ]

ACCUMULO-1685 properly parse logSet data for confirming deletes
","05/Sep/13 16:12;jira-bot;Commit 2d6499c44026ebf04cd05bffde2dbbbffa11fc55 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2d6499c ]

ACCUMULO-1685 updated test case to catch error
","11/Sep/13 12:49;jira-bot;Commit e2bc157134878dcbf74c7a1f075219b07705bf2d in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e2bc157 ]

ACCUMULO-1685 noticed a double-slash in computed file names
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bulk imported files showing up in metadata after bulk import fails,ACCUMULO-1044,12630948,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,05/Feb/13 21:03,05/Aug/13 12:20,13/Mar/19 22:01,24/Jun/13 20:57,1.4.2,,,,,,,1.5.0,,,master,tserver,,,,,0,15_qa_bug,,,,"Bulk import fails.  The file is moved to the failures directory.

But references in the !METADATA table remain.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-26 17:34:55.241,,,no_permission,,,,,,,,,,,,311444,,,Mon Aug 05 12:20:59 UTC 2013,,,,,,0|i1hqxj:,311790,,,,,,,,"26/Feb/13 17:34;hudson;Integrated in Accumulo-1.4.x #276 (See [https://builds.apache.org/job/Accumulo-1.4.x/276/])
    ACCUMULO-1044 properly extract a column qualifier as a string (Revision 1450271)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
","26/Feb/13 17:47;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #103 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/103/])
    ACCUMULO-1044 properly extract a column qualifier as a string (Revision 1450274)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/trunk/src
","26/Feb/13 18:02;hudson;Integrated in Accumulo-Trunk #745 (See [https://builds.apache.org/job/Accumulo-Trunk/745/])
    ACCUMULO-1044 properly extract a column qualifier as a string (Revision 1450274)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/trunk/src
","27/Feb/13 15:00;kturner;the change may have no effect, ArrayByteSequence has a toString method",27/Feb/13 15:04;kturner;may want to add toString to ByteSequence to  make things more clear.... ArrayByteSequence is probably the only implemetation used by Accumulo code,"29/Mar/13 14:59;ecn;If a tablet fails to update the !METADATA table with the bulk entry due to RPC timeouts, the update might execute outside of the lock/transaction counts.  Adding an arbitrator check in the MetadataConstraints might help.
","02/Apr/13 14:42;ecn;This may be impossible to fix without a complete restructuring of bulk import.

There's a race condition between the update of the metadata with a bulk-file-loaded flag, and the closing of the transaction.  The current code keeps this window very small, but it is still possible.

Another ""fix"" is to never move files to the failed directory: always copy them.  However, the race condition is just moved from the Master to the Garbage Collector.

The work-around now is to increase the number of retries to a very high number.","03/Apr/13 01:58;hudson;Integrated in Accumulo-1.5 #61 (See [https://builds.apache.org/job/Accumulo-1.5/61/])
    ACCUMULO-1044 add a metadata table constraint to require the bulk load transaction to be alive when writing the bulk-loaded flags (Revision 1463552)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/constraints/MetadataConstraintsTest.java
","03/Apr/13 02:07;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #59 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/59/])
    ACCUMULO-1044 add a metadata table constraint to require the bulk load transaction to be alive when writing the bulk-loaded flags (Revision 1463552)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/constraints/MetadataConstraintsTest.java
","04/Apr/13 02:37;kturner;commit 1463552 checks to see if METADATA_TIME_COLUMN is set to determine if something is a split mutation.   Bulk load mutations also set METADATA_TIME_COLUMN

{code:java}
 if (new ColumnFQ(update).equals(Constants.METADATA_TIME_COLUMN)){
   isSplitMutation = true;
{code}","09/Apr/13 18:40;ecn;MetadataBulkLoadFilter is running too quickly.

Bulk loading is a pretty intricate dance of checks:

 * The master distributes the bulk files to tablet servers
 * Tablet servers attempt to determine where the tablets go based on their index information
 * When a tablet incorporates the new file, it has to update the !METADATA table
 * The tablet marks the fact that it has loaded the file
 * When the master completes the bulk import, it removes a transaction id in zookeeper
 * Tablets will not load files once the transaction id is removed
 * The master than asks if anyone is still working on that transaction id
 * Once the master has verified that nobody is doing anything on behalf of the transaction, it removes the flags that indicate that the file loaded
 * Because splits can occur while the master is removing markers, there's a METADATA filter to remove them

Here's the problem:
 * the master removes the transaction id
 * the metadata table major compacts, sees the id is missing, so it removes the flags: *this is bad*
 * the master continues to wait for threads to stop doing work for the transaction
 * the master then sees that there are no references to the tablet and moves it to the failed directory","09/Apr/13 19:32;kturner;A workaround for 1.4.3 and earlier is to remove the !METADATA compaction filter that drops bulk import load flags.

{noformat}
  deleteiter -majc -n bulkLoadFilter -t !METADATA
{noformat}

Then periodically delete bulk load flags that are left by splits.  Would need to add the filter back once this bug is fixed.

I think a solution to fix the bug is to write two things to zookeeper for a bulk import transactions.  Delete the first marker in zookeeper when you want work related to the bulk import to stop.  Delete the 2nd marker when its safe for major compaction to delete bulk load markers.","10/Apr/13 01:10;hudson;Integrated in Accumulo-Trunk #824 (See [https://builds.apache.org/job/Accumulo-Trunk/824/])
    ACCUMULO-1044 make metadata constraint bulk flag check for column set when new split tablet is added (Revision 1466270)
ACCUMULO-1044 fixed bug in bulk load filter (Revision 1466263)
ACCUMULO-1044 clearly define ""transaction should stop"" and ""transaction is complete"" (Revision 1466204)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/trunk/src

kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/TransactionWatcher.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/fate/src/test/java/org/apache/accumulo/fate/zookeeper/TransactionWatcherTest.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/TransactionWatcher.java
* /accumulo/trunk/src
","10/Apr/13 01:14;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #182 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/182/])
    ACCUMULO-1044 make metadata constraint bulk flag check for column set when new split tablet is added (Revision 1466270)
ACCUMULO-1044 fixed bug in bulk load filter (Revision 1466263)
ACCUMULO-1044 clearly define ""transaction should stop"" and ""transaction is complete"" (Revision 1466204)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/trunk/src

kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/TransactionWatcher.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/fate/src/test/java/org/apache/accumulo/fate/zookeeper/TransactionWatcherTest.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/TransactionWatcher.java
* /accumulo/trunk/src
","10/Apr/13 01:18;hudson;Integrated in Accumulo-1.4.x #289 (See [https://builds.apache.org/job/Accumulo-1.4.x/289/])
    ACCUMULO-1044 fixed bug in bulk load filter (Revision 1466259)
ACCUMULO-1044 clearly define ""transaction should stop"" and ""transaction is complete"" (Revision 1466199)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java

ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/zookeeper/TransactionWatcher.java
* /accumulo/branches/1.4/src/server/src/test/java/org/apache/accumulo/server/zookeeper/TransactionWatcherTest.java
","10/Apr/13 01:23;hudson;Integrated in Accumulo-1.5 #71 (See [https://builds.apache.org/job/Accumulo-1.5/71/])
    ACCUMULO-1044 make metadata constraint bulk flag check for column set when new split tablet is added (Revision 1466269)
ACCUMULO-1044 fixed bug in bulk load filter (Revision 1466261)
ACCUMULO-1044 clearly define ""transaction should stop"" and ""transaction is complete"" (Revision 1466203)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java

kturner : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/branches/1.5/src

ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/TransactionWatcher.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/fate/src/test/java/org/apache/accumulo/fate/zookeeper/TransactionWatcherTest.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/zookeeper/TransactionWatcher.java
* /accumulo/branches/1.5/src
","10/Apr/13 01:38;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #70 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/70/])
    ACCUMULO-1044 make metadata constraint bulk flag check for column set when new split tablet is added (Revision 1466269)
ACCUMULO-1044 fixed bug in bulk load filter (Revision 1466261)
ACCUMULO-1044 clearly define ""transaction should stop"" and ""transaction is complete"" (Revision 1466203)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java

kturner : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/branches/1.5/src

ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/TransactionWatcher.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/fate/src/test/java/org/apache/accumulo/fate/zookeeper/TransactionWatcherTest.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/zookeeper/TransactionWatcher.java
* /accumulo/branches/1.5/src
","10/Apr/13 23:29;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #183 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/183/])
    ACCUMULO-1044 added unit test for metdata bulk load filter (Revision 1466667)
ACCUMULO-1044 fixed some issues w/ metadata constraint bulk flag check, made the check more strict, and added a lot test for it (Revision 1466589)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/iterators
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilterTest.java
* /accumulo/trunk/src

kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/constraints/MetadataConstraintsTest.java
* /accumulo/trunk/src
","10/Apr/13 23:34;hudson;Integrated in Accumulo-1.5 #72 (See [https://builds.apache.org/job/Accumulo-1.5/72/])
    ACCUMULO-1044 added unit test for metdata bulk load filter (Revision 1466664)
ACCUMULO-1044 fixed some issues w/ metadata constraint bulk flag check, made the check more strict, and added a lot test for it (Revision 1466582)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/iterators
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilterTest.java
* /accumulo/branches/1.5/src

kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/constraints/MetadataConstraintsTest.java
","10/Apr/13 23:38;hudson;Integrated in Accumulo-Trunk #825 (See [https://builds.apache.org/job/Accumulo-Trunk/825/])
    ACCUMULO-1044 added unit test for metdata bulk load filter (Revision 1466667)
ACCUMULO-1044 fixed some issues w/ metadata constraint bulk flag check, made the check more strict, and added a lot test for it (Revision 1466589)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilter.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/iterators
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/iterators/MetadataBulkLoadFilterTest.java
* /accumulo/trunk/src

kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/constraints/MetadataConstraintsTest.java
* /accumulo/trunk/src
","23/Apr/13 00:59;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #86 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/86/])
    ACCUMULO-1044 fix functional test to handle new constraint (Revision 1470632)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
","23/Apr/13 01:08;hudson;Integrated in Accumulo-1.5 #87 (See [https://builds.apache.org/job/Accumulo-1.5/87/])
    ACCUMULO-1044 fix functional test to handle new constraint (Revision 1470632)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
","23/Apr/13 01:13;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #198 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/198/])
    ACCUMULO-1044 fix functional test to handle new constraint (Revision 1470633)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
","23/Apr/13 01:21;hudson;Integrated in Accumulo-Trunk #840 (See [https://builds.apache.org/job/Accumulo-Trunk/840/])
    ACCUMULO-1044 fix functional test to handle new constraint (Revision 1470633)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
","23/Apr/13 19:54;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #87 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/87/])
    ACCUMULO-1044 fix unused import (Revision 1470965)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
","23/Apr/13 19:56;hudson;Integrated in Accumulo-Trunk #841 (See [https://builds.apache.org/job/Accumulo-Trunk/841/])
    ACCUMULO-1044 fix unused import (Revision 1470966)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
","23/Apr/13 20:03;hudson;Integrated in Accumulo-1.5 #88 (See [https://builds.apache.org/job/Accumulo-1.5/88/])
    ACCUMULO-1044 fix unused import (Revision 1470965)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
","23/Apr/13 20:12;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #199 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/199/])
    ACCUMULO-1044 fix unused import (Revision 1470966)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
","24/Jun/13 16:39;ecn;So, in 1.5.0, the situation is much better, but there's still a race condition:

 * master delegates loading to a tserver worker
 * worker tserver assigns the files to the appropriate serving tservers
 * the serving tserver fails to load the file due to contention, full gc, and other distributed computing problems; worker tserver times out
 * worker tserver gives up, reports failure to the master
 * a thread on the serving tserver wakes up and starts the tablet load
 * master talks to all the worker servers, and finds them not working on the transaction
 * master looks for references, finds none, and moves the file to failures
 * the server tserver awakes up again and finishes the file load and updates the !METADATA table
 * the master wipes out any loaded markers

The master needs to ask the serving tservers if they are done with the transaction; and since the master doesn't know which server got the files, it needs to ask all of them.  The serving tservers will then be up-to-date with zookeeper, and will never load the file afterwards.  If the master asks the serving tserver to remove the loaded flags, then we do not need to be concerned about splits.","24/Jun/13 20:57;ecn;In a private discussion with Keith, we've determined that this is no longer a problem: the master asks all tservers if they are working on a transaction, which synch's them to zookeeper and the non-existence of the transaction.","05/Aug/13 12:20;jira-bot;Commit ff226a78995057518ac354e671d90f1bb4c30884 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ff226a7 ]

ACCUMULO-1605

Added many finally clauses to close spans in the presence of exceptions.

I suspect that the extreme depth of the traces is caused by traces that
are started and never stopped.  This most likely happens in the presence
of errors, where exceptions jump around the the span.stop calls.
In particular, when a file is missing for a compaction.  This is known
to occur in 1.4 when bulk imports fail.  See ACCUMULO-1044.
",,,,,,,,,,,,,,,,,,,,,,,
Clonetable with excluded properties causes a NullPointerException,ACCUMULO-1565,12657312,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,shickey,shickey,shickey,11/Jul/13 19:29,31/Jul/13 15:44,13/Mar/19 22:01,29/Jul/13 14:27,,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,"When cloning a table, there's an option to exclude certain properties from being copied over. When those excluded properties are processed in clone() in TableOperations, they are passed as options with a key and a null value. When passed through Thrift, the null value isn't expected because it uses the same process to set properties as well. Here's a stack trace.

{code}
org.apache.accumulo.core.client.AccumuloException
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:319)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:285)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.clone(TableOperationsImpl.java:686)
	at org.apache.accumulo.core.util.shell.commands.CloneTableCommand.execute(CloneTableCommand.java:68)
	at org.apache.accumulo.core.util.shell.Shell.execCommand(Shell.java:617)
	at org.apache.accumulo.core.util.shell.Shell.start(Shell.java:496)
	at org.apache.accumulo.core.util.shell.Shell.main(Shell.java:418)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.accumulo.start.Main$1.run(Main.java:105)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.lang.NullPointerException
	at org.apache.thrift.protocol.TCompactProtocol.writeString(TCompactProtocol.java:325)
	at org.apache.accumulo.core.master.thrift.MasterClientService$executeTableOperation_args$executeTableOperation_argsStandardScheme.write(MasterClientService.java:15606)
	at org.apache.accumulo.core.master.thrift.MasterClientService$executeTableOperation_args$executeTableOperation_argsStandardScheme.write(MasterClientService.java:15467)
	at org.apache.accumulo.core.master.thrift.MasterClientService$executeTableOperation_args.write(MasterClientService.java:15373)
	at org.apache.thrift.TServiceClient.sendBase(TServiceClient.java:63)
	at org.apache.accumulo.core.master.thrift.MasterClientService$Client.send_executeTableOperation(MasterClientService.java:493)
	at org.apache.accumulo.core.master.thrift.MasterClientService$Client.executeTableOperation(MasterClientService.java:479)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.executeTableOperation(TableOperationsImpl.java:241)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:294)
	... 12 more
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29/Jul/13 14:04;shickey;ACCUMULO-1565.patch;https://issues.apache.org/jira/secure/attachment/12594705/ACCUMULO-1565.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-07-29 14:26:04.016,,,no_permission,,,,,,,,,,,,337534,,,Wed Jul 31 15:44:03 UTC 2013,,,,,,0|i1m7xb:,337857,,,,,,,,"29/Jul/13 14:03;shickey;I needed this to work for Table Namespaces (ACCUMULO-802), so I thought I'd try to fix it. This patch only modifies CloneTable to use an empty string instead of null when excluding properties. I'm not sure if it would screw up anything (can there be empty-string property values?), but it was a small enough fix that I thought I'd post it.","29/Jul/13 14:26;jira-bot;Commit 3d06f475ebfcb4da9789ab30c22b9d7b2ab47ddf in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3d06f47 ]

ACCUMULO-1565 applying Sean Hickey's patch
","29/Jul/13 14:27;ecn;Patched.  Thanks!  I changed ""new String()"" to """".","29/Jul/13 14:27;kturner;[~shickey], a test that reproduces the problem would be useful for preventing future regressions.

Its possible that someone may want to set empty string for a prop and not exclude it.  In addition to using empty string, I think prefixing the keys in the options map would be good.  For example prefix all props to set with ""SET:"" and all props to exclude with ""EX:"".  Then on the server side, the intent is clear based on the key prefix.","29/Jul/13 16:17;ctubbsii;I like the prefixing of the key idea. I was also thinking about this (with a ""!"" prefix, to denote ""NOT"") as a way of saying ""don't inherit from the parent configuration"" for per-table configurations (ACCUMULO-1619).","29/Jul/13 17:37;jira-bot;Commit 1c44069a35a1acfb2b806e1103c1992190c389eb in branch refs/heads/1.5.1-SNAPSHOT from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1c44069 ]

ACCUMULO-1565 fixed clone table NPE when excluding props
","31/Jul/13 15:13;jira-bot;Commit 14f8a80a84465b3d41724a7bf24544c6b0f67abe in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=14f8a80 ]

ACCUMULO-1565 converted clonet test to integration test.
","31/Jul/13 15:13;jira-bot;Commit 1c44069a35a1acfb2b806e1103c1992190c389eb in branch refs/heads/master from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1c44069 ]

ACCUMULO-1565 fixed clone table NPE when excluding props
","31/Jul/13 15:44;jira-bot;Commit 0b85105a46de675fd207bd120562e8391dce8b5a in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0b85105 ]

ACCUMULO-1565 fixed deprecation warning in test
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TFramedTransport frame size limited on client side,ACCUMULO-1251,12641288,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,afuchs,afuchs,afuchs,08/Apr/13 00:22,17/May/13 12:01,13/Mar/19 22:01,08/Apr/13 16:37,,,,,,,,1.5.0,,,client,rpc,,,,,0,,,,,"The client code restricts the size of a scan or multiscan result to 16MB. This should be configurable. We fixed this for the server side in ACCUMULO-1141.

{code}
DEBUG 2013-04-07 20:05:35,370 [batch scanner 521- 9 looking up 4 ranges at 127.0.0.1:9997] (TabletServerBatchReaderIterator.java:696) - Server : 127.0.0.1:9997 msg : Frame size (20489533) larger than max length (16384000)!
DEBUG 2013-04-07 20:05:35,371 [batch scanner 521- 9 looking up 4 ranges at 127.0.0.1:9997] (TabletServerBatchReaderIterator.java:377) - org.apache.thrift.transport.TTransportException: Frame size (20489533) larger than max length (16384000)!
java.io.IOException: org.apache.thrift.transport.TTransportException: Frame size (20489533) larger than max length (16384000)!
	at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:698)
	at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator$QueryTask.run(TabletServerBatchReaderIterator.java:361)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
	at java.lang.Thread.run(Thread.java:680)
Caused by: org.apache.thrift.transport.TTransportException: Frame size (20489533) larger than max length (16384000)!
	at org.apache.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:137)
	at org.apache.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)
	at org.apache.accumulo.core.client.impl.ThriftTransportPool$CachedTTransport.readAll(ThriftTransportPool.java:253)
	at org.apache.thrift.protocol.TCompactProtocol.readByte(TCompactProtocol.java:601)
	at org.apache.thrift.protocol.TCompactProtocol.readMessageBegin(TCompactProtocol.java:470)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_continueMultiScan(TabletClientService.java:321)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.continueMultiScan(TabletClientService.java:307)
	at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:672)
	... 7 more
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,08/Apr/13 01:31;afuchs;ACCUMULO-1251.patch;https://issues.apache.org/jira/secure/attachment/12577474/ACCUMULO-1251.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-04-08 12:26:02.972,,,no_permission,,,,,,,,,,,,321704,,,Mon Apr 08 16:37:40 UTC 2013,,,,,,0|i1ji8f:,322049,,,,,,,,08/Apr/13 01:31;afuchs;This has the effect of reverting to the Accumulo 1.4.x / Thrift 0.6 behavior for TFramedTransport. We would eventually want to offer an ability to limit the max message size to be passed to clients as well in a future version.,"08/Apr/13 12:26;ecn;Would be good to use some dependency injection tools to fix these kinds of problems all over the place.  I don't have much experience with them, though.","08/Apr/13 14:05;hudson;Integrated in Accumulo-1.5 #68 (See [https://builds.apache.org/job/Accumulo-1.5/68/])
    ACCUMULO-1251 applying Adam Fuch's patch to allow clients to recieve large messages (Revision 1465625)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
","08/Apr/13 14:07;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #67 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/67/])
    ACCUMULO-1251 applying Adam Fuch's patch to allow clients to recieve large messages (Revision 1465625)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
","08/Apr/13 14:10;hudson;Integrated in Accumulo-Trunk #820 (See [https://builds.apache.org/job/Accumulo-Trunk/820/])
    ACCUMULO-1251 applying Adam Fuch's patch to allow clients to receive large messages (Revision 1465626)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","08/Apr/13 14:11;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #180 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/180/])
    ACCUMULO-1251 applying Adam Fuch's patch to allow clients to receive large messages (Revision 1465626)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","08/Apr/13 16:37;ecn;The frame size is still not configurable.  If we want that, let's open a new ticket as an improvement.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multiple assignment may occur if tablet server dies during split,ACCUMULO-1243,12640911,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,05/Apr/13 02:09,23/Apr/13 01:21,13/Mar/19 22:01,11/Apr/13 19:08,1.4.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"Make the following change to the tablet server code.  The tablet server has to die at this exact point for the bug to occur.

{noformat}
Index: src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
===================================================================
--- src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java	(revision 1464780)
+++ src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java	(working copy)
@@ -3592,6 +3592,9 @@
       MetadataTable.splitTablet(high, extent.getPrevEndRow(), splitRatio, SecurityConstants.getSystemCredentials(), tabletServer.getLock());
       MetadataTable.addNewTablet(low, lowDirectory, tabletServer.getTabletSession(), lowDatafileSizes, bulkLoadedFiles,
           SecurityConstants.getSystemCredentials(), time, lastFlushID, lastCompactID, tabletServer.getLock());
+      
+      Runtime.getRuntime().halt(2);
+
       MetadataTable.finishSplit(high, highDatafileSizes, highDatafilesToRemove, SecurityConstants.getSystemCredentials(), tabletServer.getLock());
       
       log.log(TLevel.TABLET_HIST, extent + "" split "" + low + "" "" + high);
{noformat}

Then create a table and add a split.  

{noformat}
root@test15> createtable foo
root@test15 foo> addsplits -t foo m
{noformat}

If there are multiple tablet servers, then its possible that multiple assignment may occur.  Below is an example of this occurring after tablets were loaded.

{noformat}
root@test15 !METADATA> scan -b 1 -c loc
1;m loc:13d5a86463f4f98 []    127.0.0.1:9998
1;m loc:13d5a86463f4f9f []    127.0.0.1:10000
1< loc:13d5a86463f4f98 []    127.0.0.1:9998
{noformat}

The problem is that the assignment code in the tserver detects an incomplete split and load both children.   However, the master may also assign one of the children.   

I think the assignment code should be modified to fix up the metadata table and only load one tablet. If the new tablet was not created, it should roll back the changes and load the pre split tablets.  If the new tablet was created, then assume the master will assign it and only load the high tablet.  I think these changes would greatly simplify the code also.

I do not think the proposed changes would cause issues with merge, since the chop flag is deleted in the case where this occurs.

Need to ensure that the solution is itself fault tolerant.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1235,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-05 02:20:09.078,,,no_permission,,,,,,,,,,,,321370,,,Tue Apr 23 01:21:53 UTC 2013,,,,,,0|i1jg6n:,321715,,,,,,,,"05/Apr/13 02:20;ecn;Nice catch.  Would simplify the tablet post-recovery code, too.","10/Apr/13 01:10;hudson;Integrated in Accumulo-Trunk #824 (See [https://builds.apache.org/job/Accumulo-Trunk/824/])
    ACCUMULO-1243 Added apache header (Revision 1466244)
ACCUMULO-1243 Made tablet loading code only load one tablet when recovering a split.  Made code more strict, it will only load an exact tablet.  Made load code roll back splits that have started, but did not create a new tablet.  Added some more test. (Revision 1466217)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/CheckTabletMetadataTest.java
* /accumulo/trunk/src

kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/MetadataTable.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/CheckTabletMetadataTest.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/performance/scan/CollectTabletStats.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/TestAccumulo1235.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/TestAccumuloSplitRecovery.java
","10/Apr/13 01:14;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #182 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/182/])
    ACCUMULO-1243 Added apache header (Revision 1466244)
ACCUMULO-1243 Made tablet loading code only load one tablet when recovering a split.  Made code more strict, it will only load an exact tablet.  Made load code roll back splits that have started, but did not create a new tablet.  Added some more test. (Revision 1466217)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/CheckTabletMetadataTest.java
* /accumulo/trunk/src

kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/MetadataTable.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/tabletserver/CheckTabletMetadataTest.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/performance/scan/CollectTabletStats.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/TestAccumulo1235.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/TestAccumuloSplitRecovery.java
","10/Apr/13 01:23;hudson;Integrated in Accumulo-1.5 #71 (See [https://builds.apache.org/job/Accumulo-1.5/71/])
    ACCUMULO-1243 Added apache header (Revision 1466243)
ACCUMULO-1243 Made tablet loading code only load one tablet when recovering a split.  Made code more strict, it will only load an exact tablet.  Made load code roll back splits that have started, but did not create a new tablet.  Added some more test. (Revision 1466211)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/CheckTabletMetadataTest.java

kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/MetadataTable.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/CheckTabletMetadataTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/performance/scan/CollectTabletStats.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/TestAccumulo1235.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/TestAccumuloSplitRecovery.java
","10/Apr/13 01:38;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #70 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/70/])
    ACCUMULO-1243 Added apache header (Revision 1466243)
ACCUMULO-1243 Made tablet loading code only load one tablet when recovering a split.  Made code more strict, it will only load an exact tablet.  Made load code roll back splits that have started, but did not create a new tablet.  Added some more test. (Revision 1466211)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/CheckTabletMetadataTest.java

kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/MetadataTable.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/CheckTabletMetadataTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/performance/scan/CollectTabletStats.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/TestAccumulo1235.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/TestAccumuloSplitRecovery.java
","23/Apr/13 00:59;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #86 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/86/])
    ACCUMULO-1243 made accumulo more responsive to failed splits (Revision 1470734)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.5/test/src/test/resources/log4j.properties
","23/Apr/13 01:08;hudson;Integrated in Accumulo-1.5 #87 (See [https://builds.apache.org/job/Accumulo-1.5/87/])
    ACCUMULO-1243 made accumulo more responsive to failed splits (Revision 1470734)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.5/test/src/test/resources/log4j.properties
","23/Apr/13 01:13;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #198 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/198/])
    ACCUMULO-1243 made accumulo more responsive to failed splits
ACCUMULO-765 make getAuthorizationFailures() public like it was in 1.4
ACCUMULO-578 don't log a message for every time a sorted WALOG disappears (Revision 1470737)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/MutationsRejectedException.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/GarbageCollectWriteAheadLogs.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/test/resources/log4j.properties
","23/Apr/13 01:21;hudson;Integrated in Accumulo-Trunk #840 (See [https://builds.apache.org/job/Accumulo-Trunk/840/])
    ACCUMULO-1243 made accumulo more responsive to failed splits
ACCUMULO-765 make getAuthorizationFailures() public like it was in 1.4
ACCUMULO-578 don't log a message for every time a sorted WALOG disappears (Revision 1470737)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/MutationsRejectedException.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/GarbageCollectWriteAheadLogs.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/test/resources/log4j.properties
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Variable name inconsistency in ""Reading Data"" client code snippet",ACCUMULO-1040,12630750,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,mberman,mberman,04/Feb/13 20:56,21/Mar/13 04:15,13/Mar/19 22:01,20/Mar/13 20:09,1.4.2,,,,,,,1.5.0,,,docs,,,,,,0,,,,,"On the ""Writing Clients"" doc page, in the section ""SCANNER"" (at http://accumulo.apache.org/1.4/user_manual/Writing_Accumulo_Clients.html#Reading_Data), there is the following code snippet:

{code}
for(Entry<Key,Value> entry : scan) {
    String row = e.getKey().getRow();
    Value value = e.getValue();
}
{code}

In the loop body, {{e}} should be {{entry}}.

The same error also exists further down the page in the ""BATCHSCANNER"" section.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-20 21:05:40.975,,,no_permission,,,,,,,,,,,,311246,,,Thu Mar 21 04:15:23 UTC 2013,,,,,,0|i1hppj:,311592,,,,,,,,"20/Mar/13 21:05;hudson;Integrated in Accumulo-1.5 #44 (See [https://builds.apache.org/job/Accumulo-1.5/44/])
    ACCUMULO-1040 fixed code in documentation (Revision 1459004)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/docs/src/user_manual/chapters/clients.tex
","20/Mar/13 22:16;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #42 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/42/])
    ACCUMULO-1040 fixed code in documentation (Revision 1459004)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/branches/1.5/docs/src/user_manual/chapters/clients.tex
","20/Mar/13 23:29;hudson;Integrated in Accumulo-Trunk #790 (See [https://builds.apache.org/job/Accumulo-Trunk/790/])
    ACCUMULO-896 Added some info about automatic splitting to user manual.
ACCUMULO-1039 Added info about table creation and versioning iterator to docs.
ACCUMULO-1040 fixed code in documentation
ACCUMULO-804 another FileNotFoundException being thrown: going to keep it, though (Revision 1459026)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java
* /accumulo/trunk/src
","21/Mar/13 04:15;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #149 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/149/])
    ACCUMULO-896 Added some info about automatic splitting to user manual.
ACCUMULO-1039 Added info about table creation and versioning iterator to docs.
ACCUMULO-1040 fixed code in documentation
ACCUMULO-804 another FileNotFoundException being thrown: going to keep it, though (Revision 1459026)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooLock watcher can stop watching,ACCUMULO-954,12627044,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,afuchs,afuchs,10/Jan/13 21:49,04/Mar/13 20:13,13/Mar/19 22:01,01/Mar/13 20:19,1.4.2,,,,,,,1.4.3,1.5.0,,tserver,,,,,,0,,,,,"Basically, this will result in tablet servers failing to recognize when they lose their locks. I think the worst that can happen with this is a tablet server can fail to die after it loses its lock, which could bog down clients and create a bunch of noise in the cluster. I believe there could also be useless files generated that wouldn't get garbage collected. !METADATA table write protections and logger write protections should prevent any permanent damage or data loss. We have seen this result in warnings and errors that look like multiple hosting of tablets.

{code}
2013-01-09 19:59:27,742 [tabletserver.TabletServer] INFO : port = 9997
2013-01-09 19:59:27,926 [zookeeper.ZooLock] DEBUG: event /accumulo/655f93d8-20fc-451f-a457-458b5717a11e/tservers/172.16.2.25:9997 NodeDeleted SyncConnected
2013-01-09 19:59:27,931 [tabletserver.TabletServer] INFO : Waiting for tablet server lock
2013-01-09 19:59:32,943 [tabletserver.TabletServer] DEBUG: Obtained tablet server lock /accumulo/655f93d8-20fc-451f-a457-458b5717a11e/tservers/172.16.2.25:9997/zlock-0000000000
2013-01-09 19:59:36,703 [tabletserver.TabletServer] DEBUG: Got loadTablet message from user: !SYSTEM
{code}

Here's what happened:
1. Tablet server fails to get lock, triggering the watcher on the parent node.
2. Watcher doesn't get reset, and doesn't take any action.
3. Loop in TabletServer:~2659 retries, but uses the same ZooLock object.
4. TabletServer loses its lock, but receives a connection loss message before the NodeDeleted message.
5. TabletServer continues to try to do work instead of killing itself.

We could probably patch this for 1.4 by creating the ZooLock within the announceExistence loop, instead of reusing the one. Eventually, we ought to have an else branch in both of the Watchers that either reset the watch (resilient against zookeeper connection hiccups) or just kill the server to be safe.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-24 18:44:48.706,,,no_permission,,,,,,,,,,,,303737,,,Sat Mar 02 09:48:37 UTC 2013,,,,,,0|i17e53:,251260,,,,,,,,"24/Jan/13 18:44;kturner;This bug existed before 1.4.2, but was not likely to happen until the master started deleting stuff in zookeeper in ACCUMULO-766.  Also see ACCUMULO-799.","04/Feb/13 23:59;hudson;Integrated in Accumulo-Trunk #702 (See [https://builds.apache.org/job/Accumulo-Trunk/702/])
    ACCUMULO-954 Made zoolock rewatch its parent node and added some unit test for zoolock (Revision 1442429)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooLock.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate/zookeeper
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate/zookeeper/ZooLockTest.java
","05/Feb/13 03:54;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #61 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/61/])
    ACCUMULO-954 Made zoolock rewatch its parent node and added some unit test for zoolock (Revision 1442429)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooLock.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate/zookeeper
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate/zookeeper/ZooLockTest.java
","06/Feb/13 19:05;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #70 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/70/])
    ACCUMULO-954 suppressed warnings from zookeeper during unit test (Revision 1443085)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate/zookeeper/ZooLockTest.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MiniAccumuloClusterTest.java
","06/Feb/13 19:13;hudson;Integrated in Accumulo-Trunk #712 (See [https://builds.apache.org/job/Accumulo-Trunk/712/])
    ACCUMULO-954 suppressed warnings from zookeeper during unit test (Revision 1443085)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate/zookeeper/ZooLockTest.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MiniAccumuloClusterTest.java
","08/Feb/13 03:27;hudson;Integrated in Accumulo-Trunk #715 (See [https://builds.apache.org/job/Accumulo-Trunk/715/])
    ACCUMULO-954 made zoolock report when its no longer able to monitor lock node and there does not know the status of the lock (Revision 1443790)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooLock.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/TServerLockWatcher.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/ZooLock.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/ZombieTServer.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate/zookeeper/ZooLockTest.java
","08/Feb/13 03:34;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #73 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/73/])
    ACCUMULO-954 made zoolock report when its no longer able to monitor lock node and there does not know the status of the lock (Revision 1443790)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooLock.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/TServerLockWatcher.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/ZooLock.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/SplitRecoveryTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/ZombieTServer.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate/zookeeper/ZooLockTest.java
","02/Mar/13 09:48;hudson;Integrated in Accumulo-1.4.x #278 (See [https://builds.apache.org/job/Accumulo-1.4.x/278/])
    merged some bug fixes from 1.5:
ACCUMULO-1125 delete distributed work queue task lock when task fails
ACCUMULO-1049 modified master to stop locking tserver nodes and just monitor  tserver nodes in zookeeper
ACCUMULO-954 made zoolock report when its no longer able to monitor lock node and there does not know the status of the lock
ACCUMULO-954 Made zoolock rewatch its parent node and added some unit test for zoolock (Revision 1451708)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/TServerLockWatcher.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/test/functional
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/test/functional/SplitRecoveryTest.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/test/functional/ZombieTServer.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/zookeeper/ZooLock.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Code snippet for constructing iterators has wrong argument order,ACCUMULO-1038,12630744,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,medined,mberman,mberman,04/Feb/13 20:47,02/Mar/13 09:48,13/Mar/19 22:01,01/Mar/13 20:06,1.4.2,,,,,,,1.5.0,,,docs,,,,,,0,,,,,"On the ""Table Configuration"" doc page, in the section ""Setting Iterators Programatically"" (at http://accumulo.apache.org/1.4/user_manual/Table_Configuration.html#Iterators), there is the following code snippet:

{code}
scanner.addIterator(new IteratorSetting(
    15, // priority
    ""com.company.MyIterator"", // class name
    ""myiter"" // name this iterator
));
{code}

The actual constructor signature for IteratorSetting is (priority, name, iteratorClass).  The second and third arguments should be flipped.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-01 20:17:47.018,,,no_permission,,,,,,,,,,,,311240,,,Sat Mar 02 09:48:36 UTC 2013,,,,,,0|i1hpo7:,311586,,,,,,,,01/Mar/13 20:17;ecn;Added Michael Berman as a Contributor.,"02/Mar/13 04:16;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #114 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/114/])
    ACCUMULO-1038 commiting patch provided by Michael Berman (Revision 1451703)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","02/Mar/13 04:20;hudson;Integrated in Accumulo-Trunk #755 (See [https://builds.apache.org/job/Accumulo-Trunk/755/])
    ACCUMULO-1038 commiting patch provided by Michael Berman (Revision 1451703)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","02/Mar/13 09:20;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #9 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/9/])
    ACCUMULO-1038 commiting patch provided by Michael Berman (Revision 1451701)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/src
","02/Mar/13 09:24;hudson;Integrated in Accumulo-1.5 #10 (See [https://builds.apache.org/job/Accumulo-1.5/10/])
    ACCUMULO-1038 commiting patch provided by Michael Berman (Revision 1451701)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/src
","02/Mar/13 09:48;hudson;Integrated in Accumulo-1.4.x #278 (See [https://builds.apache.org/job/Accumulo-1.4.x/278/])
    ACCUMULO-1038 commiting patch provided by Michael Berman (Revision 1451700)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/docs/src/user_manual/chapters/table_configuration.tex
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master state is UNLOAD_METADATA_TABLE and goal state is NORMAL: stuck,ACCUMULO-1112,12634209,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,26/Feb/13 17:53,01/Mar/13 19:57,13/Mar/19 22:01,01/Mar/13 19:57,,,,,,,,1.5.0,,,,,,,,,0,15_qa_bug,,,,Master does not seem to make progress towards NORMAL state if in the UNLOAD_METADATA_TABLE state.,10-node test cluster running randomwalk test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-27 02:11:04.616,,,no_permission,,,,,,,,,,,,314702,,,Wed Feb 27 02:11:24 UTC 2013,,,,,,0|i1ib13:,315046,,,,,,,,"27/Feb/13 02:11;hudson;Integrated in Accumulo-Trunk #746 (See [https://builds.apache.org/job/Accumulo-Trunk/746/])
    ACCUMULO-1112 allow the master to transition from UNLOAD_METADATA_TABLE to NORMAL (Revision 1450398)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
","27/Feb/13 02:11;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #104 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/104/])
    ACCUMULO-1112 allow the master to transition from UNLOAD_METADATA_TABLE to NORMAL (Revision 1450398)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Master no longer cleans up recovery area,ACCUMULO-1126,12634508,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,27/Feb/13 23:04,28/Feb/13 22:16,13/Mar/19 22:01,28/Feb/13 22:16,,,,,,,,1.5.0,,,,,,,,,0,,,,,The master used to periodically clean up sorted walogs in the recovery dir.  It no longer does this.   ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,315001,,,Thu Feb 28 22:16:00 UTC 2013,,,,,,0|i1icvj:,315345,,,,,,,,28/Feb/13 22:16;kturner;[~ecn] and I were discussing this.  We decided that the best approach was to make the agc clean up unrefed logs in recovery area.  This avoids a rare problem in 1.4 where sorted logs that are still needed are deleted because log recovery takes a really long time.  I checked in a fix to do this.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
deadlock found in major compaction,ACCUMULO-1110,12634183,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,26/Feb/13 15:55,28/Feb/13 21:02,13/Mar/19 22:01,28/Feb/13 21:02,,,,,,,,1.5.0,,,tserver,,,,,,0,15_qa_bug,,,,"{noformat}
Found one Java-level deadlock:
=============================
""ClientPool 131"":
  waiting to lock monitor 0x000000005e264210 (object 0x0000000765399a38, a org.apache.accumulo.server.tabletserver.Tablet),
  which is held by ""ClientPool 76""
""ClientPool 76"":
  waiting to lock monitor 0x0000000061ed94d0 (object 0x000000075a3a0478, a org.apache.accumulo.server.tabletserver.CompactionQueue),
  which is held by ""major compactor 3""
""major compactor 3"":
  waiting to lock monitor 0x00002aaac470b690 (object 0x0000000764d0d688, a org.apache.accumulo.server.tabletserver.Tablet),
  which is held by ""ClientPool 36""
""ClientPool 36"":
  waiting to lock monitor 0x0000000061ed94d0 (object 0x000000075a3a0478, a org.apache.accumulo.server.tabletserver.CompactionQueue),
  which is held by ""major compactor 3""

Java stack information for the threads listed above:
===================================================
""ClientPool 131"":
	at org.apache.accumulo.server.tabletserver.Tablet.importMapFiles(Tablet.java:3666)
	- waiting to lock <0x0000000765399a38> (a org.apache.accumulo.server.tabletserver.Tablet)
	at org.apache.accumulo.server.tabletserver.TabletServer$ThriftClientHandler.bulkImport(TabletServer.java:898)
	at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
	at $Proxy2.bulkImport(Unknown Source)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$bulkImport.getResult(TabletClientService.java:2153)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$bulkImport.getResult(TabletClientService.java:2137)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:156)
	at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
	at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:208)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
	at java.lang.Thread.run(Thread.java:662)
""ClientPool 76"":
	at org.apache.accumulo.server.tabletserver.CompactionQueue.offer(CompactionQueue.java:54)
	- waiting to lock <0x000000075a3a0478> (a org.apache.accumulo.server.tabletserver.CompactionQueue)
	at org.apache.accumulo.server.tabletserver.CompactionQueue.offer(CompactionQueue.java:28)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:653)
	at org.apache.accumulo.trace.instrument.TraceExecutorService.execute(TraceExecutorService.java:39)
	at org.apache.accumulo.server.tabletserver.TabletServerResourceManager.executeMajorCompaction(TabletServerResourceManager.java:717)
	at org.apache.accumulo.server.tabletserver.TabletServerResourceManager$TabletResourceManager.executeMajorCompaction(TabletServerResourceManager.java:694)
	at org.apache.accumulo.server.tabletserver.Tablet.initiateMajorCompaction(Tablet.java:2924)
	- locked <0x0000000765399a38> (a org.apache.accumulo.server.tabletserver.Tablet)
	at org.apache.accumulo.server.tabletserver.Tablet.importMapFiles(Tablet.java:368)
	at org.apache.accumulo.server.tabletserver.TabletServer$ThriftClientHandler.bulkImport(TabletServer.java:898)
	at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
	at $Proxy2.bulkImport(Unknown Source)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$bulkImport.getResult(TabletClientService.java:2153)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$bulkImport.getResult(TabletClientService.java:2137)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:156)
	at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
	at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:208)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
	at java.lang.Thread.run(Thread.java:662)
""major compactor 3"":
	at org.apache.accumulo.server.tabletserver.Tablet$CompactionRunner.getNumFiles(Tablet.java:2895)
	- waiting to lock <0x0000000764d0d688> (a org.apache.accumulo.server.tabletserver.Tablet)
	at org.apache.accumulo.server.tabletserver.Tablet$CompactionRunner.compareTo(Tablet.java:2912)
	at org.apache.accumulo.server.tabletserver.Tablet$CompactionRunner.compareTo(Tablet.java:2848)
	at org.apache.accumulo.trace.instrument.TraceRunnable.compareTo(TraceRunnable.java:54)
	at org.apache.accumulo.trace.instrument.TraceRunnable.compareTo(TraceRunnable.java:23)
	at java.util.Collections.min(Collections.java:574)
	at org.apache.accumulo.server.tabletserver.CompactionQueue.poll(CompactionQueue.java:38)
	- locked <0x000000075a3a0478> (a org.apache.accumulo.server.tabletserver.CompactionQueue)
	at org.apache.accumulo.server.tabletserver.CompactionQueue.take(CompactionQueue.java:78)
	- locked <0x000000075a3a0478> (a org.apache.accumulo.server.tabletserver.CompactionQueue)
	at org.apache.accumulo.server.tabletserver.CompactionQueue.take(CompactionQueue.java:28)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
	at java.lang.Thread.run(Thread.java:662)
""ClientPool 36"":
	at org.apache.accumulo.server.tabletserver.CompactionQueue.offer(CompactionQueue.java:54)
	- waiting to lock <0x000000075a3a0478> (a org.apache.accumulo.server.tabletserver.CompactionQueue)
	at org.apache.accumulo.server.tabletserver.CompactionQueue.offer(CompactionQueue.java:28)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:653)
	at org.apache.accumulo.trace.instrument.TraceExecutorService.execute(TraceExecutorService.java:39)
	at org.apache.accumulo.server.tabletserver.TabletServerResourceManager.executeMajorCompaction(TabletServerResourceManager.java:717)
	at org.apache.accumulo.server.tabletserver.TabletServerResourceManager$TabletResourceManager.executeMajorCompaction(TabletServerResourceManager.java:694)
	at org.apache.accumulo.server.tabletserver.Tablet.initiateMajorCompaction(Tablet.java:2924)
	- locked <0x0000000764d0d688> (a org.apache.accumulo.server.tabletserver.Tablet)
	at org.apache.accumulo.server.tabletserver.Tablet.compactAll(Tablet.java:3871)
	- locked <0x0000000764d0d688> (a org.apache.accumulo.server.tabletserver.Tablet)
	at org.apache.accumulo.server.tabletserver.TabletServer$ThriftClientHandler.compact(TabletServer.java:2048)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
	at $Proxy2.compact(Unknown Source)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$compact.getResult(TabletClientService.java:2296)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$compact.getResult(TabletClientService.java:2282)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:156)
	at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
	at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:208)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
	at java.lang.Thread.run(Thread.java:662)

Found 1 deadlock.

{noformat}
",ten-node test cluster running random walk test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,314676,,,2013-02-26 15:55:03.0,,,,,,0|i1iavb:,315020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
class cast exception during Security random walk,ACCUMULO-1114,12634238,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,vines,ecn,ecn,26/Feb/13 20:27,27/Feb/13 20:57,13/Mar/19 22:01,27/Feb/13 17:11,,,,,,,,1.5.0,,,test,,,,,,0,15_qa_bug,,,,"{noformat}
26 20:07:32,902 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Security.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:264)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:97)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node security.Validate
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:264)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:251)
        ... 8 more
Caused by: java.lang.ClassCastException: [B cannot be cast to org.apache.accumulo.core.security.tokens.PasswordToken
        at org.apache.accumulo.test.randomwalk.security.WalkingSecurity.authenticateUser(WalkingSecurity.java:143)
        at org.apache.accumulo.server.security.SecurityOperation.authenticate(SecurityOperation.java:154)
        at org.apache.accumulo.server.security.SecurityOperation.canPerformSystemActions(SecurityOperation.java:306)
        at org.apache.accumulo.server.security.SecurityOperation.canAskAboutUser(SecurityOperation.java:165)
        at org.apache.accumulo.test.randomwalk.security.WalkingSecurity.canAskAboutUser(WalkingSecurity.java:373)
        at org.apache.accumulo.test.randomwalk.security.Authenticate.authenticate(Authenticate.java:52)
        at org.apache.accumulo.test.randomwalk.security.Validate.validate(Validate.java:55)
        at org.apache.accumulo.test.randomwalk.security.Validate.visit(Validate.java:37)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:251)
        ... 9 more
{noformat}
",10 node test cluster running random walk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-26 22:04:19.71,,,no_permission,,,,,,,,,,,,314731,,,Wed Feb 27 20:57:48 UTC 2013,,,,,,0|i1ib7j:,315075,,,,,,,,26/Feb/13 20:45;ecn;I fixed some problems I introduced in r1450405.,26/Feb/13 22:04;vines;But you're still getting a CCE?,"27/Feb/13 02:11;hudson;Integrated in Accumulo-Trunk #746 (See [https://builds.apache.org/job/Accumulo-Trunk/746/])
    ACCUMULO-1114 a partial fix for user/table password handling (Revision 1450424)
ACCUMULO-1114 improve message reporting (Revision 1450402)

     Result = FAILURE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/TableRangeOp.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/src
","27/Feb/13 02:11;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #104 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/104/])
    ACCUMULO-1114 a partial fix for user/table password handling (Revision 1450424)
ACCUMULO-1114 improve message reporting (Revision 1450402)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/TableRangeOp.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/src
","27/Feb/13 14:42;ecn;Yes, I'm still getting a CCE.","27/Feb/13 17:19;hudson;Integrated in Accumulo-Trunk #747 (See [https://builds.apache.org/job/Accumulo-Trunk/747/])
    ACCUMULO-1114 store token for root, not serialized bytes (Revision 1450853)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/SecurityFixture.java
","27/Feb/13 20:57;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #106 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/106/])
    ACCUMULO-1114 store token for root, not serialized bytes (Revision 1450853)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/SecurityFixture.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stack overflow in random walk test,ACCUMULO-1111,12634201,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,vines,ecn,ecn,26/Feb/13 17:02,26/Feb/13 19:44,13/Mar/19 22:01,26/Feb/13 19:44,,,,,,,,1.5.0,,,test,,,,,,0,15_qa_bug,,,,"{noformat}
Caused by: java.lang.StackOverflowError
        at org.apache.accumulo.test.randomwalk.security.WalkingSecurity.validTokenClass(WalkingSecurity.java:383)
        at org.apache.accumulo.test.randomwalk.security.WalkingSecurity.validTokenClass(WalkingSecurity.java:383)
        at org.apache.accumulo.test.randomwalk.security.WalkingSecurity.validTokenClass(WalkingSecurity.java:383)
        at org.apache.accumulo.test.randomwalk.security.WalkingSecurity.validTokenClass(WalkingSecurity.java:383)
        at org.apache.accumulo.test.randomwalk.security.WalkingSecurity.validTokenClass(WalkingSecurity.java:383)
        at org.apache.accumulo.test.randomwalk.security.WalkingSecurity.validTokenClass(WalkingSecurity.java:383)
.
.
.
{noformat}

This is caused by WalkingSecurity being self referencing and poor code on my part. validTokenClass() and login() are both implemented incorrectly.",10 node test cluster running random walk test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-26 17:47:59.044,,,no_permission,,,,,,,,,,,,314694,,,Tue Feb 26 18:02:55 UTC 2013,,,,,,0|i1iazb:,315038,,,,,,,,"26/Feb/13 17:47;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #103 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/103/])
    ACCUMULO-1111 - fixed infinite loops clobering the stack (Revision 1450297)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","26/Feb/13 18:02;hudson;Integrated in Accumulo-Trunk #745 (See [https://builds.apache.org/job/Accumulo-Trunk/745/])
    ACCUMULO-1111 - fixed infinite loops clobering the stack (Revision 1450297)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
continuous ingest detected data loss,ACCUMULO-1053,12631479,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,08/Feb/13 16:33,26/Feb/13 18:04,13/Mar/19 22:01,26/Feb/13 16:43,,,,,,,,1.5.0,,,test,tserver,,,,,0,15_qa_bug,,,,"Now that we're logging directly HDFS, we added datanodes to the agitator. That is, we are now killing data nodes during ingest, and now we are losing data.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-08 16:59:07.668,,,no_permission,,,,,,,,,,,,311975,,,Mon Feb 25 17:22:18 UTC 2013,,,,,,0|i1hu7b:,312321,,,,,,,,"08/Feb/13 16:59;kturner;what version of hadoop were you running?  Were all hdfs settings correct?  We have sanity checks for that, but those could have missed something.  ","08/Feb/13 17:02;ecn;I'm running 0.20.205.0. dfs.support.append is set to true.

If I just kill tservers, there is no data loss.  
","08/Feb/13 20:28;afuchs;Does this problem manifest itself solely through the continuous ingest verify step, or are there also reports of missing blocks in HDFS?","08/Feb/13 20:31;afuchs;Also, would it help to try to isolate this to the new WAL changes by running the same test with 1.4.2?","08/Feb/13 20:40;ecn;This is from the verify step.  The data is missing without any other problems reported from HDFS.


","08/Feb/13 20:40;ecn;Hmm... scouting around on the internets, I'm seeing signs that a fully sync'd flush on HDFS may not be available in a released version of HDFS:

* HADOOP-6313
* HDFS-744

Anybody know the status of this for HDFS?



","08/Feb/13 22:22;billie.rinaldi;I checked with the HDFS guys about whether there are known issues.  They said a lot of bugs have been fixed since 0.20.205.0.  I would suggest trying the most recent 1.x release you can manage, ideally 1.1.1 or 1.1.2 (for which votes are currently winding down).  If it isn't fixed there, then we'll know it's not fixed in Hadoop 1.",11/Feb/13 15:53;ecn;I just verified 4.3B entries with several data node restarts; so it looks like this is going to be a challenge to figure out.  I'm going to run against 1.1.2rc5 and see how that goes.,"11/Feb/13 22:45;ecn;Verification failed with hadoop-1.1.2rc5:

||Counter||Total
|*UNDEFINED*|*8,003*
|REFERENCED|4,897,596,907
|UNREFERENCED|9,009,194

","12/Feb/13 14:40;ecn;Here's a basic analysis of the data loss.  It is incomplete, but I want to document the approach.

First, I look at the reported missing entries.  They look like this:

{noformat}
7001d8d9c37ff1a0        259018854a9e0ab5
700255fb34764bf0        598c79d47356f8da
70031a5ad5ff67c0        017b55debd8b9ba7
...
{noformat}

You read this as ""row id 7001d8d9c37ff1a0 is missing, it is referenced in row 259018854a9e0ab5"".

A basic check with the shell confirms this:

{noformat}
root@test ci> scan -r 7001d8d9c37ff1a0
root@test ci> scan -r 259018854a9e0ab5 -st
259018854a9e0ab5 5705:3563 [] 1360613984602    74430138-9c16-4135-8230-53b2c7e9af94:000000001987ebe3:7001d8d9c37ff1a0:87abf256
{noformat}

The reference row contains:
||Key Element||Data||
|row| random id|
|cf:cq| random column|
|ts| ingest time|
|value| ingester uuid: counter: reference: checksum

Find the ingester by greping through the ingest logs for the ingester uuid.

From there, find the moment when the flush occurred to look for errors:

{noformat}
...
FLUSH 1360613974304 3085438 3081429 427999984 1000000
FLUSH 1360614028073 53769 49119 428999984 1000000
...
{noformat}

Verify the count matches the timeframe (000000001987ebe3 == 428338147):

{noformat}
FLUSH 1360613974304 3085438 3081429 427999984 1000000
      1360613984602                 428338147 
FLUSH 1360614028073 53769 49119     428999984 1000000
{noformat}

It's good to verify these little assumptions because its very easy to make a small mistake and look at the wrong log file, or misread a digit.

Find the tablet name by scanning the !METADATA table:

{noformat}
scan -b 5;7001d8d9c37ff1a0 -c ~tab:~pr,file
5;7020c49ba5e354a file:/t-0008a8t/A0008ld2.rf []    95094250,2306420
5;7020c49ba5e354a file:/t-0008a8t/C000919w.rf []    95750715,2319223
5;7020c49ba5e354a file:/t-0008a8t/F000921z.rf []    6838391,170103
5;7020c49ba5e354a file:/t-0008a8t/F000924e.rf []    5517442,136722
5;7020c49ba5e354a ~tab:~pr []    \x0170000000000000a8
{noformat} 

Find the location of the tablet at the time of the loss by looking for ""5;7020c49ba5e354a"" in all the tserver logs, sorted by time.

Now you can find the walogs in use by the tablet server, the updates made by the ingester (by ip address).

In this case, the data was written to a walog, but the tablet was successfully minor compacted.  The minor compaction file was compacted into a 2nd file.  That file was compacted into C000919w.rf.  However C000919w.rf does not contain 7001d8d9c37ff1a0.

However, there was no read of the WAL, no recovery took place all of this took place on a single server.

I've turned on a 48-hour trash, and will re-run the test, so I can narrow down where the data is lost.

","12/Feb/13 16:26;kturner;bq. Find the location of the tablet at the time of the loss

Were you looking at the logs for the timeframe 1360613974304 to 1360614028073?  This is the timeframe in which the pointer to the missing the data was written.  The missing data was written in the previous time frame X to 1360613974304.  Also, is time across the cluster consistent?","12/Feb/13 19:08;ecn;Yes, the tablet had been loaded on the server for a long time.  And time is consistent across the cluster.
","13/Feb/13 18:06;ecn;I've had several runs over the last two days where I'm just killing data nodes, somewhat aggressively, too.  They have all verified cleanly.
","15/Feb/13 15:39;ecn;Letting CI run all night, randomly killing servers, had a failure due to data loss.

The loss occurred during the recovery of the root tablet.  In this case, a small WAL had a few mutations about the compaction of the table_info METADATA tablet.  When the file was recovered, the last few mutations were not found in the flushed WAL.

Examining the NN logs, I see the file's block allocated, followed by two fsync's and seven minutes later, a lease recovery.

After that, the sort file is created.

However, the commitBlockSynchronization on the file finishes some 90 seconds *after* the log sort is complete.

There's something I'm not understanding about how the HDFS file recovery is supposed to work.  Time to go back into the HBase code to see what I'm missing.",15/Feb/13 16:35;ecn;HDFS-2296,"15/Feb/13 16:42;vines;So is this something that affects all versions of Accumulo, but hasn't been witnessed because we never stressed the underlying DFS before?","15/Feb/13 17:37;ecn;No, when we had the logger servers, we were not dependent on flush/leaseRecovery.  Now that we log directly to HDFS (new in 1.5) we are subject to the way in which HDFS implements flush.","15/Feb/13 17:53;vines;I thought you had concluded the logging had nothing to do with it since
that tablet never had to be recovered?

Sent from my phone, please pardon the typos and brevity.

","15/Feb/13 18:03;ecn;We may be dealing with multiple bugs, or bugs masquerading as other problems.  In my long analysis write-up above, I was unable to finish because I didn't have the data to figure out what went wrong.  Hopefully other people will find the analysis helpful for their own debugging.","15/Feb/13 18:16;ecn;It looks like leaseRecovery is an async operation.  You request it, and sometime later, it finishes. From the javadoc:

""Start the lease recovery of a file""

""@return true if the file is already closed""

HDFS unit tests do this:

{noformat}
while (!fs.recoverLease(path)) {
   Thread.sleep(5000);
}
{noformat}

I've updated my workspace with this approach to wait for the file to be closed.  In my initial tests, this seems to provide the necessary wait for the commit of the last block to the file. Interestingly, HBase does not do this, but has a hard-coded one-second sleep after the recovery (I'm looking at 0.94.4).


",19/Feb/13 14:50;ecn;Created HBASE-7878 so someone in the HBase world investigates their approach to lease recovery.,"19/Feb/13 15:03;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #94 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/94/])
    ACCUMULO-1053 wait until a file has been closed before using it for recovery (Revision 1447710)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
","19/Feb/13 15:10;hudson;Integrated in Accumulo-Trunk #736 (See [https://builds.apache.org/job/Accumulo-Trunk/736/])
    ACCUMULO-1053 wait until a file has been closed before using it for recovery (Revision 1447710)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
","19/Feb/13 15:33;ecn;Keith writes on the dev list:

bq. Seems like this loop should be moved to isReady() part of repo.  This has two advantages.  It does not tie up a Fate thread.  Also if lots of leases need to be recovered it can cycle through all of them calling recoverLease once, instead of waiting for each one to be done. Maybe this would spin up a lot of parallel work in the namenode

I agree: I'll refactor the code.","19/Feb/13 22:28;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #95 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/95/])
    ACCUMULO-1053 revert inadvertent version change (Revision 1447854)
ACCUMULO-1053 revert inadvertent version change (Revision 1447853)
ACCUMULO-1053 merge inadvertent commit in trunk back to trunk (Revision 1447850)
ACCUMULO-1053 let file-not-found errors propagate and fail the FATE operation, merge to trunk (Revision 1447848)
ACCUMULO-1053 move lease recovery check to isReady() (Revision 1447829)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/examples/instamo/pom.xml

ecn : 
Files : 
* /accumulo/trunk/pom.xml

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/examples/instamo/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/FindOfflineTablets.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
","19/Feb/13 22:35;hudson;Integrated in Accumulo-Trunk #737 (See [https://builds.apache.org/job/Accumulo-Trunk/737/])
    ACCUMULO-1053 revert inadvertent version change (Revision 1447854)
ACCUMULO-1053 revert inadvertent version change (Revision 1447853)
ACCUMULO-1053 merge inadvertent commit in trunk back to trunk (Revision 1447850)
ACCUMULO-1053 let file-not-found errors propagate and fail the FATE operation, merge to trunk (Revision 1447848)
ACCUMULO-1053 move lease recovery check to isReady() (Revision 1447829)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/examples/instamo/pom.xml

ecn : 
Files : 
* /accumulo/trunk/pom.xml

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/examples/instamo/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/FindOfflineTablets.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
","20/Feb/13 21:59;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #97 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/97/])
    ACCUMULO-1053 merge in changes to 1.5 branch (Revision 1448388)
ACCUMULO-1053 merge to trunk (Revision 1448336)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/DfsLogger.java
* /accumulo/trunk/src
","20/Feb/13 22:13;hudson;Integrated in Accumulo-Trunk #739 (See [https://builds.apache.org/job/Accumulo-Trunk/739/])
    ACCUMULO-1053 merge in changes to 1.5 branch (Revision 1448388)
ACCUMULO-1053 merge to trunk (Revision 1448336)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/DfsLogger.java
* /accumulo/trunk/src
",21/Feb/13 15:45;ecn;Several overnight runs have verified clean using 1.1.2rc5 with the latest calls to recoverLease().  Going to test on 1.0.4.,25/Feb/13 15:17;ecn;A long test against hadoop-1.0.4 verified clean.,"25/Feb/13 15:19;kturner;bq. A long test against hadoop-1.0.4 verified clean.

Can you give more details about the test?","25/Feb/13 15:53;ecn;I ran CI on a 10 node cluster, with agitation.  I'm presently working through several issues related to how the master handles restarted tservers, so I did not restart the master.  In particular, I did not want master restarts to hide any potential problem.  I set the test to randomly kill 1-3 tservers or data nodes every 5 minutes, with a two-minute rest before each restart.

I let the test run over the weekend, with the HDFS Trash turned on for post-mortem analysis.  It managed to get 18B key-values in before filling the file system.

","25/Feb/13 17:08;hudson;Integrated in Accumulo-Trunk #743 (See [https://builds.apache.org/job/Accumulo-Trunk/743/])
    ACCUMULO-1053 ACCUMULO-498 merge to trunk (Revision 1449745)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/Key.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/data/KeyTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/LogSorter.java
* /accumulo/trunk/src
","25/Feb/13 17:22;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #101 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/101/])
    ACCUMULO-1053 ACCUMULO-498 merge to trunk (Revision 1449745)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/Key.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/data/KeyTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/LogSorter.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,
Proxy examples broken again: PrincipalToken is undefined,ACCUMULO-1046,12630991,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,elserj,elserj,06/Feb/13 02:48,06/Feb/13 15:29,13/Mar/19 22:01,06/Feb/13 14:32,1.5.0,,,,,,,,,,proxy,,,,,,0,,,,,"Went to run both the python and ruby proxy examples tonight and encountered errors in each regarding PrincipalToken being undefined.

I'm trying to piece back together what changed in ACCUMULO-996 (I think it's relevant?), but I'm at a loss. I see a generated PrincipalToken Java class in the proxy module (proxy/src/main/java/org/apache/accumulo/proxy/thrift/PrincipalToken.java), but there's not for the cpp,java, python or ruby bindings. I don't see it defined in proxy.thrift, either.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-06 03:59:12.335,,,no_permission,,,,,,,,,,,,311487,,,Wed Feb 06 15:29:27 UTC 2013,,,,,,0|i1hr73:,311833,,,,,,,,"06/Feb/13 03:59;vines;There currently is no token, just user/password. Details are in
Accumulo-1041

Sent from my phone, please pardon the typos and brevity.

","06/Feb/13 04:05;vines;I accidentally a currently

Sent from my phone, please pardon the typos and brevity.

","06/Feb/13 15:23;hudson;Integrated in Accumulo-Trunk #711 (See [https://builds.apache.org/job/Accumulo-Trunk/711/])
    ACCUMULO-1046 fix the examples (Revision 1442987)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/proxy/examples/python/TestClient.py
* /accumulo/trunk/proxy/examples/ruby/test_client.rb
","06/Feb/13 15:29;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #69 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/69/])
    ACCUMULO-1046 fix the examples (Revision 1442987)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/proxy/examples/python/TestClient.py
* /accumulo/trunk/proxy/examples/ruby/test_client.rb
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
VisibilityFilter does not catch BadArgumentException,ACCUMULO-844,12615005,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,06/Nov/12 18:55,27/Dec/12 21:25,13/Mar/19 22:01,27/Dec/12 20:26,1.4.0,1.4.1,,,,,,1.4.3,1.5.0,,tserver,,,,,,0,,,,,"If an invalid column visibility makes it into the system, then the VisibilityFilter may not handle it properly.   The accept method handles VisibilityParseException, but some of the parse code throws a BadArgumentException which is not handled.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-27 21:11:37.489,,,no_permission,,,,,,,,,,,,255548,,,Thu Dec 27 21:25:05 UTC 2012,,,,,,0|i0eten:,84529,,,,,,,,"27/Dec/12 21:11;hudson;Integrated in Accumulo-1.4.x #258 (See [https://builds.apache.org/job/Accumulo-1.4.x/258/])
    ACCUMULO-844 made visibilityfilter catch badargument exception (merged from tunk) (Revision 1426303)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/iterators/system/VisibilityFilter.java
* /accumulo/branches/1.4/src/core/src/test/java/org/apache/accumulo/core/iterators/system/VisibilityFilterTest.java
* /accumulo/branches/1.4/src/server
","27/Dec/12 21:25;hudson;Integrated in Accumulo-Trunk #593 (See [https://builds.apache.org/job/Accumulo-Trunk/593/])
    ACCUMULO-844 made visibilityfilter catch badargument exception (Revision 1426302)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/system/VisibilityFilter.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/iterators/system/VisibilityFilterTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
No longer seeing TApplicationException,ACCUMULO-701,12600068,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,24/Jul/12 21:06,27/Dec/12 19:50,13/Mar/19 22:01,27/Dec/12 19:50,,,,,,,,1.5.0,,,,,,,,,0,,,,,"When an unexpected exception occurred server side, the client used to see a TApplicationException on the client side.  It appears this not happening anymore in trunk since the switch to thrift 0.8.  A lot of code depends on the previous behavior.

Code that used to throw an exception to the client is now getting stuck indefinitely.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-07-24 21:42:50.251,,,no_permission,,,,,,,,,,,,245598,,,Thu Dec 27 19:50:55 UTC 2012,,,,,,0|i06bzb:,34875,,,,,,,,24/Jul/12 21:42;jvines;Is this a fault of the exception not propagating back or our server side code not spitting the errors back?,"24/Jul/12 21:52;kturner;When I turn debug on in the shell, I am seeing TTransportException.  Because I am seeing this exception, I suspect the server is just closing the connection but I am not sure.",25/Jul/12 18:38;kturner;I looked into this a bit more.  The Processor code generated by 0.6 catches Throwable and returns TApplicationException to the client.  The code generated by 0.8 does not seem to do this.,25/Jul/12 19:00;kturner;Opened THRIFT-1658,27/Dec/12 19:50;kturner;upgrading to thrift 0.9 fixed this issue,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Large bulk imports timing out,ACCUMULO-408,12542774,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,kturner,kturner,15/Feb/12 22:46,19/Dec/12 23:00,13/Mar/19 22:01,19/Dec/12 18:14,1.4.0,,,,,,,1.5.0,,,master,tserver,,,,,0,,,,,"Large bulk imports that take more than 2 minutes to process are failing.  The master ask a tablet sever to bulk import the files and times out after 2 minutes.  It retries, but the retry will take over 2 minutes.  Eventually it gives up and starts copying all of the data to the fail dir which takes forever.  This copy is all through the master and for large data basically never completes.  The bulk import threads on the tablet server probably complete eventually, so the data is still there.

The master should not time these request out.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-12 15:30:19.402,,,no_permission,,,,,,,,,,,,228060,,,Wed Dec 19 23:00:02 UTC 2012,,,,,,0|i06bz3:,34873,,,,,,,,"21/Feb/12 17:41;kturner;A fix for this was checked in svn commit #1245631.  This fix is still susceptible to the timeout issue.  This fix makes the problem much less likely and is the fix for 1.4.x.  For 1.5, we may want to consider a fix that is not susceptible to the timeout issue.","12/Dec/12 15:30;ecn;On large clusters, I'm seeing bulk imports fail, so the master moves the files, and yet there are entries in the METADATA table for those files.  Later, tservers complain that the files do not exist.
",19/Dec/12 18:14;ecn;fixed with 1423994,"19/Dec/12 22:50;hudson;Integrated in Accumulo-Trunk #586 (See [https://builds.apache.org/job/Accumulo-Trunk/586/])
    ACCUMULO-408 get the bulk functional tests working (Revision 1424060)
ACCUMULO-408 use sync to make sure we do not read old data from zookeeper (Revision 1424050)
ACCUMULO-408 use sync to make sure we do not read old data from zookeeper (Revision 1424036)
ACCUMULO-408 track threads which are assigning files to tservers, make connection timeout configurable for bulk requests (Revision 1423994)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooReader.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/functional/BulkSplitOptimizationTest.java
* /accumulo/trunk/test/system/auto/TestUtils.py

ecn : 
Files : 
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooReader.java

ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ServerClient.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/IZooReader.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooReader.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooReaderWriter.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/TransactionWatcher.java

ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ServerClient.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
","19/Dec/12 23:00;hudson;Integrated in Accumulo-1.4.x #256 (See [https://builds.apache.org/job/Accumulo-1.4.x/256/])
    ACCUMULO-408 merge from trunk (Revision 1424065)
ACCUMULO-408 use sync to make sure we do not read old data from zookeeper (Revision 1424053)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java
* /accumulo/branches/1.4/src/server

ecn : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/client/impl/ServerClient.java
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/zookeeper/IZooReader.java
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/zookeeper/TransactionWatcher.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accumulo system tests (SunnyDay at least) are locking up,ACCUMULO-100,12529539,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,,vines,jvines,31/Oct/11 19:44,18/Dec/12 18:39,13/Mar/19 22:01,01/Nov/11 14:49,,,,,,,,1.4.0,,,client,test,,,,,0,,,,,"I'm attempting to run the Sunny Day test and it's stuck at trying to create a shell. The monitor is not up, but running, as are the other processes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215399,,,2011-10-31 19:44:34.0,,,,,,0|i07p7z:,42852,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Makefile needs play nice on 64 and 32 bit systems,ACCUMULO-160,12531950,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,lpeaslee,vines,jvines,18/Nov/11 15:15,18/Dec/12 18:38,13/Mar/19 22:01,14/Oct/12 01:09,1.3.5-incubating,1.3.6,1.4.0,1.5.0,,,,1.5.0,,,tserver,,,,,,0,hackathon,make,,,Currently the makefile for the native in memory maps does not play well depending on system configuration. It should check in some way for either a 64 bit compiler or that it's on a 64 bit system and then attempt a 64 bit build. Otherwise it should do a 32 bit build.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,13/Oct/12 23:02;lpeaslee;accumulo-160.patch;https://issues.apache.org/jira/secure/attachment/12549045/accumulo-160.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-10-13 23:02:07.969,,,no_permission,,,,,,,,,,,,217686,,,Sun Oct 14 01:04:11 UTC 2012,,,,,,0|i06byv:,34872,,,,,,,,"13/Oct/12 23:02;lpeaslee;Modified the Makefile to check for an environment variable ""DARCH,"" which can be either 32, 64, or ""both"" to specify whether the 32 or 64 bit native libs should be built. If no DARCH is specified, it will now automatically determine which libraries to build based on the user's environment.

For example, ""make DARCH=32"" will now only build the 32 bit library even when the user is on a 64 bit machine. The default behavior of just issuing ""make"" has changed to automatically determine if the user is running in a 32 or 64 bit environment and will build only that corresponding library.",14/Oct/12 00:48;elserj;Patch contributed by Laura Peaslee,"14/Oct/12 00:51;elserj;Laura,

Thanks for that patch! I did make a few changes. It looks like you missed two includes on the CXXFLAGS variable from the original Makefile. I added those back, and did a little more indenting. I tested the modified Makefile on my 32bit laptop which successfully built only the 32bit native library.

Also, I added you to the Accumulo contributor's group.",14/Oct/12 01:04;elserj;Also made the same change in MLock since [~vines] hasn't purged it yet :) [ACCUMULO-796],,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Column family search with sparse files is painfully long,ACCUMULO-516,12549756,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,vines,jvines,05/Apr/12 17:43,18/Dec/12 18:38,13/Mar/19 22:01,19/Apr/12 10:35,1.3.5-incubating,1.4.0,,,,,,1.4.1,1.5.0,,tserver,,,,,,0,,,,,"Background: a tablet with 3 files, coming in at ~500MB, 200MB, and ~20MB. One of the files (I believe smallest) did not have the column of interest at all. Running a query filtering on a column family/qualifier pair. I can scan the entirety of the table in ~30 minutes. I aborted a scan for just that column after 2 hours.

Cause: Keith and I investigated, major compacting the tablet brought a column scan down to under 7 minutes. Dumping the largest file and grepping for the column of interest resulted in a large dead spot for that column which took minutes to grep over. After looking it over, the problem is how we do column family filtering. We handle colf filtering below the multi-iterator, which handles the merge read between multiple files. We do it at this level because we keep column info in the RFile metadata for quick filtering of entire files. The problem here is one of the files has that column, but does not have any relevant data in a large period. So every time we seek, which is for each batch of the query, we go down to the multi-iterator and seek for the first hit of the column(s) of interest. This means we are constantly spending minutes grabbing a key of interest to us which is substantially far down in the stack, such that we won't merge read it for many, MANY batches.

Proposed Solution: Split the column family filter into two seperate pieces. Keep the RFile optimized portion, as it can only occur at this level. But move the actual column family filter for files with that column above the MultiIterator. This will prevent this constant repetition of a large, painful seek.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-04-10 15:13:04.91,,,no_permission,,,,,,,,,,,,234747,,,Tue Apr 10 15:13:04 UTC 2012,,,,,,0|i07mpz:,42447,,,,,,,,"10/Apr/12 15:13;kturner;One possible work around is to manually place the column family filtering iterator higher up in the stack.   This would avoid the filtering at the lower level that is causing the problem.  However, this solution will not work well on a table that has locality groups configured because the iterator will drop the info needed by rfile to make smart locality group decisions.

One issue with this work around is that this iterator does not have an init method, so you would need to extend it and add an init method.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MapReduce over accumlo fails if process that started job is killed,ACCUMULO-826,12612762,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,19/Oct/12 19:26,22/Oct/12 19:50,13/Mar/19 22:01,22/Oct/12 19:04,1.4.1,,,,,,,1.4.2,,,,,,,,,0,,,,,"While testing the 1.4.2rc2 I started a continuous verify and killed the process that started the job.  Normally you would expect the job to keep running when you do this.  Howerver task started to fail.  I was seeing errors like the following.

{noformat}
java.io.FileNotFoundException: File does not exist: /user/hadoop/ContinuousVerify_13506740685261350674068686.pw
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1685)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.<init>(DFSClient.java:1676)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:479)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:187)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:418)
	at org.apache.accumulo.core.client.mapreduce.InputFormatBase.getPassword(InputFormatBase.java:681)
	at org.apache.accumulo.core.client.mapreduce.InputFormatBase$RecordReaderBase.initialize(InputFormatBase.java:1155)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:522)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:763)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:370)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.mapred.Child.main(Child.java:249)
{noformat}


I think this is caused by the following code in InputFormatBase

{code:java}
  public static void setInputInfo(Configuration conf, String user, byte[] passwd, String table, Authorizations auths) {
    if (conf.getBoolean(INPUT_INFO_HAS_BEEN_SET, false))
      throw new IllegalStateException(""Input info can only be set once per job"");
    conf.setBoolean(INPUT_INFO_HAS_BEEN_SET, true);
    
    ArgumentChecker.notNull(user, passwd, table);
    conf.set(USERNAME, user);
    conf.set(TABLE_NAME, table);
    if (auths != null && !auths.isEmpty())
      conf.set(AUTHORIZATIONS, auths.serialize());
    
    try {
      FileSystem fs = FileSystem.get(conf);
      Path file = new Path(fs.getWorkingDirectory(), conf.get(""mapred.job.name"") + System.currentTimeMillis() + "".pw"");
      conf.set(PASSWORD_PATH, file.toString());
      FSDataOutputStream fos = fs.create(file, false);
      fs.setPermission(file, new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE));
      fs.deleteOnExit(file);  // <--- NOT 100% sure, but I think this is the culprit
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-19 20:28:12.188,,,no_permission,,,,,,,,,,,,250019,,,Mon Oct 22 19:50:51 UTC 2012,,,,,,0|i0antb:,60131,,,,,,,,19/Oct/12 19:45;kturner;Why does the code that reads and write the password to a file put it in the DistributedCache and then read it directly from HDFS?  Seems like the code that reads the password should use DistributedCache.getLocalCacheFiles().,"19/Oct/12 20:28;ctubbsii;I think a more important question is: why does the user's password get stored in a file without their knowledge, as a side-effect of the implementation? I think this fundamentally goes against the point of having static method to manipulate the job configuration (the point being to only hold job state in the configuration, and not elsewhere with side-effects).

I do understand the benefit of not showing the user's password in the job configuration, which is viewable from the JobTracker page, whereas the contents of this file wouldn't be. Perhaps that was the reasoning for storing the password in a file in the first place. However, I think it should be up to the user to manage this file's persistence, so we don't do unpredictable/unexpected things, like create a file with their password in it without their knowledge or expectation, or automatically delete the file when the client dies after the MapReduce job has been submitted, therefore killing the MapReduce job.

I propose we modify the method signature to look like:
{code:java}
public static void setInputInfo(Configuration conf, String user, Path fileWithPasswordInHDFS, String table, Authorizations auths);
{code}

Users could then re-use this file for multiple jobs, and they can control read/write access to it.

This change may need to go through a deprecation path, and we may not want to do this until 1.5.0.","19/Oct/12 20:31;kturner;Seems like the methods to get and set ranges may have the same issues with delteOnExit and distributedCache.  Also, AccumuloOutputFormat.setOuputInfo() may have the same problem.","19/Oct/12 21:29;mdrob;The passwords are in files because of ACCUMULO-489.

I'm not a fan of adding more complexity to the client API by asking for a path to a file that contains the password instead of just asking for the password itself. Maybe it makes sense to still put the password in the job conf, but encrypt it using a shared secret (which I think Accumulo already has?). Oh, and make sure that the secret isn't in the conf as well.","19/Oct/12 22:05;ctubbsii;Thanks [~mdrob]! I hadn't realized it was only just fixed in 1.4.1. I propose we just revert to the 1.4.0 behavior of having base64 world-readable passwords in the config for 1.4.2, and fix it properly in 1.5.0 by accepting a Path to a file in HDFS that the user manages, to supply the password, as described in my previous comment.","19/Oct/12 22:19;kturner;bq. I propose we just revert to the 1.4.0 behavior of having base64 world-readable passwords in the config for 1.4.2, and fix it properly in 1.5.0

I think this sounds reasonable.  The bug fix in 1.4.1 fixed and introduced bugs.  It slightly improved security, but not in any dramatic way (i.e. using cryptography).    Also, I can not find a way to delete the file when the job finishes as opposed to when the process that started the job exits.  Does anyone know of a way to delete the file when the job exits?  If we were to roll this back, should we roll back the changes to get and set ranges also?

bq.  using a shared secret (which I think Accumulo already has?)
Probably should not assume map reduce system can access accumulo's shared secret.  Christopher and I discussed using a public key to encrypt the password.  Would need to find a standard to use, its hard to get crypto protocols right.   But this is work for 1.5 I think, need to determine what we want to do for 1.4.2.","22/Oct/12 18:11;kturner;In revision 1400976 : reverted revisions 1397700,1382923,1339308,1339223,1336322.  These changes caused map reduce jobs to fail if the process that started the job exited.  

The reverse merge in svn worked very nicely.","22/Oct/12 19:04;kturner;Rolled back changes in trunk also,  r1401004","22/Oct/12 19:17;vines;The file gets stored in the private distributed cache, which was added in Hadoop 20.20something. The method for accessing that may not be accurate. Mike Drob is correct, that was implemented for ACCUMULO-489, which is a critical issue. The other implementation idea was having it stored temporarily in zookeeper. Having issues have to mess with the file system is worse, IMO. It will lead to users having passwords laying around in the filesystem world-readable because some do not know or do not care about securing their identity, they just want to run their MR job.

I think the only other secure implementation would be a token system implemented, but for the effort of timeliness, using the private distributed cache is a safe method of implementing this.","22/Oct/12 19:45;hudson;Integrated in Accumulo-1.4.x #244 (See [https://builds.apache.org/job/Accumulo-1.4.x/244/])
    ACCUMULO-826 ACCUMULO-507 reverted revisions 1397700,1382923,1339308,1339223,1336322.  These changes caused map reduce jobs to fail if the process that started the job exited. (Revision 1400976)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/branches/1.4/src/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormatTest.java
","22/Oct/12 19:50;hudson;Integrated in Accumulo-Trunk #533 (See [https://builds.apache.org/job/Accumulo-Trunk/533/])
    ACCUMULO-826 ACCUMULO-507 reverted changes that caused map reduce jobs to fail if the process that started the job exited (Revision 1401004)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormatTest.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockConnector returns a MockInstance that is not equivalent to it's parent MockInstance,ACCUMULO-782,12610097,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ekohlwey,ekohlwey,ekohlwey,03/Oct/12 16:37,09/Oct/12 19:55,13/Mar/19 22:01,09/Oct/12 19:55,1.4.1,1.4.2,1.5.0,,,,,1.4.2,1.5.0,,client,,,,,,0,,,,,,MockConnector should return it's parent instance as the MockInstance for getInstance().,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,03/Oct/12 16:56;ekohlwey;ACCUMULO-782.patch;https://issues.apache.org/jira/secure/attachment/12547554/ACCUMULO-782.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-10-09 19:55:42.054,,,no_permission,,,,,,,,,,,,244047,,,Tue Oct 09 19:55:42 UTC 2012,,,,,,0|i05fiv:,29612,,,,,,,,03/Oct/12 16:56;ekohlwey;Ooops- forgot part of the fix ;),"09/Oct/12 19:55;kturner;When I first looked at the patch, I thought we would need to offer deprecated versions of the old MockConnector constructors.  Then I realized the methods were not public.  I just applied the patch to 1.4 and trunk.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooStore can starve completed Repos,ACCUMULO-779,12609455,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,ecn,ecn,27/Sep/12 21:10,04/Oct/12 02:10,13/Mar/19 22:01,04/Oct/12 02:09,1.4.0,1.4.1,,,,,,1.4.2,1.5.0,,master,,,,,,0,,,,,"A user aggressively used the compactrange command.  This queued dozens of Repos in zookeeper.  Pulling new Repos from zookeeper is fairly slow.  Checking if they are ready, is also slow.  The threads running the Repos would not finish getting through the list of Repos, some of which had finished, before the first item in the list was ready to be checked again.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-09-27 21:20:43.897,,,no_permission,,,,,,,,,,,,240619,,,Thu Sep 27 21:20:43 UTC 2012,,,,,,0|i013y7:,4409,,,,,,,,"27/Sep/12 21:20;kturner;The txids are random.  The repos that were basically finished were holding locks and had higher txids.  Fate kept cycling through the lower txids, that were just waiting on the lock, never getting to the higher txids.  

Need to make sure the reservation function cycles through all txids before starting over.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failed bulk import files are copied through master,ACCUMULO-409,12542775,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,15/Feb/12 22:50,05/Jul/12 20:41,13/Mar/19 22:01,05/Jul/12 16:20,1.4.0,,,,,,,1.4.2,,,master,,,,,,0,,,,,"When bulk import fails, the failed files are copied into a fail dir by the master.  This is very bad if its a large amount of data.  Noticed this while debugging ACCUMULO-408.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29/Jun/12 21:28;kturner;ACCUMULO-409-1.txt;https://issues.apache.org/jira/secure/attachment/12534045/ACCUMULO-409-1.txt,03/Jul/12 12:46;kturner;ACCUMULO-409-3.txt;https://issues.apache.org/jira/secure/attachment/12534862/ACCUMULO-409-3.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2012-07-05 20:41:18.219,,,no_permission,,,,,,,,,,,,228061,,,Thu Jul 05 20:41:18 UTC 2012,,,,,,0|i07ndb:,42552,,,,,,,,15/Feb/12 22:50;kturner;I supposed one solution is to use distcp.,21/Feb/12 17:48;kturner;One tricky issue about using distcp is reliably determining the status of the map reduce job.,18/Apr/12 15:17;kturner;Another solution may be to farm copying out to tservers.,24/Apr/12 17:11;kturner;Files that were not bulk imported into any tablet can be moved instead of copied.,"21/Jun/12 23:05;kturner;I found something interesting while looking into this.  Tablet servers currently copy failures and then the master copies them.  This copy by the tserver is not something that we could rely on to happen, it does not help fix this problem in anyway.  Its duplicate effort that needs to be removed.  Its an artifact of using the old bulk import code in FATE.

Also, its possible that a tablet server could copy something into the failed dir, then a later import attempt by the master could succeed.  This would result in an unnecessary file in the failed dir.
",21/Jun/12 23:09;kturner;Another thing I have realized while looking into this code is that the Arbiter code needs to call the zookeeper sync() method before reading if a work id is active.,"30/Jun/12 03:19;kturner;Can someone code review the patch?

https://reviews.apache.org/r/5684/",03/Jul/12 12:46;kturner;An updated patch,"05/Jul/12 20:41;ecn;Updated patch looks great.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ScannerOptions reverses the iterator name and iterator class if the deprecated API is used,ACCUMULO-660,12596143,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,billie.rinaldi,ecn,ecn,27/Jun/12 19:09,28/Jun/12 18:22,13/Mar/19 22:01,28/Jun/12 18:22,1.4.0,,,,,,,1.4.1,,,client,,,,,,0,,,,,"setScanIterators(int, String, String) reverses the two strings.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246407,,,2012-06-27 19:09:53.0,,,,,,0|i07ltz:,42303,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tablet server fails to start because it looks for walogs in wrong place,ACCUMULO-639,12560799,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,15/Jun/12 16:08,15/Jun/12 20:09,13/Mar/19 22:01,15/Jun/12 20:09,,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"Seeing the following when trying to start tserver

{noformat}
Uncaught exception in TabletServer.main, exiting    java.lang.NullPointerException
    at org.apache.accumulo.server.tabletserver.TabletServer.recoverLocalWriteAheadLogs(TabletServer.java:3141)
    at org.apache.accumulo.server.tabletserver.TabletServer.main(TabletServer.java:3122)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.accumulo.start.Main$1.run(Main.java:87)
    at java.lang.Thread.run(Thread.java:662)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246428,,,2012-06-15 16:08:22.0,,,,,,0|i07lyv:,42325,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"with a large root tablet, tablet servers will get stuck loading other metadata tablets",ACCUMULO-542,12551305,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,17/Apr/12 21:25,27/Apr/12 11:52,13/Mar/19 22:01,27/Apr/12 11:52,1.3.5-incubating,1.4.0,,,,,,1.3.6,1.4.1,,tserver,,,,,,0,,,,,"Trying to bring up a large cluster, metadata tablets failed to load. These metadata tablets were trying to read their entries from the root tablet.

Workaround is to double the memory used for scanning the !METADATA table:

{noformat}
shell> config -t !METADATA -s table.scan.max.memory=2M
{noformat}

Nothing needs to be done: the tablet servers will recover as soon as this value is changed.
",large cluster with 390+ metadata data tablets,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-04-17 21:33:41.194,,,no_permission,,,,,,,,,,,,236169,,,Tue Apr 17 21:33:41 UTC 2012,,,,,,0|i07mk7:,42421,,,,,,,,17/Apr/12 21:33;kturner;For 1.5 we may want to consider switching the old code the reads directly from the root tablet to user a scanner.  Also we noticed the code was reading everything in the root tablet after the tablet of interest.  This is completely unnecessary.  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
data lost during merge,ACCUMULO-424,12543701,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,ecn,ecn,22/Feb/12 15:41,28/Feb/12 19:00,13/Mar/19 22:01,28/Feb/12 19:00,,,,,,,,1.4.0,,,master,,,,,,0,14_qa_bug,,,,"A chopped, unassigned tablet with walogs was merged, which removed the walog entry, and the associated mutations.
","randomwalk test, under agitation, 10-node test cluster",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,228940,,,Tue Feb 28 14:22:17 UTC 2012,,,,,,0|i07n9z:,42537,,,,,,,,"28/Feb/12 14:22;ecn;randomwalk blocked when deleterange didn't put dirty tablets back online, since those tablets didn't need to be chopped.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hole in metadata table occurred during random walk test,ACCUMULO-315,12538384,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,14/Jan/12 02:38,09/Feb/12 22:25,13/Mar/19 22:01,01/Feb/12 20:41,,,,,,,,1.4.0,,,master,tserver,,,,,0,14_qa_bug,,,,"While running the random walk test a hole in the metadata table occurred.  A client tried to delete the table with the whole and the fate op got stuck.  Was continually seeing the following in the master logs.

{noformat}
14 00:02:11,273 [tableOps.CleanUp] DEBUG: Still waiting for table to be deleted: 4ct locationState: 4ct;4d2d3be2823b0bf4;27b693c626c2d4ef@(null,xxx.xxx.xxx.xxx:9997[134d7425fc503e1],null)
{noformat}

The metadata table contained the following.  Tablet 4ct;4d2d3be2823b0bf4 had a location.

{noformat}
4ct;262249211a62cd6f ~tab:~pr []    \x011819e56edae21302
4ct;27b693c626c2d4ef ~tab:~pr []    \x01262249211a62cd6f
4ct;43422047c78fa52b ~tab:~pr []    \x0141ea825af0f262d9
4ct;4d2d3be2823b0bf4 ~tab:~pr []    \x0127b693c626c2d4ef
4ct;4f89df61392bb311 ~tab:~pr []    \x014d2d3be2823b0bf4
{noformat}

Found the following events on a tablet server.

{noformat}
#the tablet server events below are caused by the delete range operation
13 21:36:04,287 [tabletserver.Tablet] TABLET_HIST: 4ct;4d2d3be2823b0bf4;262249211a62cd6f split 4ct;27b693c626c2d4ef;262249211a62cd6f 4ct;4d2d3be2823b0bf4;27b693c626c2d4ef

13 21:36:04,369 [tabletserver.Tablet] TABLET_HIST: 4ct;4d2d3be2823b0bf4;27b693c626c2d4ef split 4ct;41ea825af0f262d9;27b693c626c2d4ef 4ct;4d2d3be2823b0bf4;41ea825af0f262d9

13 21:36:04,370 [tabletserver.Tablet] TABLET_HIST: 4ct;4d2d3be2823b0bf4;41ea825af0f262d9 opened

13 21:36:06,141 [tabletserver.Tablet] TABLET_HIST: 4ct;4d2d3be2823b0bf4;41ea825af0f262d9 closed
13 21:36:06,142 [tabletserver.Tablet] DEBUG: Files for low split 4ct;43422047c78fa52b;41ea825af0f262d9  [/t-0001cdi/F0001bmw.rf, /t-0001cdi/F0001bn1.rf]
13 21:36:06,142 [tabletserver.Tablet] DEBUG: Files for high split 4ct;4d2d3be2823b0bf4;43422047c78fa52b  [/t-0001cdi/A0001cef.rf, /t-0001cdi/F0001bmw.rf, /t-0001cdi/F0001bn1.rf]

#split from other random walker
13 21:36:06,351 [tabletserver.Tablet] TABLET_HIST: 4ct;4d2d3be2823b0bf4;41ea825af0f262d9 split 4ct;43422047c78fa52b;41ea825af0f262d9 4ct;4d2d3be2823b0bf4;43422047c78fa52b
{noformat}

The following events occurred on the master and overlap in time with the split on the tablet server.

{noformat}
13 21:36:06,312 [master.EventCoordinator] INFO : Merge state of 4ct;41ea825af0f262d9;27b693c626c2d4ef set to MERGING
13 21:36:06,312 [master.Master] DEBUG: Deleting tablets for 4ct;41ea825af0f262d9;27b693c626c2d4ef
13 21:36:06,316 [master.Master] DEBUG: Found following tablet 4ct;4d2d3be2823b0bf4;43422047c78fa52b
13 21:36:06,317 [master.Master] DEBUG: Making file deletion entries for 4ct;41ea825af0f262d9;27b693c626c2d4ef
13 21:36:06,325 [master.Master] DEBUG: Removing metadata table entries in range [4ct;27b693c626c2d4ef%00; : [] 9223372036854775807 false,4ct;41ea825af0f262d9%00; : [] 9223372036854775807 false)
13 21:36:06,331 [master.Master] DEBUG: Updating prevRow of 4ct;4d2d3be2823b0bf4;43422047c78fa52b to 27b693c626c2d4ef
{noformat}

After many hours of debugging Eric and I figured out what was going on.  Two random walkers were running the concurrent test.  One client initiated a delete range on table id 4ct for the range 27b693c626c2d4ef to 41ea825af0f262d9.  While this delete range operation was occurring another client add the split point 43422047c78fa52b.  The master read the metadata table while the split was occurring and got inconsistent/incomplete information about what tablets related to the delete range operation were online.  It assumed the required tablets were offline when they were not.  The log messages above show that the split and updating of the prevRow by the master overlap in time.

We think the best solution is to ensure that scans of the metadata table for merges and delete range are consistent with respect to end row and prev end row matching.  Can not consider tablets individually.  Must ensure the portion of the metadata table under consideration forms a proper sorted linked list.      ",Running 1.4.0 SNAPSHOT on 10 node cluster.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-17 21:25:02.107,,,no_permission,,,,,,,,,,,,223890,,,Sat Jan 28 00:31:26 UTC 2012,,,,,,0|i07nxb:,42642,,,,,,,,"17/Jan/12 21:25;ecn;The master was performing a range-delete.  It split a tablet into three sections, to remove the center with tablet operations.

While it was working through the online->chop->offline state transition, the last tablet of the three had a split.  This caused the main loop to miss a tablet, and to have bad counts.  The master then mistakenly believed that all the tablets needed to be offline had been taken offline.  The master then updated the prevRow of the last tablet while the tablet was still online, which caused the hole in the metadata table.
",17/Jan/12 21:52;kturner;The range for the delete range operation was completely contained in the tablet 4ct;4d2d3be2823b0bf4;262249211a62cd6f when the operation started.,"20/Jan/12 20:11;jvines;Brain dump of discussions throughout the day-

Going in the path that there was a potential issue of a split occuring during a merge, such that the split data was lost, we went in the direction to ensure that merges could not include split data. Through code review, we're comfortable saying that it's not a problem with our logic of ensuring offline == total to determine all tablets are offline. We were originally thinking that this had the possibility of total not being updated accurately, causing there to be another tablet in the range which was not offline which should have been offline. This is not possible, since the totals are updates within the code. However, the code could be simplified by looking for the existence of ANY (boolean) online tablets in the range. Additionally, a similar fix could have been made for needsChop.

Unfortunately, we realized that this is not the case because of the keyextents we deal with. We believe that it's not possible to get a partial key extent, such as taht after the very first write of a split (changing of prevRow in the parent of the split). This means that if we catch a scan between the first and second writes of a split, we will be missing a tablet which is abou to come online. Keith originally had the idea, which I'm not 100% thrilled with, but I believe is the only solution, which is to have merge have a dedicated scanner which goes over the METADATA table for the merge range to ensure that the startrow = next KE prevendrow. This would catch the previously mentioned partial write of the split. It would be enough information for the merge to rescan and ensure the data is valid.

The state changes for the merge FATE operation seem valid, I can only really attribute it to our scanning and the interruptableness of splits. The only other way I see us accomplishing this possibility of merge/split conflicts is to have a mechanism in place to halt splits during the chop. We sort of have this by taking tablets offline, but we still have this race condition of the three writes for a split and the offlining of a tablet to occur while the scanner is after the newly created tablet and the tablet going offline.","28/Jan/12 00:31;kturner;With the most recent changes against this ticket, including the bug fixes I just committed, I am seeing merge operations get stuck during random walk test.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tablet is both assigned and hosted,ACCUMULO-7,12525981,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,ecn,kturner,kturner,05/Oct/11 22:38,30/Nov/11 18:54,13/Mar/19 22:01,30/Nov/11 18:54,1.4.0,,,,,,,1.4.0,,,master,,,,,,0,,,,,"At startup, the master did not successfully complete its scan of tablet servers in zookeeper because of an I/O error communicating with a tablet server.  This caused the master to assume online tablet servers were offline.  This led to multiple tablet assignment.  Need to make the zookeeper scan of tablet servers more robust.

At this point some work has been done for some of the ill effects. scanServers needs to be adjusted to handle exceptions instead of just catching them and logging.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,47475,,,Thu Oct 20 19:18:14 UTC 2011,,,,,,0|i07psn:,42945,,,,,,,,"13/Oct/11 18:19;kturner;There is a fix for this in the TServerConnection constructor, however this is a fix for just the exception we saw.  The code in LiveTServerSet.scanServers() needs to be made more robust against any unexpected exceptions.",20/Oct/11 19:18;kturner;The fix currently checked in is good for 1.3.  May want to do the more general fix for 1.4.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Files deleted while in use by scan,ACCUMULO-6,12525980,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,05/Oct/11 22:34,18/Nov/11 15:28,13/Mar/19 22:01,07/Oct/11 22:57,,,,,,,,1.4.0,,,tserver,,,,,,0,,,,,"When merging minor compactions occur, the merged file is made available for delete by the garbage collector.  In some situations this is done when the file is in use by a scan.  

This bug is caused by the fact that bringMinorCompactionOnline() does not remove the merged file from the list of tablet files before calling waitForScansToFinish().  Major compactions do remove the file before calling waitForScansToFinish().

Possible solutions

 * Always assume a merged file is in use by scans instead of calling waitForScansToFinish().  Would need to move the call to removeFilesAfterScan() after the tablet files are updated.

 * Remove file from tablet files before calling waitForScansToFinish()... in the case of failures, users may see the results of a compaction and then not see it... this is what major compactions do.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,47354,,,Fri Oct 07 23:01:26 UTC 2011,,,,,,0|i07psv:,42946,,,,,,,,07/Oct/11 23:01;kturner;This bug was found while running the continuous ingest test for a few days.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
upgrade script is broken,ACCUMULO-104,12529668,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,01/Nov/11 14:43,01/Nov/11 17:21,13/Mar/19 22:01,01/Nov/11 17:21,,,,,,,,1.3.5-incubating,,,,,,,,,0,,,,,The script to upgrade a cloudbase instance to accumulo is not working.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215527,,,2011-11-01 14:43:16.0,,,,,,0|i07p73:,42848,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Default config for table.scan.max.memory is suboptimal,ACCUMULO-105,12529671,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,01/Nov/11 14:46,01/Nov/11 15:03,13/Mar/19 22:01,01/Nov/11 15:03,,,,,,,,1.3.5-incubating,,,client,tserver,,,,,0,,,,,"The default for table.scan.max.memory is 50M.  This is way to high, it causes each batch scanner thread to pull back 50M at a time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215530,,,2011-11-01 14:46:41.0,,,,,,0|i07p6v:,42847,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Logical time not considered in merge,ACCUMULO-72,12528769,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Critical,Fixed,kturner,kturner,kturner,25/Oct/11 21:40,26/Oct/11 21:32,13/Mar/19 22:01,26/Oct/11 21:32,,,,,,,,1.4.0,,,master,,,,,,0,,,,,"When merging tablets, logical time is not considered.  

In the shell session below, the second insert should have timestamp of 2.

{noformat}
root@a14> createtable -tl foo
root@a14 foo> addsplits -t foo m
root@a14 foo> insert a cf1 cq1 v1
root@a14 foo> scan -st
a cf1:cq1 [] 1    v1
root@a14 foo> merge -t foo
root@a14 foo> insert b cf1 cq1 v1
root@a14 foo> scan -st           
a cf1:cq1 [] 1    v1
b cf1:cq1 [] 1    v1
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,214629,,,2011-10-25 21:40:08.0,,,,,,0|i07pe7:,42880,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ColumnAgeOffFilter doesn't validate options correctly,ACCUMULO-1604,12659450,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,milleruntime,ctubbsii,ctubbsii,23/Jul/13 22:12,23/Dec/17 20:22,13/Mar/19 22:01,17/Jul/16 15:16,,,,,,,,1.8.0,,,,,,,,,0,newbie,,,,"The o.a.a.core.iterators.user.ColumnAgeOffFilter doesn't validate options correctly. It incorrectly assumes all options are for itself, and ignores the fact that some options may be for the parent class (""negate"" option on Filter).",,"GitHub user milleruntime opened a pull request:

    https://github.com/apache/accumulo/pull/122

    ACCUMULO-1604: added check for negate option in ColumnAgeOffFilter an…

    …d new test in FilterTest

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/milleruntime/accumulo ACCUMULO-1604

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/accumulo/pull/122.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #122
    
----
commit b045255770676e034b6a394768c34af81a13192c
Author: Mike Miller <michaelpmiller@gmail.com>
Date:   2016-07-05T19:11:26Z

    ACCUMULO-1604: added check for negate option in ColumnAgeOffFilter and new test in FilterTest

----
;05/Jul/16 19:34;githubbot;600","Github user dhutchis commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r69675388
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/user/ColumnAgeOffFilter.java ---
    @@ -43,6 +43,9 @@ public TTLSet(Map<String,String> objectStrings) {
           for (Entry<String,String> entry : objectStrings.entrySet()) {
             String column = entry.getKey();
             String ttl = entry.getValue();
    +        // skip the negate option, it will cause an exception to be thrown
    +        if (column.equals(NEGATE))
    --- End diff --
    
    A user might want to use this filter on a column named NEGATE. Could you add a condition `&& !TTL.equalsIgnoreCase(""true"") && !ttl.equalsIgnoreCase(""false"")`?
;06/Jul/16 04:56;githubbot;600","Github user milleruntime commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r69723197
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/user/ColumnAgeOffFilter.java ---
    @@ -43,6 +43,9 @@ public TTLSet(Map<String,String> objectStrings) {
           for (Entry<String,String> entry : objectStrings.entrySet()) {
             String column = entry.getKey();
             String ttl = entry.getValue();
    +        // skip the negate option, it will cause an exception to be thrown
    +        if (column.equals(NEGATE))
    --- End diff --
    
    Yeah sure thing
;06/Jul/16 12:48;githubbot;600","Github user milleruntime commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r69723256
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/user/ColumnAgeOffFilter.java ---
    @@ -43,6 +43,9 @@ public TTLSet(Map<String,String> objectStrings) {
           for (Entry<String,String> entry : objectStrings.entrySet()) {
             String column = entry.getKey();
             String ttl = entry.getValue();
    +        // skip the negate option, it will cause an exception to be thrown
    +        if (column.equals(NEGATE))
    --- End diff --
    
    Yeah sure thing
;06/Jul/16 12:48;githubbot;600","Github user dhutchis commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r69844349
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/user/ColumnAgeOffFilter.java ---
    @@ -43,6 +43,9 @@ public TTLSet(Map<String,String> objectStrings) {
           for (Entry<String,String> entry : objectStrings.entrySet()) {
             String column = entry.getKey();
             String ttl = entry.getValue();
    +        // skip the negate option, it will cause an exception to be thrown
    +        if (column.equalsIgnoreCase(NEGATE) && (ttl.equalsIgnoreCase(""true"") || ttl.equalsIgnoreCase(""false"")))
    --- End diff --
    
    Nitpick: the column check could change to `column.equals(NEGATE)` since Filter performs a case-sensitive checking.  But this is fine as is.  Thanks @milleruntime!
;07/Jul/16 02:42;githubbot;600","Github user dhutchis commented on the issue:

    https://github.com/apache/accumulo/pull/122
  
    +1
;07/Jul/16 02:43;githubbot;600","Github user keith-turner commented on the issue:

    https://github.com/apache/accumulo/pull/122
  
    @milleruntime would you like to squash this into one commit before its merged?
;08/Jul/16 20:42;githubbot;600","Github user milleruntime commented on the issue:

    https://github.com/apache/accumulo/pull/122
  
    Yeah I can do that
    
    On Friday, July 8, 2016, Keith Turner <notifications@github.com> wrote:
    
    > @milleruntime <https://github.com/milleruntime> would you like to squash
    > this into one commit before its merged?
    >
    > —
    > You are receiving this because you were mentioned.
    > Reply to this email directly, view it on GitHub
    > <https://github.com/apache/accumulo/pull/122#issuecomment-231467545>, or mute
    > the thread
    > <https://github.com/notifications/unsubscribe/ALUpGz6MStXgGlCAU2XgRskjeF7By7lQks5qTrZHgaJpZM4JFc8O>
    > .
    >

;09/Jul/16 13:56;githubbot;600","Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r70193586
  
    --- Diff: core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java ---
    @@ -234,20 +234,101 @@ public void test2a() throws IOException {
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 902);
    +    assertEquals(902, size(a));
     
         ColumnAgeOffFilter.addTTL(is, new IteratorSetting.Column(""a"", ""b""), 101l);
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 102);
    +    assertEquals(102, size(a));
     
         ColumnAgeOffFilter.removeTTL(is, new IteratorSetting.Column(""a"", ""b""));
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a = (ColumnAgeOffFilter) a.deepCopy(null);
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 902);
    +    assertEquals(902, size(a));
    +  }
    +
    +  /**
    +   * Test for fix to ACCUMULO-1604: ColumnAgeOffFilter was throwing an error when using negate
    +   */
    +  @Test
    +  public void test2aNegate() throws IOException {
    +    Text colf = new Text(""a"");
    +    Text colq = new Text(""b"");
    +    Value dv = new Value();
    +    TreeMap<Key,Value> tm = new TreeMap<Key,Value>();
    +    IteratorSetting is = new IteratorSetting(1, ColumnAgeOffFilter.class);
    +    ColumnAgeOffFilter.addTTL(is, new IteratorSetting.Column(""a""), 901l);
    +    ColumnAgeOffFilter.setNegate(is, true);
    +    long ts = System.currentTimeMillis();
    +
    +    for (long i = 0; i < 1000; i++) {
    +      Key k = new Key(new Text(String.format(""%03d"", i)), colf, colq, ts - i);
    +      tm.put(k, dv);
    +    }
    +    assertTrue(tm.size() == 1000);
    --- End diff --
    
    Nit, `assertEquals` would give a better error message on failure
;11/Jul/16 01:37;githubbot;600","Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r70193707
  
    --- Diff: core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java ---
    @@ -208,9 +208,9 @@ public void test2() throws IOException {
         a = a.deepCopy(null);
         SortedKeyValueIterator<Key,Value> copy = a.deepCopy(null);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 900);
    +    assertEquals(900, size(a));
    --- End diff --
    
    Separating out these test fixes into a separate commit (with a separate JIRA) would make me happy as it makes the changeset easier to comprehend if we ever need to go back in history, but I'm not -1 either if you don't.
;11/Jul/16 01:40;githubbot;600","Github user joshelser commented on the issue:

    https://github.com/apache/accumulo/pull/122
  
    Left some nit-picky suggestions, but :+1: from me as-is too. Thanks for the fix!
;11/Jul/16 01:44;githubbot;600","Github user milleruntime commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r70254227
  
    --- Diff: core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java ---
    @@ -234,20 +234,101 @@ public void test2a() throws IOException {
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 902);
    +    assertEquals(902, size(a));
     
         ColumnAgeOffFilter.addTTL(is, new IteratorSetting.Column(""a"", ""b""), 101l);
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 102);
    +    assertEquals(102, size(a));
     
         ColumnAgeOffFilter.removeTTL(is, new IteratorSetting.Column(""a"", ""b""));
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a = (ColumnAgeOffFilter) a.deepCopy(null);
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 902);
    +    assertEquals(902, size(a));
    +  }
    +
    +  /**
    +   * Test for fix to ACCUMULO-1604: ColumnAgeOffFilter was throwing an error when using negate
    +   */
    +  @Test
    +  public void test2aNegate() throws IOException {
    +    Text colf = new Text(""a"");
    +    Text colq = new Text(""b"");
    +    Value dv = new Value();
    +    TreeMap<Key,Value> tm = new TreeMap<Key,Value>();
    +    IteratorSetting is = new IteratorSetting(1, ColumnAgeOffFilter.class);
    +    ColumnAgeOffFilter.addTTL(is, new IteratorSetting.Column(""a""), 901l);
    +    ColumnAgeOffFilter.setNegate(is, true);
    +    long ts = System.currentTimeMillis();
    +
    +    for (long i = 0; i < 1000; i++) {
    +      Key k = new Key(new Text(String.format(""%03d"", i)), colf, colq, ts - i);
    +      tm.put(k, dv);
    +    }
    +    assertTrue(tm.size() == 1000);
    --- End diff --
    
    It looks like there are a bunch assertTrue checks that would be better as assertEquals. How about I create an improvement ticket in JIRA?
;11/Jul/16 13:13;githubbot;600","Github user milleruntime commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r70258356
  
    --- Diff: core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java ---
    @@ -208,9 +208,9 @@ public void test2() throws IOException {
         a = a.deepCopy(null);
         SortedKeyValueIterator<Key,Value> copy = a.deepCopy(null);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 900);
    +    assertEquals(900, size(a));
    --- End diff --
    
    I will undo this commit and save it off for a separate JIRA ticket.
;11/Jul/16 13:39;githubbot;600","Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r70259979
  
    --- Diff: core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java ---
    @@ -234,20 +234,101 @@ public void test2a() throws IOException {
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 902);
    +    assertEquals(902, size(a));
     
         ColumnAgeOffFilter.addTTL(is, new IteratorSetting.Column(""a"", ""b""), 101l);
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 102);
    +    assertEquals(102, size(a));
     
         ColumnAgeOffFilter.removeTTL(is, new IteratorSetting.Column(""a"", ""b""));
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a = (ColumnAgeOffFilter) a.deepCopy(null);
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 902);
    +    assertEquals(902, size(a));
    +  }
    +
    +  /**
    +   * Test for fix to ACCUMULO-1604: ColumnAgeOffFilter was throwing an error when using negate
    +   */
    +  @Test
    +  public void test2aNegate() throws IOException {
    +    Text colf = new Text(""a"");
    +    Text colq = new Text(""b"");
    +    Value dv = new Value();
    +    TreeMap<Key,Value> tm = new TreeMap<Key,Value>();
    +    IteratorSetting is = new IteratorSetting(1, ColumnAgeOffFilter.class);
    +    ColumnAgeOffFilter.addTTL(is, new IteratorSetting.Column(""a""), 901l);
    +    ColumnAgeOffFilter.setNegate(is, true);
    +    long ts = System.currentTimeMillis();
    +
    +    for (long i = 0; i < 1000; i++) {
    +      Key k = new Key(new Text(String.format(""%03d"", i)), colf, colq, ts - i);
    +      tm.put(k, dv);
    +    }
    +    assertTrue(tm.size() == 1000);
    --- End diff --
    
    If you'd like, I'd certainly welcome the fix :)
;11/Jul/16 13:48;githubbot;600","Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r70260012
  
    --- Diff: core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java ---
    @@ -208,9 +208,9 @@ public void test2() throws IOException {
         a = a.deepCopy(null);
         SortedKeyValueIterator<Key,Value> copy = a.deepCopy(null);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 900);
    +    assertEquals(900, size(a));
    --- End diff --
    
    Thanks, much appreciated!
;11/Jul/16 13:48;githubbot;600","Github user keith-turner commented on the issue:

    https://github.com/apache/accumulo/pull/122
  
    @milleruntime are you finished with this and ready for it be merged?
;11/Jul/16 16:03;githubbot;600","Github user milleruntime commented on the issue:

    https://github.com/apache/accumulo/pull/122
  
    @keith-turner Yes ACCUMULO-1604 is good to go
;11/Jul/16 16:16;githubbot;600","Github user milleruntime commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/122#discussion_r70811144
  
    --- Diff: core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java ---
    @@ -234,20 +234,101 @@ public void test2a() throws IOException {
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 902);
    +    assertEquals(902, size(a));
     
         ColumnAgeOffFilter.addTTL(is, new IteratorSetting.Column(""a"", ""b""), 101l);
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 102);
    +    assertEquals(102, size(a));
     
         ColumnAgeOffFilter.removeTTL(is, new IteratorSetting.Column(""a"", ""b""));
         a.init(new SortedMapIterator(tm), is.getOptions(), new DefaultIteratorEnvironment());
         a = (ColumnAgeOffFilter) a.deepCopy(null);
         a.overrideCurrentTime(ts);
         a.seek(new Range(), EMPTY_COL_FAMS, false);
    -    assertEquals(size(a), 902);
    +    assertEquals(902, size(a));
    +  }
    +
    +  /**
    +   * Test for fix to ACCUMULO-1604: ColumnAgeOffFilter was throwing an error when using negate
    +   */
    +  @Test
    +  public void test2aNegate() throws IOException {
    +    Text colf = new Text(""a"");
    +    Text colq = new Text(""b"");
    +    Value dv = new Value();
    +    TreeMap<Key,Value> tm = new TreeMap<Key,Value>();
    +    IteratorSetting is = new IteratorSetting(1, ColumnAgeOffFilter.class);
    +    ColumnAgeOffFilter.addTTL(is, new IteratorSetting.Column(""a""), 901l);
    +    ColumnAgeOffFilter.setNegate(is, true);
    +    long ts = System.currentTimeMillis();
    +
    +    for (long i = 0; i < 1000; i++) {
    +      Key k = new Key(new Text(String.format(""%03d"", i)), colf, colq, ts - i);
    +      tm.put(k, dv);
    +    }
    +    assertTrue(tm.size() == 1000);
    --- End diff --
    
    Created an improvement ticket in JIRA for this [here](https://issues.apache.org/jira/browse/ACCUMULO-4367)
;14/Jul/16 14:09;githubbot;600","Github user joshelser commented on the issue:

    https://github.com/apache/accumulo/pull/122
  
    Will merge shortly.
;17/Jul/16 13:50;githubbot;600","Commit a8f804e9e8d0bfe1ff93065e4714483a262440de in accumulo's branch refs/heads/1.8 from [~milleruntime]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a8f804e ]

ACCUMULO-1604: added check for negate option in ColumnAgeOffFilter and new test in FilterTest

Closes apache/accumulo#122

Signed-off-by: Josh Elser <elserj@apache.org>
;17/Jul/16 15:14;jira-bot;600","Commit a8f804e9e8d0bfe1ff93065e4714483a262440de in accumulo's branch refs/heads/master from [~milleruntime]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a8f804e ]

ACCUMULO-1604: added check for negate option in ColumnAgeOffFilter and new test in FilterTest

Closes apache/accumulo#122

Signed-off-by: Josh Elser <elserj@apache.org>
;17/Jul/16 15:14;jira-bot;600","Github user asfgit closed the pull request at:

    https://github.com/apache/accumulo/pull/122
;17/Jul/16 15:14;githubbot;600",,0,13200,,,0,13200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-01 15:31:51.287,,,no_permission,,,,,,,,,,,,339643,,,Mon Jul 18 13:49:16 UTC 2016,,,,,,0|i1mkx3:,339963,,,,,,,,23/Jul/13 22:14;ctubbsii;May want to check that other filters are susceptible to the same bug.,"01/Sep/13 15:31;yuzhihong@gmail.com;From trunk:
{code}
  public boolean validateOptions(Map<String,String> options) {
    if (super.validateOptions(options) == false)
      return false;
    try {
      this.ttls = new TTLSet(options);
    } catch (Exception e) {
      throw new IllegalArgumentException(""bad TTL options"", e);
    }
    return true;
{code}
Options for parent would be validated by super class.

Can you highlight the bug ?

Thanks","01/Sep/13 15:48;billie.rinaldi;[~ctubbsii], were you looking at 1.4?  In 1.4, some iterators called super.validateOptions but didn't check whether it returned false.  I attempted to fix that in ACCUMULO-846.","05/Sep/13 19:00;ctubbsii;The bug is in the assignment:
{code:java}
  this.ttls = new TTLSet(options);
{code}

It is not possible to distinguish whether the ""negate"" option was intended as configuration for the parent, or as a column name for the current iterator, because it assumes that options are for itself rather than the parent... even after negate is validated by the parent. The options for the columns should have been prefixed with a configuration name that distinguishes it from other options.","05/Sep/13 19:38;billie.rinaldi;Good point.  I guess this is an issue whenever the option names aren't fixed.  If the iterator doesn't use fixed option names, and has a superclass or the possibility of a subclass that has any options, it needs to use a prefix so that it doesn't pick up options that aren't its own.  I believe the ColumnAgeOffFilter is the only iterator that currently has this issue.",05/Sep/13 20:01;ctubbsii;A reasonable prefix to use could be the name of the class that defines the option. That's what I've tried to do with all the mapred configuration.,"05/Sep/13 20:08;billie.rinaldi;It's going to be ugly, though.  I might be inclined towards something descriptive in this case, since unfixed names is not a common configuration pattern.","05/Sep/13 21:01;ctubbsii;If we're just looking for a quick fix for this particular iterator, then we can just use a simple ""column:"" prefix (descriptive), but whatever change is made, it's not going to be compatible with pre-existing persistent configuration of this iterator.","05/Sep/13 21:06;billie.rinaldi;True.  A non-breaking alternative would be to ignore the ""negate"" option manually in this iterator, and document heavily that it is a poor solution.","05/Sep/13 22:01;kturner;bq. use a simple ""column:"" prefix (descriptive), but whatever change is made, it's not going to be compatible with pre-existing persistent configuration

Could look for the ""column:"" prefix and if present only use keys with that prefix.  If the prefix is not present in any key, then assume its the old style config.",06/Sep/13 15:30;billie.rinaldi;Good idea.,"15/Jul/16 23:25;ctubbsii;Bumping this back to 1.8.0, just because the patch is ready and just needs to be merged.","17/Jul/16 15:16;elserj;Pushed to branches 1.8 and master. Great that we finally get this one fixed :)

Thanks for the contribution, [~milleruntime]! Let me know if you'd like to be added to our [contributor's page|http://accumulo.apache.org/people.html] in recognition of your efforts (if yes, you can optionally provide an organization you're affiliated with and a timezone).","18/Jul/16 13:41;milleruntime;Yeah that would be cool, thanks. I am ET and my company is Centroid, LLC http://www.centroid-llc.com/",18/Jul/16 13:49;elserj;Done!,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to handle case where tablet has lots of delete entries,ACCUMULO-96,12529298,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,28/Oct/11 19:11,24/Mar/17 00:05,13/Mar/19 22:01,20/Mar/17 15:07,,,,,,,,2.0.0,,,tserver,,,,,,0,,,,,"Currently Accumulo only drops delete entries when its major compacting all files.  All files may never be compacted.  Lots of delete entries building up can be problematic for scan performance.

Possible solutions :
 * Keep a count of the # of delete entries per file.  Compact all when the ratio of delete entries to entries crosses a threshold.
 * When a scan encounters a tablet w/ a lot of delete entries, schedule a majc.  This is reactive, but removes the need for bookkeeping in the previous solution. ",,"Commit 94cdcc4d3f0a8ccf95894f206cb71e6117f4e51d in accumulo's branch refs/heads/master from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=94cdcc4 ]

ACCUMULO-4501 ACCUMULO-96 Added Summarization

closes apache/accumulo#224
closes apache/accumulo#168
;20/Mar/17 14:49;jira-bot;600",,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-12-17 03:45:22.434,,,no_permission,,,,,,,,,,,,215158,,,Fri Mar 24 00:05:37 UTC 2017,,,,,,0|i07p8v:,42856,,,,,,,,"28/Oct/11 19:15;kturner;A work around when the user has inserted a lot of deletes, is to force a compaction on the range of the table where the deletes were inserted.","17/Dec/14 03:45;medined;If this issue is superceded, it should be resolved?",17/Dec/14 19:00;ctubbsii;I think the case still has merit. I don't know if anybody's interested in working on it.,"24/Mar/17 00:05;ctubbsii;[~kturner], you marked this issue as resolved, with your change in ACCUMULO-4501. Can you add more explanation here how that commit addresses this issue? I assume you've added the ability to keep track of the number of deletes for a tablet, but did you do anything else to facilitate this issue?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PermGen leak,ACCUMULO-1379,12646002,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,mgiordano,mgiordano,03/May/13 16:10,10/Jun/16 20:31,13/Mar/19 22:01,02/Oct/13 18:57,1.4.3,1.5.0,,,,,,1.6.0,,,client,,,,,,1,,,,,"Under version 1.3.7 we are using the following code to initialize a cloudbase connection during initialization of our web app:

                        ZooKeeperInstance instance = new ZooKeeperInstance(instanceName, zooKeepers);
                        connector = instance.getConnector(userId, password.getBytes());

The problem is that under the hood, this call creates several threads that are not cleaned up when the app is undeployed in JBoss. This is occurring without performing any scans or interacting with cloudbase in any other way. After relatively few redeploys of the app, the PermGen Space is OOM.

I can't find any reference in the cloudbase API akin to a close() method for the Connector object. This is a classloader leak effecting any webapp that is accessing cloudbase directly. The result of this leak is not simply orphaned threads, but thousands of classes not gc'd because the classloader itself can't be gc'd. This is what is filling up PermGen.
",Linux/JBoss,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1858,,,ACCUMULO-2027,,,,,,,,,,,09/Sep/13 21:52;vines;ACCUMULO-1379.patch;https://issues.apache.org/jira/secure/attachment/12602214/ACCUMULO-1379.patch,10/Sep/13 20:58;vines;ACCUMULO-1379_v2.patch;https://issues.apache.org/jira/secure/attachment/12602418/ACCUMULO-1379_v2.patch,11/Sep/13 18:32;vines;ACCUMULO-1379_v3.patch;https://issues.apache.org/jira/secure/attachment/12602621/ACCUMULO-1379_v3.patch,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2013-05-03 22:01:35.326,,,no_permission,,,,,,,,,,,,326361,,,Fri Jun 10 20:31:33 UTC 2016,,,,,,0|i1kay7:,326706,,,,,,,,03/May/13 22:01;kturner;There was discussion of this issue on the mailing list : http://markmail.org/message/odbadc5vo4n2fefk,"06/Jun/13 16:45;vines;Related issue, that I think falls in the same problem space - included in the ZooKeeper instance are several threads, most of which are daemons. The one exception is the Zookeeper 'main-SendThread'. Providing a mechanism to close an instance I think would resolve both this issue as well as this issue.","02/Jul/13 21:29;vines;I'm going to be handling this in the curator branch, because this also makes things a lot more pleasant in testing due to staticness of things.",07/Sep/13 01:10;elserj;[~jvines@gmail.com] since you decided against the Curator work you had been doing.. are you still going to be adding a close to Instance to clean up the ZK internals?,07/Sep/13 01:36;vines;Oh yeah... that. I can do that.,"07/Sep/13 02:16;elserj;Either way, doesn't matter :) Just wanted to follow up.","09/Sep/13 21:52;vines;This is a first pass at dealing with this. I have no tomcat environment so I can't easily test how it behaves when redeploying, but this should clean up the instance and zooKeeper cruft. However, the other ticket seems to indicate something must be done about the thrift pool too.","10/Sep/13 20:58;vines;Attaching a revised patch which deals with thrift. The plumbing for thrift feels a bit weird since a lot of our thrift accesses (including that which creates the Daemon) is in static methods, but I did work it through ThriftUtils so it seems a bit consistent. Going to let this sit for a day or 3 before I commit to see if there are better ideas.

And yes, I did test it and after jstacking some code which did a METADATA scan, I had no standing Accumulo threads active. So I deem it a success.",10/Sep/13 21:38;kturner;close() on instance as implemented in patch v2 introduces confusing behavior.  It closes resources that may be used by other instance objects.   ,10/Sep/13 21:44;vines;Are we sure this thrift daemon behavior doesn't cause issues with multiple simultaneous instances? But we could just change the check from a flag to a counting semaphore to achieve the desired behavior in light of this.,10/Sep/13 22:07;kturner;In ACCUMULO-1697 [~jstoneham] made a comment about zookeepers being shared across ZookeeperInstance objects.  This also applies to the Thrift connection pool.,"10/Sep/13 22:17;vines;Yep, I see that code for ZooKeepers as well. Options are counting semaphores or reducing the staticness of things...","10/Sep/13 22:45;kturner;Reference counting would be the simplest code change.   When all instances are closed, then the background threads can be stopped.   However this should not preclude instances from being created in the future.

If ref counting is done, calling the instance close() method ZKI.finalize() could be tricky. One hypothetical problem is the following situation.

 # create ZookeeperInstance (ZKI)
 # create Connector from ZKI and drops ref to ZKI
 # create Scanner from Connector and drop ref to Connector

Currently this type of code works w/ no problem.  If Scanner does not reference ZKI, then ZKI will be garbage collected and possibly close resources the scanner needs.  I think the scanner does ref the instance, so it would be ok in this case, was using it as an example.




","11/Sep/13 03:32;vines;I had no intention of implementing a finalize(). I think if users want to close it properly, then they need to retain the object and close it themselves. I think that's a reasonable requirement.

Although, if we really wanted to, we could just keep refs to Instance propagated throughout the entire client object set, but that seems ugly.","11/Sep/13 14:01;kturner;bq. I had no intention of implementing a finalize().

Thats probably best.  Might even be worthwhile to add an emtpy finalize with a comment say it was intentionally left blank and why.  I know a year from now if someone came along and asked why ZKI finalize() does not call close() I would not have a clue.

Do you think close should be on Connector as opposed to Instance?",11/Sep/13 14:04;jstoneham;I'm partial to finalize()s that complain at you with a warning that you didn't release the resource properly.,"11/Sep/13 14:13;kturner;bq. I'm partial to finalize()s that complain at you with a warning that you didn't release the resource properly.

I like that.  It does not break existing code, but encourages users to call the new close() method.","11/Sep/13 14:32;vines;I say no on Connector.close because Connector doesn't have references to the ZooCache needed to make the code path make sense. We document things very strongly that for each instance you connect to, you only want one Instance object. This makes the counting straight forward.","11/Sep/13 18:32;vines;Version 3 of the patch. Added the finalize() method that just explains why it tries nothing and throws a warning if the ZKI wasn't closed.

I put the counting semaphore in the ZKI because the code that gets ZooKeepers and ThriftThreadPools is static and singleton-ish, so there's really no place to put in a counting semaphore directly in there without replumbing a lot of the client code. This is a larger issue of how we want to utilize thrift/ZK with statics that is outside the scope of this ticket.

I did test this by creating two seperate ZKIs in a test, scan with them, close one, wait, and then close the other and it did work. So I think this satisfies what we're gunning for, albeit in a someone clunky way.","02/Oct/13 18:57;jira-bot;Commit 7da1164d87227960d3e0cfc841f753067e2c0304 in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7da1164 ]

ACCUMULO-1379 - Adding close() to Instance to assist in freeing up resources
","25/Oct/13 19:26;jira-bot;Commit 3f6c66ede52cb1fb5a122d7bad06d7978ff0a671 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3f6c66e ]

ACCUMULO-1379 Fix edge cases if error in closing ZooKeeperInstance
","18/Nov/13 18:18;jira-bot;Commit 79d686faa1e477b9cbd80c6f833ece402050b490 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=79d686f ]

ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.

Fix cherry picks two commits:

ACCUMULO-1379 - Adding close() to Instance to assist in freeing up resources

(cherry picked from commit 7da1164d87227960d3e0cfc841f753067e2c0304)

Reason: bugfix
Author: John Vines <jvines@gmail.com>

Differs from original by path changes and leaving out ConditionalWriterTest, which is only in 1.6.0+

----

ACCUMULO-1379 Fix edge cases if error in closing ZooKeeperInstance

(cherry picked from commit 3f6c66ede52cb1fb5a122d7bad06d7978ff0a671)

Reason: bugfix
Author: Christopher Tubbs <ctubbsii@apache.org>

Signed-off-by: Bill Slacum <ujustgotbilld@apache.org>
","18/Nov/13 18:19;jira-bot;Commit 79d686faa1e477b9cbd80c6f833ece402050b490 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=79d686f ]

ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.

Fix cherry picks two commits:

ACCUMULO-1379 - Adding close() to Instance to assist in freeing up resources

(cherry picked from commit 7da1164d87227960d3e0cfc841f753067e2c0304)

Reason: bugfix
Author: John Vines <jvines@gmail.com>

Differs from original by path changes and leaving out ConditionalWriterTest, which is only in 1.6.0+

----

ACCUMULO-1379 Fix edge cases if error in closing ZooKeeperInstance

(cherry picked from commit 3f6c66ede52cb1fb5a122d7bad06d7978ff0a671)

Reason: bugfix
Author: Christopher Tubbs <ctubbsii@apache.org>

Signed-off-by: Bill Slacum <ujustgotbilld@apache.org>
","18/Nov/13 19:39;jira-bot;Commit 79d686faa1e477b9cbd80c6f833ece402050b490 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=79d686f ]

ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.

Fix cherry picks two commits:

ACCUMULO-1379 - Adding close() to Instance to assist in freeing up resources

(cherry picked from commit 7da1164d87227960d3e0cfc841f753067e2c0304)

Reason: bugfix
Author: John Vines <jvines@gmail.com>

Differs from original by path changes and leaving out ConditionalWriterTest, which is only in 1.6.0+

----

ACCUMULO-1379 Fix edge cases if error in closing ZooKeeperInstance

(cherry picked from commit 3f6c66ede52cb1fb5a122d7bad06d7978ff0a671)

Reason: bugfix
Author: Christopher Tubbs <ctubbsii@apache.org>

Signed-off-by: Bill Slacum <ujustgotbilld@apache.org>
","18/Nov/13 19:39;jira-bot;Commit 79d686faa1e477b9cbd80c6f833ece402050b490 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=79d686f ]

ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.

Fix cherry picks two commits:

ACCUMULO-1379 - Adding close() to Instance to assist in freeing up resources

(cherry picked from commit 7da1164d87227960d3e0cfc841f753067e2c0304)

Reason: bugfix
Author: John Vines <jvines@gmail.com>

Differs from original by path changes and leaving out ConditionalWriterTest, which is only in 1.6.0+

----

ACCUMULO-1379 Fix edge cases if error in closing ZooKeeperInstance

(cherry picked from commit 3f6c66ede52cb1fb5a122d7bad06d7978ff0a671)

Reason: bugfix
Author: Christopher Tubbs <ctubbsii@apache.org>

Signed-off-by: Bill Slacum <ujustgotbilld@apache.org>
","10/Jun/16 20:29;reggert1980;This issue is marked as Fixed, but I can find no evidence of it in the Git master branch or 1.6.0 tag, nor does the ""close"" method appear in the published Javadocs. What gives?","10/Jun/16 20:31;elserj;Because the fix didn't include an addition of a close() method.

Take a look at the commits that are listed right above your comment as to what actually changed.",,,,,,,,,,,,,,,,,,,,,,,,,,,
Combiners can cause deleted data to come back,ACCUMULO-2232,12690066,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,vines,vines,21/Jan/14 17:21,03/Jun/16 18:10,13/Mar/19 22:01,03/Oct/15 22:20,,,,,,,,1.6.5,1.7.1,1.8.0,client,tserver,,,,,0,,,,,"The case-
3 files with-
* 1 with a key, k, with timestamp 0, value 3
* 1 with a delete of k with timestamp 1
* 1 with k with timestamp 2, value 2

The column of k has a summing combiner set on it. The issue here is that depending on how the major compactions play out, differing values with result. If all 3 files compact, the correct value of 2 will result. However, if 1 & 3 compact first, they will aggregate to 5. And then the delete will fall after the combined value, resulting in the result 5 to persist.

First and foremost, this should be documented. I think to remedy this, combiners should only be used on full MajC, not not full ones. This may necessitate a special flag or a new combiner that implemented the proper semantics.",,"Commit 7a1d6d921ba81c7f92eab8d3b20aae461a46066a in accumulo's branch refs/heads/1.6 from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7a1d6d9 ]

ACCUMULO-2232 Added options to Combiner for handling deletes
;02/Oct/15 16:03;jira-bot;600","Commit 7a1d6d921ba81c7f92eab8d3b20aae461a46066a in accumulo's branch refs/heads/1.7 from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7a1d6d9 ]

ACCUMULO-2232 Added options to Combiner for handling deletes
;02/Oct/15 16:04;jira-bot;600","Commit 7a1d6d921ba81c7f92eab8d3b20aae461a46066a in accumulo's branch refs/heads/master from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7a1d6d9 ]

ACCUMULO-2232 Added options to Combiner for handling deletes
;02/Oct/15 17:16;jira-bot;600","Commit f3203854451c41b06210a9a9fc3ce492f9feb58c in accumulo's branch refs/heads/1.6 from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f320385 ]

ACCUMULO-2232 fix since version
;02/Oct/15 20:12;jira-bot;600","Commit f3203854451c41b06210a9a9fc3ce492f9feb58c in accumulo's branch refs/heads/1.7 from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f320385 ]

ACCUMULO-2232 fix since version
;02/Oct/15 20:12;jira-bot;600","Commit f3203854451c41b06210a9a9fc3ce492f9feb58c in accumulo's branch refs/heads/master from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f320385 ]

ACCUMULO-2232 fix since version
;02/Oct/15 20:13;jira-bot;600","Commit 445f3fe1dc0fb61ec3ac67ed9793f755293eb4f4 in accumulo's branch refs/heads/master from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=445f3fe ]

ACCUMULO-2232 Fix test
;02/Oct/15 20:13;jira-bot;600","Commit 1ab3827bec21ab61c4bec5e6029e596e8ff5b2e5 in accumulo's branch refs/heads/1.6 from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1ab3827 ]

ACCUMULO-2232 Deal with extra Combiner option in ShellServerIT
;18/Oct/15 22:00;jira-bot;600","Commit 1ab3827bec21ab61c4bec5e6029e596e8ff5b2e5 in accumulo's branch refs/heads/1.7 from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1ab3827 ]

ACCUMULO-2232 Deal with extra Combiner option in ShellServerIT
;18/Oct/15 22:00;jira-bot;600","Commit 1ab3827bec21ab61c4bec5e6029e596e8ff5b2e5 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1ab3827 ]

ACCUMULO-2232 Deal with extra Combiner option in ShellServerIT
;18/Oct/15 22:00;jira-bot;600",,,,,,,,,,,,,,0,6000,,,0,6000,,,,,,,,ACCUMULO-1266,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-21 17:32:49.9,,,no_permission,,,,,,,,,,,,369023,,,Sat Oct 03 22:20:14 UTC 2015,,,,,,0|i1rlrz:,369328,,,,,,,,"21/Jan/14 17:32;elserj;I've seen this one happen before, and it can be rather surprising.

Definitely on the documentation. Interesting idea about usage on full MajC.","22/Jan/14 19:16;kturner;bq.  I think to remedy this, combiners should only be used on full MajC, not not full ones.

+1

bq.  This may necessitate a special flag or a new combiner that implemented the proper semantics.

Why not just modify current combiner to only run on full majc?

If there is a special flag that allows running the combiner for partial compactions, it could fail if it detects a delete.  However there are other ways to delete and this sanity check would not cover the case of row deletion, row filtering, etc.   

Seems like this should be fixed in 1.4, 1.5, and 1.6.","22/Jan/14 19:51;busbey;bq. If there is a special flag that allows running the combiner for partial compactions, it could fail if it detects a delete. However there are other ways to delete and this sanity check would not cover the case of row deletion, row filtering, etc.

I say a flag to allow running on partial compactions is reasonable, provided it comes with a strong warning about not seeing all rows (calling out this specific issue).

In that case, I think it should be up to the combiner to handle logic around deletes. I can think of combiner applications where it would make sense not to fail when there's a delete.

bq. Seems like this should be fixed in 1.4, 1.5, and 1.6.

+1, seems like an oversight that combiners didn't default to full majc","22/Jan/14 20:44;elserj;I'm a little worried about implications (sorry for using that phrase) that only running combiners on full MajC would have on performance since, for heavy combination, you're going to be persisting and later re-reading many records instead of just once for a potentially very long time (if you assume that full MajCs are few and far between).

I can't come up with another easy way to fix it though for the SummingCombiner example, so accuracy is still better than being slow. Anything else I can think of would involve persisting deletes across non-full compactions which would require quite a bit more work to get correct, I imagine.","23/Jan/14 02:06;afuchs;I agree with Josh (and everyone else) on both counts: the performance
implications will be huge and this is enough rope for people to hang
themselves with.  However, I think a lot of people use combiners on tables
that are append-only and never delete (at least not a record at a time).
The *warning unsafe doom will ensue* bypass is pretty important to support
those uses, but I also think it is best to default to accuracy while we
implement a better fix.

It seems like the right way to fix this in the long run is to keep track of
timestamp ranges of files and calculate two properties on the set of files
being compacted:
1. Is the time range contiguous, or are there other files not being
compacted that overlap the range?
2. Are there any files with an older timestamp?
This way we can run combiners on any compactions that satisfy property #1,
and preserve the most recent deletes in any compaction that satisfies
property #2. This generally makes minor compactions safe for running
combiners (assuming Accumulo sets the timestamps and there is no bulk
loading), although the most recent delete needs to be preserved. If I were
to speculate about general major compactions, I would say that when splits
are rare most other compactions also have property #1.

I think we could expose these properties in the iterator environment. We
could even come up with a compaction strategy that biases compactions
towards contiguous time ranges if we were ambitious.



",23/Jan/14 18:02;kturner;Another possible way to handle efficiency concerns is to have Accumulo initiate a major compaction if scans are repeatedly combining a lot of data.   This serves as a use case for ACCUMULO-1266.   ,"23/Jan/14 21:45;ctubbsii;This issue would probably go away entirely, if we separated the Combiner from the scope it's supposed to run at, and made the ""full major compaction"" scope a top-level iterator scope, along with ""partial major compaction"". Obviously, this is not a simple transition..., but I think it's an (eventual) worthwhile one.","01/Sep/15 16:56;kturner;bq. the performance implications will be huge and this is enough rope for people to hang themselves with. However, I think a lot of people use combiners on tables that are append-only and never delete

Thinking about this case where people want to use combiners and do not delete, there is the exception option to consider.
Make combiners throw an exception if a delete marker is seen during a partial major compaction.  However this only makes a user aware of the problem, it does not prevent the problem.  The reason this approach does not prevent the problems is that by the time a delete marker is seen, data that was supposed to have been deleted could have already been combined by a previous partial compaction that did not see any delete markers.","01/Sep/15 17:31;kturner; I was trying to think of something that could be done for 1.6.4 to improve this situation.  One thing I thought of is doing the following as a subtask.
 * Log an error if combiner sees a delete marker (and option suggested below is not configured).  Would use some static state to ensure error msg is not logged to often.
 * Add a combiner option to only run a full major compaction  (gives users a possible work around for 1.6.4)

If I hear no objections I'll do this in a few days for 1.6.4",01/Sep/15 17:40;elserj;+1 makes sense,"22/Sep/15 00:39;githubbot;GitHub user keith-turner opened a pull request:

    https://github.com/apache/accumulo/pull/47

    ACCUMULO-2232 Added options to Combiner for handling deletes

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/keith-turner/accumulo ACCUMULO-2232

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/accumulo/pull/47.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #47
    
----
commit 0ca928603078ed1698186515325b20eb98b4515a
Author: Keith Turner <kturner@apache.org>
Date:   2015-09-21T19:23:18Z

    ACCUMULO-2232 Added options to Combiner for handling deletes

----
","22/Sep/15 04:33;githubbot;Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40052439
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -149,6 +159,37 @@ public void next() throws IOException {
     
       private Key workKey = new Key();
     
    +  private static Cache<String,Long> loggedMsgCache = CacheBuilder.newBuilder().expireAfterWrite(1, TimeUnit.HOURS).build();
    --- End diff --
    
    +final
","22/Sep/15 04:35;githubbot;Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40052506
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -227,10 +271,25 @@ public void init(SortedKeyValueIterator<Key,Value> source, Map<String,String> op
           throw new IllegalArgumentException(""The "" + COLUMNS_OPTION + "" must not be empty"");
     
         combiners = new ColumnSet(Lists.newArrayList(Splitter.on("","").split(encodedColumns)));
    +
    +    isPartialCompaction = ((env.getIteratorScope() == IteratorScope.majc) && !env.isFullMajorCompaction());
    +    if (options.containsKey(DELETE_HANDLING_ACTION_OPTION)) {
    +      deleteHandlingAction = DeleteHandlingAction.valueOf(options.get(DELETE_HANDLING_ACTION_OPTION));
    --- End diff --
    
    A warning message with the actual property being checked (DELETE_HANDLING_ACTION_OPTION) and the value that we have no enum-value for would be useful.
","22/Sep/15 04:35;githubbot;Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40052512
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -240,15 +299,18 @@ public void init(SortedKeyValueIterator<Key,Value> source, Map<String,String> op
         newInstance.setSource(getSource().deepCopy(env));
         newInstance.combiners = combiners;
         newInstance.combineAllColumns = combineAllColumns;
    +    newInstance.isPartialCompaction = isPartialCompaction;
    +    newInstance.deleteHandlingAction = deleteHandlingAction;
         return newInstance;
       }
     
       @Override
       public IteratorOptions describeOptions() {
         IteratorOptions io = new IteratorOptions(""comb"", ""Combiners apply reduce functions to multiple versions of values with otherwise equal keys"", null, null);
    -    io.addNamedOption(ALL_OPTION, ""set to true to apply Combiner to every column, otherwise leave blank. if true, "" + COLUMNS_OPTION
    -        + "" option will be ignored."");
    +    io.addNamedOption(ALL_OPTION,
    --- End diff --
    
    Nit: unrelated formatting.
","22/Sep/15 04:36;githubbot;Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40052520
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -240,15 +299,18 @@ public void init(SortedKeyValueIterator<Key,Value> source, Map<String,String> op
         newInstance.setSource(getSource().deepCopy(env));
         newInstance.combiners = combiners;
         newInstance.combineAllColumns = combineAllColumns;
    +    newInstance.isPartialCompaction = isPartialCompaction;
    +    newInstance.deleteHandlingAction = deleteHandlingAction;
         return newInstance;
       }
     
       @Override
       public IteratorOptions describeOptions() {
         IteratorOptions io = new IteratorOptions(""comb"", ""Combiners apply reduce functions to multiple versions of values with otherwise equal keys"", null, null);
    -    io.addNamedOption(ALL_OPTION, ""set to true to apply Combiner to every column, otherwise leave blank. if true, "" + COLUMNS_OPTION
    -        + "" option will be ignored."");
    +    io.addNamedOption(ALL_OPTION,
    +        ""set to true to apply Combiner to every column, otherwise leave blank. if true, "" + COLUMNS_OPTION + "" option will be ignored."");
         io.addNamedOption(COLUMNS_OPTION, ""<col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non-alphanum chars using %<hex>."");
    +    // TODO
    --- End diff --
    
    Did you forget todo something?
","22/Sep/15 04:36;githubbot;Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40052524
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -275,6 +337,10 @@ public boolean validateOptions(Map<String,String> options) {
             throw new IllegalArgumentException(""invalid column encoding "" + encodedColumns);
         }
     
    +    if (options.containsKey(DELETE_HANDLING_ACTION_OPTION)) {
    +      DeleteHandlingAction.valueOf(options.get(DELETE_HANDLING_ACTION_OPTION));
    --- End diff --
    
    Same suggestion about a meaningful error message here.
","22/Sep/15 04:36;githubbot;Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40052540
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -313,4 +378,46 @@ public static void setColumns(IteratorSetting is, List<IteratorSetting.Column> c
       public static void setCombineAllColumns(IteratorSetting is, boolean combineAllColumns) {
         is.addOption(ALL_OPTION, Boolean.toString(combineAllColumns));
       }
    +
    +  public static enum DeleteHandlingAction {
    +    /**
    +     * Do nothing when a a delete is observed by a combiner during a partial major compaction.
    +     */
    +    IGNORE,
    +
    +    /**
    +     * Log an error when a a delete is observed by a combiner during a partial major compaction. An error is not logged for each delete entry seen. Once a
    +     * combiner has seen a delete during a partial compaction and logged an error, it will not do so again for at least an hour.
    +     */
    +    LOG_ERROR,
    +
    +    /**
    +     * Throw an exception when a a delete is observed by a combiner during a partial major compaction.
    +     */
    +    THROW_EXCEPTION,
    +
    +    /**
    +     * Pass all data through during partial major compactions, no reducing is done. With this option reducing is only done during scan and full major
    +     * compactions, when deletes can be correctly handled.
    +     */
    +    REDUCE_ON_FULL_COMPACTION_ONLY
    +  }
    +
    +  /**
    +   * Combiners may not work correctly with deletes. Sometimes when Accumulo compacts the files in a tablet, it only compacts a subset of the files. If a delete
    --- End diff --
    
    Great writeup.
","22/Sep/15 04:38;githubbot;Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40052565
  
    --- Diff: core/src/test/java/org/apache/accumulo/core/iterators/user/CombinerTest.java ---
    @@ -786,4 +816,107 @@ public void testAdds() {
         assertEquals(LongCombiner.safeAdd(Long.MAX_VALUE - 5, 5), Long.MAX_VALUE);
       }
     
    +  private TreeMap<Key,Value> readAll(SortedKeyValueIterator<Key,Value> combiner) throws Exception {
    +    TreeMap<Key,Value> ret = new TreeMap<Key,Value>();
    +
    +    combiner.seek(new Range(), EMPTY_COL_FAMS, false);
    +
    +    while (combiner.hasTop()) {
    +      ret.put(new Key(combiner.getTopKey()), new Value(combiner.getTopValue()));
    +      combiner.next();
    +    }
    +
    +    return ret;
    +  }
    +
    +  private void runDeleteHandlingTest(TreeMap<Key,Value> input, TreeMap<Key,Value> expected, DeleteHandlingAction dha, IteratorEnvironment env)
    +      throws Exception {
    +    runDeleteHandlingTest(input, expected, dha, env, null);
    +  }
    +
    +  private void runDeleteHandlingTest(TreeMap<Key,Value> input, TreeMap<Key,Value> expected, DeleteHandlingAction dha, IteratorEnvironment env,
    +      String expectedLog) throws Exception {
    +    boolean deepCopy = expected == null;
    +
    +    StringWriter writer = new StringWriter();
    +    WriterAppender appender = new WriterAppender(new PatternLayout(""%p, %m%n""), writer);
    +    Logger logger = Logger.getLogger(Combiner.class);
    +    boolean additivity = logger.getAdditivity();
    +    try {
    +      logger.addAppender(appender);
    +      logger.setAdditivity(false);
    +
    +      Combiner ai = new SummingCombiner();
    +
    +      IteratorSetting is = new IteratorSetting(1, SummingCombiner.class);
    +      SummingCombiner.setEncodingType(is, LongCombiner.StringEncoder.class);
    +      Combiner.setColumns(is, Collections.singletonList(new IteratorSetting.Column(""cf001"")));
    +      if (dha != null) {
    +        Combiner.setDeleteHandlingAction(is, dha);
    +      }
    +
    +      ai.init(new SortedMapIterator(input), is.getOptions(), env);
    +
    +      if (deepCopy)
    +        assertEquals(expected, readAll(ai.deepCopy(env)));
    +      assertEquals(expected, readAll(ai));
    +
    +    } finally {
    +      logger.removeAppender(appender);
    --- End diff --
    
    Glad to see the try/finally logger reset.
","22/Sep/15 04:39;githubbot;Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40052599
  
    --- Diff: core/src/test/java/org/apache/accumulo/core/iterators/user/CombinerTest.java ---
    @@ -786,4 +816,107 @@ public void testAdds() {
         assertEquals(LongCombiner.safeAdd(Long.MAX_VALUE - 5, 5), Long.MAX_VALUE);
       }
     
    +  private TreeMap<Key,Value> readAll(SortedKeyValueIterator<Key,Value> combiner) throws Exception {
    +    TreeMap<Key,Value> ret = new TreeMap<Key,Value>();
    +
    +    combiner.seek(new Range(), EMPTY_COL_FAMS, false);
    +
    +    while (combiner.hasTop()) {
    +      ret.put(new Key(combiner.getTopKey()), new Value(combiner.getTopValue()));
    +      combiner.next();
    +    }
    +
    +    return ret;
    +  }
    +
    +  private void runDeleteHandlingTest(TreeMap<Key,Value> input, TreeMap<Key,Value> expected, DeleteHandlingAction dha, IteratorEnvironment env)
    +      throws Exception {
    +    runDeleteHandlingTest(input, expected, dha, env, null);
    +  }
    +
    +  private void runDeleteHandlingTest(TreeMap<Key,Value> input, TreeMap<Key,Value> expected, DeleteHandlingAction dha, IteratorEnvironment env,
    +      String expectedLog) throws Exception {
    +    boolean deepCopy = expected == null;
    +
    +    StringWriter writer = new StringWriter();
    +    WriterAppender appender = new WriterAppender(new PatternLayout(""%p, %m%n""), writer);
    +    Logger logger = Logger.getLogger(Combiner.class);
    +    boolean additivity = logger.getAdditivity();
    +    try {
    +      logger.addAppender(appender);
    +      logger.setAdditivity(false);
    +
    +      Combiner ai = new SummingCombiner();
    +
    +      IteratorSetting is = new IteratorSetting(1, SummingCombiner.class);
    +      SummingCombiner.setEncodingType(is, LongCombiner.StringEncoder.class);
    +      Combiner.setColumns(is, Collections.singletonList(new IteratorSetting.Column(""cf001"")));
    +      if (dha != null) {
    +        Combiner.setDeleteHandlingAction(is, dha);
    +      }
    +
    +      ai.init(new SortedMapIterator(input), is.getOptions(), env);
    +
    +      if (deepCopy)
    +        assertEquals(expected, readAll(ai.deepCopy(env)));
    +      assertEquals(expected, readAll(ai));
    +
    +    } finally {
    +      logger.removeAppender(appender);
    +      logger.setAdditivity(additivity);
    +    }
    +
    +    String logMsgs = writer.toString();
    +    if (expectedLog == null) {
    +      Assert.assertTrue(logMsgs, logMsgs.length() == 0);
    +    } else {
    +      logMsgs = logMsgs.replace('\n', ' ');
    +      Assert.assertTrue(logMsgs, logMsgs.matches(expectedLog));
    +    }
    +  }
    +
    +  @Test
    +  public void testDeleteHandling() throws Exception {
    +    Encoder<Long> encoder = LongCombiner.STRING_ENCODER;
    +
    +    TreeMap<Key,Value> input = new TreeMap<Key,Value>();
    +
    +    IteratorEnvironment paritalMajcIe = new CombinerIteratorEnvironment(IteratorScope.majc, false);
    +    IteratorEnvironment fullMajcIe = new CombinerIteratorEnvironment(IteratorScope.majc, true);
    +
    +    // keys that aggregate
    +    nkv(input, 1, 1, 1, 1, false, 4l, encoder);
    +    nkv(input, 1, 1, 1, 2, true, 0l, encoder);
    +    nkv(input, 1, 1, 1, 3, false, 2l, encoder);
    +    nkv(input, 1, 1, 1, 4, false, 9l, encoder);
    +
    +    TreeMap<Key,Value> expected = new TreeMap<Key,Value>();
    +    nkv(expected, 1, 1, 1, 1, false, 4l, encoder);
    +    nkv(expected, 1, 1, 1, 2, true, 0l, encoder);
    +    nkv(expected, 1, 1, 1, 4, false, 11l, encoder);
    +
    +    try {
    +      runDeleteHandlingTest(input, expected, DeleteHandlingAction.THROW_EXCEPTION, paritalMajcIe);
    +      Assert.fail();
    +    } catch (IllegalStateException ise) {
    +      Assert.assertTrue(ise.getMessage().contains(""Saw a delete during a partial compaction""));
    --- End diff --
    
    Try to include a meaningful error message if the assertion fails. We should be able to explain the exact reason the test failed just by looking at surefire output.
","22/Sep/15 04:42;githubbot;Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40052699
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -149,6 +159,37 @@ public void next() throws IOException {
     
       private Key workKey = new Key();
     
    +  private static Cache<String,Long> loggedMsgCache = CacheBuilder.newBuilder().expireAfterWrite(1, TimeUnit.HOURS).build();
    --- End diff --
    
    Would be safer to include a high-watermark on the size of the cache. Maybe 500 elements just to prevent catastrophic failure if we somehow create a bug that causes things to be added to this cache incorrectly.
","22/Sep/15 04:43;githubbot;Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40052742
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -149,6 +159,37 @@ public void next() throws IOException {
     
       private Key workKey = new Key();
     
    +  private static Cache<String,Long> loggedMsgCache = CacheBuilder.newBuilder().expireAfterWrite(1, TimeUnit.HOURS).build();
    +
    +  private void sawDelete() {
    +    if (isPartialCompaction) {
    +      switch (deleteHandlingAction) {
    +        case LOG_ERROR:
    +          try {
    +            loggedMsgCache.get(this.getClass().getName(), new Callable<Long>() {
    +              @Override
    +              public Long call() throws Exception {
    +                log.error(""Combiner of type "" + this.getClass().getSimpleName()
    +                    + "" saw a delete during a partial compaction.  This could cause undesired results.  See ACCUMULO-2232.  Will not log subsequent occurences for at least 1 hour."");
    +                return System.currentTimeMillis();
    --- End diff --
    
    Do we really need the current time? Isn't `0` sufficient since we don't inspect the value of the cache entries? A comment that the value returned by the Callable is meaningless would also be nice.
","22/Sep/15 04:44;githubbot;Github user joshelser commented on the pull request:

    https://github.com/apache/accumulo/pull/47#issuecomment-142180658
  
    As commented on JIRA before, approach looks good. Pointed out what I see as room for some improvements.
","22/Sep/15 15:37;githubbot;Github user keith-turner commented on the pull request:

    https://github.com/apache/accumulo/pull/47#issuecomment-142326951
  
    @joshelser thanks for the feedback, it was very useful.   I think I fixed all the issues you found.
","22/Sep/15 15:38;githubbot;Github user joshelser commented on the pull request:

    https://github.com/apache/accumulo/pull/47#issuecomment-142327147
  
    Great. I'll try to take another peek today, but if you think it's ready, don't feel obligated to wait on me.
","22/Sep/15 16:56;githubbot;Github user ctubbsii commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40111853
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -149,6 +160,38 @@ public void next() throws IOException {
     
       private Key workKey = new Key();
     
    +  private static final Cache<String,Long> loggedMsgCache = CacheBuilder.newBuilder().expireAfterWrite(1, TimeUnit.HOURS).maximumSize(10000).build();
    +
    +  private void sawDelete() {
    +    if (isPartialCompaction) {
    +      switch (deleteHandlingAction) {
    +        case LOG_ERROR:
    +          try {
    +            loggedMsgCache.get(this.getClass().getName(), new Callable<Long>() {
    --- End diff --
    
    At first, I thought ""Callable<Void>"" might be better, but apparently CacheBuilder doesn't like that, so might be better to use ""Callable<Boolean>"", because it's more readable to see ""Boolean.TRUE"" inserted into the cache to denote that a log message has recently occurred. (Unless you were going to use the integer to denote how many times it has been logged before suppressing repeats after some threshold, like 5.)
","22/Sep/15 17:48;githubbot;Github user keith-turner commented on the pull request:

    https://github.com/apache/accumulo/pull/47#issuecomment-142362740
  
    In 31fcf00 I changed the behaviour slightly.
    
    I dropped the option to throw an exception.  I was thinking this option could prevent problems, but it can not.  It can still only detect problems.  For detecting problems I think logging an error is sufficient.
    
    I also changed logging to log on partial and full major compactions.   If a full major compaction sees a delete, then its evidence that a problem could have occurred in the past with a partial compaction.
","22/Sep/15 17:51;githubbot;Github user joshelser commented on the pull request:

    https://github.com/apache/accumulo/pull/47#issuecomment-142363719
  
    :+1:
","22/Sep/15 21:32;githubbot;Github user ctubbsii commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40147270
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -313,4 +392,48 @@ public static void setColumns(IteratorSetting is, List<IteratorSetting.Column> c
       public static void setCombineAllColumns(IteratorSetting is, boolean combineAllColumns) {
         is.addOption(ALL_OPTION, Boolean.toString(combineAllColumns));
       }
    +
    +  /**
    +   * @since 1.6.4 1.7.1 1.8.0
    --- End diff --
    
    Instead of offering the options `IGNORE` and `LOG_ERROR`, we should probably just always log a warning (if `REDUCE_ON_FULL_COMPACTION_ONLY` is not set) and let users disable it in the log4j config, rather than in code.
    
    The `REDUCE_ON_FULL_COMPACTION_ONLY` should be treated as a distinct boolean value which can be set to `true` or `false` as a normal iterator option (similar to `Filter`'s `negate` option), with a default value of `false` to preserve existing behavior.
    
    That would also minimize API changes, especially for 1.6.x and 1.7.x. While this isn't technically public API, it'd still be good to minimize API impact on users using those versions.
","22/Sep/15 21:39;githubbot;Github user ctubbsii commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40147937
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -313,4 +392,48 @@ public static void setColumns(IteratorSetting is, List<IteratorSetting.Column> c
       public static void setCombineAllColumns(IteratorSetting is, boolean combineAllColumns) {
         is.addOption(ALL_OPTION, Boolean.toString(combineAllColumns));
       }
    +
    +  /**
    +   * @since 1.6.4 1.7.1 1.8.0
    +   */
    +  public static enum DeleteHandlingAction {
    +    /**
    +     * Do nothing when a a delete is observed by a combiner during a major compaction.
    +     */
    +    IGNORE,
    +
    +    /**
    +     * Log an error when a a delete is observed by a combiner during a major compaction. An error is not logged for each delete entry seen. Once a
    +     * combiner has seen a delete during a major compaction and logged an error, it will not do so again for at least an hour.
    +     */
    +    LOG_ERROR,
    +
    +    /**
    +     * Pass all data through during partial major compactions, no reducing is done. With this option reducing is only done during scan and full major
    +     * compactions, when deletes can be correctly handled.
    +     */
    +    REDUCE_ON_FULL_COMPACTION_ONLY
    +  }
    +
    +  /**
    +   * Combiners may not work correctly with deletes. Sometimes when Accumulo compacts the files in a tablet, it only compacts a subset of the files. If a delete
    +   * marker exists in one of the files that is not being compacted, then data that should be deleted may be combined. See
    +   * <a href=""https://issues.apache.org/jira/browse/ACCUMULO-2232"">ACCUMULO-2232</a> for more information.
    +   *
    +   * <p>
    +   * This method allows users to configure how they want to handle the combination of delete markers, combiners, and major compactions. The default behavior is
    +   * {@link DeleteHandlingAction#LOG_ERROR}. See the javadoc on each {@link DeleteHandlingAction} enum for a description of each option.
    +   *
    +   * <p>
    +   * For correctness deletes should not be used with columns that are combined OR the {@link DeleteHandlingAction#REDUCE_ON_FULL_COMPACTION_ONLY} option should
    +   * be used. Only reducing on full major compactions may have negative performance implications.
    +   *
    --- End diff --
    
    Another option to give users the ability to ""delete"" without using problematic deletes is to give them the ability to return a `null` value, with the semantics of `null` being ""drop them all"". This, combined with the ability to detect which iterator scope and and major compaction mode is being run, could be used to drop data in a sensible way, suitable to the user's schema, without inserting problematic delete markers.
    
    If we did that, it'd be good to add that here, with the recommendation to avoid using deletes entirely.
","25/Sep/15 15:28;githubbot;Github user keith-turner commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40442099
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -313,4 +392,48 @@ public static void setColumns(IteratorSetting is, List<IteratorSetting.Column> c
       public static void setCombineAllColumns(IteratorSetting is, boolean combineAllColumns) {
         is.addOption(ALL_OPTION, Boolean.toString(combineAllColumns));
       }
    +
    +  /**
    +   * @since 1.6.4 1.7.1 1.8.0
    --- End diff --
    
    I like this approach because it simplified things.  In bbea55d I got rid of the enum and swithced to a boolean.  There is still an addition of a public method to Combiner.
","25/Sep/15 15:35;githubbot;Github user keith-turner commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/47#discussion_r40442327
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java ---
    @@ -313,4 +392,48 @@ public static void setColumns(IteratorSetting is, List<IteratorSetting.Column> c
       public static void setCombineAllColumns(IteratorSetting is, boolean combineAllColumns) {
         is.addOption(ALL_OPTION, Boolean.toString(combineAllColumns));
       }
    +
    +  /**
    +   * @since 1.6.4 1.7.1 1.8.0
    +   */
    +  public static enum DeleteHandlingAction {
    +    /**
    +     * Do nothing when a a delete is observed by a combiner during a major compaction.
    +     */
    +    IGNORE,
    +
    +    /**
    +     * Log an error when a a delete is observed by a combiner during a major compaction. An error is not logged for each delete entry seen. Once a
    +     * combiner has seen a delete during a major compaction and logged an error, it will not do so again for at least an hour.
    +     */
    +    LOG_ERROR,
    +
    +    /**
    +     * Pass all data through during partial major compactions, no reducing is done. With this option reducing is only done during scan and full major
    +     * compactions, when deletes can be correctly handled.
    +     */
    +    REDUCE_ON_FULL_COMPACTION_ONLY
    +  }
    +
    +  /**
    +   * Combiners may not work correctly with deletes. Sometimes when Accumulo compacts the files in a tablet, it only compacts a subset of the files. If a delete
    +   * marker exists in one of the files that is not being compacted, then data that should be deleted may be combined. See
    +   * <a href=""https://issues.apache.org/jira/browse/ACCUMULO-2232"">ACCUMULO-2232</a> for more information.
    +   *
    +   * <p>
    +   * This method allows users to configure how they want to handle the combination of delete markers, combiners, and major compactions. The default behavior is
    +   * {@link DeleteHandlingAction#LOG_ERROR}. See the javadoc on each {@link DeleteHandlingAction} enum for a description of each option.
    +   *
    +   * <p>
    +   * For correctness deletes should not be used with columns that are combined OR the {@link DeleteHandlingAction#REDUCE_ON_FULL_COMPACTION_ONLY} option should
    +   * be used. Only reducing on full major compactions may have negative performance implications.
    +   *
    --- End diff --
    
    I don't think this should be coupled with this fix.  Also not sure about doing this in 1.6.  I opened a new issue [ACCUMULO-4011](https://issues.apache.org/jira/browse/ACCUMULO-4011)
","02/Oct/15 16:24;ctubbsii;[~kturner], the {{@since}} line is incorrect. 1.6.4 passed without this change. The line should note the change occurs in 1.6.5 instead.","02/Oct/15 17:11;kturner;[~ctubbsii] thanks for updating it.   I am thinking this ticket can be closed, ACCUMULO-4011 outlines further follow on work.  If there is any other follow on work, then should probably open specific tickets.","02/Oct/15 17:45;githubbot;Github user keith-turner closed the pull request at:

    https://github.com/apache/accumulo/pull/47
","02/Oct/15 19:00;ctubbsii;To be clear, I only updated the fixVersion on this JIRA. The {{@since}} tag still needs to be updated in the javadocs before this ticket closes.",03/Oct/15 22:20;elserj;Looks like Keith fixed the since annotation. Closing given conversation.,,,,,,,,,,,,,,,,,,
Make UtilWaitThread.sleep() reset interrupt status,ACCUMULO-2346,12694294,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,10/Feb/14 16:48,17/Jul/15 21:06,13/Mar/19 22:01,17/Jul/15 21:06,,,,,,,,1.8.0,,,,,,,,,0,,,,,"Look into making UtilWaitThread.sleep() reset the interrupt status by calling {{Thread.currentThread().interrupt()}}.  This seems like a good thing to do, it allows code that does not want to deal with the interrupt to pass it on.  The question is, does doing this cause new bugs?",,"Commit b3692d464e8834f7ef561a45bc39509898b2741f in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b3692d4 ]

ACCUMULO-2346 use Uninterruptibles.sleepUninterruptibly
;17/Jul/15 18:53;jira-bot;600","Commit 5dbb768d7f503d87929bbd0fcd1b8c1b827cc10a in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5dbb768 ]

ACCUMULO-2346 update all sleeps to a specific time unit
;17/Jul/15 18:53;jira-bot;600",,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,ACCUMULO-2344,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-10 20:16:22.527,,,no_permission,,,,,,,,,,,,372803,,,Fri Jul 17 21:06:43 UTC 2015,,,,,,0|i1s8wf:,373107,,,,,,,,"10/Feb/14 20:16;bhavanki;I'd be happier if this method were abandoned and its users dealt with the {{InterruptedException}} properly, especially by gracefully ending threads. I recall discussion on this across the community in the past but haven't found a record of it yet.",12/Feb/14 18:01;ctubbsii;There was a [mailing list thread|http://mail-archives.apache.org/mod_mbox/accumulo-dev/201311.mbox/%3CCAL5zq9a3Y+szSbr7qvHh2=dvQf7gwnbWn3m0As4COwJ=eiS8dg@mail.gmail.com%3E] regarding this back in November.,"07/Jul/15 23:20;vines;I would also like to +1 this. I don't know of the repercussions, but currently this can cause threads that are impossible to interrupt out, which is infuriating. There need to be means for clients to interrupt out their threads.","07/Jul/15 23:21;vines;Also, might I suggest replacing it entirely with Uninterruptibles.sleep",17/Jul/15 21:06;ecn;I probably should have sent out a heads-up ... many files updated.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Functional tests don't configure Monitor log,ACCUMULO-1870,12678292,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,rfishel,busbey,busbey,08/Nov/13 19:14,10/Jun/15 18:03,13/Mar/19 22:01,13/Nov/13 18:43,1.4.5,1.5.1,,,,,,1.4.5,1.5.1,,test,,,,,,0,newbie,patch,,,"In reviewing ACCUMULO-1658, we missed one line that has an extra level of ""conf"":

test/system/auto/TestUtils.py line 50
{code}
LOG_MONITOR = os.path.join(ACCUMULO_CONF_DIR, 'conf', 'monitor_logger.xml')
{code}

I believe the net result is tests end up using the original monitor logger file.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11/Nov/13 14:55;rfishel;ACCUMULO-1870.patch;https://issues.apache.org/jira/secure/attachment/12613164/ACCUMULO-1870.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-11-13 18:38:52.158,,,no_permission,,,,,,,,,,,,357667,,,Wed Nov 13 18:43:28 UTC 2013,,,,,,0|i1pnpb:,357957,,,,,,,,11/Nov/13 14:57;busbey;+1 (non-binding) looks good.,"11/Nov/13 16:56;busbey;Increasing the priority to Major, because this actually causes the functional tests to fail unless you create a $ACCUMULO_CONF_DIR/conf directory","13/Nov/13 18:38;jira-bot;Commit 1e96138bb544e02829474011df850d5f28f299e6 in branch refs/heads/1.4.5-SNAPSHOT from ofishel
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1e96138 ]

ACCUMULO-1870 Functional tests don't configure Monitor log

Signed-off-by: Josh Elser <elserj@apache.org>
","13/Nov/13 18:40;jira-bot;Commit 1e96138bb544e02829474011df850d5f28f299e6 in branch refs/heads/1.5.1-SNAPSHOT from ofishel
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1e96138 ]

ACCUMULO-1870 Functional tests don't configure Monitor log

Signed-off-by: Josh Elser <elserj@apache.org>
","13/Nov/13 18:42;jira-bot;Commit 1e96138bb544e02829474011df850d5f28f299e6 in branch refs/heads/1.6.0-SNAPSHOT from ofishel
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1e96138 ]

ACCUMULO-1870 Functional tests don't configure Monitor log

Signed-off-by: Josh Elser <elserj@apache.org>
","13/Nov/13 18:42;jira-bot;Commit 1e96138bb544e02829474011df850d5f28f299e6 in branch refs/heads/master from ofishel
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1e96138 ]

ACCUMULO-1870 Functional tests don't configure Monitor log

Signed-off-by: Josh Elser <elserj@apache.org>
","13/Nov/13 18:43;elserj;Applied to 1.4.5-SNAPSHOT and 1.5.1-SNAPSHOT, OBE in >=1.6.0-SNAPSHOT.

Thanks for the patch, [~rfishel]; sorry for the delay.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in MemKeyConversionIterator constructor,ACCUMULO-1897,12679447,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,busbey,bhavanki,bhavanki,15/Nov/13 18:02,14/Apr/15 18:58,13/Mar/19 22:01,04/Apr/14 02:13,1.5.0,1.5.1,,,,,,1.5.2,1.6.0,,tserver,,,,,,0,,,,,"The constructor for {{InMemoryMap.MemKeyConversionIterator}} which takes a starting key does not correctly clone the key. The parameter to the constructor is {{startKey}}, but the code looks at the {{currKey}} field to check whether a key is available.

{code:java}
if (currKey != null)  // <- should be startKey != null
        currKey = (MemKey) startKey.clone();
{code}

This class was introduced in version 1.5.0, and is not present in 1.4.x.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,03/Apr/14 08:31;busbey;ACCUMULO-1897.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12638441/ACCUMULO-1897.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-04-03 08:20:16.413,,,no_permission,,,,,,,,,,,,358807,,,Tue Apr 08 00:37:07 UTC 2014,,,,,,0|i1puq7:,359097,,,,,,,,"03/Apr/14 08:20;busbey;I believe this constructor can be removed.

# AFAICT, it's only used in the deepCopy implementation. 
# [the API for deepCopy says that it makes a copy as if seek() has not been called|http://accumulo.apache.org/1.5/apidocs/org/apache/accumulo/core/iterators/SortedKeyValueIterator.html#deepCopy(org.apache.accumulo.core.iterators.IteratorEnvironment)]
# all of the other methods require a seek call before they can be used
# seek overwrites currKey

Rather than add a test to express this error and fix it, we should pull the Constructor and update deepCopy to use the single argument constructor.",03/Apr/14 08:31;busbey;Patch to remove incorrect constructor.,04/Apr/14 01:25;mdrob;+1,"04/Apr/14 02:01;jira-bot;Commit 75d62a46279aa448c386d7408a4268b0fe842c20 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=75d62a4 ]

ACCUMULO-1897 removes unneeded constructor for MemKeyConversionIterator.

Signed-off-by: Mike Drob <mdrob@cloudera.com>
","04/Apr/14 02:01;jira-bot;Commit 75d62a46279aa448c386d7408a4268b0fe842c20 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=75d62a4 ]

ACCUMULO-1897 removes unneeded constructor for MemKeyConversionIterator.

Signed-off-by: Mike Drob <mdrob@cloudera.com>
","04/Apr/14 02:01;jira-bot;Commit 75d62a46279aa448c386d7408a4268b0fe842c20 in accumulo's branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=75d62a4 ]

ACCUMULO-1897 removes unneeded constructor for MemKeyConversionIterator.

Signed-off-by: Mike Drob <mdrob@cloudera.com>
","07/Apr/14 21:07;jira-bot;Commit bcc9e7e41c9a40cc36502fece266780c7cba0de8 in accumulo's branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bcc9e7e ]

ACCUMULO-1897 Move shell into new package and module
",07/Apr/14 21:10;mdrob;Commit bcc9e7 really belongs to ACCUMULO-1879.,"08/Apr/14 00:37;jira-bot;Commit b2b985e240b90cb3645a9d7d4d8469d660961d1b in accumulo's branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b2b985e ]

Revert ""ACCUMULO-1897 Move shell into new package and module""

This reverts commit bcc9e7e41c9a40cc36502fece266780c7cba0de8.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bulk import failing when tablet server dies,ACCUMULO-422,12543536,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,kturner,kturner,21/Feb/12 18:47,10/Feb/15 20:53,13/Mar/19 22:01,28/Feb/12 18:38,,,,,,,,1.4.0,,,,,,,,,0,14_qa_bug,,,,"Saw this issue while running random walk test w/ agitation.  The bulk import code picks random tablet servers and ask them to bulk load files.  If a tablet server dies it takes 30 seconds for the master to see the zookeeper lock was lost.  During this 30 second period the bulk import code will still try to use the tserver and fail. After it fails three times it will mark the file as a failure.  This all happens within a second.

The bulk import code should probably catch TTransportException and black list the tablet server for that bulk import transaction.",10 node cluster running 1.4.0-SNAPSHOT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-3574,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,228775,,,Tue Feb 21 20:20:09 UTC 2012,,,,,,0|i07naf:,42539,,,,,,,,"21/Feb/12 20:20;kturner;Found another case where bulk import was failing because a tablet server died.  

{noformat}
21 19:21:18,386 [fate.Fate] WARN : Failed to execute Repo, tid=7427f4b91dc2fbb0
java.lang.NullPointerException
        at org.apache.accumulo.server.master.tableOps.CleanUpBulkImport.isReady(BulkImport.java:286)
        at org.apache.accumulo.server.master.tableOps.CleanUpBulkImport.isReady(BulkImport.java:262)
        at org.apache.accumulo.server.master.tableOps.TraceRepo.isReady(TraceRepo.java:50)
        at org.apache.accumulo.server.fate.Fate$TransactionRunner.run(Fate.java:62)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)

21 19:21:18,398 [thrift.MasterClientService$Processor] ERROR: Internal error processing waitForTableOperation
java.lang.NullPointerException
        at org.apache.accumulo.server.master.tableOps.CleanUpBulkImport.isReady(BulkImport.java:286)
        at org.apache.accumulo.server.master.tableOps.CleanUpBulkImport.isReady(BulkImport.java:262)
        at org.apache.accumulo.server.master.tableOps.TraceRepo.isReady(TraceRepo.java:50)
        at org.apache.accumulo.server.fate.Fate$TransactionRunner.run(Fate.java:62)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
{noformat}

This error propogated to the randomwalk test client causing it to die.

{noformat}
21 19:21:18,411 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Concurrent.xml
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:259)
	at org.apache.accumulo.server.test.randomwalk.Framework.run(Framework.java:61)
	at org.apache.accumulo.server.test.randomwalk.Framework.main(Framework.java:114)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.accumulo.start.Main$1.run(Main.java:89)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node ct.BulkImport
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:259)
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
	... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloException: Internal error processing waitForTableOperation
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:293)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:261)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.importDirectory(TableOperationsImpl.java:938)
	at org.apache.accumulo.server.test.randomwalk.concurrent.BulkImport.visit(BulkImport.java:132)
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
	... 9 more
Caused by: org.apache.thrift.TApplicationException: Internal error processing waitForTableOperation
	at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
	at org.apache.accumulo.core.master.thrift.MasterClientService$Client.recv_waitForTableOperation(MasterClientService.java:684)
	at org.apache.accumulo.core.master.thrift.MasterClientService$Client.waitForTableOperation(MasterClientService.java:665)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at cloudtrace.instrument.thrift.TraceWrap$2.invoke(TraceWrap.java:83)
	at $Proxy1.waitForTableOperation(Unknown Source)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.waitForTableOperation(TableOperationsImpl.java:233)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:275)
	... 13 more

{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Tablet constructor can hang on vfs classloader, preventing tablets from loading",ACCUMULO-1292,12643017,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,vines,vines,17/Apr/13 20:29,23/Jan/15 20:21,13/Mar/19 22:01,23/Jan/15 15:31,1.5.0,1.6.0,1.6.1,,,,,1.6.2,1.7.0,,tserver,,,,,,0,,,,,Taken from TODO from r1424106 regarding ACCUMULO-867. This is something that we should at least look into more before 1.5 is released.,,"Commit 40b41f26ed65ccc9ea9028d664505a4a875e9bd4 in accumulo's branch refs/heads/1.6 from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=40b41f2 ]

ACCUMULO-1292 update the classloader in a background thread
;23/Jan/15 15:30;jira-bot;600","Commit 40b41f26ed65ccc9ea9028d664505a4a875e9bd4 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=40b41f2 ]

ACCUMULO-1292 update the classloader in a background thread
;23/Jan/15 15:31;jira-bot;600","Commit 9f2fcf4aa3072a6eb1cc714506afc2dd84fd99d8 in accumulo's branch refs/heads/1.6 from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9f2fcf4 ]

ACCUMULO-1292 Remove use of guava class to avoid needing to add a new dependency
;23/Jan/15 19:38;jira-bot;600","Commit 9f2fcf4aa3072a6eb1cc714506afc2dd84fd99d8 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9f2fcf4 ]

ACCUMULO-1292 Remove use of guava class to avoid needing to add a new dependency
;23/Jan/15 19:38;jira-bot;600",,,,,,,,,,,,,,,,,,,,0,2400,,,0,2400,,,,,,,,,,,,,,,,,,,,,,22/Jan/15 19:26;ecn;ACCUMULO-1292-04.patch;https://issues.apache.org/jira/secure/attachment/12693968/ACCUMULO-1292-04.patch,22/Jan/15 22:13;ecn;ACCUMULO-1292-05.patch;https://issues.apache.org/jira/secure/attachment/12694012/ACCUMULO-1292-05.patch,22/Jan/15 22:44;ecn;ACCUMULO-1292-06.patch;https://issues.apache.org/jira/secure/attachment/12694025/ACCUMULO-1292-06.patch,22/Jan/15 17:44;ecn;ACCUMULO-1292-atomic-update.patch;https://issues.apache.org/jira/secure/attachment/12693936/ACCUMULO-1292-atomic-update.patch,22/Jan/15 01:50;dlmarion;ACCUMULO-1292-using-locks.patch;https://issues.apache.org/jira/secure/attachment/12693774/ACCUMULO-1292-using-locks.patch,21/Jan/15 23:15;ecn;ACCUMULO-1292.patch;https://issues.apache.org/jira/secure/attachment/12693739/ACCUMULO-1292.patch,,,,,,,6.0,,,,,,,,,,,,,,,,,,,2013-05-14 19:10:25.82,,,no_permission,,,,,,,,,,,,323427,,,Fri Jan 23 20:21:08 UTC 2015,,,,,,0|i1jsv3:,323772,,,,,,,,"14/May/13 16:49;vines;I think if this hangs, it's a bigger issue of classloader configuration. Can you provide clarification on your speculation here, [~kturner]?","14/May/13 19:10;kturner;bq. Can you provide clarification on your speculation

I was thinking of the situation where tablet X from table 1 has classpath config that causes tablet X to hang.  Tablet Z from table 2 would load fine, but the thread that processes tablet loads is stuck trying to load tablet X.","14/May/13 19:57;vines;Is that code synchronized somewhere? I traced it back and I don't see how that code can only be hit once at a time.

Furthermore, I'm still struggling to understand how the classpath config could cause hanging.","14/May/13 20:21;kturner;bq. Is that code synchronized somewhere? I traced it back and I don't see how that code can only be hit once at a time.

There is one thread in the tablet server that processes loading tablet.  See ACCUMULO-1085 for discussion on why it needs to be one thread in 1.5.

bq. Furthermore, I'm still struggling to understand how the classpath config could cause hanging.

I do not remember the specifics.  I think it comes down to doing some sort of I/O through VFS and the possibility that the I/O could hang.","14/May/13 20:28;vines;Thanks for the link to that ticket, it was quite informative to read through again.

It really does sound like the only 2 solutions then are 1085 or having a timeout mechanism, possibly exclusively around that classloader creation. But I doubt either of these are in scope for 1.5.0, possibly even 1.5.x unless experienced in the wild?","14/May/13 20:40;kturner;I agree, this is not a fix for 1.5.0.  I think there is currently sufficient logging for tablet loading that if this did get stuck we could determine the tablet.   ","07/Jan/14 23:58;elserj;bq. I agree, this is not a fix for 1.5.0.

[~kturner] what about for 1.6.0?",21/Jan/15 23:15;ecn;Discussed this issue with [~dlmarion] today.  The aggressive reset of the underlying classloader is the problem.  I've attached a patch that uses a background thread to reset the classloader.,22/Jan/15 01:50;dlmarion;[~ecn] Alternate implementation without synchronization. ,"22/Jan/15 02:15;ecn;[~dlmarion] I like your change, too. I don't think you can do this:

{noformat}
while (cl == null || cl.getParent() != parent.getClassLoader()) {
{noformat}

if you don't hold the read lock. We are mixing class synchronization with a Read/Write lock, so it would be easy to miss some other locking issues. If you are going to hold a write lock while updating class members (and possibly blocking), how is this that much different from a synchronized method?

Either patch needs a review from at least [~kturner], though I hope a few other folks would check it out, too.","22/Jan/15 02:22;dlmarion;I will admit that I was distracted trying to help the kids with their homework at the same time. I will give it another look tomorrow. You might be right, I should hold the read lock while checking to see if cl is equal to null. The sychronized methods will block each other. The locks allow concurrent readers, but the write lock blocks all reads.","22/Jan/15 02:45;elserj;Giving it a quick look (not nearly in the depth/context necessary):

Why the need to use a new thread to rebuild the classloader in either patch? It's possible that I'm not understanding the problem entirely, though.

If you have multiple callers coming in that want to reload the classloader, you only want one to do that reload, and then have the other callers use the result from the single caller which actually updated the classloader. All of the callers try to race to reinitialize the classloader, one wins and updates it, while the others wait for it to finish. In other words, the ReadWriteLock and marking the VFSClassLoader as volatile or wrapping it in an AtomicReference seems to me to provide all the concurrency control that you need. Did I misinterpret the problem?","22/Jan/15 03:11;dlmarion;I was trying to remove the synchronization on the getClassLoader method due to the lazy refresh of the classloader. This is the cause of the hang in the tablet server.

The FileListener api methods are called by the FileMonitor object in a different thread. I think in the current version of VFS the FileListener methods are called serially. I am not 100% sure about that and it may not be true in future versions.

The intention of my patch, if it is flawed currently, is to refresh in a separate thread when a modification occurs. If another modification occurs while that thread is running, then queue another refresh. If more modifications occur, then do nothing. The thought being that the currently executing thread may miss a change that happens, but the thread that is queued and has not started will not miss it. So, at most, we will have one thread performing a refresh and another thread queued up. If for some reason there is an error in the refresh thread, then the next call to getClassLoader will force a refresh in yet another thread (or maybe we do it in the current thread to catch the reason why the background threads were failing).

The fact that we have multiple readers and one writer seemed to fit the ReentrantReadWriteLock well. Maybe I didn't apply it in all cases and should be easy to fix. Now thinking about it, I do think I can tighten up the time in which the write lock is held in the refresh thread.",22/Jan/15 13:17;dlmarion;[~elserj] Thanks for the idea about the AtomicReference. I was able to remove all of the lock code.,22/Jan/15 16:42;kturner;I will look at it this afternoon,"22/Jan/15 17:46;ecn;[~dlmarion] and I conjured up a new patch: async handling is done by an {{ExecutorService}}, member declarations cleaned up, and uses [~elserj]'s idea for an {{AtomicReference}}.
","22/Jan/15 18:03;elserj;Thanks for the details last night, Dave. I think I know where my confusion was coming from now. You're trying to avoid blocking all threads from executing knowing that the classloader needs to be refreshed at the cost of continuing to run with ""stale"" artifacts? That's why you wanted to use the async thread.

Assuming I'm on the same page now, that makes a lot more sense. What would happen with the VFS classloader if a filesystem change happened (Jar was replaced), refresh on the classloader is started but takes a long time, class load is requested for a class that was from the replaced jar? Is that safe -- it would continue to load the old version of the class? Would requests before the classloader is updated fail?

{code}
+  private final ThreadPoolExecutor executor =
+      new ThreadPoolExecutor(1, 1, 1, SECONDS, new ArrayBlockingQueue<Runnable>(2));
{code}

Wouldn't {{Executors.newSingleThreadExecutor()}} be more concise? Is your keepAliveTime actually doing to do anything with a coreSize of 1?

{code}
+  private void scheduleRefresh() {
+    try {
+      executor.execute(new Runnable() {
+        @Override
+        public void run() {
+          try {
+            recreateClassloaderNow();
+          } catch (FileSystemException e) {
+            log.error(""Error refreshing classloader"", e);
+            clRef.set(null);
+          }
+        }
+      });
+    } catch (RejectedExecutionException e) {
+      // don't care, queue is full
+    }
+  }
{code}

Make the Runnable once. You don't need to make a new instance of it every time you call this method. Also, debug or trace level logging in the catch?

{code}
   public void close() {
+    executor.shutdown();
     monitor.stop();
   }
{code}

This will initiate the shutdown, but doesn't wait for it to finish. If the tserver is trying to stop but is stuck trying to reload a class, we don't want it to block the tserver from exiting (especially if the remote IO eats the interrupted exception). Need to make sure that the async refreshing thread is a daemon or provide a way to stop the thread.

I see you made some modifications to AccumuloVFSClassLoaderTest as well, but it doesn't look like those are actually testing anything related to these changes. Have you put any thought into how you can verify the correctness of these changes?","22/Jan/15 18:47;dlmarion;bq. What would happen with the VFS classloader if a filesystem change happened (Jar was replaced), refresh on the classloader is started but takes a long time, class load is requested for a class that was from the replaced jar? Is that safe – it would continue to load the old version of the class? Would requests before the classloader is updated fail?

 The classloader should provide the old version of the jar until the new classloader is constructed. This behavior should be the same as the previous implementation of the classloader. It would fail if your application depended on the new jar being available at a certain time. I don't think we have ever had a guarantee on some time constraint across all of the tservers. It's eventually consistent within, most likely, 2 times the refresh interval. The default interval is 30 seconds, but appears to be overridden in AccumuloVFSClassLoader to 1 second (with a TODO to make configurable). Having said that, if the thread is hung on I/O to HDFS or some other service that VFS supports (http, ftp, etc.) for retrieving jars, we can't provide any guarantee.

bq. Wouldn't Executors.newSingleThreadExecutor() be more concise? Is your keepAliveTime actually doing to do anything with a coreSize of 1?

  I want to ensure that 1 thread is running and that there is a max of 2 objects in the queue. I don't believe that with Executors.newSingleThreadExecutor() that you can change or control the size of the queue. My keepAliveTime should do nothing, but I don't think there is a constructor variant that does not require the information.

bq. Need to make sure that the async refreshing thread is a daemon or provide a way to stop the thread.

 Good point, we should make it a daemon, maybe provide a ThreadFactory to the ThreadPoolExecutor.

bq. executor.shutdown();

  Good point.","22/Jan/15 19:26;ecn;Patch has been updated, let me know if I missed anything.","22/Jan/15 19:46;dlmarion;Small nit, feel free to ignore. The missing paren threw me off:

+      log.trace(""Ignoring refresh request (already refreshing"");
","22/Jan/15 19:53;elserj;{{DaemonFactory}} is marked:

{code}
@InterfaceAudience.LimitedPrivate({""HDFS"", ""MapReduce""})
@InterfaceStability.Unstable
{code}

I'd prefer to see the {{Runnable}} {{refresher}} be made a {{Daemon}}. The possible Hadoop instability isn't worth it when an alternative is so simple, IMO.

Also, any comments on actually testing these changes?  It would be very nice to have something in place to verify correct functionality.

Aside from that, I think it looks OK.","22/Jan/15 19:58;ctubbsii;If this patch ends up looking good enough (with the recommended fixes), we could probably get this in to 1.6.2-rc2.",22/Jan/15 19:58;dlmarion;We changed the implementation of the refresh. There were tests already in place to test that the refresh was working. Those tests pass. Do you think we need more in-depth tests?,"22/Jan/15 20:05;elserj;I'm not familiar with the scope of coverage of those tests currently :)

Looking at the changes objectively, it would be good to verify:

1) The queuing of refreshes workes as expected (notably the RejectedExecution when >2 queued refreshes)
2) Clients don't block for a refresh to finish
3) Clients see the updated CL after a refresh

I haven't looked at things close enough to know how many of these are possible (nor may already exist) -- they just seem like coverage which we should have. No one had said anything the first time I asked, so I just wanted to make sure that we're not adding tests simply due to laziness/forgetfulness.","22/Jan/15 20:45;kturner;There is a race condition in the following code

{code:java}
     final VFSClassLoader cl = clRef.get();
     if (cl == null || cl.getParent() != parent.getClassLoader()) {
{code}

Check done w/ old version of {{cl}} may force update unnecessarily.  Also check {{cl.getParent() != parent.getClassLoader()}} may cause a blocking refresh, when an older version of the classloader could be returned immediately.","22/Jan/15 21:00;kturner;Thinking of following behavior change.   
 
  * When error in background thread updating classloader, it does not set clRef to null.  Just keeps retrying until it can update (logging error messages).  
  * clRef is never null after init.   All getClassloader does is return clRef.get(), it never waits.
  * something needs to check {{cl.getParent() != parent.getClassLoader()}} and queue a classloader update.","22/Jan/15 22:17;ecn;New patch, using a much simpler approach: always keep the old classloader and use it until we can load a new one.",22/Jan/15 22:45;ecn;Simplified by removing the atomic reference.,"23/Jan/15 00:59;dlmarion;Looks good to me. Only thing I saw is something that [~elserj] raised, calling executor.shutdownNow() in close().","23/Jan/15 14:54;ecn;I think {{shutdownNow()}} is what we want.  The threads are Daemon'ized, and the background thread checks the terminating status of the executor.  [~elserj], any thoughts?","23/Jan/15 15:19;elserj;Yup, I agree that should be fine. I think I said that as an option earlier. Thanks for dbl checking.","23/Jan/15 19:24;elserj;I wanted to say that I'm a little frustrated that this got committed without really responding about my concerns on test coverage (thank you, Dave. I know you did engage me on the subject). Even if it was infeasible to add tests to cover these changes, it would have been nice to say so rather than pretty much ignoring the concerns and moving forward.

Also, the final patch included a guava class which doesn't exist as a dependency in accumulo-start. I'm removing the usage of it to remove the necessity to add a new dependency here.","23/Jan/15 20:21;kturner;bq.  I'm a little frustrated that this got committed without really responding about my concerns on test coverage

In hindsight, it would have been better to use RB.  It hard to track whats going on here.   RB issues would have made it easy to see concerns not addressed.

bq. the final patch included a guava class which doesn't exist as a dependency in accumulo-start

A bit ago I ran into a compile issue w/ master caused by this.  On a whim I tried git pull and got your update that fixed it.  ",,,,,,,,,,,,,,,,,,,,,
Test Kerberos work with Apache Directory,ACCUMULO-1489,12650889,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,vines,vines,04/Jun/13 14:52,15/Jan/15 18:07,13/Mar/19 22:01,15/Jan/15 18:07,,,,,,,,1.7.0,,,test,,,,,,0,,,,,Apache Directory allows you to spin up a Kerberos server on the fly for testing. We should probably utilize this to have real tests for the Kerberos implementation.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-11-20 14:59:58.94,,,no_permission,,,,,,,,,,,,331216,,,Thu Jan 15 18:07:18 UTC 2015,,,,,,0|i1l533:,331549,,,,,,,,"20/Nov/14 14:59;elserj;Looks like we could use MiniKDC from Hadoop which is built using Apache Directory. Likely, this would be a more encapsulated solution for us. HADOOP-9848",15/Jan/15 18:07;elserj;Done as a part of ACCUMULO-2815,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
WriteAheadLogIT failed,ACCUMULO-2168,12688174,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,10/Jan/14 01:57,12/Nov/14 19:03,13/Mar/19 22:01,10/Jan/14 16:29,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Saw the following the tserver log when WriteAheadLogIT failed.  I think this prevented the table from loading, which caused the test timeout.  The message was repeated.   I the // in hdfs:// is what zookeeper is complaining about.

{noformat}
2014-01-09 19:45:54,791 [util.MetadataTableUtil] ERROR: java.lang.IllegalArgumentException: Invalid path string ""/accumulo/af3b249b-d1ff-4c94-acd5-83f35e3647b8/root_tablet/walogs/hdfs://localhost:52141/accumulo/wal/node1+41165/fb6791ec-9cdc-4d73-aef5-60ad59bb7a15"" caused by empty node name specified @72
java.lang.IllegalArgumentException: Invalid path string ""/accumulo/af3b249b-d1ff-4c94-acd5-83f35e3647b8/root_tablet/walogs/hdfs://localhost:52141/accumulo/wal/node1+41165/fb6791ec-9cdc-4d73-aef5-60ad59bb7a15"" caused by empty node name specified @72
        at org.apache.zookeeper.common.PathUtils.validatePath(PathUtils.java:99)
        at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1231)
        at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1277)
        at org.apache.accumulo.fate.zookeeper.ZooUtil.recursiveDelete(ZooUtil.java:103)
        at org.apache.accumulo.fate.zookeeper.ZooUtil.recursiveDelete(ZooUtil.java:117)
        at org.apache.accumulo.fate.zookeeper.ZooReaderWriter.recursiveDelete(ZooReaderWriter.java:65)
        at org.apache.accumulo.server.util.MetadataTableUtil.removeUnusedWALEntries(MetadataTableUtil.java:611)
        at org.apache.accumulo.tserver.Tablet.<init>(Tablet.java:1393)
        at org.apache.accumulo.tserver.Tablet.<init>(Tablet.java:1235)
        at org.apache.accumulo.tserver.Tablet.<init>(Tablet.java:1090)
        at org.apache.accumulo.tserver.Tablet.<init>(Tablet.java:1079)
        at org.apache.accumulo.tserver.TabletServer$AssignmentHandler.run(TabletServer.java:2895)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler$3.run(TabletServer.java:2262)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-10 16:29:06.728,,,no_permission,,,,,,,,,,,,367194,,,Fri Jan 10 16:30:00 UTC 2014,,,,,,0|i1rakv:,367503,,,,,,,,"10/Jan/14 16:29;jira-bot;Commit 9372608b16f97a5dcb6e8096fe5cbf4623fe8ff8 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9372608 ]

ACCUMULO-2168 log entry in zk is the last element of the file name
","10/Jan/14 16:30;jira-bot;Commit 9372608b16f97a5dcb6e8096fe5cbf4623fe8ff8 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9372608 ]

ACCUMULO-2168 log entry in zk is the last element of the file name
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
get rid of Instance.getConfiguration(),ACCUMULO-1866,12678256,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,mberman,mberman,08/Nov/13 16:38,01/Oct/14 01:13,13/Mar/19 22:01,21/Nov/13 16:32,,,,,,,,1.6.0,,,,,,,,,0,,,,,"It emerged when I introduced ClientConfiguration that there is general consensus that Instance.getConfiguration() should never have existed...Instance is supposed to be about the client, AccumuloConfiguration is supposed to be about the server.  We should pull it out.  We should also decide if this was really part of the public client API, in which case we probably want to think about a suitable replacement (maybe implemented in terms of ClientConfiguration).

[~kturner] said he was looking into whether or not he wants to do it for 1.6.0.  If not, I'm interested in looking into it for a future release, as part of a bigger effort to push ClientConfiguration deeper throughout the stack.",,"Commit a697516751426ec5143cea860ed6cbbaa85cf9af in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a697516 ]

ACCUMULO-1866 fix deprecation warning in test
;23/Sep/14 14:35;jira-bot;600",,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,ACCUMULO-2350,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-21 16:25:14.363,,,no_permission,,,,,,,,,,,,357631,,,Thu Nov 21 22:41:26 UTC 2013,,,,,,0|i1pnhb:,357921,,,,,,,,"21/Nov/13 16:25;jira-bot;Commit efb424680fd7edb1a475fbb2015af2bc8d0583a4 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=efb4246 ]

ACCUMULO-1866 deprecated Instance.getConfiguration()
","21/Nov/13 17:54;jira-bot;Commit efb424680fd7edb1a475fbb2015af2bc8d0583a4 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=efb4246 ]

ACCUMULO-1866 deprecated Instance.getConfiguration()
","21/Nov/13 21:02;jira-bot;Commit 32b5aee44f4b6b1bdd4b531132c6f855f433bcc8 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=32b5aee ]

ACCUMULO-1866 avoid using ServerConfigurationUtil in server code
","21/Nov/13 21:14;jira-bot;Commit de8ecd4a71cb7fda3525798c7e658c8f65efe6c2 in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=de8ecd4 ]

ACCUMULO-1866 Add missing deprecation annotations
","21/Nov/13 22:41;jira-bot;Commit 32b5aee44f4b6b1bdd4b531132c6f855f433bcc8 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=32b5aee ]

ACCUMULO-1866 avoid using ServerConfigurationUtil in server code
","21/Nov/13 22:41;jira-bot;Commit de8ecd4a71cb7fda3525798c7e658c8f65efe6c2 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=de8ecd4 ]

ACCUMULO-1866 Add missing deprecation annotations
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update to guava 15,ACCUMULO-2125,12687058,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,02/Jan/14 22:07,05/Sep/14 16:07,13/Mar/19 22:01,09/Jan/14 21:45,,,,,,,,1.6.0,,,,,,,,,0,,,,,"We should probably update to guava 15. It has a few bug fixes which may or may not affect us, but it will also make the user experience better since people won't be stuck with older versions of guava.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-3100,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-02 22:33:52.599,,,no_permission,,,,,,,,,,,,366053,,,Mon Jan 13 20:06:16 UTC 2014,,,,,,0|i1r3jz:,366364,,,,,,,,"02/Jan/14 22:33;busbey;Just curious, is there a reason we don't stick with the version of guava used by hadoop?

Even hadoop-client includes guava in the classpath.","02/Jan/14 22:55;elserj;Looks like it was introduced when the proxy came in. I imagine no one gave it any thought at the time. We would still want to depend on guava since we use it directly in Accumulo code. 

Also, it looks like hadoop2 has guava, but not hadoop1. I think I'd rather just stick to explicitly declaring and packaging the version of Guava that we choose rather than try to guess at when we need to include it in an assembly (makes us a little more portable too as we shouldn't have to recompile Accumulo for specific Hadoop versions).","02/Jan/14 23:01;busbey;If Hadoop 1 doesn't have it, then I agree we should package. Still using the same version that is in Hadoop 2 would save us future classpath troubleshooting issues like ACCUMULO-2127","08/Jan/14 21:52;jira-bot;Commit 1a9ae3cccf9e390ed6a6019a38fb3ee30965572a in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1a9ae3c ]

ACCUMULO-2125 - bumping up guava
","08/Jan/14 23:33;jira-bot;Commit 1a9ae3cccf9e390ed6a6019a38fb3ee30965572a in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1a9ae3c ]

ACCUMULO-2125 - bumping up guava
","08/Jan/14 23:42;jira-bot;Commit 5d573050b265fe99f4ee8c9bf5acaf1c3f6c685d in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5d57305 ]

Revert ""ACCUMULO-2125 - bumping up guava""

reverting until classpath issues in MAC are resolved

This reverts commit 1a9ae3cccf9e390ed6a6019a38fb3ee30965572a.
","09/Jan/14 03:05;jira-bot;Commit 5d573050b265fe99f4ee8c9bf5acaf1c3f6c685d in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5d57305 ]

Revert ""ACCUMULO-2125 - bumping up guava""

reverting until classpath issues in MAC are resolved

This reverts commit 1a9ae3cccf9e390ed6a6019a38fb3ee30965572a.
","09/Jan/14 21:45;jira-bot;Commit e256960c02b66fcbbb2bd3f74abe2bafb254d507 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e256960 ]

ACCUMULO-2125 upping guava
","13/Jan/14 20:05;jira-bot;Commit 6c4fa8ee5bdbafd032ac76e5a4a4884dd9e59723 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6c4fa8e ]

ACCUMULO-2125 fix deprecated warnings
","13/Jan/14 20:06;jira-bot;Commit 6c4fa8ee5bdbafd032ac76e5a4a4884dd9e59723 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6c4fa8e ]

ACCUMULO-2125 fix deprecated warnings
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Lacking fallback when ACCUMULO_LOG_HOST isn't set,ACCUMULO-2334,12693754,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,06/Feb/14 22:34,27/Aug/14 17:28,13/Mar/19 22:01,11/Feb/14 20:25,1.5.0,,,,,,,1.5.1,1.6.0,,tserver,,,,,,0,,,,,"For log-forwarding, if ACCUMULO_LOG_HOST is not set, the code falls back to using the hostname for localhost.

We already have an address for the monitor in ZK; we should use that instead when populated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-3086,,,ACCUMULO-2425,ACCUMULO-2373,,,,,,ACCUMULO-1736,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-07 22:23:15.036,,,no_permission,,,,,,,,,,,,372263,,,Wed Feb 19 20:09:55 UTC 2014,,,,,,0|i1s5lb:,372567,,,,,,,,"07/Feb/14 22:23;jira-bot;Commit fde149125478a294c0a04009ad6c96a7aea27675 in branch refs/heads/2334-loghost-squash from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fde1491 ]

ACCUMULO-2334 Remove ACCUMULO_LOG_HOST in favor of pull host and port log-forwarding from zookeeper

Advertising both the host and port for log4j gives us a couple of benefits.
We can do away with ACCUMULO_LOG_HOST, simplify the code to always
do the same thing (pull from zookeeper), and gain robust failover
if the monitor is moved to a different host or is restarted with a random
port (does not require any other service restart to become aware).
","07/Feb/14 22:31;elserj;In implementing this, I came to the conclusion that it's actually a bit cleaner to just remove ACCUMULO_LOG_HOST completely and use zookeeper for monitor log-forwarding discovery.

Made a review for the changes just to get some extra eyes on it, but I feel pretty comfortable with the changes.","11/Feb/14 18:41;jira-bot;Commit 0351d0d416df51f0b10d91acdc074dced36e40d4 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0351d0d ]

ACCUMULO-2334 Remove ACCUMULO_LOG_HOST in favor of pull host and port log-forwarding from zookeeper

Advertising both the host and port for log4j gives us a couple of benefits.
We can do away with ACCUMULO_LOG_HOST, simplify the code to always
do the same thing (pull from zookeeper), and gain robust failover
if the monitor is moved to a different host or is restarted with a random
port (does not require any other service restart to become aware).

The monitor will now acquire a zoolock before starting, which ensures that
all tservers will perform log-forwarding to the correct monitor (in the case
that there were multiple for some reason). Creates a better hierarchy in ZooKeeper
for all monitor data (HTTP and Log4j advertisement). Update `accumulo init`,
`accumulo info` and ensure that the zookeeper layout can handle an ""upgrade""
from 1.5.0.
","11/Feb/14 18:41;jira-bot;Commit fd31595b55f66627cf6d64cb20cc874c04e9da58 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fd31595 ]

ACCUMULO-2334 Make a slightly better ZK check for the mid-1.5.1-SNAPSHOT state.
","11/Feb/14 18:41;jira-bot;Commit fafa42961be8c6f457c5519852b398c488654980 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fafa429 ]

ACCUMULO-2334 Use the ZooReaderWriter exists() and make a slightly better comment.
","11/Feb/14 18:41;jira-bot;Commit 0351d0d416df51f0b10d91acdc074dced36e40d4 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0351d0d ]

ACCUMULO-2334 Remove ACCUMULO_LOG_HOST in favor of pull host and port log-forwarding from zookeeper

Advertising both the host and port for log4j gives us a couple of benefits.
We can do away with ACCUMULO_LOG_HOST, simplify the code to always
do the same thing (pull from zookeeper), and gain robust failover
if the monitor is moved to a different host or is restarted with a random
port (does not require any other service restart to become aware).

The monitor will now acquire a zoolock before starting, which ensures that
all tservers will perform log-forwarding to the correct monitor (in the case
that there were multiple for some reason). Creates a better hierarchy in ZooKeeper
for all monitor data (HTTP and Log4j advertisement). Update `accumulo init`,
`accumulo info` and ensure that the zookeeper layout can handle an ""upgrade""
from 1.5.0.
","11/Feb/14 18:41;jira-bot;Commit fd31595b55f66627cf6d64cb20cc874c04e9da58 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fd31595 ]

ACCUMULO-2334 Make a slightly better ZK check for the mid-1.5.1-SNAPSHOT state.
","11/Feb/14 18:41;jira-bot;Commit fafa42961be8c6f457c5519852b398c488654980 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fafa429 ]

ACCUMULO-2334 Use the ZooReaderWriter exists() and make a slightly better comment.
","11/Feb/14 18:41;jira-bot;Commit fd31595b55f66627cf6d64cb20cc874c04e9da58 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fd31595 ]

ACCUMULO-2334 Make a slightly better ZK check for the mid-1.5.1-SNAPSHOT state.
","11/Feb/14 18:41;jira-bot;Commit fafa42961be8c6f457c5519852b398c488654980 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fafa429 ]

ACCUMULO-2334 Use the ZooReaderWriter exists() and make a slightly better comment.
","11/Feb/14 20:04;jira-bot;Commit 15bbd5393029ac2538950ce36809dd24a4b2ec32 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=15bbd53 ]

ACCUMULO-2334 Comment in Master.upgradeZookeeper() about the checks that the monitor is also doing.
","11/Feb/14 20:04;jira-bot;Commit 15bbd5393029ac2538950ce36809dd24a4b2ec32 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=15bbd53 ]

ACCUMULO-2334 Comment in Master.upgradeZookeeper() about the checks that the monitor is also doing.
","11/Feb/14 20:04;jira-bot;Commit 15bbd5393029ac2538950ce36809dd24a4b2ec32 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=15bbd53 ]

ACCUMULO-2334 Comment in Master.upgradeZookeeper() about the checks that the monitor is also doing.
","19/Feb/14 20:09;jira-bot;Commit dcc19ccbada8c2f0a206ec797455294015e8ca6d in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=dcc19cc ]

ACCUMULO-1961 Re-apply inadvertently dropped 4abb3f1 to master branch

  Fixes trivial warnings and broken javadocs which have been recently
  introduced. Specifically, removes references to private and
  package-private (default) classes in public javadoc comments (internal
  details aren't relevant to the API and subject to change). Another
  common warning was unused imports and javadoc param tags that refer to
  non-existent parameters.

  Commits against the following JIRA issues introduced these:
  ACCUMULO-1948, ACCUMULO-1974, ACCUMULO-2021, ACCUMULO-2136,
  ACCUMULO-2322, ACCUMULO-2334, ACCUMULO-2350
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tablets not assigned to last location,ACCUMULO-2037,12685068,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,17/Dec/13 00:12,23/Aug/14 00:38,13/Mar/19 22:01,19/Dec/13 16:41,1.4.0,1.4.1,1.4.2,1.4.4,1.5.0,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"I ran continuous ingest on a small cluster, stopped ingest, and then restarted Accumulo.   After restart I looked last and current locations of tablets in the metadata table.   There were 2k tablets and I just spot checked a few random places, but nothing seemed to be assigned to the last loc.

{noformat}
root@accumulo> scan -t accumulo.metadata -b 2 -c loc,last
2;001015b last:142f897d61d0004 []    ip-10-1-3-16:9997
2;001015b loc:342f897d5cd000d []    ip-10-1-3-27:9997
2;002028 last:242f897d5dd0002 []    ip-10-1-3-28:9997
2;002028 loc:142f897d61d01ae []    ip-10-1-3-20:9997
2;00303c last:342f897d5cd0004 []    ip-10-1-3-25:9997
2;00303c loc:142f897d61d01b1 []    ip-10-1-3-23:9997
2;00404a last:342f897d5cd0004 []    ip-10-1-3-25:9997
2;00404a loc:142f897d61d01b5 []    ip-10-1-3-26:9997
2;00505b last:142f897d61d0004 []    ip-10-1-3-16:9997
2;00505b loc:342f897d5cd000d []    ip-10-1-3-27:9997
2;006066 last:142f897d61d0004 []    ip-10-1-3-16:9997
2;006066 loc:342f897d5cd000c []    ip-10-1-3-29:9997
2;007073a last:142f897d61d0004 []    ip-10-1-3-16:9997
2;007073a loc:342f897d5cd000f []    ip-10-1-3-21:9997
  .
  .
  .
{noformat}",,"Commit bab90f89ce398dfcfa3ecb22584041d9a3d3384c in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bab90f8 ]

ACCUMULO-2037 WARNING cleanup;22/Jul/14 21:27;jira-bot;600","Commit ac2e60164626e51e5932d0c30c6b4b68ea1414c1 in accumulo's branch refs/heads/1.6.1-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ac2e601 ]

ACCUMULO-2037 Close scanner
;23/Aug/14 00:37;jira-bot;600","Commit ac2e60164626e51e5932d0c30c6b4b68ea1414c1 in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ac2e601 ]

ACCUMULO-2037 Close scanner
;23/Aug/14 00:38;jira-bot;600",,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,ACCUMULO-2185,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-17 19:04:02.409,,,no_permission,,,,,,,,,,,,364145,,,Tue Dec 17 20:56:09 UTC 2013,,,,,,0|i1qrm7:,364445,,,,,,,,"17/Dec/13 19:04;jira-bot;Commit 59932f6d273067faaf9639ef4b632f67587bf5ad in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=59932f6 ]

ACCUMULO-2037 master is not fetching last location from the metadata table
","17/Dec/13 19:04;jira-bot;Commit 59932f6d273067faaf9639ef4b632f67587bf5ad in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=59932f6 ]

ACCUMULO-2037 master is not fetching last location from the metadata table
","17/Dec/13 19:04;jira-bot;Commit 59932f6d273067faaf9639ef4b632f67587bf5ad in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=59932f6 ]

ACCUMULO-2037 master is not fetching last location from the metadata table
","17/Dec/13 19:04;jira-bot;Commit 44a91663652e96f35de6b5e6c73090d4c6c29d35 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=44a9166 ]

ACCUMULO-2037 master is not fetching last location from the metadata table
","17/Dec/13 19:04;jira-bot;Commit 59932f6d273067faaf9639ef4b632f67587bf5ad in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=59932f6 ]

ACCUMULO-2037 master is not fetching last location from the metadata table
","17/Dec/13 19:04;jira-bot;Commit 44a91663652e96f35de6b5e6c73090d4c6c29d35 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=44a9166 ]

ACCUMULO-2037 master is not fetching last location from the metadata table
","17/Dec/13 20:04;jira-bot;Commit bec36bc3f4164dbb5bceb9b558b0aa9b0ae150c4 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bec36bc ]

ACCUMULO-2037 host:port[123456] sorts before host:port[], so the correct host was being skipped
","17/Dec/13 20:04;jira-bot;Commit bec36bc3f4164dbb5bceb9b558b0aa9b0ae150c4 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bec36bc ]

ACCUMULO-2037 host:port[123456] sorts before host:port[], so the correct host was being skipped
","17/Dec/13 20:04;jira-bot;Commit bec36bc3f4164dbb5bceb9b558b0aa9b0ae150c4 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bec36bc ]

ACCUMULO-2037 host:port[123456] sorts before host:port[], so the correct host was being skipped
","17/Dec/13 20:04;jira-bot;Commit bec36bc3f4164dbb5bceb9b558b0aa9b0ae150c4 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bec36bc ]

ACCUMULO-2037 host:port[123456] sorts before host:port[], so the correct host was being skipped
","17/Dec/13 20:56;jira-bot;Commit 741c83ca1a87dac227ddc783e94dab1924716658 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=741c83c ]

ACCUMULO-2037 quick test to verify locality, location state management
","17/Dec/13 20:56;jira-bot;Commit b54b130491100b100caca72f1075a9dc91be5f5d in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b54b130 ]

ACCUMULO-2037 use the last location information
","17/Dec/13 20:56;jira-bot;Commit 741c83ca1a87dac227ddc783e94dab1924716658 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=741c83c ]

ACCUMULO-2037 quick test to verify locality, location state management
","17/Dec/13 20:56;jira-bot;Commit b54b130491100b100caca72f1075a9dc91be5f5d in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b54b130 ]

ACCUMULO-2037 use the last location information
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
overnight integration tests sometimes fails,ACCUMULO-2455,12700797,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,11/Mar/14 20:17,07/Aug/14 19:20,13/Mar/19 22:01,07/Aug/14 19:20,,,,,,,,1.6.1,1.7.0,,test,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-11 20:31:02.548,,,no_permission,,,,,,,,,,,,379140,,,Thu Aug 07 19:20:31 UTC 2014,,,,,,0|i1tbuv:,379432,,,,,,,,11/Mar/14 20:18;ecn;Several tests failed on nightly regression tests.  See sub-tickets.,"11/Mar/14 20:31;jira-bot;Commit 09307322a3e9f45cd37bbd4c63fa66ccbe2cc0a2 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0930732 ]

ACCUMULO-2455 small work arounds to increase the chance that zookeeper updates are in place before tservers need to see them
","11/Mar/14 20:32;jira-bot;Commit 09307322a3e9f45cd37bbd4c63fa66ccbe2cc0a2 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0930732 ]

ACCUMULO-2455 small work arounds to increase the chance that zookeeper updates are in place before tservers need to see them
","12/Mar/14 05:12;jira-bot;Commit 09307322a3e9f45cd37bbd4c63fa66ccbe2cc0a2 in accumulo's branch refs/heads/ACCUMULO-2061 from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0930732 ]

ACCUMULO-2455 small work arounds to increase the chance that zookeeper updates are in place before tservers need to see them
","28/Mar/14 16:59;jira-bot;Commit e5070d0ad084f218d283b9daa58246184afdb477 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e5070d0 ]

ACCUMULO-2455 1s timeout is too tight for testing
","28/Mar/14 16:59;jira-bot;Commit e5070d0ad084f218d283b9daa58246184afdb477 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e5070d0 ]

ACCUMULO-2455 1s timeout is too tight for testing
","04/Apr/14 23:58;jira-bot;Commit 2cb526e5e11a54e6e1932cf37fa715b2cae22533 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2cb526e ]

ACCUMULO-2455 Remove JVM reuse, causing some test failures

  Forked JVMs are reused, but a JVM can be left in a bad state, causing
  a cascade of other test failures. This reuse can speed up the tests,
  but I'm disabling it, until we can figure out which tests leave the
  JVM in a bad (non-reusable) state and whether we can actually avoid
  that or not, such that it'd be safe to turn JVM reuse back on.
","04/Apr/14 23:59;jira-bot;Commit 2cb526e5e11a54e6e1932cf37fa715b2cae22533 in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2cb526e ]

ACCUMULO-2455 Remove JVM reuse, causing some test failures

  Forked JVMs are reused, but a JVM can be left in a bad state, causing
  a cascade of other test failures. This reuse can speed up the tests,
  but I'm disabling it, until we can figure out which tests leave the
  JVM in a bad (non-reusable) state and whether we can actually avoid
  that or not, such that it'd be safe to turn JVM reuse back on.
",05/Apr/14 00:16;mdrob;Is there a way to mark individual tests (or test classes) as eligible for reuse. Something like Spring's [Dirties Context|http://docs.spring.io/spring/docs/3.0.x/api/org/springframework/test/annotation/DirtiesContext.html] Annotation,05/Apr/14 13:37;ctubbsii;I'm not sure if that's possible.,07/Aug/14 19:20;ecn;Open new tickets for any other nightly test failures.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Functional test for Examples doesn't check return codes; many examples don't run,ACCUMULO-1878,12678589,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,busbey,busbey,busbey,11/Nov/13 15:02,30/Jul/14 15:17,13/Mar/19 22:01,12/Jan/14 06:10,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,,,1.4.5,1.5.1,,test,,,,,,0,,,,,"While investigating a failure on the bloom filter speed test in the simple.examples.Examples functional test, I found that no data was getting written in the 1.4.x branch.

After changing things to check return codes be default (so the above would fail), I found that most of the Examples aren't actually running in 1.4 or 1.5 because of incorrect class names.

I have most of a fix, just waiting actually run through the fixes and figure out handling the merge of fixes from 1.4 -> 1.5 -> 1.6.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-3029,,,,,,,,,,,14/Nov/13 16:57;busbey;ACCUMULO-1878.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12613875/ACCUMULO-1878.1.patch.txt,15/Nov/13 18:43;busbey;ACCUMULO-1878.2.patch.txt;https://issues.apache.org/jira/secure/attachment/12614103/ACCUMULO-1878.2.patch.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-11-25 14:38:29.934,,,no_permission,,,,,,,,,,,,357956,,,Tue Dec 31 02:18:43 UTC 2013,,,,,,0|i1pphb:,358246,,,,,,,,14/Nov/13 16:54;busbey;review board to check return codes by default. made the batchread/writer examples return errors.,"14/Nov/13 16:54;busbey;without ACCUMULO-1892, will have failures",14/Nov/13 16:57;busbey;attaching preliminary patch in case reviewboard is misbehaving.,"15/Nov/13 18:43;busbey;Updated patch to match current review board, incorporates feedback and changes in ACCUMULO-1892",22/Nov/13 21:01;busbey;Bump. Could a committer take a look at pushing this?,25/Nov/13 14:38;kturner;I am working on applying this and merging it forward.,"25/Nov/13 18:17;jira-bot;Commit 1fe5f7f528d39746c0e5cffb8710b4db21c3a5b2 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1fe5f7f ]

ACCUMULO-1878 handle error conditions in example tests.

* ensure simple examples used in integration tests properly set non-zero exit on errors
* check return code of executed commands.
* fix typo in bloom filter speed comparison
* fix error in arg order on helloworld examples
* Makes sure paired examples for RandomBatch use the same seed.

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 18:18;jira-bot;Commit 1fe5f7f528d39746c0e5cffb8710b4db21c3a5b2 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1fe5f7f ]

ACCUMULO-1878 handle error conditions in example tests.

* ensure simple examples used in integration tests properly set non-zero exit on errors
* check return code of executed commands.
* fix typo in bloom filter speed comparison
* fix error in arg order on helloworld examples
* Makes sure paired examples for RandomBatch use the same seed.

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 18:29;kturner;I think I did git wrong when merging this from 1.4 to 1.5.  When merging there were conflicts which I resolved and then tried to run the test.   When running the test I started finding and fixing many problems with it.   I ended up bundling all of the fixes in the merge commit.  I think it may have been better to resolve the conflicts, commit that and then start resolving general issue witht the test a separate commit.

The test passes now in 1.5, but some of the map reduce jobs it runs are failing (yet the test still passes).  I will open a sub task for this.","25/Nov/13 20:25;jira-bot;Commit 1fe5f7f528d39746c0e5cffb8710b4db21c3a5b2 in branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1fe5f7f ]

ACCUMULO-1878 handle error conditions in example tests.

* ensure simple examples used in integration tests properly set non-zero exit on errors
* check return code of executed commands.
* fix typo in bloom filter speed comparison
* fix error in arg order on helloworld examples
* Makes sure paired examples for RandomBatch use the same seed.

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 20:25;jira-bot;Commit fd652ca0dd60030b6b7e665476ad2ed72574dd36 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fd652ca ]

ACCUMULO-1878 fix example integration tests
","25/Nov/13 20:39;jira-bot;Commit 1fe5f7f528d39746c0e5cffb8710b4db21c3a5b2 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1fe5f7f ]

ACCUMULO-1878 handle error conditions in example tests.

* ensure simple examples used in integration tests properly set non-zero exit on errors
* check return code of executed commands.
* fix typo in bloom filter speed comparison
* fix error in arg order on helloworld examples
* Makes sure paired examples for RandomBatch use the same seed.

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 20:39;jira-bot;Commit fd652ca0dd60030b6b7e665476ad2ed72574dd36 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fd652ca ]

ACCUMULO-1878 fix example integration tests
","06/Dec/13 19:56;busbey;[~kturner], is there anything else you'd like to see done on this issue before closing out?",09/Dec/13 16:27;kturner;I opened a subtask for the issues I was seeing with the map reduce examples.  Those failures are a specific case of the more general description of this ticket.   Should probably address ACCUMULO-1988 before closing this out.  ,"31/Dec/13 02:18;ctubbsii;Note: A similar issue to this one existed in 1.6.0, where we weren't checking the return codes of ExamplesIT. That was fixed, however.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
refactor Tablet,ACCUMULO-2041,12685189,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,17/Dec/13 15:28,24/Jul/14 20:13,13/Mar/19 22:01,24/Jul/14 20:13,,,,,,,,1.7.0,,,tserver,,,,,,0,,,,,"Tablet has some very delicate state stored in several variables.  Translate this into some sort of sane state machine, with appropriate, clean log messages when the state transitions.  I'm specifically thinking of {{closing}}, {{closed}}, {{closeComplete}} and {{closeCompleting}}.  That's 16 possible states, but I'm thinking that only a few make any sense.  May want to look at the {{...InProgress}} and {{..WaitingToStart}} booleans, too.  Some of the embedded classes could be moved out to their own files, just to reduce the size of the class.  There are 17 uses of the keyword {{class}} in this one file. The constructor nesting is pretty crazy.  The constructor is doing too much.  It should not be doing recovery, for example.  It should not be passing ""this"" to anything.  Small things, like {{extent}}, {{fs}}, {{conf}} should be final.  Anything that would facilitate unit testing would be welcome.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2872,,,,,,,,,,,,,,21/Apr/14 19:32;ecn;ACCUMULO-2041-v1.patch;https://issues.apache.org/jira/secure/attachment/12641107/ACCUMULO-2041-v1.patch,21/Apr/14 20:55;ecn;ACCUMULO-2041-v2.patch;https://issues.apache.org/jira/secure/attachment/12641117/ACCUMULO-2041-v2.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2014-02-04 15:38:58.396,,,no_permission,,,,,,,,,,,,364266,,,Thu Jun 05 20:05:39 UTC 2014,,,,,,0|i1qsd3:,364566,,,,,,,,04/Feb/14 15:38;bhavanki;I'd like to help out on this if I may. ACCUMULO-1948 has given me the chance to delve into {{Tablet}} code.,21/Apr/14 19:32;ecn;Updated patch based on review comments.,"03/Jun/14 18:49;jira-bot;Commit 7db2abf19c2e0585b2f3ea32068c3d62bd891590 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7db2abf ]

ACCUMULO-2041 extract tablet classes to new files, move tablet-related code to o.a.a.tserver.tablet, make member variables private
","03/Jun/14 18:49;jira-bot;Commit 8049859154dc5cab5a5a0ce1d6babaf243c06922 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8049859 ]

ACCUMULO-2041 updates from initial review
","03/Jun/14 18:49;jira-bot;Commit 459d3048eb39650ebff2c93734d2886a9d4869c7 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=459d304 ]

ACCUMULO-2041 more review updates
","03/Jun/14 18:49;jira-bot;Commit a13f788d45db934412bbd45da9650110a5cd1dd0 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a13f788 ]

ACCUMULO-2041 provide alternative name for entries in a WAL
","03/Jun/14 20:42;jira-bot;Commit f280e9713ca3016cec3c082321774d579c86d51e in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f280e97 ]

ACCUMULO-2041 finished state management in Tablet
","05/Jun/14 20:05;jira-bot;Commit 8071252801817dc88d5e6b50fa58ad3b0a629446 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8071252 ]

ACCUMULO-2041 should not clear compaction state while still compacting
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
use reflection to improve compatibility between Hadoop 1 and 2,ACCUMULO-1421,12647979,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,afuchs,afuchs,afuchs,16/May/13 15:48,24/Jul/14 17:19,13/Mar/19 22:01,18/May/13 11:16,,,,,,,,1.5.0,,,client,,,,,,0,,,,,"JobContext switches between an abstract class and an interface in hadoop 1 and 2, causing runtime compatibility problems in the compiled Accumulo bytecode. Avoid the runtime problem by using reflection to access the configuration object stored in the JobContext.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-3013,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-16 16:28:02.499,,,no_permission,,,,,,,,,,,,328335,,,Fri Mar 28 21:26:16 UTC 2014,,,,,,0|i1knef:,328679,,,,,,,,"16/May/13 16:28;busbey;If I wanted to test this, which profile did you build with?","16/May/13 16:37;vines;I believe the version is irrelevant.

Sent from my phone, please pardon the typos and brevity.

","16/May/13 16:45;busbey;The version is very relevant. I need to test on the opposite one to make sure we haven't missed references to incompatible classes.

I guess I can just search through the byte code. :/","16/May/13 16:47;busbey;Oh I see, I can just do both myself. Fair point.","16/May/13 17:49;billie.rinaldi;Putting the getConfiguration(JobContext) method in InputFormatBase makes it part of the public API.  Should we consider making a core.util.CompatibilityLayer class where we could put stuff like this, and then it will be easy to get rid of it when we no longer need it?

Do we want this in 1.5 yet, or just trunk?  It will only be needed when we've tracked down all the incompatibilities.  And if their fixes are all non-API-changing like this, it will be an easy decision to merge them to 1.5 given the benefits.  On the other hand ... if it's possible that we might only support hadoop 2 for 1.6, then we only want this fix in 1.5.  I guess there's no way to predict that at this point.","16/May/13 18:07;busbey;A compatibility layer would be a great idea. It also gives some room for dealing with future incompatibilities. Hive (HIVE-3029) does this, and Pig (PIG-2686) used to. Probably a package, as Hive does, would be best.

I think pushing for trunk is prudent, since the pressure to get 1.5 out is high and there's uncertainty on how wide a change this needs.","16/May/13 18:36;afuchs;RE location of getConfiguration: how about if we make it package protected in InputFormatBase for now?

RE compatibility layer: As a general solution I would say that's a good solution, but since we can (in theory) enumerate all of the versions we want to be compatible with it's better if we can just make one simple release to rule them all.

RE 1.5 vs. trunk: Is there another point of incompatibility? If this just fixes the problem entirely then we definitely want to have it in 1.5.0. If not, then we haven't sacrificed much by putting it in 1.5. Sean, are you running compatibility tests with CDH 3 and 4?","16/May/13 19:13;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #120 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/120/])
    ACCUMULO-1421 simplify reflection lookup of SafeModeAction, reverting inadvertent check-in of LargeRowTest (Revision 1483496)
ACCUMULO-1421 simplify reflection lookup of SafeModeAction (Revision 1483494)
ACCUMULO-1421 fix warnings introduced by previous commits (Revision 1483435)
ACCUMULO-1421 added reflection to improve runtime compatibility between hadoop 1 and 2 JobContext objects (Revision 1483417)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java

ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java

ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/Accumulo.java

afuchs : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
","16/May/13 19:18;hudson;Integrated in Accumulo-1.5 #118 (See [https://builds.apache.org/job/Accumulo-1.5/118/])
    ACCUMULO-1421 simplify reflection lookup of SafeModeAction, reverting inadvertent check-in of LargeRowTest (Revision 1483496)
ACCUMULO-1421 simplify reflection lookup of SafeModeAction (Revision 1483494)
ACCUMULO-1421 fix warnings introduced by previous commits (Revision 1483435)
ACCUMULO-1421 added reflection to improve runtime compatibility between hadoop 1 and 2 JobContext objects (Revision 1483417)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java

ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java

ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/Accumulo.java

afuchs : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
","16/May/13 20:12;kturner;bq. Should we consider making a core.util.CompatibilityLayer 

I like the idea of having all of this crazy reflection code in one place.  Do not really have a good reason.  I just do not like the idea of it sprinkled throughout the codebase.","16/May/13 20:47;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #232 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/232/])
    merge changes from 1.5

ACCUMULO-1421 simplify reflection lookup of SafeModeAction
ACCUMULO-???? changed getConfiguration to be package protected so that it is not in the public API
ACCUMULO-1274 classpath command shows two java configured classpaths before showing Accumulo configured classpaths.
ACCUMULO-970 use reasonable defaults for batchwriter in documentation (Revision 1483510)
ACCUMULO-1421 simplify reflection lookup of SafeModeAction (Revision 1483498)
ACCUMULO-1421, ACCUMULO-904 merge to trunk (Revision 1483461)
ACCUMULO-1413,ACCUMULO-1421 merge to trunk (Revision 1483431)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/docs/src/main/latex/accumulo_user_manual/chapters/analytics.tex
* /accumulo/trunk/docs/src/main/latex/accumulo_user_manual/chapters/clients.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/vfs/AccumuloVFSClassLoader.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/src

ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/src

ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/TTimeoutTransport.java
* /accumulo/trunk/docs/src/main/latex/accumulo_user_manual/chapters/administration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
","16/May/13 20:53;hudson;Integrated in Accumulo-Trunk #874 (See [https://builds.apache.org/job/Accumulo-Trunk/874/])
    merge changes from 1.5

ACCUMULO-1421 simplify reflection lookup of SafeModeAction
ACCUMULO-???? changed getConfiguration to be package protected so that it is not in the public API
ACCUMULO-1274 classpath command shows two java configured classpaths before showing Accumulo configured classpaths.
ACCUMULO-970 use reasonable defaults for batchwriter in documentation (Revision 1483510)
ACCUMULO-1421 simplify reflection lookup of SafeModeAction (Revision 1483498)
ACCUMULO-1421, ACCUMULO-904 merge to trunk (Revision 1483461)
ACCUMULO-1413,ACCUMULO-1421 merge to trunk (Revision 1483431)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/docs/src/main/latex/accumulo_user_manual/chapters/analytics.tex
* /accumulo/trunk/docs/src/main/latex/accumulo_user_manual/chapters/clients.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/vfs/AccumuloVFSClassLoader.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/src

ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/src

ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/TTimeoutTransport.java
* /accumulo/trunk/docs/src/main/latex/accumulo_user_manual/chapters/administration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
","17/May/13 00:41;busbey;[~afuchs], that's my intention. Having trouble building the 1.5 branch on either OS X or CentOS 6.2, so probably I'm going to be delayed. Different tests failing in both cases.","18/May/13 02:33;afuchs;Mike Berman found another issue: org.apache.hadoop.net.NetUtils.getInputStream(Ljava/net/Socket;J)Ljava/io/InputStream; became org.apache.hadoop.net.NetUtils.getInputStream(Ljava/net/Socket;J)Lorg/apache/hadoop/net/SocketInputWrapper;. We use this at org.apache.accumulo.core.util.TTimeoutTransport.create(TTimeoutTransport.java:39). This breaks bytecode compatibility, but not source code compatibility. Time for more reflection!",18/May/13 03:39;ecn;svn update?  I fixed that yesterday.,18/May/13 11:16;afuchs;Eric already fixed it! Guess it was a build management problem on our side.,18/May/13 12:15;ctubbsii;What version was this fixed for? 1.5? 1.6?,18/May/13 13:16;afuchs;May still require a merge to trunk.,"18/May/13 17:01;billie.rinaldi;Let's see if I understand this correctly: we will still support building
against different versions of Hadoop, but it will not be necessary for
running Accumulo. We will only need to to make one binary package that will
work against either Hadoop 1 or 2.

Would it be possible or desirable to make Hadoop 1 and Hadoop 2 testing
modules to test against whichever jars we're not building against?
","18/May/13 17:20;ctubbsii;{quote}We will only need to to make one binary package that will
work against either Hadoop 1 or 2.{quote}

Hopefully that is a true statement.

{quote}Would it be possible or desirable to make Hadoop 1 and Hadoop 2 testing
modules to test against whichever jars we're not building against?{quote}

Desirable, definitely. Certainly it's possible to run the python test suite on both. It might be possible to create some explicit integration tests in the build, but I'm not entirely sure how the dependencies management would need to work for that (probably would have to be two different sub-modules of the test module).","21/May/13 22:31;hudson;Integrated in Accumulo-1.5 #131 (See [https://builds.apache.org/job/Accumulo-1.5/131/])
    ACCUMULO-1421 use reflection to work around class/interface change in Counter (Revision 1484908)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/continuous/ContinuousVerify.java
","21/May/13 22:42;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #243 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/243/])
    ACCUMULO-1421 use reflection to work around class/interface change in Counter (Revision 1484917)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/continuous/ContinuousVerify.java
","21/May/13 22:47;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #133 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/133/])
    ACCUMULO-1421 use reflection to work around class/interface change in Counter (Revision 1484908)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/continuous/ContinuousVerify.java
","21/May/13 22:51;hudson;Integrated in Accumulo-Trunk #884 (See [https://builds.apache.org/job/Accumulo-Trunk/884/])
    ACCUMULO-1421 use reflection to work around class/interface change in Counter (Revision 1484917)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/continuous/ContinuousVerify.java
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
",,,,,,,,,,,,,,,,,,
Major compacting files not empty,ACCUMULO-2082,12685942,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,elserj,elserj,21/Dec/13 02:28,11/Jun/14 20:13,13/Mar/19 22:01,11/Jun/14 20:13,,,,,,,,1.6.0,,,,,,,,,0,16_qa_bug,,,,"Saw this during a randomwalk:

{noformat}
MajC Failed, message = Major compacting files not empty [hdfs://nameservice/accumulo/tables/p/t-0001pfx/C0001qir.rf, hdfs://nameservice/accumulo/tables/p/t-0001pfx/C0001qip.rf, hdfs://nameservice/accumulo/tables/p/b-0001qh4/I0001qh5.rf, hdfs://nameservice/accumulo/tables/p/b-0001qgt/I0001qgv.rf, hdfs://nameservice/accumulo/tables/p/b-0001qg5/I0001qg6.rf, hdfs://nameservice/accumulo/tables/p/b-0001qem/I0001qeo.rf, hdfs://nameservice/accumulo/tables/p/b-0001qgj/I0001qgk.rf, hdfs://nameservice/accumulo/tables/p/t-0001pfx/C0001qis.rf, hdfs://nameservice/accumulo/tables/p/b-0001qga/I0001qgb.rf, hdfs://nameservice/accumulo/tables/p/t-0001pfx/A0001pg9.rf]
	java.lang.IllegalStateException: Major compacting files not empty [hdfs://nameservice/accumulo/tables/p/t-0001pfx/C0001qir.rf, hdfs://nameservice/accumulo/tables/p/t-0001pfx/C0001qip.rf, hdfs://nameservice/accumulo/tables/p/b-0001qh4/I0001qh5.rf, hdfs://nameservice/accumulo/tables/p/b-0001qgt/I0001qgv.rf, hdfs://nameservice/accumulo/tables/p/b-0001qg5/I0001qg6.rf, hdfs://nameservice/accumulo/tables/p/b-0001qem/I0001qeo.rf, hdfs://nameservice/accumulo/tables/p/b-0001qgj/I0001qgk.rf, hdfs://nameservice/accumulo/tables/p/t-0001pfx/C0001qis.rf, hdfs://nameservice/accumulo/tables/p/b-0001qga/I0001qgb.rf, hdfs://nameservice/accumulo/tables/p/t-0001pfx/A0001pg9.rf]
		at org.apache.accumulo.tserver.Tablet$DatafileManager.reserveMajorCompactingFiles(Tablet.java:933)
		at org.apache.accumulo.tserver.Tablet._majorCompact(Tablet.java:3187)
		at org.apache.accumulo.tserver.Tablet.majorCompact(Tablet.java:3371)
		at org.apache.accumulo.tserver.Tablet.access$4700(Tablet.java:168)
		at org.apache.accumulo.tserver.Tablet$CompactionRunner.run(Tablet.java:2849)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at java.lang.Thread.run(Thread.java:744)
{noformat}

I don't actually know if it's a problem. A first read over that section of the code wasn't obvious to me one way or the other. ",5bb28edba7ff587191e8c33cd909e3677465af48,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-24 01:00:36.018,,,no_permission,,,,,,,,,,,,364929,,,Wed Jun 11 20:13:15 UTC 2014,,,,,,0|i1qwfr:,365229,,,,,,,,"23/Dec/13 17:58;elserj;Looking over this, it's not obvious to me yet what's happening here. My first hunch was that there was another compaction that tried to run over an overlapping set of files for the given Tablet. I've ruled that out, however, because of the check against the {{majorCompactionInProgress}} member of {{Tablet}}. It doesn't appear possible to run multiple compactions over the same Tablet (even if the compaction files are disjoint).","23/Dec/13 19:44;elserj;Some more information: the tablet that failed the majc was split about 2 minutes before the first failure happened. After the split, there were a number of bulk imports interspersed with two user-initiated major compactions that appear to have finished successfully.

On the third user-initiated compaction, we failed on an exception similar to the one above. After about 2 minutes to repeated majc failure, the tablet was unloaded and not reloaded anywhere else.

Edit: From the master log, the tablet looks like it was merged away:

{noformat}
2013-12-20 18:14:55,910 [master.Master] INFO : Asking tserver:9997[342e4bd7cd90326] to chop p;r05974<
2013-12-20 18:14:56,142 [master.Master] DEBUG: mergeInfo overlaps: p;r05974< true
{noformat}","23/Dec/13 22:06;elserj;I correlated some logs from the randomwalk clients that would have affected the tablet which first saw a MajC failure.

{noformat}
18:12:33 Compact everything
18:12:44 Compact (r0500e, r0dd4f]
18:13:01 Merge (r0527, r14b05]
18:13:59 First MajC failure (inlined from tserver logs)
18:14:39 Merge (r04cbc, r05c8a]
{noformat}

There were two other active RW processes, one in Sequential and one in Security. Both of these appear to be doing things in isolation. I'm hopeful that a re-run of just the Bulk stuff will net a similar result. Meanwhile, I'll make sure tickets exists for the unexpected RW failures.","24/Dec/13 00:13;elserj;I was curious if I could replicate this. I did so in less than 10 minutes.

[~ecn], you haven't seen this while running randomwalk yet? That makes me wonder if this was a recent regression.","24/Dec/13 00:44;elserj;Assigning to myself to at least advertise that I'm looking into this, but I did already ping Keith for some help/direction so I know he has also looked into this a little.","24/Dec/13 01:00;jira-bot;Commit 92bd40c6ee5ce095321d5e876591874abc0b462e in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=92bd40c ]

ACCUMULO-2082 Add in some better logging for the randomwalk Bulk tests.
","24/Dec/13 05:22;kturner;I think I have tracked this down.  In Tablet.majorCompact() when a threads decides it should not compact, it goes to the finally block and sets majorCompactionInProgress to false.  This is done even if another thread is compacting and has set majorCompactionInProgress to true.  This allows multiple threads to enter the major compaction code, where they bump into the sanity check.   I looked in the 1.5 branch and the problem does not seem to exist.  I tracked down the commit ff226a78 that introduced this to see if it was a merge problem, but it was not.

","24/Dec/13 06:17;jira-bot;Commit db746960fbcafb1651c15ec2e5493d56acb5065c in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=db74696 ]

ACCUMULO-2082 fixed bug that allowed multiple threads to attempt to compact a single tablet
","24/Dec/13 06:21;jira-bot;Commit db746960fbcafb1651c15ec2e5493d56acb5065c in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=db74696 ]

ACCUMULO-2082 fixed bug that allowed multiple threads to attempt to compact a single tablet
",24/Dec/13 14:56;elserj;Awesome! I'll try to test out this change and see if it fixes things for me. Thanks for looking at this. ,"25/Dec/13 03:48;elserj;I'm running another round of Bulk.xml and things appear to be running much better. Thanks again for your help, [~kturner].",11/Jun/14 20:08;ecn;Still broken.  I've seen it while running ContinuousIngest on 38-node cluster.,11/Jun/14 20:13;ecn;Need to open a new ticket for 1.7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improper handling of rename in root tablet file management,ACCUMULO-2428,12698802,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,05/Mar/14 03:54,08/May/14 21:52,13/Mar/19 22:01,05/Mar/14 23:08,1.4.0,,,,,,,1.5.2,1.6.0,,,,,,,,0,,,,,"While working on ACCUMULO-2190 I noticed that the code that handles root tablet compactions does not handle renames returning false very well.  In some cases it does nothing, in others it logs  a warning when it should probably throw an exception.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-05 23:04:59.425,,,no_permission,,,,,,,,,,,,377150,,,Thu May 08 21:52:21 UTC 2014,,,,,,0|i1szmn:,377445,,,,,,,,"05/Mar/14 23:04;jira-bot;Commit 4fd48fd2390cc3f4f2e76933833506ab26132c2c in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4fd48fd ]

ACCUMULO-2428 throw exception when rename fails after compaction
","05/Mar/14 23:05;jira-bot;Commit 4fd48fd2390cc3f4f2e76933833506ab26132c2c in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4fd48fd ]

ACCUMULO-2428 throw exception when rename fails after compaction
","05/Mar/14 23:05;jira-bot;Commit 4fd48fd2390cc3f4f2e76933833506ab26132c2c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4fd48fd ]

ACCUMULO-2428 throw exception when rename fails after compaction
","05/Mar/14 23:05;jira-bot;Commit 4fd48fd2390cc3f4f2e76933833506ab26132c2c in accumulo's branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4fd48fd ]

ACCUMULO-2428 throw exception when rename fails after compaction
","08/May/14 21:52;ctubbsii;Dropped 1.4.6 fix version, as that version doesn't exist (and isn't planned to exist, since active development on 1.4 has stopped). This fix was included in the abandoned branch at git commit: 5bd4465c433860624091b0d97892e02f58154e7a",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Getting ""cp: illegal option -- u"" when running bootstrap_config.sh on Mac",ACCUMULO-1401,12646840,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,sonixbp,sonixbp,sonixbp,09/May/13 19:14,29/Apr/14 16:36,13/Mar/19 22:01,13/May/13 15:36,,,,,,,,1.5.0,,,,,,,,,0,,,,,Mac's cp command does not support a -u option. rsync works but we should find a better way that supports Mac users.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11/May/13 03:49;sonixbp;ACCUMULO-1401.1.patch;https://issues.apache.org/jira/secure/attachment/12582764/ACCUMULO-1401.1.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-05-13 16:13:39.169,,,no_permission,,,,,,,,,,,,327197,,,Mon May 13 16:24:25 UTC 2013,,,,,,0|i1kgdj:,327541,,,,,,,,"11/May/13 03:50;sonixbp;rsync is supported in Mac by default- if ""cp -u"" doesn't exist, then fallback to rsync.","13/May/13 16:13;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #220 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/220/])
    Applying patch ACCUMULO-1401 (Revision 1481928)

     Result = SUCCESS
cjnolet : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/bin/bootstrap_config.sh
","13/May/13 16:16;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #111 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/111/])
    Applying patch ACCUMULO-1401 (Revision 1481924)

     Result = SUCCESS
cjnolet : 
Files : 
* /accumulo/branches/1.5/bin/bootstrap_config.sh
","13/May/13 16:23;hudson;Integrated in Accumulo-Trunk #862 (See [https://builds.apache.org/job/Accumulo-Trunk/862/])
    Applying patch ACCUMULO-1401 (Revision 1481928)

     Result = SUCCESS
cjnolet : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/bin/bootstrap_config.sh
","13/May/13 16:24;hudson;Integrated in Accumulo-1.5 #109 (See [https://builds.apache.org/job/Accumulo-1.5/109/])
    Applying patch ACCUMULO-1401 (Revision 1481924)

     Result = SUCCESS
cjnolet : 
Files : 
* /accumulo/branches/1.5/bin/bootstrap_config.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
start-here.sh and stop-here.sh throw errors on OS X,ACCUMULO-1951,12682219,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,supermallen,supermallen,supermallen,02/Dec/13 20:37,28/Apr/14 19:26,13/Mar/19 22:01,02/Dec/13 20:56,1.5.1,,,,,,,1.5.2,1.6.0,,,,,,,,0,,,,,"The start-here.sh and stop-here.sh scripts throw errors when used on OS X because OS X's {{hostname}} command does not have a {{- a}} option.

I'm about to include a patch that makes things much nicer on OS X without breaking any other system (to my knowledge).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,02/Dec/13 20:38;supermallen;0001-Fixes-hostname-a-errors-on-OS-X.patch;https://issues.apache.org/jira/secure/attachment/12616612/0001-Fixes-hostname-a-errors-on-OS-X.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-12-02 20:56:48.331,,,no_permission,,,,,,,,,,,,361476,,,Tue Dec 03 19:39:08 UTC 2013,,,,,,0|i1qb87:,361775,,,,,,,,02/Dec/13 20:38;supermallen;Patch to address bug,02/Dec/13 20:56;vines;Seems to address issue without interfering with my ubuntu box,03/Dec/13 19:39;bhavanki;Works on CentOS.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nativeMap test doesn't run on OS X,ACCUMULO-1852,12677496,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,mberman,mberman,05/Nov/13 02:36,28/Apr/14 19:07,13/Mar/19 22:01,05/Dec/13 17:35,,,,,,,,1.6.0,,,build,,,,,,0,,,,,"The Makefile has bad includes for the test run, but even when I fix that, it still fails looking like it's not linking stdc++ properly.  [~elserj] and I both looked at it for a bit and couldn't make it work.

Since I last saw it succeed, I have both updated to Mavericks and merged in the change to have the pom manage make.

I also haven't seen NativeMapIT pass since the updates, so I'm wondering if it's not just the test execution that's broken, but also the actual nativemap build.",Mac OS X Mavericks,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,05/Dec/13 15:50;supermallen;0001-ACCUMULO-1852-Further-fixes-nativemap-test-on-OSX.patch;https://issues.apache.org/jira/secure/attachment/12617176/0001-ACCUMULO-1852-Further-fixes-nativemap-test-on-OSX.patch,14/Nov/13 22:13;bhavanki;ACCUMLUO-1852.patch;https://issues.apache.org/jira/secure/attachment/12613951/ACCUMLUO-1852.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-11-05 03:36:09.123,,,no_permission,,,,,,,,,,,,356871,,,Thu Dec 05 17:35:51 UTC 2013,,,,,,0|i1pisv:,357161,,,,,,,,"05/Nov/13 03:36;ctubbsii;NativeMapIT is a known issue and I can address that, but I don't have a Mac to reproduce the test failure in the Makefile.","13/Nov/13 21:41;bhavanki;I have some success with running NativeMapIT. Here is some background.

The suffix that Java uses to look for a library file changed from Java 6 to Java 7. Before, it was ""jnilib"". After, it is ""dylib"". The {{System.mapLibraryName()}} method is the originator of that difference; that method is used in {{NativeMap.getNativeLibPath()}}, whose result is used in the class's static initializer to try to load the library.

So, if you are still running Java 6 (like me!), the ""dylib"" file is never looked for. If you are running Java 7 (the Mavericks upgrade apparently removes Java, so of course you'd re-install 7), it looks for ""dylib"".

(By the way, the path also includes the result of {{Platform.getPlatform()}}, which adds the ""Mac_OS_X-x86_64-64"" component of the file name. See ACCUMULO-1843.

There is code in {{MiniAccumuloCluster}} specifically designed to copy the native map library into the ""mini-test"" test directory, under lib/native/map. The code there looks under ""server/src/main/c++"", which is OK for 1.5.x, but for 1.6.x it's ""server/native/target/<project-artifact-version>/<project-artifact-version>. Therefore, the copy never happens, and NativeMapIT fails since there is no library present.

So, I have two changes. I'll post a review once Review Board is OK, and I've run the tests all the way through with {{mvn verify}}.

1. Update the nativeMap Makefile to create .dylib and .jnilib copies of the library.
2. Update the code that looks for the libraries in {{MiniAccumuloCluster}} to look in the right spot, and copy any library it finds over (so, both jnilib and dylib).",13/Nov/13 22:57;bhavanki;Review available: https://reviews.apache.org/r/15499/,14/Nov/13 22:14;bhavanki;Patch applies to 1.6.0-SNAPSHOT (and higher).,"21/Nov/13 22:26;jira-bot;Commit 2aad7fe0af7701609df67dea3daf872a526761be in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2aad7fe ]

ACCUMULO-1852 Fix native maps on OS X 10.9
","21/Nov/13 22:31;ctubbsii;Fixed, tested on OS X 10.8.2 and 10.9.","21/Nov/13 22:41;jira-bot;Commit 2aad7fe0af7701609df67dea3daf872a526761be in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2aad7fe ]

ACCUMULO-1852 Fix native maps on OS X 10.9
","22/Nov/13 14:39;bhavanki;After pulling this ticket's commits, I'm still unable to run {{NativeMapIT}} on my Mac (10.8.5). I'm seeing UnsatisfiedLinkErrors. Am I verifying this ticket the wrong way, or perhaps I'm missing something in my environment?","22/Nov/13 15:21;bhavanki;I should follow up that it appears {{NativeMapIT}} passes when I run {{mvn verify}}, but not if I run {{mvn -Dtest=NativeMapIT -DfailIfNoTests=true test}}.",22/Nov/13 16:32;elserj;That's odd. The {{mvn test...}} invocation works for me.,25/Nov/13 19:33;bhavanki;... and today it's working for me. *shrug*,"29/Nov/13 20:29;vines;Hey [~bhavanki], do you mind closing https://reviews.apache.org/r/15499/",02/Dec/13 14:01;bhavanki;Done! Thanks for the bump.,"05/Dec/13 15:50;supermallen;This did not work for me on my laptop until I added one more include to the native map test path.  I'm submitting another patch, perhaps this bug needs to be reopened?",05/Dec/13 16:35;elserj;Weird - it works on my mac (mavericks). What's your OSX and Java version?,"05/Dec/13 16:40;bhavanki;I'm still working without that extra patch. I'm OSX 10.8.5, Java 1.6.0_65 (Apple's own). I found I needed to run mvn install before NativeMapIT would work (on 1.6.0-SNAPSHOT).

{noformat}
mvn -DskipTests=true clean install
mvn -Dtest=NativeMapIT -DfailIfNoTests=false test
{noformat}",05/Dec/13 16:44;elserj;Wait a second.. who is talking about which test now? [~supermallen] is `make test` or the NativeMapIT failing for you? Or both?,"05/Dec/13 16:55;mberman;I think he was talking about `make test`.  The error was about being unable to find jni_md.h.  It works for me (mavericks, 1.7.0_25), and it's pulling that file from /System/Library/Frameworks/JavaVM.framework/Headers/jni_md.h (which through a series of symlinks is really /System/Library/Frameworks/JavaVM.framework/Versions/A/Headers/jni_md.h).  Interestingly, the file is _not_ identical to the one in $JAVA_HOME/include/darwin/jni_md.h, which maybe means we should be careful about which one we choose.

In any case, I'm wondering which part of this isn't true for [~supermallen].  I believe he was running 1.7.0_45, so maybe they rearranged the header files?","05/Dec/13 17:00;supermallen;It was definitely just the basic 'make test' part that was failing for me.  On my Mac, for whatever reason, I do not have /System/Library/Frameworks/JavaVM.framework/Headers as a directory, so I'm not surprised it didn't work.  I am running 1.7.0_45.","05/Dec/13 17:08;elserj;Interesting. I'm on 1.7.0_40, /System/Library/Frameworks/JavaVM.framework/Headers is symlinked to /System/Library/Frameworks/JavaVM.framework/Versions/Current/Headers and contains jni_md.h, but my JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home, not /System/Library/blah-blah.

Honestly, I don't understand OSX java packaging one bit (/Library versus /System/Library), nor the differences between Apple java and Oracle Java.","05/Dec/13 17:11;supermallen;[~elserj] I agree that OSX packaging is just kind of a mess.  From a defensive ""let's just make this work"" perspective, I'm not sure there's any downside to just putting more include directories on that test line that cover the majority of cases, even if on certain systems those directories don't technically exist.  :)",05/Dec/13 17:14;elserj;Agreed -- just wanted to rule out the possibility of user configuration first.,"05/Dec/13 17:15;bhavanki;I think that Apple's Java (which discontinued with Java 7) lives under /System/Library, but Oracle's Java 7 and later live under /Library.

Sorry about the earlier confusion.

I noticed when I run {{make test}} that the Makefile picks up that I have Oracle's Java 7 installed and uses that as JAVA_HOME for its includes: /Library/Java/JavaVirtualMachines/jdk1.7.0_45.jdk/Contents/Home. I forced it to use Java 6's JAVA_HOME and it still worked: /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home.","05/Dec/13 17:16;bhavanki;Regardless, +1 to adding the include as a defensive measure anyway. :)","05/Dec/13 17:34;jira-bot;Commit f0c12cd04761b40b4642b9a03640c11ee72ce0e0 in branch refs/heads/1.6.0-SNAPSHOT from [~mallen]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f0c12cd ]

ACCUMULO-1852 Further fixes nativemap test on OSX

To make it work on my system I had to add this bit
to the include path for executing the test.

Signed-off-by: Josh Elser <elserj@apache.org>
","05/Dec/13 17:34;jira-bot;Commit f0c12cd04761b40b4642b9a03640c11ee72ce0e0 in branch refs/heads/master from [~mallen]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f0c12cd ]

ACCUMULO-1852 Further fixes nativemap test on OSX

To make it work on my system I had to add this bit
to the include path for executing the test.

Signed-off-by: Josh Elser <elserj@apache.org>
","05/Dec/13 17:35;elserj;New patch applied, thanks [~supermallen].",,,,,,,,,,,,,,,,,,,,,,,,,,,
Using non-default CONTINUOUS_CONF_DIR breaks agitation,ACCUMULO-2382,12696012,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,busbey,busbey,busbey,19/Feb/14 17:04,28/Apr/14 19:07,13/Mar/19 22:01,20/Mar/14 16:26,1.5.1,,,,,,,1.5.2,1.6.0,,test,,,,,,0,newbie,,,,"The start agitation script attempts to run the the various agitation scripts out of CONTINUOUS_CONF_DIR rather than out of the installation directory.

When CONTINUOUS_CONF_DIR points at configuration files outside of ACCUMULO_HOME/test/system/continuous, the start agitation scripts are missing and agitation fails with a message to the stderr log of the agitators. 

All are similar to this example, given ACCUMULO_CONF_DIR=/etc/accumulo/continuous and ACCUMULO_HOME=/usr/lib/accumulo-1.5.1-rc2, with start-agitator.sh run within /usr/lib/accumulo/1.5.1-rc2/test/system/continuous.

{noformat}
nohup: failed to run command `/etc/accumulo/continuous/master-agitator.pl': No such file or directory
{noformat}

Workaround: Either don't use agitation, place configuration files in the default location, or copy agitation perl scripts to CONTINUOUS_CONF_DIR",1.5.1-rc2 on CDH 4.5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20/Mar/14 07:23;busbey;ACCUMULO-2382.1-1.5.2-SNAPSHOT.patch.txt;https://issues.apache.org/jira/secure/attachment/12635734/ACCUMULO-2382.1-1.5.2-SNAPSHOT.patch.txt,20/Mar/14 07:23;busbey;ACCUMULO-2382.1-1.6.0-SNAPSHOT.patch.txt;https://issues.apache.org/jira/secure/attachment/12635735/ACCUMULO-2382.1-1.6.0-SNAPSHOT.patch.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2014-02-21 19:36:57.746,,,no_permission,,,,,,,,,,,,374489,,,Thu Mar 20 16:26:10 UTC 2014,,,,,,0|i1sj93:,374789,,,,,,,,"21/Feb/14 19:36;mdrob;Also breaks verification.

{noformat}
./run-verify.sh: line 31: /etc/accumulo/continuous/mapred-setup.sh: No such file or directory
{noformat}","20/Mar/14 07:23;busbey;patches attached, review board coming. 1.6.0 patch is applied after applying the 1.5.2 version and merging forward to 1.6.0 (the fixes for MR jobs were only applicable to 1.6).","20/Mar/14 16:26;jira-bot;Commit d22bf18f4ccb56e7fe263f6e5e1aaffe6d41d2b2 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d22bf18 ]

ACCUMULO-2382 make agitation work with a non-default CONTINUOUS_CONF_DIR.

* Change start-agitator to use inferred installation directory instead of passed in conf dir.
* Ensure tserver and master agitator default ot ACCUMULO_HOME if present, so that starting all as root works.
","20/Mar/14 16:26;jira-bot;Commit d22bf18f4ccb56e7fe263f6e5e1aaffe6d41d2b2 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d22bf18 ]

ACCUMULO-2382 make agitation work with a non-default CONTINUOUS_CONF_DIR.

* Change start-agitator to use inferred installation directory instead of passed in conf dir.
* Ensure tserver and master agitator default ot ACCUMULO_HOME if present, so that starting all as root works.
","20/Mar/14 16:26;jira-bot;Commit 0fb0369af97c5d1a299b2ec9119374ab982bdf89 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0fb0369 ]

ACCUMULO-2382 make continuous ingest test mapreduce jobs work with non-default CONTINUOUS_CONF_DIR
","20/Mar/14 16:26;jira-bot;Commit d22bf18f4ccb56e7fe263f6e5e1aaffe6d41d2b2 in accumulo's branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d22bf18 ]

ACCUMULO-2382 make agitation work with a non-default CONTINUOUS_CONF_DIR.

* Change start-agitator to use inferred installation directory instead of passed in conf dir.
* Ensure tserver and master agitator default ot ACCUMULO_HOME if present, so that starting all as root works.
","20/Mar/14 16:26;jira-bot;Commit 0fb0369af97c5d1a299b2ec9119374ab982bdf89 in accumulo's branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0fb0369 ]

ACCUMULO-2382 make continuous ingest test mapreduce jobs work with non-default CONTINUOUS_CONF_DIR
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooKeeperInstance close method should mark instance closed.,ACCUMULO-1889,12679053,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,busbey,busbey,busbey,13/Nov/13 16:53,28/Apr/14 19:06,13/Mar/19 22:01,19/Nov/13 17:40,1.4.5,1.5.1,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"(1.4.5 and 1.5.1 impact presumes ACCUMULO-1858 gets applied)

The current close() implementation on ZooKeeperInstance only marks a given instance as closed if the outstanding client count is 0.

{code}
  public synchronized void close() throws AccumuloException {
    if (!closed && clientInstances.decrementAndGet() == 0) {
      try {
        zooCache.close();
        ThriftUtil.close();
      } catch (InterruptedException e) {
        clientInstances.incrementAndGet();
        throw new AccumuloException(""Issues closing ZooKeeper."");
      }
      closed = true;
    }
  }
{code}

This is incorrect for two reason:

1) It allows continued operations on a given ZKI after it has had close() called on it

2) It allows a given ZKI to decrement the number of open clients more than once
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1858,,13/Nov/13 20:34;busbey;ACCUMULO-1889.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12613676/ACCUMULO-1889.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-11-13 20:26:24.396,,,no_permission,,,,,,,,,,,,358418,,,Mon Jan 06 22:43:46 UTC 2014,,,,,,0|i1psbr:,358708,,,,,,,,"13/Nov/13 17:08;busbey;review board of fix against 1.4.5-SNAPSHOT, presuming application of ACCUMULO-1858.

That combination should allow this fix to go against 1.4.5-SNAPSHOT and then forward merge cleanly through to master (modulo file renames).",13/Nov/13 20:26;kturner;[~busbey] nice catch.  Can you attach the patch?  RB is not working.,"13/Nov/13 20:34;busbey;Attaching patch for fix, against 1.4.5-SNAPSHOT branch (which presumes ACCUMULO-1858 is already applied)","13/Nov/13 20:40;ctubbsii;Good catch; my bad. Also, there's another issue I missed: the case where an AccumuloException is thrown while trying to close, then the counter is off again, which can result in a negative number of client connections, or (more importantly, closing resources that are actually still in use).",13/Nov/13 20:52;busbey;I can update the patch to account for that exception. Prefer it broken into its own block (to make refactoring when we want to correctly handle InterruptedException easier) or change the existing block to catch Exception (to make current code simpler)?,"13/Nov/13 21:14;ctubbsii;I don't like catching Exception, so I'd prefer a separate block that increments and re-throws. Exception isn't expressive enough about which exceptions the code is resilient against (one of the benefits of bumping to JDK 1.7 is reusing block, without losing expressiveness). Besides, ""Exception""-only runs the risk of somebody deleting the entire block when the InterruptedException is handled better, without realizing that AccumuloException still needs to be handled before being re-thrown.","13/Nov/13 21:27;busbey;patch updated per Chris' suggestion. Review board also updated, restarting functional tests.",13/Nov/13 21:33;busbey;Actually it looks like neither of those methods throws AccumuloException. rolling back.,"14/Nov/13 17:06;busbey;changing to patch submitted based on review board feedback.

Chris, let me know if you'd prefer I change ZooCache and ThriftUtil to have their close methods throw AccumuloException so we can get catching it properly in place proactively.","15/Nov/13 01:58;ctubbsii;Ugh. I hadn't realized how bad the InterruptedException got propagated throughout our interfaces, and I didn't realize that AccumuloException wasn't being thrown from the try block (only explicitly thrown in the catch block).

It seems to me that the best fix is to:
# patch org.apache.accumulo.fate.zookeeper.ZooReader.close() to handle the ZooKeeper close()'s InterruptedException properly with {{Thread.currentThread().interrupt()}}
# stop propagating InterruptedException through the hierarchy of close() statements
# drop the AccumuloException from the Instance.close() method signature and make Interface extend java.io.Closeable instead (at the very least, drop the unnecessary AccumuloException and make it AutoCloseable when we switch to JDK1.7; changing it to java.io.Closeable now would ease that)
# change that catch statement to catch RuntimeExceptions instead of InterruptedException and rethrow them after fixing the counter
","19/Nov/13 17:37;jira-bot;Commit ada4180379d46297c1531cf8065de5030d12953d in branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ada4180 ]

ACCUMULO-1889 mark ZKI as closed once close() is called.

Once a given ZKI has .close() called, mark that instance closed regardless of outstanding client count.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","19/Nov/13 17:43;jira-bot;Commit ada4180379d46297c1531cf8065de5030d12953d in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ada4180 ]

ACCUMULO-1889 mark ZKI as closed once close() is called.

Once a given ZKI has .close() called, mark that instance closed regardless of outstanding client count.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","19/Nov/13 17:44;jira-bot;Commit ada4180379d46297c1531cf8065de5030d12953d in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ada4180 ]

ACCUMULO-1889 mark ZKI as closed once close() is called.

Once a given ZKI has .close() called, mark that instance closed regardless of outstanding client count.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","19/Nov/13 17:45;jira-bot;Commit ada4180379d46297c1531cf8065de5030d12953d in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ada4180 ]

ACCUMULO-1889 mark ZKI as closed once close() is called.

Once a given ZKI has .close() called, mark that instance closed regardless of outstanding client count.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","19/Dec/13 21:27;jira-bot;Commit 674fa95cacaa9353142071a66006e0ffb65cae94 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=674fa95 ]

ACCUMULO-1889 found a few more ZooKeeperInstances that are not closed
","19/Dec/13 21:27;jira-bot;Commit 674fa95cacaa9353142071a66006e0ffb65cae94 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=674fa95 ]

ACCUMULO-1889 found a few more ZooKeeperInstances that are not closed
","20/Dec/13 17:23;bhavanki;[~ecn]: In commit 674fa95, {{InputConfigurator.getTabletLocator()}}: is the closing of the instance there OK? The instance object is preserved in a {{MetadataLocationObtainer}} object in the created locator, and that object uses it for tablet location lookups. I'm comparing this commit to the work I have ongoing in ACCUMUL0-1923. Thanks!","20/Dec/13 17:33;ecn;[~bhavanki] it is ok, but it's not really obvious that it is.

The uses of the instance in that code uses a lower-level API, and doesn't use it to create connectors.  It just references instanceId and zookeeper values.

It might fail in the future if someone changes the code to use a higher level API.  We may be safe from that because the higher level API needs the Locator to work.  We could scramble the state of the Instance in Instance.close, and then we would not be able to close it like I did in 
{{InputConfigurator.getTabletLocator()}}.","20/Dec/13 18:15;bhavanki;Thanks for the information! It might be good to try separating the instance information, like ID and zookeepers, from the active components that require closure, so that it's easier to make cases such as this one easier to grok.","20/Dec/13 19:19;busbey;[~ecn] and [~bhavanki], this discussion (and that last patch) appear to all be related to ACCUMULO-1923 rather than this ticket. Could we move discussion over there please?","06/Jan/14 20:20;jira-bot;Commit 016f3bb10c43f6461c5d41025b0e07b50f1638a2 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=016f3bb ]

ACCUMULO-2128 Revert ""ACCUMULO-1889 found a few more ZooKeeperInstances that are not closed""

This reverts commit 674fa95cacaa9353142071a66006e0ffb65cae94.

Conflicts:
	core/src/main/java/org/apache/accumulo/core/client/mapreduce/AbstractInputFormat.java
","06/Jan/14 22:37;jira-bot;Commit e946ba052c3fcce8d07815b9daf51bcdc3febbd3 in branch refs/heads/1.4.5-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e946ba0 ]

ACCUMULO-1858 revert commits that added ZooKeeperInstance.close()

Revert ""ACCUMULO-2027 Synchronized access to ZooKeeperInstance methods that mutated state""

This reverts commit 975e8c05e8d11f3848e6c800f4d2772026f6c3a3.

Revert ""ACCUMULO-1984 Rework interruption for instance implementations.""

This reverts commit 0d0bc4643a8680593e2cf5f828b7566c30fcb345.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java

Revert ""ACCUMULO-1889 mark ZKI as closed once close() is called.""

This reverts commit ada4180379d46297c1531cf8065de5030d12953d.

Revert ""ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.""

This reverts commit 79d686faa1e477b9cbd80c6f833ece402050b490.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
","06/Jan/14 22:40;jira-bot;Commit e946ba052c3fcce8d07815b9daf51bcdc3febbd3 in branch refs/heads/1.5.1-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e946ba0 ]

ACCUMULO-1858 revert commits that added ZooKeeperInstance.close()

Revert ""ACCUMULO-2027 Synchronized access to ZooKeeperInstance methods that mutated state""

This reverts commit 975e8c05e8d11f3848e6c800f4d2772026f6c3a3.

Revert ""ACCUMULO-1984 Rework interruption for instance implementations.""

This reverts commit 0d0bc4643a8680593e2cf5f828b7566c30fcb345.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java

Revert ""ACCUMULO-1889 mark ZKI as closed once close() is called.""

This reverts commit ada4180379d46297c1531cf8065de5030d12953d.

Revert ""ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.""

This reverts commit 79d686faa1e477b9cbd80c6f833ece402050b490.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
","06/Jan/14 22:43;jira-bot;Commit e946ba052c3fcce8d07815b9daf51bcdc3febbd3 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e946ba0 ]

ACCUMULO-1858 revert commits that added ZooKeeperInstance.close()

Revert ""ACCUMULO-2027 Synchronized access to ZooKeeperInstance methods that mutated state""

This reverts commit 975e8c05e8d11f3848e6c800f4d2772026f6c3a3.

Revert ""ACCUMULO-1984 Rework interruption for instance implementations.""

This reverts commit 0d0bc4643a8680593e2cf5f828b7566c30fcb345.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java

Revert ""ACCUMULO-1889 mark ZKI as closed once close() is called.""

This reverts commit ada4180379d46297c1531cf8065de5030d12953d.

Revert ""ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.""

This reverts commit 79d686faa1e477b9cbd80c6f833ece402050b490.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Scalability test does not run,ACCUMULO-2042,12685222,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,bhavanki,bhavanki,17/Dec/13 19:21,28/Apr/14 19:00,13/Mar/19 22:01,07/Jan/14 14:42,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,test,,,,,,0,,,,,"Attempting to run the scalability test:

{noformat}
cd test/system/scalability && ./run.py Ingest
{noformat}

fails to locate the test class:

java.lang.ClassNotFoundException: accumulo.server.test.scalability.Ingest

This is because the {{Class.forName()}} call in the main {{Run}} class uses an incorrect package. (This is a Java problem, not a Python problem, so it persists even in master.)

I would not assume that, once this minor issue is fixed, that the scalability test will then run without trouble, so consider using this ticket to cover all work needed to get scalability tests going.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20/Dec/13 16:34;bhavanki;ACCUMULO-2042.patch;https://issues.apache.org/jira/secure/attachment/12619855/ACCUMULO-2042.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-01-07 14:23:37.103,,,no_permission,,,,,,,,,,,,364299,,,Tue Jan 07 14:28:21 UTC 2014,,,,,,0|i1qskf:,364599,,,,,,,,"19/Dec/13 17:32;bhavanki;Review of, as it turns out, minor changes available.","07/Jan/14 14:23;jira-bot;Commit a3d77e4ff2a12f161f1343490f42aa91d5b109d3 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3d77e4 ]

ACCUMULO-2042 Get scalability test running

Two problems prevented scalability tests from being run properly.
1. The Run class was looking for test classes under the ""accumulo""
   package instead of ""org.apache.accumulo"".
2. A results subdirectory on the local filesystem was not being
   created, and so result data from HDFS could not be copied out.

This commit also updates the scalability test README with more
detail.
","07/Jan/14 14:24;jira-bot;Commit a3d77e4ff2a12f161f1343490f42aa91d5b109d3 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3d77e4 ]

ACCUMULO-2042 Get scalability test running

Two problems prevented scalability tests from being run properly.
1. The Run class was looking for test classes under the ""accumulo""
   package instead of ""org.apache.accumulo"".
2. A results subdirectory on the local filesystem was not being
   created, and so result data from HDFS could not be copied out.

This commit also updates the scalability test README with more
detail.
","07/Jan/14 14:24;jira-bot;Commit 833ac35339e91893063aba0f5cde8ff4886b2337 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=833ac35 ]

ACCUMULO-2042 Merge branch '1.4.5-SNAPSHOT' into 1.5.1-SNAPSHOT

Conflicts:
	test/src/main/java/org/apache/accumulo/test/scalability/Run.java
","07/Jan/14 14:25;jira-bot;Commit a3d77e4ff2a12f161f1343490f42aa91d5b109d3 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3d77e4 ]

ACCUMULO-2042 Get scalability test running

Two problems prevented scalability tests from being run properly.
1. The Run class was looking for test classes under the ""accumulo""
   package instead of ""org.apache.accumulo"".
2. A results subdirectory on the local filesystem was not being
   created, and so result data from HDFS could not be copied out.

This commit also updates the scalability test README with more
detail.
","07/Jan/14 14:25;jira-bot;Commit 833ac35339e91893063aba0f5cde8ff4886b2337 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=833ac35 ]

ACCUMULO-2042 Merge branch '1.4.5-SNAPSHOT' into 1.5.1-SNAPSHOT

Conflicts:
	test/src/main/java/org/apache/accumulo/test/scalability/Run.java
","07/Jan/14 14:26;jira-bot;Commit c4cddf97f86d3a20a945c417eb5546f8a0c2e54a in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c4cddf9 ]

ACCUMULO-2042 Merge branch '1.5.1-SNAPSHOT' into 1.6.0-SNAPSHOT
","07/Jan/14 14:26;jira-bot;Commit a3d77e4ff2a12f161f1343490f42aa91d5b109d3 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3d77e4 ]

ACCUMULO-2042 Get scalability test running

Two problems prevented scalability tests from being run properly.
1. The Run class was looking for test classes under the ""accumulo""
   package instead of ""org.apache.accumulo"".
2. A results subdirectory on the local filesystem was not being
   created, and so result data from HDFS could not be copied out.

This commit also updates the scalability test README with more
detail.
","07/Jan/14 14:27;jira-bot;Commit 833ac35339e91893063aba0f5cde8ff4886b2337 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=833ac35 ]

ACCUMULO-2042 Merge branch '1.4.5-SNAPSHOT' into 1.5.1-SNAPSHOT

Conflicts:
	test/src/main/java/org/apache/accumulo/test/scalability/Run.java
","07/Jan/14 14:27;jira-bot;Commit c4cddf97f86d3a20a945c417eb5546f8a0c2e54a in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c4cddf9 ]

ACCUMULO-2042 Merge branch '1.5.1-SNAPSHOT' into 1.6.0-SNAPSHOT
","07/Jan/14 14:28;jira-bot;Commit a72e80ca45962e807b5195e5f619e8da5b537c43 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a72e80c ]

ACCUMULO-2042 Merge branch '1.6.0-SNAPSHOT'
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NoSuchMethodError when compiling 1.7.0 Snapshot,ACCUMULO-1874,12678444,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,medined,medined,10/Nov/13 10:59,28/Apr/14 18:59,13/Mar/19 22:01,10/Nov/13 22:45,,,,,,,,1.6.0,,,build,,,,,,0,,,,,"Using 'git clone https://github.com/apache/accumulo.git' I ran this command:

mvn package -Dhadoop.profile=1.2 -Dhadoop.version=1.0.4 -Passemble

I see this error:

testFileMonitor(org.apache.accumulo.start.classloader.vfs.providers.VfsClassLoaderTest)  Time elapsed: 0.004 sec  <<< ERROR!
java.lang.NoSuchMethodError: org.apache.hadoop.hdfs.MiniDFSCluster.getFileSystem()Lorg/apache/hadoop/hdfs/DistributedFileSystem;
	at org.apache.accumulo.test.AccumuloDFSBase.<clinit>(AccumuloDFSBase.java:71)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)",Ubuntu 12.04 inside a virtualbox.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-10 14:39:01.481,,,no_permission,,,,,,,,,,,,357819,,,Thu Nov 14 01:20:39 UTC 2013,,,,,,0|i1pon3:,358109,,,,,,,,10/Nov/13 14:39;billie.rinaldi;Thanks for pointing this out.  I'm looking at it now.  I may need assistance testing. Does anyone know why this is platform dependent?,"10/Nov/13 15:04;billie.rinaldi;[~medined], I believe this error happened because ""clean"" was not included in your command, i.e. ""mvn clean package ..."".  However, another error occurs when trying to compile against a hadoop version earlier than 1.2, because examples.simple.mapreduce.TokenWordFileCount  was recently switched from ""new Job"" (which is deprecated in 1.2) to ""Job.getInstance"".  Presumably we should keep the deprecated usage to allow building against more versions of hadoop?","10/Nov/13 16:17;medined;I am using brand-new VirtualBox VMs for the compilation using my https://github.com/medined/Accumulo_Snapshot_By_Vagrant project so the experiment is repeatable. The HADOOP_1_0_4 branch displays the NoSuchMethodError behavior.

I did update the configuration scripts to use Hadoop 1.2.1 to see if that causes a behavior change. It did. The NoSuchMethodError does not persist. But compilation now says ""could not find artifact org.apache.accumulo:accumulo-native:tar.gz:1.7.0-SNAPSHOT in apache.snapshots"". I'll make another JIRA ticket for this.

The Vagrant boxes are provisioned by shell scripts so they are easy to understand. They install Accumulo to the /home/vagrant/accumulo_home/software/accumulo-1.7.0 directory. ","10/Nov/13 16:26;jira-bot;Commit d868e30d7bc60b3478272bbdd395a45a5ba05a69 in branch refs/heads/1.6.0-SNAPSHOT from [~billie.rinaldi@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d868e30 ]

ACCUMULO-1874 removed usage of Job.getInstance, moved job instance creation to a utility class for examples
","10/Nov/13 16:33;jira-bot;Commit d868e30d7bc60b3478272bbdd395a45a5ba05a69 in branch refs/heads/master from [~billie.rinaldi@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d868e30 ]

ACCUMULO-1874 removed usage of Job.getInstance, moved job instance creation to a utility class for examples
","10/Nov/13 16:34;jira-bot;Commit f63448c9cc93757fd904522ea4d3493d2ff0f559 in branch refs/heads/master from [~billie.rinaldi@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f63448c ]

ACCUMULO-1874 Merge branch '1.6.0-SNAPSHOT'
","10/Nov/13 17:03;billie.rinaldi;Not to sound superstitious, but ... I have occasionally observed vagrant VMs exhibiting behavior that would indicate that the VMs preserve some state when you destroy and start them again.  Anyway, I cloned your accumulo vagrant project (which is awesome, by the way), edited install_accumulo.sh so the mvn command used hadoop.version=1.0.4, and ran {{vagrant up}}.  I got the accumulo-native error, not the NoSuchMethod error.  If you're still getting the NoSuchMethod error with 1.0.4, could you try adding ""clean"" to the command (for superstition's sake) and verify that doesn't fix the error?",10/Nov/13 22:45;medined;The NoSuchMethod error is no longer happening.,"14/Nov/13 01:19;jira-bot;Commit feb0f3151d9849c7cca669278ec2d9a8f7aeec35 in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=feb0f31 ]

ACCUMULO-1874 Remove warning
","14/Nov/13 01:20;jira-bot;Commit feb0f3151d9849c7cca669278ec2d9a8f7aeec35 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=feb0f31 ]

ACCUMULO-1874 Remove warning
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Re-queue tablets immediately after major compaction if there is more work,ACCUMULO-314,12538366,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,13/Jan/12 22:38,25/Apr/14 19:17,13/Mar/19 22:01,24/Jan/12 18:53,1.3.5-incubating,,,,,,,1.4.0,,,tserver,,,,,,0,14_qa_bug,,,,"While running the random walk test, I noticed the shard test was running slowly sometimes thanks to ACCUMULO-273.

{noformat}
13 19:56:47,284 [shard.Merge] DEBUG: merging ST_index_6389_1326478898465
13 19:56:52,543 [shard.Insert] DEBUG: Inserted document ac64000000000000
13 19:56:54,016 [shard.Commit] DEBUG: Committed inserts
13 19:56:54,019 [shard.Insert] DEBUG: Inserted document bc64000000000000
13 19:56:54,020 [shard.Insert] DEBUG: Inserted document cc64000000000000
13 19:56:54,021 [shard.Insert] DEBUG: Inserted document dc64000000000000
13 19:56:54,022 [shard.Insert] DEBUG: Inserted document ec64000000000000
13 19:56:54,023 [shard.Insert] DEBUG: Inserted document fc64000000000000
13 19:56:54,025 [shard.Insert] DEBUG: Inserted document 0d64000000000000
13 19:56:54,026 [shard.Insert] DEBUG: Inserted document 1d64000000000000
13 19:56:54,055 [shard.Commit] DEBUG: Committed inserts
13 19:56:54,068 [shard.Search] DEBUG: Looking up terms [154l, 1kzi] expect to find 9ee0000000000000
13 20:01:54,102 [randomwalk.Module] WARN : Node org.apache.accumulo.server.test.randomwalk.shard.Search has been running for 300.0 seconds. You may want to look into it.
13 20:05:52,530 [randomwalk.Module] WARN : Node org.apache.accumulo.server.test.randomwalk.shard.Search, which was running long, has now completed after 538.475 seconds
{noformat}

I noticed a merge usually preceded the slow lookups.  I looked the the master logs and saw that the merge finished ok and saw which tablet server the merged tablet was assigned to. Below are some snippets from the master log that show the table id and tablet server.

{noformat}
13 18:36:43,236 [tableOps.RenameTable] DEBUG: Renamed table 1bk ST_index_6389_1326478898465_tmp ST_index_6389_1326478898465

13 19:56:47,293 [tableOps.Utils] INFO : table 1bk (3b08cf01ba49883) locked for write operation: MERGE

13 19:56:52,496 [tableOps.Utils] INFO : table 1bk (3b08cf01ba49883) unlocked for write
13 19:56:52,504 [master.Master] DEBUG: Normal Tablets assigning tablet 1bk<<=xxx.xxx.xxx.xxx:9997[134d7425fc503db]
{noformat}

Some snippets from the tablet server logs are below and this shows the problem.

{noformat}
13 19:56:52,522 [tabletserver.Tablet] TABLET_HIST: 1bk<< opened

13 19:56:54,065 [tabletserver.Tablet] WARN : Tablet 1bk<< has too many files, batch lookup can not run

13 19:57:10,383 [tabletserver.Compactor] DEBUG: Compaction 1bk<< 6,954 read | 6,954 written | 108,656 entries/sec |  0.064 secs
13 19:57:10,402 [tabletserver.Tablet] TABLET_HIST: 1bk<< MajC [/t-0000qzs/C0000sj3.rf, /t-0000qzt/F0000rtf.rf, /t-0000qzt/F0000s0r.rf, /t-0000qzz/F0000sc0.rf, /t-0000r00/F0000s0v.rf, /t-0000r0f/C0000rpu.rf, /t-0000r0l/C0000qqz.rf, /t-0000rqt/C0000s3m.rf, /t-0000rra/C0000sbx.rf, /t-0000rrh/F0000sgj.rf] --> /c-00000054/C0000soe.rf

13 19:57:40,534 [tabletserver.Compactor] DEBUG: Compaction 1bk<< 21,036 read | 21,036 written | 104,656 entries/sec |  0.201 secs
13 19:57:40,564 [tabletserver.Tablet] TABLET_HIST: 1bk<< MajC [/t-0000qzm/C0000rfa.rf, /t-0000r0l/F0000sc6.rf, /t-0000rr1/C0000rpr.rf, /t-0000rr4/F0000sc2.rf, /t-0000rr5/F0000rq0.rf, /t-0000rr9/F0000s0y.rf, /t-0000rrb/F0000sc5.rf, /t-0000rrs/F0000sc7.rf, /t-0000rs1/F0000ssf.rf, /t-0000rs2/F0000ssg.rf] --> /c-00000054/C0000son.rf
{noformat}

The problem is that the merged tablet has too many files to open, so the batch scan for the shard test can not run.  However it takes the tablet server forver to work this issue out.  Every 30 seconds it compacts 10 tablet files down to one.  The compactions take a few hundred milliseconds, so it could be worked out much faster if the compactions occurred back to back.

In 1.3 compactions were changed from depth first to breadth first (e.g. if a tablet server has 100 tablets and all have 100 files, instead of compacting each tablet to one file go across the tablets compacting 10 at a time until each tablet has one file).  This change introduced this bug.  There is no need to wait 30 seconds between compactions in this case.",1.4.0-SNAPSHOT on 10 node cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,223872,,,Fri Jan 13 22:42:47 UTC 2012,,,,,,0|i07nxj:,42643,,,,,,,,13/Jan/12 22:42;kturner;Re-queuing tablet for compaction immediately if there is more work to will still preserve the breadth first nature because tablet in the compaction queue are sorted by the number of files.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shell needs add aggregator ability restored,ACCUMULO-606,12558107,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,25/May/12 14:23,25/Apr/14 18:35,13/Mar/19 22:01,25/May/12 18:32,,,,,,,,1.5.0,,,client,,,,,,0,,,,,"We removed the ability to add aggregators in the shell. We are keeping aggs for a while, so as long as we have aggregators we need to maintain the shell commands for it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246460,,,2012-05-25 14:23:28.0,,,,,,0|i07m5z:,42357,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AccumuloSecurityException might be thrown instead of TableNotFoundException on flush or clone,ACCUMULO-2293,12692382,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,30/Jan/14 21:36,25/Apr/14 15:18,13/Mar/19 22:01,30/Jan/14 22:06,1.5.0,,,,,,,1.5.1,1.6.0,,client,,,,,,0,1.5.1-findbugs,findbugs,,,"When examining findbugs, I found that in the face of a {{ThriftSecurityException}} on {{TableOperationsImpl._flush}}, we check against the wrong {{SecurityErrorCode}} and would incorrectly throw an {{AccumuloSecurityException}} instead of a {{TableNotFoundException}} when the {{ThriftSecurityException}} contains a {{SecurityErrorCode.TABLE_DOESNT_EXIST}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-30 22:00:51.705,,,no_permission,,,,,,,,,,,,370977,,,Thu Jan 30 22:00:53 UTC 2014,,,,,,0|i1rxpz:,371282,,,,,,,,"30/Jan/14 22:00;jira-bot;Commit 5fe2cccaf2266e3f8d2d8ebcb4d2fafb0e24e181 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5fe2ccc ]

ACCUMULO-2293 Check the correct SecurityErrorCode on ThriftSecurityException in the _flush method
","30/Jan/14 22:00;jira-bot;Commit 5fe2cccaf2266e3f8d2d8ebcb4d2fafb0e24e181 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5fe2ccc ]

ACCUMULO-2293 Check the correct SecurityErrorCode on ThriftSecurityException in the _flush method
","30/Jan/14 22:00;jira-bot;Commit 5fe2cccaf2266e3f8d2d8ebcb4d2fafb0e24e181 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5fe2ccc ]

ACCUMULO-2293 Check the correct SecurityErrorCode on ThriftSecurityException in the _flush method
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OfflineIterator does not bound range,ACCUMULO-654,12595987,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,kturner,kturner,26/Jun/12 21:35,23/Apr/14 16:46,13/Mar/19 22:01,24/Jul/12 18:46,1.4.0,,,,,,,1.4.2,1.5.0,,client,,,,,,0,findbugs,,,,Saw this while looking at output of findbugs.  When the OfflineIterator bounds the range it stores the result to a local var instead of the instance var.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246413,,,2012-06-26 21:35:20.0,,,,,,0|i07lvj:,42310,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide better error handling when unable to cleanly close log,ACCUMULO-2208,12689292,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,16/Jan/14 17:14,23/Apr/14 15:22,13/Mar/19 22:01,22/Apr/14 21:40,1.5.0,,,,,,,1.5.1,1.6.0,,tserver,,,,,,0,,,,,"I saw this once over 36 tserver/days, caused by an InvalidArgumentException, so odd occurrence. It was doing CI but before agitation started so it was a non issue, but it could be. The code around this is
{code}for (DfsLogger logger : loggers) {
        try {
          logger.close();
        } catch (DfsLogger.LogClosedException ex) {
          // ignore
        } catch (Throwable ex) {
          log.error(""Unable to cleanly close log "" + logger.getFileName() + "": "" + ex);
        }
      }
      loggers.clear();
      logSizeEstimate.set(0);{code}

so it seems like it blindly powered forward. However, because of the frequency of syncs and such, even if there was agitation the odds of losing data are very minute, but I do believe their still there.

But  because the log message just relies on error.toString, I didn't get the violating stack trace. At the bare minimum, the message should be updated to log the full stack trace.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-16 17:26:21.22,,,no_permission,,,,,,,,,,,,368259,,,Tue Apr 22 21:45:11 UTC 2014,,,,,,0|i1rh27:,368564,,,,,,,,"16/Jan/14 17:26;jira-bot;Commit fe1348fd0087c85f116d50c4abe09215a893766f in branch refs/heads/1.5.1-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fe1348f ]

ACCUMULO-2208 Provides better error message in case this happens again
","16/Jan/14 17:51;jira-bot;Commit fe1348fd0087c85f116d50c4abe09215a893766f in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fe1348f ]

ACCUMULO-2208 Provides better error message in case this happens again
","17/Jan/14 16:45;vines;FTR, the error I saw has been traced back to the work I've been doing in 1998. Not sure if we want better handling here though.","22/Apr/14 21:33;mdrob;Closing as resolved, to track work done in 1.6.0 release.

[~ctubbsii] - Please update the CHANGES file for 1.6.0 accordingly

[~vines] - If you see this error again, please create a follow-on JIRA.",22/Apr/14 21:45;mdrob;Setting fixVersion to 1.6.1 and 1.7.0 so that [~ctubbsii] can easily find it during his RC-cleanup scan.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cannot create splits with MSBit set in MSByte via API,ACCUMULO-2437,12699353,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,busbey,kimballa,kimballa,07/Mar/14 06:32,16/Apr/14 00:28,13/Mar/19 22:01,18/Mar/14 17:49,1.5.1,,,,,,,1.5.2,1.6.0,,client,docs,,,,,0,,,,,"I cannot create a table with 256 evenly-sliced splits using the API. I believe due to the fact that Text can only hold valid Unicode characters, the following only generates 129 splits:

{code}
    TableOperations tableOps = connector.tableOperations();
    TreeSet<Text> splits = new TreeSet<Text>();
    for (int i = 0; i < 256; i++) { 
      byte[] bytes = { (byte) i };
      String theStr = new String(bytes);
      splits.add(new Text(theStr));
    } 
    tableOps.addSplits(TABLE_NAME, splits);
{code}

Using {{getsplits}} in the shell, I see the highest split be 0x7F; while we can use byte values 0x80 through 0xFF as leading bytes in row keys, the use of {{Text}} in the {{addSplits()}} method makes these invalid strings to split on.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,18/Mar/14 08:26;busbey;ACCUMULO-2437.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12635261/ACCUMULO-2437.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-03-07 15:41:03.799,,,no_permission,,,,,,,,,,,,377700,,,Tue Mar 18 17:48:33 UTC 2014,,,,,,0|i1t2zj:,377992,,,,,,,,"07/Mar/14 06:33;kimballa;I also tried ranging i from -127 to 127 for good measure.


For what its worth, the following lines do work in the Accumulo shell:

{code}addsplits \x80 -t entity_test
addsplits \x81 -t entity_test
addsplits \x82 -t entity_test
...{code}

so its possible to add the high-bit byte-centric splits there. I think the limitation is in the API's use of Text more than a fundamental implementation detail
","07/Mar/14 15:41;vines;Don't go through a String
intead of
{code}
      byte[] bytes = { (byte) i };
      String theStr = new String(bytes);
      splits.add(new Text(theStr));
{code}

do

{code}
      byte[] bytes = { (byte) i };
      splits.add(new Text(bytes));
{code}","07/Mar/14 17:57;kimballa;John, Thanks for the tip! The code fragment you offered will behave as I expect (creating 256 uniform splits).

As a nitpick though, the API for {{o.a.h.io.Text}} specifies that its byte stream should be UTF-8 encoded. The constructor that you suggest will not perform any translation/validation, so it works in this case. But it is possible that a Text object with such data in it will experience other errors if other of its methods are used (e.g., if you call {{toString()}} on such a text, it will return a {{RuntimeException}}). 

That having been said, reading through the source of Text, it doesn't enforce UTF-8 except at certain boundaries like {{toString()}} or {{charAt()}}, so it is capable of holding, serializing, and deserializing byte arrays that are not legal UTF-8... So you're probably in the clear in practice as long as clients are mindful not to actually treat the {{Text}} instances as true strings.

(see https://github.com/apache/hadoop-common/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/Text.java for reference)

If that kind of API precision isn't desired, please feel free to resolve this as Invalid or Wontfix.","07/Mar/14 18:48;vines;Yeah, Text is more of a byte container with some psuedo string functionality. It's not really clear, but that's how we use it.","07/Mar/14 18:56;busbey;While we may treat Text as a byte container, I don't think that lines up with how Hadoop documents it (even if historically the implementation allows it).

I'd like to see all of our APIs offer a better byte interface so we can deprecate and eventually phase out use of Text.","09/Mar/14 15:24;ctubbsii;It seems to me that there's a valid workaround for this now, and the work to phase out Text in place of a better byte interface is a separate issue.",10/Mar/14 14:28;busbey;Good point [~ctubbsii]. I'd like to make sure the work around is in the javadocs for this ticket. I filed ACCUMULO-2445 for follow on to cover the API changes.,18/Mar/14 08:25;busbey;Attaching review board of proposed javadoc change.,"18/Mar/14 08:26;busbey;Initial javadocs, in case RB goes down.","18/Mar/14 17:48;jira-bot;Commit 205f0dca8cc86d2c8ecab710719cfb7682920ed1 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=205f0dc ]

ACCUMULO-2437 Add javadoc for addSplits that documents the workaround using Text's byte[] constructor.
","18/Mar/14 17:48;jira-bot;Commit 205f0dca8cc86d2c8ecab710719cfb7682920ed1 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=205f0dc ]

ACCUMULO-2437 Add javadoc for addSplits that documents the workaround using Text's byte[] constructor.
","18/Mar/14 17:48;jira-bot;Commit 205f0dca8cc86d2c8ecab710719cfb7682920ed1 in accumulo's branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=205f0dc ]

ACCUMULO-2437 Add javadoc for addSplits that documents the workaround using Text's byte[] constructor.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Misc functional test fixes,ACCUMULO-1520,12653465,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,18/Jun/13 15:05,11/Apr/14 15:54,13/Mar/19 22:01,18/Jun/13 23:23,,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,"* In TestUtils.getTableId, allow for the warning statement ""Unable to load native-hadoop library"" since hadoop doesn't have native libs for Mac.
* In examples, the dir list example is trying to index ACCUMULO_HOME/fate, which doesn't exist due to the new packaging; index the test directory instead, and search for itself (test/system/auto/simple/examples.py).
* LargeRowTest is failing again because it found 26 split points! Upping the max number of splits to NUM_PRE_SPLITS * 4 passes, but I did not look into why it had too many.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-18 22:52:04.539,,,no_permission,,,,,,,,,,,,333743,,,Tue Jun 18 23:19:45 UTC 2013,,,,,,0|i1lkmf:,334071,,,,,,,,"18/Jun/13 22:52;jira-bot;Commit 1494361 from [~billie.rinaldi]
[ https://svn.apache.org/r1494361 ]

ACCUMULO-1520 misc functional test fixes","18/Jun/13 23:19;jira-bot;Commit 1494368 from [~billie.rinaldi]
[ https://svn.apache.org/r1494368 ]

ACCUMULO-1520 misc functional test fixes - merge to trunk",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Can't batchscan over the !METADATA table,ACCUMULO-335,12539149,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,vines,jvines,20/Jan/12 15:07,08/Apr/14 17:25,13/Mar/19 22:01,06/Sep/13 20:47,1.4.0,,,,,,,1.6.0,,,client,tserver,,,,,0,,,,,"If you batch scan over the !METADATA table and have a tserver hosting both the root tablet and a metadata tablet, then you you will get an error. The quick fix is to specify a range. We should fix this in the long term. Perhaps this is a good reason to finally split the root tablet into it's own table?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-28 21:34:16.513,,,no_permission,,,,,,,,,,,,224651,,,Fri Sep 06 20:47:43 UTC 2013,,,,,,0|i07nsv:,42622,,,,,,,,"28/Jan/13 21:34;kturner;An exception like the following will show up in 1.4 when you run into this issue.  

{noformat}
root@test14> grep -t !METADATA -nt 1 time
28 16:25:45,753 [impl.TabletServerBatchReaderIterator] WARN : multiple extent types not allowed METADATA ROOT
java.lang.IllegalArgumentException: multiple extent types not allowed METADATA ROOT
	at org.apache.accumulo.core.client.impl.TabletType.type(TabletType.java:45)
	at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:537)
	at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator$QueryTask.run(TabletServerBatchReaderIterator.java:338)
	at org.apache.accumulo.cloudtrace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
{noformat}

A workaround is to scan the root tablet and metadata tablets separately as follows :

{noformat}
root@test14> grep -t !METADATA -e !0< time
!0;~ srv:time []    L3
!0< srv:time []    L0
root@test14> grep -t !METADATA -b 0 time
1< srv:time []    M0
{noformat}
","06/Sep/13 20:47;jira-bot;Commit 2a968563500f2fbbfcef75be4112694e24a5eda6 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2a96856 ]

ACCUMULO-335 Create test to ensure batch scanning over metadata works
","06/Sep/13 20:47;ctubbsii;This was fixed by ACCUMULO-1481, but I added a test to be sure.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AccumuloInputFormat can be less strict about contents of Configuration,ACCUMULO-1854,12677624,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,05/Nov/13 19:05,07/Apr/14 23:55,13/Mar/19 22:01,24/Nov/13 00:33,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"The AccumuloInputFormat required that the same exact Configuration object which was provided to its static configuration methods is also provided to its getSplits() and createRecordReader() methods.

In practice, some tools, like MultipleInputs or Pig, don't guarantee that the same Configuration object is provided to getSplits() and createRecordReader(). This tends to be a common method of interaction to ensure that multiple InputFormats don't collide with one another in the same Configuration object (e.g. FileInputFormat). By serialization the necessary information from the Configuration regarding how to query Accumulo into the InputSplit AccumuloInputFormat creates, we can alleviate this requirement and make client interaction a little more standard.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1783,,,ACCUMULO-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-05 22:17:29.487,,,no_permission,,,,,,,,,,,,356999,,,Tue Nov 26 18:20:04 UTC 2013,,,,,,0|i1pjlb:,357289,,,,,,,,"05/Nov/13 19:27;elserj;My initial approach is to introduce the notion of a ""sequence id"" to the Input/Output Formats. Adding new methods to each class allows us to preserve the old functionality (of one ""configuration"" per Configuration), yet also gives clients the hooks to store multiple configurations.

My only concern was the contract on the getSplits() method. I believe we can increment through each sequence id that we ""gave"" clients and attempt to set each of them. Initial tests seem to show that this approach will work out.","05/Nov/13 22:17;jira-bot;Commit 921617d4dac38e81571dc852308ff4924530092b in branch refs/heads/ACCUMULO-1854-multi-aif from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=921617d ]

ACCUMULO-1854 First stab at being able to use multiple
AccumuloInputFormats and AccumuloOutputFormats in the same
Configuration.

Modified the static API calls on both AIF and AOF to include the notion
of a ""sequence"" number. The original methods still exist, defaulting to
'0', to preserve backwards compatibility with API and functionality. A
primitive method to get a sequence number was added to both and is used
to properly generate InputSplits and output info.
",05/Nov/13 22:19;elserj;Review is welcome/appreciated if anyone has opinions on this. The changes should be backwards compatible. It's fixed the use case I had which was to make the MultipleInput-esque code that Pig has work with Accumulo.,"05/Nov/13 23:17;bhavanki;An alternative which would probably avoid a lot of the changes to AIF and AOF is to bake the sequencing idea into the Configuration object. I'm thinking a decorator around the Configuration which lets you shift it to the next sequence, say. It remembers where it is and the counts so far, and can enforce ordering access, bounds checking, maximums, etc.

SequencedConfiguration sconf = new SequencedConfiguration(conf);  // initially no sequence
// do stuff with sconf
sconf.increment()
// next pass with sequence 1
...","06/Nov/13 00:58;elserj;That's not a bad idea, but, if I understand you correctly, it wouldn't work for the case when you're not controlling the Job and Configuration yourself (e.g. Pig). At first glance, I wouldn't be able to use your approach because I'm handed a Job from the framework and have no ability to override a special Configuration object.

But, when using MultipleInputs, your approach would definitely seem much more succinct.","07/Nov/13 05:24;jira-bot;Commit 5d3c3d5fdd2691f87a5319672c1d9f7dd29f457f in branch refs/heads/ACCUMULO-1854-multi-aif from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5d3c3d5 ]

ACCUMULO-1854 Add AIF test to retrieve relevant configuration entries.
Remove the internal AtomicIntegers in favor of state management through
the Configuration object.

Using static concurrent structures in the InputFormat didn't work well
when making multiple calls to the class and altering the state. By
holding state on the Configuration for the input format, we can
alleviate some of this and do better duplication checking.
","07/Nov/13 05:25;jira-bot;Commit c5dc070f0c10c0f9b00647934edd35e22a6b036c in branch refs/heads/ACCUMULO-1854-multi-aif from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c5dc070 ]

ACCUMULO-1854 More unit tests and fix a bug.
","07/Nov/13 05:25;jira-bot;Commit 1fe223813a246a9943dbc9eda1a71de07ae27f12 in branch refs/heads/ACCUMULO-1854-multi-aif from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1fe2238 ]

ACCUMULO-1854 Make the same changes to AOF as AIF has.
","07/Nov/13 05:26;jira-bot;Commit 0f10a6ffb0400424d30d3f49312bb500265cb276 in branch refs/heads/ACCUMULO-1854-multi-aif from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0f10a6f ]

ACCUMULO-1854 Lift duplicated code between AIF and AOF into a helper
class
","07/Nov/13 05:26;jira-bot;Commit c50a22296d80042a86639129a02e2b9468dc3330 in branch refs/heads/ACCUMULO-1854-multi-aif from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c50a222 ]

ACCUMULO-1854 Ended up re-implementing some of the old approach to get
back to a functional state.

Couldn't solely use the Configuration for things as getting the same
Configuration each time getSplits is called isn't guaranteed. Since
getSplits are always called serially by one client, we can use that fact
to keep some state and not read the same data many times.
","07/Nov/13 05:28;elserj;I was talking to Christopher tonight about this. He did bring up the good point about why not to use the AccumuloMultiTableInputFormat. One point we came to was that making these changes would allow single M/R jobs to talk to separate Accumulo clusters instead of a single cluster.

I did settle on a change that I'm not completely happy about that is reliant on the fact that splits are generated by one host in serial. If they were generated in parallel, my approach would break. However, given that the InputFormata can't rely on getting the same Configuration object in each invocation of getSplits, the only other reliable approach I could come up with was to use something like HDFS which has its own sort of concurrency issues. Since it's not an issue now, I've punted on worrying about it.","09/Nov/13 03:16;elserj;First off, thanks to [~ctubbsii] and [~bills] because they were both helpful in talking this out.

Came to the conclusion that I don't need to rework the Configuration object, but instead could leverage all of the necessary information inside of the RangeInputSplit class (instead of just the location and Range as it currently contains). This allows us to let multiple invocations of the AccumuloInputFormat create RangeInputSplits without requiring all of the connection information contained in the Configuration.

This creates a *much* cleaner changeset as well as backwards compatibility with the current implementation which falls back to using the information in the Configuration when the information is not present (null) in the RangeInputSplit.","09/Nov/13 03:17;jira-bot;Commit cdbed432400da7b17b177e4a53d9440ff23bff9f in branch refs/heads/ACCUMULO-1854-info-in-splits from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cdbed43 ]

ACCUMULO-1854 Move RangeInputSplit into its own file and store all
connection information into it.
","09/Nov/13 03:17;jira-bot;Commit 7c549ab0d5a05a1f5daa36be21ece2e9e291aa3c in branch refs/heads/ACCUMULO-1854-info-in-splits from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7c549ab ]

ACCUMULO-1854 Clean up constructors. Add a test.
","09/Nov/13 03:18;jira-bot;Commit a9644f5b94d74466db624fb06bd3d70fb5bf9cf9 in branch refs/heads/ACCUMULO-1854-info-in-splits from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a9644f5 ]

ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
RangeInputSplit and fall back onto the Configuration.
",09/Nov/13 03:24;elserj;Because RB is pretty broken as of late... https://git-wip-us.apache.org/repos/asf?p=accumulo.git;a=commitdiff;h=a9644f5b94d74466db624fb06bd3d70fb5bf9cf9;hp=6648056cac0a3d271744ab322e8fede221c1f792,"22/Nov/13 01:43;jira-bot;Commit 45ae55fcb74832983ffc188524790a56e5261ae0 in branch refs/heads/ACCUMULO-1854-merge from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=45ae55f ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","22/Nov/13 01:43;jira-bot;Commit 45ae55fcb74832983ffc188524790a56e5261ae0 in branch refs/heads/ACCUMULO-1854-merge from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=45ae55f ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","22/Nov/13 01:43;jira-bot;Commit 45ae55fcb74832983ffc188524790a56e5261ae0 in branch refs/heads/ACCUMULO-1854-merge from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=45ae55f ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","22/Nov/13 01:43;jira-bot;Commit 3beb9f710f526672fc67850b84c4999d968dc925 in branch refs/heads/ACCUMULO-1854-merge from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3beb9f7 ]

ACCUMULO-1854 Remove unnecessary arguments from methods
","22/Nov/13 20:21;jira-bot;Commit 73114819e85714f56838e2bcf16bf9b5c6c6a397 in branch refs/heads/ACCUMULO-1854-merge from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7311481 ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","22/Nov/13 20:21;jira-bot;Commit 73114819e85714f56838e2bcf16bf9b5c6c6a397 in branch refs/heads/ACCUMULO-1854-merge from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7311481 ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","22/Nov/13 20:21;jira-bot;Commit 73114819e85714f56838e2bcf16bf9b5c6c6a397 in branch refs/heads/ACCUMULO-1854-merge from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7311481 ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","22/Nov/13 20:21;jira-bot;Commit 8dd3ae4b1d614182f26d382d3d16956726d26702 in branch refs/heads/ACCUMULO-1854-merge from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8dd3ae4 ]

ACCUMULO-1854 Remove unnecessary arguments from methods
","22/Nov/13 20:21;jira-bot;Commit e1dd6f9b28fa579eada4334b7072fca4155add15 in branch refs/heads/ACCUMULO-1854-merge from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e1dd6f9 ]

ACCUMULO-1854 Remove todo and finish toString
","23/Nov/13 01:21;jira-bot;Commit 73114819e85714f56838e2bcf16bf9b5c6c6a397 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7311481 ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","23/Nov/13 01:21;jira-bot;Commit 73114819e85714f56838e2bcf16bf9b5c6c6a397 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7311481 ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","23/Nov/13 01:21;jira-bot;Commit 73114819e85714f56838e2bcf16bf9b5c6c6a397 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7311481 ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","23/Nov/13 01:21;jira-bot;Commit 8dd3ae4b1d614182f26d382d3d16956726d26702 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8dd3ae4 ]

ACCUMULO-1854 Remove unnecessary arguments from methods
","23/Nov/13 01:21;jira-bot;Commit e1dd6f9b28fa579eada4334b7072fca4155add15 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e1dd6f9 ]

ACCUMULO-1854 Remove todo and finish toString
","23/Nov/13 01:41;jira-bot;Commit 67189202183342888dc9b00b5ef3366e748997d6 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6718920 ]

ACCUMULO-1854 Merge the mapred and mapreduce RangeInputSplits into one class
","23/Nov/13 01:41;jira-bot;Commit 73114819e85714f56838e2bcf16bf9b5c6c6a397 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7311481 ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","23/Nov/13 01:41;jira-bot;Commit 73114819e85714f56838e2bcf16bf9b5c6c6a397 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7311481 ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","23/Nov/13 01:42;jira-bot;Commit 73114819e85714f56838e2bcf16bf9b5c6c6a397 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7311481 ]

Squashed commit of the following:

commit dfbe098fb650d1d1605ac28ff0b195e229ecb345
Author: Josh Elser <elserj@apache.org>
Date:   Wed Nov 20 23:57:18 2013 -0500

    ACCUMULO-1843 Add in log4j Level to RangeInputSplit. Add more tests, notably ones that exercise delegation of the input
    split to the Configuration.

commit 38fdee9916edd938bea1642de5d4e5cf54a81596
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 17:47:57 2013 -0500

    ACCUMULO-1854 Fix up InputFormatBase to use the information stored on
    RangeInputSplit and fall back onto the Configuration.

commit 0e6d1aba7eacef357e0a17c67a453dd5b50a49dc
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 16:23:49 2013 -0500

    ACCUMULO-1854 Clean up constructors. Add a test.

commit 2f59f81f6e75f8a90ccfe3df00c6ad3f69174e0c
Author: Josh Elser <elserj@apache.org>
Date:   Fri Nov 8 15:46:39 2013 -0500

    ACCUMULO-1854 Move RangeInputSplit into its own file and store all
    connection information into it.
","23/Nov/13 01:42;jira-bot;Commit 8dd3ae4b1d614182f26d382d3d16956726d26702 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8dd3ae4 ]

ACCUMULO-1854 Remove unnecessary arguments from methods
","23/Nov/13 01:42;jira-bot;Commit e1dd6f9b28fa579eada4334b7072fca4155add15 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e1dd6f9 ]

ACCUMULO-1854 Remove todo and finish toString
","23/Nov/13 01:42;jira-bot;Commit 3a703d75d0bc37ad7aceb7357f1a69b67b7216d4 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3a703d7 ]

Merge branch '1.4.5-SNAPSHOT' into ACCUMULO-1854-1.5-merge

Conflicts:
	core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
	server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
	src/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
	src/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormatTest.java
	src/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormatTest.java
	src/examples/simple/src/test/java/org/apache/accumulo/examples/simple/filedata/ChunkInputFormatTest.java
","23/Nov/13 07:10;jira-bot;Commit 6caa1597231bddc806fa2e8f4be596fc1e95e949 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6caa159 ]

ACCUMULO-1854 Add in missing license.
","23/Nov/13 07:10;jira-bot;Commit 6caa1597231bddc806fa2e8f4be596fc1e95e949 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6caa159 ]

ACCUMULO-1854 Add in missing license.
","23/Nov/13 19:28;jira-bot;Commit c88d87aa08819ed94fa9aae8583985b4fcf8e588 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c88d87a ]

ACCUMULO-1854 Update tests for hadoop-2 compatibility
","23/Nov/13 19:28;jira-bot;Commit e6e1df41abad9291b919b675147e211ad7cc8cef in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e6e1df4 ]

ACCUMULO-1854 More missing licenses
","23/Nov/13 23:51;jira-bot;Commit c88d87aa08819ed94fa9aae8583985b4fcf8e588 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c88d87a ]

ACCUMULO-1854 Update tests for hadoop-2 compatibility
","23/Nov/13 23:51;jira-bot;Commit e6e1df41abad9291b919b675147e211ad7cc8cef in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e6e1df4 ]

ACCUMULO-1854 More missing licenses
","24/Nov/13 00:33;jira-bot;Commit c88d87aa08819ed94fa9aae8583985b4fcf8e588 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c88d87a ]

ACCUMULO-1854 Update tests for hadoop-2 compatibility
","24/Nov/13 00:33;jira-bot;Commit e6e1df41abad9291b919b675147e211ad7cc8cef in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e6e1df4 ]

ACCUMULO-1854 More missing licenses
",25/Nov/13 18:44;elserj;Felt the need to update the title and description to better match what was actually done and be a little less misleading.,"26/Nov/13 18:20;jira-bot;Commit f8e14c794992bd5d8d530b50338b16436088c243 in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f8e14c7 ]

ACCUMULO-1854 Remove compiler warnings
",,,,,,,
NativeMap Makefile fails under OSX for 1.6.x and higher,ACCUMULO-1884,12678798,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,bhavanki,bhavanki,12/Nov/13 13:20,04/Apr/14 21:29,13/Mar/19 22:01,13/Nov/13 18:05,,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"The NativeMap Makefile was fixed in ACCUMULO-1819 to work under the latest Mac OS X. However, the Makefile changed was src/server/src/main/c++/nativeMap. In 1.6.0-SNAPSHOT and master, the Makefile resides in server/native/src/main/resources/Makefile, and that copy did not receive the fixes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1852,,,,ACCUMULO-1819,,,,,,,,,,,,,,12/Nov/13 18:09;bhavanki;ACCUMULO-1884.patch;https://issues.apache.org/jira/secure/attachment/12613401/ACCUMULO-1884.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-11-12 19:31:35.231,,,no_permission,,,,,,,,,,,,358165,,,Wed Nov 13 18:22:50 UTC 2013,,,,,,0|i1pqrj:,358455,,,,,,,,12/Nov/13 16:22;bhavanki;Review available: https://reviews.apache.org/r/15457/. At least one other person should probably try this out before the patch is committed.,"12/Nov/13 19:31;elserj;So that the comment is also on this ticket and not just RB, the patch here isn't a sufficient fix for OSX (Mavericks, specifically). There are additional includes that are also needed to make it work, but [~mberman] and I both got stuck trying to make it work.

Make sure you're running {{mvn verify}} and not just {{mvn package}}. The Makefile's tests are bound to the verify lifecycle phase; running package won't even invoke them.","12/Nov/13 20:58;bhavanki;Yes, I normally run with -DskipTests=true as I've found in the past that the tests can really tie up resources on my Macbook Air. I'll give {{mvn verify}} a fresh try.","12/Nov/13 22:29;bhavanki;Ran {{mvn verify}} and indeed, NativeMapIT failed for me. I would be happy to help in getting it to work under ACCUMULO-1852, since I use a Mac for development. It sounds like [~ctubbsii] might know what to do already?

In the meantime, should the build patch under this ticket be committed or should it go in with -1852? This patch by itself can at least get compile to pass, but I defer to your judgment.","12/Nov/13 22:37;elserj;One or the other should be closed. Take your pick -- I doesn't much matter to me :)

IIRC, [~ctubbsii] knows how to fix the NativeMapIT, but he doesn't know how to get `make test` working on OSX (nor does he have a mac to use).","13/Nov/13 18:04;jira-bot;Commit e5dfd06ce9f52b606984c1331f6ee2c155f44d1d in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e5dfd06 ]

ACCUMULO-1884 Fix NativeMap Makefile for OS X

The NativeMap Makefile was originally updated for recent OS X versions
under ACCUMULO-1819, but when the file moved for 1.6.x, the changes
were not included.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","13/Nov/13 18:05;ecn;Patched, thanks!","13/Nov/13 18:05;jira-bot;Commit e5dfd06ce9f52b606984c1331f6ee2c155f44d1d in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e5dfd06 ]

ACCUMULO-1884 Fix NativeMap Makefile for OS X

The NativeMap Makefile was originally updated for recent OS X versions
under ACCUMULO-1819, but when the file moved for 1.6.x, the changes
were not included.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",13/Nov/13 18:22;bhavanki;Thanks Eric! On to -1819. :),"13/Nov/13 18:22;bhavanki;Ugh, I mean, -1852. Why won't Jira let me edit ...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$ACCUMULO_CONF_DIR isn't respected everywhere,ACCUMULO-1839,12676951,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,mberman,mberman,31/Oct/13 20:27,04/Apr/14 19:45,13/Mar/19 22:01,19/Nov/13 18:01,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Conf used to be in $ACCUMULO_HOME/conf, but now the canonical location is $ACCUMULO_CONF_DIR.  Some code tries to be smart about preferring the new one but falling back to the old one, but there are still a couple code paths that have no awareness of the new one.  They should be updated.

- MetricsConfiguration.loadConfiguration()
- Accumulo.init() (the section about auditLog.xml)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,12/Nov/13 14:56;bhavanki;ACCUMULO-1839.patch;https://issues.apache.org/jira/secure/attachment/12613381/ACCUMULO-1839.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-11-11 21:34:46.377,,,no_permission,,,,,,,,,,,,356327,,,Wed Nov 13 18:16:53 UTC 2013,,,,,,0|i1pffr:,356615,,,,,,,,"11/Nov/13 21:34;bhavanki;It appears that the problem in {{MetricsConfiguration}} was handled in ACCUMULO-1584, unless I'm missing something.

The problem in {{Accumulo.init()}} is there in 1.6.0-SNAPSHOT and master, but not in 1.4.5-SNAPSHOT or 1.5.1-SNAPSHOT, so presumably it only needs to be fixed in those later branches.",12/Nov/13 14:56;bhavanki;Simple one-line change to 1.6.0-SNAPSHOT.,"13/Nov/13 18:16;jira-bot;Commit 743d64b29d83587170e71c22dab9915548b61e3e in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=743d64b ]

ACCUMULO-1839 Fix ACCUMULO_CONF_DIR usage in Accumulo.java

The lookup of auditLog.xml in Accumulo.java was still looking in
$ACCUMULO_HOME/conf instead of $ACCUMULO_CONF_DIR.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","13/Nov/13 18:16;jira-bot;Commit 743d64b29d83587170e71c22dab9915548b61e3e in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=743d64b ]

ACCUMULO-1839 Fix ACCUMULO_CONF_DIR usage in Accumulo.java

The lookup of auditLog.xml in Accumulo.java was still looking in
$ACCUMULO_HOME/conf instead of $ACCUMULO_CONF_DIR.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incorrect handling of auth byte sequences in TabletServer,ACCUMULO-1987,12683626,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,supermallen,supermallen,supermallen,09/Dec/13 16:12,04/Apr/14 19:13,13/Mar/19 22:01,09/Dec/13 16:20,,,,,,,,1.6.0,,,,,,,,,0,,,,,"In TabletServer.java: 667

return security.userHasAuthorizations(credentials, Collections.<ByteBuffer> singletonList(ByteBuffer.wrap(****auth.getBackingArray()****)));

(Emphasis mine obviously)

That getBackingArray() will return the whole array even when the auth object has limits set upon it.  That has the effect of passing labels to userHasAuthorization() that are incorrect.  For instance, if your label expression has & and | in it, it will pass the entire string as the label string, as opposed to just one part of it in certain parts of the parsing.

The fix is to also use the auth.offset() and auth.length() parameters when building the ByteBuffer.  Patch coming.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,09/Dec/13 16:14;supermallen;Fixes-byte-buffer-copy-bug.patch;https://issues.apache.org/jira/secure/attachment/12617852/Fixes-byte-buffer-copy-bug.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-12-09 16:18:57.418,,,no_permission,,,,,,,,,,,,362698,,,Mon Dec 09 16:20:12 UTC 2013,,,,,,0|i1qipz:,362992,,,,,,,,09/Dec/13 16:14;supermallen;Patch for fix,"09/Dec/13 16:18;jira-bot;Commit 8f9258500e02e0be7965ebac3912d5dbd9e7c489 in branch refs/heads/1.6.0-SNAPSHOT from [~mallen]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8f92585 ]

ACCUMULO-1987 Fixes byte buffer copy bug

This patch fixes an issue where the byte buffer for an
authorization expression was being incorrectly handled on
evaluation.
","09/Dec/13 16:19;jira-bot;Commit 8f9258500e02e0be7965ebac3912d5dbd9e7c489 in branch refs/heads/master from [~mallen]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8f92585 ]

ACCUMULO-1987 Fixes byte buffer copy bug

This patch fixes an issue where the byte buffer for an
authorization expression was being incorrectly handled on
evaluation.
","09/Dec/13 16:20;vines;Patch applied. I corrected them, but please include the ticket number in the commit message and make sure you have the patch use our formatting. Thanks!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Building RPMs requires thrift profile to be active,ACCUMULO-2197,12688936,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,elserj,elserj,15/Jan/14 04:39,02/Apr/14 14:56,13/Mar/19 22:01,04/Feb/14 22:44,1.5.0,,,,,,,1.5.1,,,build,proxy,,,,,0,,,,,"The generated sources (cpp, rb, py) for the proxy are only generated when the thrift maven profile is activated. An RPM assembly expects these files to be present. Thus, the following fails:

{code}
mvn package -Passemble,rpm -DskipTests
{code}

We should probably just include the gen-* variants under src/generated (or similar), commit them to the repository, and let the thrift profile regenerate those files as necessary.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-15 19:43:50.927,,,no_permission,,,,,,,,,,,,367903,,,Wed Apr 02 14:56:31 UTC 2014,,,,,,0|i1rewv:,368210,,,,,,,,"15/Jan/14 19:43;ctubbsii;I'm not a fan of version-controlling generated code. We've previously discussed removing the option of removing the existing generated code from version control. However, I don't think it's a problem that one maven profile requires another one. Unfortunately, there's no good way to auto-activate one via another, so you just have to specify both. But I don't think this is a bug... I don't see it as an issue at all.","15/Jan/14 20:21;busbey;What's the error message when it fails? at a minimum we can make sure the error is informative ala our hadoop.profile checks.
","15/Jan/14 20:35;elserj;You get an error on copy from the rpm plugin. At a minimum we should have
some enforcer rule.

I disagree with you, Chris. You find me one sysadmin who will submit to
installing thrift as a prereq to building Accumulo rpms. Granted an
alternative solution could probably be created to work around this proxy
case.

","24/Jan/14 23:16;ctubbsii;[~elserj]: While sysadmins may wish to build Accumulo, I don't see that as a sysadmin responsibility. Technically speaking, it's probably a ""package maintainer"" responsibility... and package maintainers typically have the same dependency environment as a developer, because they typically must build everything from source.

Ideally, it'd be nice to provide SRPMs which include generated source, for sysadmins to build an RPM from. If they're building from raw source, I don't see why their environment should be any different than any other developer, though.

On the other hand, I do think that there'd be some merit to separating out the thrift build so that it produces versioned release artifacts, rather than version-controlling thrift IDL files. This could/should be done as part of ACCUMULO-756, which I've been meaning to revisit soon.","27/Jan/14 17:31;elserj;bq. Technically speaking, it's probably a ""package maintainer"" responsibility

Ok, let me change my argument to something more accurate. *I* don't even want to have to deal with Thrift (unless I'm actively changing something). If I want to build some RPMs for testing Accumulo (as an Accumulo dev), I don't want to have to manage (2+ versions of) Thrift, and personally, I don't think we should be pushing that on all Accumulo developers, as most changes don't necessitate IDL changes.

We presently already have 103 thrift-generated classes in SCM (in 1.6.0), I (obviously) don't see a big burden coming out of adding a few more from the proxy. We could potentially create an RPM just for those thrift classes in the proxy module (and thus only activate when rpm and thrift profiles are active) and remove it from the assemble module, but that also introduces some unwanted complexity.

The other simple alternative is to just not bundle the gen-* source in an RPM.","28/Jan/14 04:20;vines;I agree with Josh. We have a bunch of thrift generated classes sitting around already, I don't see why things need to be different here. The thrift  protocol doesn't change much, and I agree that we should put the burden of having thrift compiled on those who change the protocol, not on every developer.","04/Feb/14 22:19;jira-bot;Commit 3d436e7bd2dabf9388bea78620d9f072542b580b in branch refs/heads/1.5.1-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3d436e7 ]

ACCUMULO-2197 provide generated proxy libraries, with modified generate-thrift script which tacks on headers
","04/Feb/14 22:19;jira-bot;Commit 3d436e7bd2dabf9388bea78620d9f072542b580b in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3d436e7 ]

ACCUMULO-2197 provide generated proxy libraries, with modified generate-thrift script which tacks on headers
","04/Feb/14 22:19;jira-bot;Commit 3298263a770143873b01f5b0aa1ffaa9d01783c7 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3298263 ]

ACCUMULO-2197 updating files for this version
",04/Feb/14 22:30;vines;Might help if I actually update the rpms...,"04/Feb/14 22:38;jira-bot;Commit 9ff6eea4169e431b5667464b9231a4f6cee9f487 in branch refs/heads/1.5.1-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9ff6eea ]

ACCUMULO-2197 updating assembly for new locations
","04/Feb/14 22:44;jira-bot;Commit 9ff6eea4169e431b5667464b9231a4f6cee9f487 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9ff6eea ]

ACCUMULO-2197 updating assembly for new locations
","04/Feb/14 22:58;jira-bot;Commit 9ff6eea4169e431b5667464b9231a4f6cee9f487 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9ff6eea ]

ACCUMULO-2197 updating assembly for new locations
",02/Apr/14 14:56;ctubbsii;Superceded by ACCUMULO-2606 for 1.6.0 and later,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Backport randomwalk changes,ACCUMULO-2182,12688414,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,elserj,elserj,11/Jan/14 22:39,26/Mar/14 17:13,13/Mar/19 22:01,03/Feb/14 22:10,,,,,,,,1.4.5,1.5.1,,test,,,,,,0,,,,,"I (sadly) just noticed that with randomwalk on 1.5 I'm running into a some of the same bugs that I already fixed as a part of 1.6 testing.

Tickets I need to revisit: ACCUMULO-2105, ACCUMULO-2096, ACCUMULO-2106, and ACCUMULO-2104",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-12 22:07:44.466,,,no_permission,,,,,,,,,,,,367433,,,Wed Mar 26 17:13:46 UTC 2014,,,,,,0|i1rc1j:,367742,,,,,,,,"12/Jan/14 22:07;mdrob;[~bhavanki], do you see any impact to 1.4 here?","13/Jan/14 04:56;elserj;Sigh, looks like at least one of the bugs affects 1.4 (MultiTable ACCUMULO-2106).","13/Jan/14 14:40;bhavanki;[~mdrob]: Probably. I already need to backport ACCUMULO-1123 and ACCUMULO-295. I'll be in a cycle of backport/run until I get all the way through, so knowing about these may come in handy.","13/Jan/14 22:02;bhavanki;So far for 1.4.x I am backporting:

* ACCUMULO-1123
* ACCUMULO-2104 / ACCUMULO-2106","13/Jan/14 23:09;elserj;Yeah that looks right. I don't think ACCUMULO-2096 or ACCUMULO-2105 are relevant for either at second glance.

Have you seen ACCUMULO-1123 in practice for 1.4?

Also, if you're doing this right now, feel free to reassign. I'll comment when I have cycles to do this (probably tomorrow).","14/Jan/14 02:37;bhavanki;Oh yeah, the problem behind ACCUMULO-1123 pops up a lot for me.

I am testing out my backports, so hopefully tomorrow (Tuesday) I'll have some patches available. I'll reassign to myself for now, and you can take it back for whatever else you do. Sharing is great. :)","14/Jan/14 14:10;bhavanki;First set of backports up for review. Since the backports were not straightforward, review is definitely advisable.","14/Jan/14 20:48;jira-bot;Commit ed4c2273f7fd34e27fbda1616321117b0561badf in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ed4c227 ]

ACCUMULO-2182 Backport of ACCUMULO-1123 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit ed4c2273f7fd34e27fbda1616321117b0561badf in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ed4c227 ]

ACCUMULO-2182 Backport of ACCUMULO-1123 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit a3eae058d8fff13c768aa7ae1828cee617426878 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3eae05 ]

ACCUMULO-2182 Backport ACCUMULO-2104 and ACCUMULO-2106 to 1.5.x

This commit is an adaption of the backport to 1.4.x, adapted due to files moving
between the releases.
","14/Jan/14 20:48;jira-bot;Commit ed4c2273f7fd34e27fbda1616321117b0561badf in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ed4c227 ]

ACCUMULO-2182 Backport of ACCUMULO-1123 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit a3eae058d8fff13c768aa7ae1828cee617426878 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3eae05 ]

ACCUMULO-2182 Backport ACCUMULO-2104 and ACCUMULO-2106 to 1.5.x

This commit is an adaption of the backport to 1.4.x, adapted due to files moving
between the releases.
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:49;jira-bot;Commit a3eae058d8fff13c768aa7ae1828cee617426878 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3eae05 ]

ACCUMULO-2182 Backport ACCUMULO-2104 and ACCUMULO-2106 to 1.5.x

This commit is an adaption of the backport to 1.4.x, adapted due to files moving
between the releases.
","14/Jan/14 20:59;bhavanki;For those needing to trace the commit history for the recent commits:

* 1.4.5-SNAPSHOT received two backports, one for -1123 and the other for -2104/-2106.
* 1.5.1-SNAPSHOT only received one backport, for -2104/-2106. -1123 already fixed the issue under 1.5.0. The backport commit needed to be hand-tweaked to apply to the files, since they were moved since 1.4.x. After that, there is a merge -s ours of 1.4.5-SNAPSHOT.
* 1.6.0-SNAPSHOT was merged -s ours from 1.5.1-SNAPSHOT, and so on.

This may be a sub-optimal merging, so my apologies.",03/Feb/14 20:51;elserj;[~bhavanki] can this ticket be closed?,"03/Feb/14 22:10;bhavanki;Yup, thanks for the reminder.","26/Mar/14 17:12;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
","26/Mar/14 17:13;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
","26/Mar/14 17:13;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
","26/Mar/14 17:13;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
VolumeManagerImpl.create doesn't set bufferSize on 0,ACCUMULO-2440,12699486,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,07/Mar/14 19:26,24/Mar/14 23:37,13/Mar/19 22:01,24/Mar/14 23:37,,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"When bufferSize is zero, we never set to the value of io.file.buffer.size we checked in the configuration for.

{code}
    if (bufferSize == 0) {
      fs.getConf().getInt(""io.file.buffer.size"", 4096);
    }
{code}

This doesn't look quite right.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-24 23:37:15.554,,,no_permission,,,,,,,,,,,,377833,,,Mon Mar 24 23:37:17 UTC 2014,,,,,,0|i1t3sv:,378125,,,,,,,,"07/Mar/14 19:27;elserj;The odd part here is that digging down through the DistributedFileSystem impl (and ultimately DFSClient), the buffersize argument isn't even *used* (in 2.2.0). Strange.","07/Mar/14 19:42;elserj;Looks like there is a {{correctBufferSize(Configuration, int)}} already present in that Class which should be used instead.","24/Mar/14 23:37;jira-bot;Commit 62ce7524f4618e1b46166a6d8f4f65fbbda4c4ec in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=62ce752 ]

ACCUMULO-2440 Use the correctBufferSize method to (correctly) fix the bufferSize when not provided.
","24/Mar/14 23:37;jira-bot;Commit 62ce7524f4618e1b46166a6d8f4f65fbbda4c4ec in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=62ce752 ]

ACCUMULO-2440 Use the correctBufferSize method to (correctly) fix the bufferSize when not provided.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Security.xml random walk test fails,ACCUMULO-1162,12635803,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,ecn,ecn,07/Mar/13 14:48,20/Mar/14 15:25,13/Mar/19 22:01,07/Mar/13 23:33,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"{noformat}
07 14:21:47,926 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Security.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:99)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node SystemChangeTablePass
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloException: User table_example_com doesn't exist and they SHOULD.
        at org.apache.accumulo.test.randomwalk.security.ChangePass.visit(ChangePass.java:77)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 9 more
Caused by: org.apache.accumulo.core.client.AccumuloSecurityException: Error USER_DOESNT_EXIST for user table_example_com - The user does not exist
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.execute(SecurityOperationsImpl.java:59)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.changeLocalUserPassword(SecurityOperationsImpl.java:154)
        at org.apache.accumulo.test.randomwalk.security.ChangePass.visit(ChangePass.java:68)
        ... 10 more
Caused by: ThriftSecurityException(user:table_example_com, code:USER_DOESNT_EXIST)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$changeLocalUserPassword_result$changeLocalUserPassword_resultStandardScheme.read(ClientService.java:11182)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$changeLocalUserPassword_result$changeLocalUserPassword_resultStandardScheme.read(ClientService.java:11168)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$changeLocalUserPassword_result.read(ClientService.java:11118)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$Client.recv_changeLocalUserPassword(ClientService.java:420)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$Client.changeLocalUserPassword(ClientService.java:404)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl$4.execute(SecurityOperationsImpl.java:157)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl$4.execute(SecurityOperationsImpl.java:154)
        at org.apache.accumulo.core.client.impl.ServerClient.executeRaw(ServerClient.java:108)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.execute(SecurityOperationsImpl.java:51)
        ... 12 more
{noformat}",ten node test cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-07 19:11:52.677,,,no_permission,,,,,,,,,,,,316295,,,Thu Mar 20 15:25:20 UTC 2014,,,,,,0|i1ikun:,316638,,,,,,,,07/Mar/13 19:11;vines;This was caused by improper cleaning/initialization for repeated Security walks being hit in a single run. It only occurred when the table user existed prior to teardown of the first security walk and then an operation against the table user occurred on a subsequent security walk.,"07/Mar/13 21:54;hudson;Integrated in Accumulo-1.5 #22 (See [https://builds.apache.org/job/Accumulo-1.5/22/])
    ACCUMULO-1162 - Initialization now sets TableUser to non-existant. (Revision 1454004)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","07/Mar/13 22:01;hudson;Integrated in Accumulo-Trunk #767 (See [https://builds.apache.org/job/Accumulo-Trunk/767/])
    ACCUMULO-1162 - Initialization now sets TableUser to non-existant. (Revision 1454008)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","07/Mar/13 22:03;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #20 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/20/])
    ACCUMULO-1162 - Initialization now sets TableUser to non-existant. (Revision 1454004)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","07/Mar/13 22:05;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #126 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/126/])
    ACCUMULO-1162 - Initialization now sets TableUser to non-existant. (Revision 1454008)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","07/Mar/13 23:17;vines;In the same vain, I hit an identical issue with table's existence.","08/Mar/13 02:10;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #21 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/21/])
    ACCUMULO-1162 - WalkingSecurity was being cached, so state initialization in it never happened (Revision 1454165)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/SecurityFixture.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","08/Mar/13 02:50;hudson;Integrated in Accumulo-Trunk #768 (See [https://builds.apache.org/job/Accumulo-Trunk/768/])
    ACCUMULO-1162 - WalkingSecurity was being cached, so state initialization in it never happened (Revision 1454168)

     Result = FAILURE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/SecurityFixture.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","08/Mar/13 02:51;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #127 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/127/])
    ACCUMULO-1162 - WalkingSecurity was being cached, so state initialization in it never happened (Revision 1454168)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/SecurityFixture.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","08/Mar/13 04:25;hudson;Integrated in Accumulo-1.5 #23 (See [https://builds.apache.org/job/Accumulo-1.5/23/])
    ACCUMULO-1162 - WalkingSecurity was being cached, so state initialization in it never happened (Revision 1454165)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/SecurityFixture.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","18/Mar/14 20:55;jira-bot;Commit 4a27da54696ed97b197ce0abd5bef0a2ccfc2b80 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4a27da5 ]

ACCUMULO-2491 Correct table user state upon termination of Security randomwalk

A partial backport of ACCUMULO-1162 to 1.4 - commit e93a11a only. As the Security randomwalk
ends and drops the table user, it now also sets the user's existence flag to false.
","18/Mar/14 20:55;jira-bot;Commit 4a27da54696ed97b197ce0abd5bef0a2ccfc2b80 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4a27da5 ]

ACCUMULO-2491 Correct table user state upon termination of Security randomwalk

A partial backport of ACCUMULO-1162 to 1.4 - commit e93a11a only. As the Security randomwalk
ends and drops the table user, it now also sets the user's existence flag to false.
","18/Mar/14 20:55;jira-bot;Commit 4a27da54696ed97b197ce0abd5bef0a2ccfc2b80 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4a27da5 ]

ACCUMULO-2491 Correct table user state upon termination of Security randomwalk

A partial backport of ACCUMULO-1162 to 1.4 - commit e93a11a only. As the Security randomwalk
ends and drops the table user, it now also sets the user's existence flag to false.
","18/Mar/14 20:55;jira-bot;Commit 4a27da54696ed97b197ce0abd5bef0a2ccfc2b80 in accumulo's branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4a27da5 ]

ACCUMULO-2491 Correct table user state upon termination of Security randomwalk

A partial backport of ACCUMULO-1162 to 1.4 - commit e93a11a only. As the Security randomwalk
ends and drops the table user, it now also sets the user's existence flag to false.
","20/Mar/14 15:25;jira-bot;Commit 4a27da54696ed97b197ce0abd5bef0a2ccfc2b80 in accumulo's branch refs/heads/ACCUMULO-2061 from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4a27da5 ]

ACCUMULO-2491 Correct table user state upon termination of Security randomwalk

A partial backport of ACCUMULO-1162 to 1.4 - commit e93a11a only. As the Security randomwalk
ends and drops the table user, it now also sets the user's existence flag to false.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
maven-plugin's classpath is not assembled similarly to a real accumulo or mac,ACCUMULO-2165,12688128,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,vines,vines,09/Jan/14 20:37,18/Mar/14 00:28,13/Mar/19 22:01,18/Mar/14 00:28,,,,,,,,1.6.0,,,maven-plugin,,,,,,0,,,,,"the maven plugin uses AbstractAccumuloMojo#configureMiniClasspath to assemble the classpath. All it does it get the list of artifacts in the order reported by project.getArtifacts(), which includes maven dependencies, including the sisu forks of guice and guava. This causes the maven-plugin to use a heavily bastardized classpath which is both out of order of normal accumulo classpaths but also with additional libraries injected.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-09 21:46:01.621,,,no_permission,,,,,,,,,,,,367134,,,Tue Mar 18 00:28:11 UTC 2014,,,,,,0|i1ra7r:,367444,,,,,,,,"09/Jan/14 21:46;jira-bot;Commit b4a832da7515bde113856313d1d4fcd497f4ee0b in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b4a832d ]

ACCUMULO-2165 temporary fix
","10/Jan/14 16:29;jira-bot;Commit b4a832da7515bde113856313d1d4fcd497f4ee0b in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b4a832d ]

ACCUMULO-2165 temporary fix
",18/Mar/14 00:28;ctubbsii;I think the underlying issue is resolved. The plugin cannot get the classpath the same way as a regular Accumulo instance... as that defeats the whole point of the plugin. It needs to get it from the build environment instead.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Concurrent randomwalk fails with unbalanced servers,ACCUMULO-2198,12689007,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,bhavanki,bhavanki,15/Jan/14 14:29,17/Mar/14 21:11,13/Mar/19 22:01,16/Jan/14 20:25,1.4.4,,,,,,,1.4.5,1.5.1,1.6.0,test,,,,,,0,randomwalk,test,,,"Not always, but sometimes I am seeing the Concurrent randomwalk test fail with:

{noformat}
java.lang.Exception: Error running node Concurrent.xml
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:259)
...
Caused by: java.lang.Exception: Error running node ct.CheckBalance
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:259)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
        ... 8 more
Caused by: java.lang.Exception: servers are unbalanced!
        at org.apache.accumulo.server.test.randomwalk.concurrent.CheckBalance.visit(CheckBalance.java:74)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
        ... 9 more
{noformat}

In one case, the 15-minute allowance for balancing extended to a prior run of Concurrent.xml within the same overall test run. In another case, the time span begins at a point when HDFS failed to contact a datanode.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1239,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-16 20:16:52.181,,,no_permission,,,,,,,,,,,,367974,,,Thu Jan 16 20:16:55 UTC 2014,,,,,,0|i1rfcn:,368281,,,,,,,,16/Jan/14 14:12;bhavanki;Review available for at least a partial solution.,"16/Jan/14 15:56;bhavanki;The second review builds on the first. It adds an additional check backported from 1.5.x, so that the test cannot fail until there have been at least three failed server balance checks (in a row). This should improve the success rate of the Concurrent test under 1.4.x.","16/Jan/14 20:16;jira-bot;Commit cd4eac0d7e2820321db9fc9cdfc8dc89f7dd53d2 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cd4eac0 ]

ACCUMULO-2198 Concurrent randomwalk: add teardown, fix server balance check

The Concurrent randomwalk test had been using a test node property to remember the
last time when servers were unbalanced, but this property was not getting cleaned up
between runs. Therefore, if a new Concurrent test was started some time later, it
would pick up the old timestamp property from the last run. This commit adds removal
of the property during test teardown, and also moves the tracking from a node
property to test state.

In addition, the test logic would reset the timestamp every time servers were found
unbalanced, provided the 15-minute allowance hadn't expired. This commit fixes that
issue as well. This could lead to more, correct, reports of unbalanced servers.

Lastly, the test in 1.5.x requires three checks for unbalanced servers to fail before
failing the test. This commit backports that requirement to 1.4.x.

The timestamp reset and three-check fixes were added to 1.5.x in commit 0ee7e5a8.
","16/Jan/14 20:16;jira-bot;Commit cd4eac0d7e2820321db9fc9cdfc8dc89f7dd53d2 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cd4eac0 ]

ACCUMULO-2198 Concurrent randomwalk: add teardown, fix server balance check

The Concurrent randomwalk test had been using a test node property to remember the
last time when servers were unbalanced, but this property was not getting cleaned up
between runs. Therefore, if a new Concurrent test was started some time later, it
would pick up the old timestamp property from the last run. This commit adds removal
of the property during test teardown, and also moves the tracking from a node
property to test state.

In addition, the test logic would reset the timestamp every time servers were found
unbalanced, provided the 15-minute allowance hadn't expired. This commit fixes that
issue as well. This could lead to more, correct, reports of unbalanced servers.

Lastly, the test in 1.5.x requires three checks for unbalanced servers to fail before
failing the test. This commit backports that requirement to 1.4.x.

The timestamp reset and three-check fixes were added to 1.5.x in commit 0ee7e5a8.
","16/Jan/14 20:16;jira-bot;Commit cd4eac0d7e2820321db9fc9cdfc8dc89f7dd53d2 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cd4eac0 ]

ACCUMULO-2198 Concurrent randomwalk: add teardown, fix server balance check

The Concurrent randomwalk test had been using a test node property to remember the
last time when servers were unbalanced, but this property was not getting cleaned up
between runs. Therefore, if a new Concurrent test was started some time later, it
would pick up the old timestamp property from the last run. This commit adds removal
of the property during test teardown, and also moves the tracking from a node
property to test state.

In addition, the test logic would reset the timestamp every time servers were found
unbalanced, provided the 15-minute allowance hadn't expired. This commit fixes that
issue as well. This could lead to more, correct, reports of unbalanced servers.

Lastly, the test in 1.5.x requires three checks for unbalanced servers to fail before
failing the test. This commit backports that requirement to 1.4.x.

The timestamp reset and three-check fixes were added to 1.5.x in commit 0ee7e5a8.
","16/Jan/14 20:16;jira-bot;Commit cd4eac0d7e2820321db9fc9cdfc8dc89f7dd53d2 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cd4eac0 ]

ACCUMULO-2198 Concurrent randomwalk: add teardown, fix server balance check

The Concurrent randomwalk test had been using a test node property to remember the
last time when servers were unbalanced, but this property was not getting cleaned up
between runs. Therefore, if a new Concurrent test was started some time later, it
would pick up the old timestamp property from the last run. This commit adds removal
of the property during test teardown, and also moves the tracking from a node
property to test state.

In addition, the test logic would reset the timestamp every time servers were found
unbalanced, provided the 15-minute allowance hadn't expired. This commit fixes that
issue as well. This could lead to more, correct, reports of unbalanced servers.

Lastly, the test in 1.5.x requires three checks for unbalanced servers to fail before
failing the test. This commit backports that requirement to 1.4.x.

The timestamp reset and three-check fixes were added to 1.5.x in commit 0ee7e5a8.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client side metadata cache caches credentials,ACCUMULO-295,12537838,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,kturner,kturner,10/Jan/12 00:29,14/Mar/14 17:46,13/Mar/19 22:01,05/Mar/13 22:49,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,client,,,,,,0,,,,,"Saw the following while running the random walk test.  Not sure, but I think this is a bug with the test.  I think it does not properly handle the bad credentials case. 

{noformat}
09 20:40:40,275 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Security.xml
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:236)
	at org.apache.accumulo.server.test.randomwalk.Framework.run(Framework.java:61)
	at org.apache.accumulo.server.test.randomwalk.Framework.main(Framework.java:114)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.accumulo.start.Main$1.run(Main.java:89)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node security.TableOp
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:236)
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:234)
	... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloException: Unexpected exception!
	at org.apache.accumulo.server.test.randomwalk.security.TableOp.visit(TableOp.java:125)
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:234)
	... 9 more
Caused by: java.lang.RuntimeException: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_CREDENTIALS - Username or Password is Invalid
	at org.apache.accumulo.core.client.impl.ScannerIterator.hasNext(ScannerIterator.java:186)
	at org.apache.accumulo.server.test.randomwalk.security.TableOp.visit(TableOp.java:90)
	... 10 more
Caused by: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_CREDENTIALS - Username or Password is Invalid
	at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:576)
	at org.apache.accumulo.core.client.impl.MetadataLocationObtainer.lookupTablets(MetadataLocationObtainer.java:146)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl.processInvalidated(TabletLocatorImpl.java:580)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl._locateTablet(TabletLocatorImpl.java:524)
	at org.apache.accumulo.core.client.impl.TabletLocator$1._locateTablet(TabletLocator.java:115)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl.locateTablet(TabletLocatorImpl.java:370)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl.lookupTabletLocation(TabletLocatorImpl.java:390)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl._locateTablet(TabletLocatorImpl.java:536)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl.locateTablet(TabletLocatorImpl.java:370)
	at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:245)
	at org.apache.accumulo.core.client.impl.ScannerIterator$Reader.run(ScannerIterator.java:94)
	at org.apache.accumulo.core.client.impl.ScannerIterator.hasNext(ScannerIterator.java:176)
	... 11 more
Caused by: ThriftSecurityException(user:xxx, code:BAD_CREDENTIALS)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$startMultiScan_result.read(TabletClientService.java:7586)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_startMultiScan(TabletClientService.java:306)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.startMultiScan(TabletClientService.java:274)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at cloudtrace.instrument.thrift.TraceWrap$2.invoke(TraceWrap.java:83)
	at $Proxy4.startMultiScan(Unknown Source)
	at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:539)
	... 22 more
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1154,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-10 13:51:48.367,,,no_permission,,,,,,,,,,,,223344,,,Fri Mar 14 17:46:51 UTC 2014,,,,,,0|i07o1b:,42660,,,,,,,,"10/Jan/12 13:51;jvines;I agree that it's the bad credentials case. However, I do not have a case which forces bad credentials on a scan. I wonder if this is another case of a synchronization delay of a password change.","13/Jan/12 19:29;kturner;This is a bug w/ the client side metadata table cache.  The cache is a singleton and it uses the credentials from the first time it was created.  If the credentials become invalid, it will fail.  ","13/Jan/12 20:59;kturner;This is an odd bug, not likely to occur in normal use.  The best fix would be to change the TabletLocator API to pass in the credentials on all of its methods. This is not a small change and may introduce bugs.  Therefore its probably not worth the risk of fixing in 1.4 since we would like to release that ASAP.  This bug has existed for a long time and no user has run into it. It was only found after writing the security random walk test and running that on a cluster.","06/Mar/13 00:50;hudson;Integrated in Accumulo-1.5 #16 (See [https://builds.apache.org/job/Accumulo-1.5/16/])
    ACCUMULO-295 - shifted TCredentials into all calls instead of the locator itself
ACCUMULO-259 - Found some translation misses in mapred.InputFormatBase (Revision 1453058)

     Result = FAILURE
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/MetadataLocationObtainer.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/RootTabletLocator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocatorImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReaderIterator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchWriter.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftScanner.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TimeoutTabletLocator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/Writer.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/InputConfigurator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mock/MockTabletLocator.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/client/impl/TabletLocatorImplTest.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/client/BulkImporterTest.java
","06/Mar/13 00:51;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #119 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/119/])
    ACCUMULO-295 - shifted TCredentials into all calls instead of the locator itself
ACCUMULO-259 - Found some translation misses in mapred.InputFormatBase (Revision 1453061)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/MetadataLocationObtainer.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/RootTabletLocator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocatorImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReaderIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchWriter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftScanner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TimeoutTabletLocator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/Writer.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/InputConfigurator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockTabletLocator.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/impl/TabletLocatorImplTest.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/client/BulkImporterTest.java
","06/Mar/13 00:54;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #16 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/16/])
    ACCUMULO-295 - shifted TCredentials into all calls instead of the locator itself
ACCUMULO-259 - Found some translation misses in mapred.InputFormatBase (Revision 1453058)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/MetadataLocationObtainer.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/RootTabletLocator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocatorImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReaderIterator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchWriter.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftScanner.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TimeoutTabletLocator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/Writer.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/InputConfigurator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mock/MockTabletLocator.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/client/impl/TabletLocatorImplTest.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/client/BulkImporterTest.java
","06/Mar/13 00:59;hudson;Integrated in Accumulo-Trunk #760 (See [https://builds.apache.org/job/Accumulo-Trunk/760/])
    ACCUMULO-295 - shifted TCredentials into all calls instead of the locator itself
ACCUMULO-259 - Found some translation misses in mapred.InputFormatBase (Revision 1453061)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/MetadataLocationObtainer.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/RootTabletLocator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocatorImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReaderIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchWriter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftScanner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TimeoutTabletLocator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/Writer.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/InputConfigurator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockTabletLocator.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/impl/TabletLocatorImplTest.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/client/BulkImporterTest.java
","14/Mar/14 17:46;bhavanki;Greetings from the future!

I encountered this problem while running randomwalk tests for the 1.4.5 release. Rather than try to fix it, I altered the flow for LongClean to start with a short run of the bulk test. This will hopefully avoid priming the tablet locator(s) with the temporary users created during the security test.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[RW] Error in Bulk.Verify,ACCUMULO-2110,12686653,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,elserj,elserj,29/Dec/13 04:12,13/Mar/14 16:07,13/Mar/19 22:01,10/Jan/14 20:11,,,,,,,,1.6.0,,,test,,,,,,0,16_qa_bug,,,,"Saw this across three different RW clients. Obviously the key differs each time.

{noformat}
java.lang.Exception: Error running node Bulk.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.start.Main$1.run(Main.java:137)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.Exception: Error running node bulk.Verify
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
Caused by: java.lang.Exception: Bad key at r08930 cf:000 [] 1388209514232 false 1
        at org.apache.accumulo.test.randomwalk.bulk.Verify.visit(Verify.java:65)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 9 more
{noformat}

Some relevant logs from the RW client, but there's nothing in the server log that I've seen.

{noformat}
27 21:18:34,660 [bulk.BulkPlusOne] DEBUG: preparing bulk files with start rows [r00000, r00483, r08930, r0a413, r0a603, r0b20e, r10a31, r1481e, r15e3d, r1853e] last row r1869f marker 0000379
...
27 21:21:03,710 [bulk.BulkPlusOne] DEBUG: Finished bulk import, start rows [r00000, r00483, r08930, r0a413, r0a603, r0b20e, r10a31, r1481e, r15e3d, r1853e] last row r1869f marker 0000379
27 21:21:03,710 [bulk.BulkPlusOne] INFO : Incrementing
...
27 21:48:36,260 [impl.ThriftTransportPool] INFO : Thread ""bulkImportPool 3"" no longer stuck on IO  to master:9999 (0) sawError = false
27 21:48:36,347 [bulk.Compact] INFO : Compaction (r0349f -> r08a2e] finished
27 21:48:44,229 [impl.ThriftScanner] DEBUG: Scan failed, not serving tablet (lw;r0077a;r004a1,tserver1:9997,1432840570f049e)
27 21:48:46,145 [impl.ThriftScanner] DEBUG: Scan failed, not serving tablet (lw;r007d5;r0077a,tserver1:9997,1432840570f049e) 
27 21:48:48,738 [impl.ThriftScanner] DEBUG: Scan failed, not serving tablet (lw;r00f3b;r00e54,tserver3:9997,34328404fc00428)
27 21:48:50,331 [impl.ThriftScanner] DEBUG: Scan failed, not serving tablet (lw;r014f1;r00f3b,tserver3:9997,34328404fc00428)
27 21:49:00,030 [impl.ThriftScanner] DEBUG: Scan failed, not serving tablet (lw;r017a3;r014f1,tserver1:9997,1432840570f049e)
27 21:49:07,122 [impl.ThriftScanner] DEBUG: Scan failed, not serving tablet (lw;r02f24;r02824,tserver4:9997,1432840570f045b)


{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31/Dec/13 19:39;ecn;0001-ACCUMULO-2110-cannot-remove-a-FileRef-with-a-Path.patch;https://issues.apache.org/jira/secure/attachment/12620973/0001-ACCUMULO-2110-cannot-remove-a-FileRef-with-a-Path.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-12-30 19:58:24.842,,,no_permission,,,,,,,,,,,,365646,,,Fri Jan 10 20:11:52 UTC 2014,,,,,,0|i1r10v:,365953,,,,,,,,29/Dec/13 04:45;elserj;Not really sure about this one. It's not outwardly clear if this is actually a bug in Accumulo or if it's a bug in the test.,"30/Dec/13 19:58;ecn;[~elserj], it's probably a bug in accumulo.  This test has been stable.","30/Dec/13 20:04;elserj;Ok, that's good to know.","31/Dec/13 15:04;ecn;I replicated this problem on a 20-node AWS cluster.

{noformat}
30 22:17:54,447 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Bulk.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.start.Main$1.run(Main.java:137)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.Exception: Error running node bulk.Verify
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
Caused by: java.lang.Exception: Bad key at r13684 cf:000 [] 1388441757199 false -1
        at org.apache.accumulo.test.randomwalk.bulk.Verify.visit(Verify.java:65)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 9 more
{noformat}

The Bulk RW test does a bunch of random operations concurrently, but at the end (during the Verify), it should have imported an equal number of ""1"" and ""-1"" values. The table has a Combiner to add the values up. Every row value should be zero.  In this case, rows r13684 - r1442d are ""-1"".  So, somewhere, data was lost, or imported more than once.

The row r1442d shows up as a split added during the import of a file containing ""1"".
","31/Dec/13 15:31;ecn;In addition to importing ""1"" and ""-1"" values, a marker column is added to each row for each bulk file.  No marker columns are missing, so it's probably bulk importing a file multiple times.","31/Dec/13 15:42;ecn;The combiner should be adding up the markers, but they are always ""1"".  If a bulk file was imported multiple times, the count would be higher.
","31/Dec/13 15:43;ecn;Oh, it looks like there is a multiple bulk import:
{noformat}
...
r13686 marker:0000050 []    1
r13686 marker:0000051 []    1
r13686 marker:0000052 []    2
r13686 marker:0000053 []    1
r13686 marker:0000054 []    1
...
{noformat}
",31/Dec/13 19:39;ecn;git seems to be read-only at the moment,"31/Dec/13 20:23;jira-bot;Commit 16ccbf5e16467729b558cf08a379770cba10f5ab in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=16ccbf5 ]

ACCUMULO-2110 cannot remove a FileRef with a Path
","31/Dec/13 20:24;jira-bot;Commit ec7724823628c240f6f31a3fbd5b4b59bb03053e in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ec77248 ]

ACCUMULO-2110 cannot remove a FileRef with a Path
","31/Dec/13 20:24;jira-bot;Commit ec7724823628c240f6f31a3fbd5b4b59bb03053e in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ec77248 ]

ACCUMULO-2110 cannot remove a FileRef with a Path
","31/Dec/13 20:24;jira-bot;Commit 16ccbf5e16467729b558cf08a379770cba10f5ab in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=16ccbf5 ]

ACCUMULO-2110 cannot remove a FileRef with a Path
","02/Jan/14 21:23;kturner;I was looking at the patch, It may not go far enough to fix the issue.  The comparison w/ the load marker is done using absolute paths.   Its possible that different absolute paths could be constructed that ref the same file.",10/Jan/14 20:11;kturner;I opened ACCUMULO-2173 to address the more general issue of comparing absolute paths.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bulk random walk test failed,ACCUMULO-334,12539044,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,19/Jan/12 21:49,13/Mar/14 16:06,13/Mar/19 22:01,26/Jan/12 22:51,,,,,,,,1.4.0,,,test,,,,,,0,14_qa_bug,,,,"The bulk random walk test failed while running on a 10 node cluster w/ the following error message.

{noformat}
18 23:36:05,167 [bulk.Setup] INFO : Starting bulk test on 459a04a0


19 00:24:33,950 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Bulk.xml
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:253)
        at org.apache.accumulo.server.test.randomwalk.Framework.run(Framework.java:61)
        at org.apache.accumulo.server.test.randomwalk.Framework.main(Framework.java:114)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:89)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node bulk.Verify
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:253)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:249)
        ... 8 more
Caused by: java.lang.Exception: Bad key at r0d646 cf:000 [] 1326932285943 false -1
        at org.apache.accumulo.server.test.randomwalk.bulk.Verify.visit(Verify.java:51)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:249)
        ... 9 more
{noformat}

Looking at the table the rows [r0d646, r0edd9] and [r0f056, r10467] all had -1 values.  There was a tablet that overlapped the first range of -1 rows exactly 268;r0edd9;r0d645.  This tablet had only the following activity on a tablet server and was then merged out of existence.  The merge operation was 268;r10eff;r093b1.

{noformat}
19 00:05:10,966 [tabletserver.Tablet] DEBUG: Files for low split 268;r0edd9;r0d645  [/b-0001azp/I0001azt.rf, /b-0001azp/I0001azu.rf, /t-0001ale/A0001an3.rf]
19 00:05:10,974 [tabletserver.Tablet] TABLET_HIST: 268;r0f055;r0d645 split 268;r0edd9;r0d645 268;r0f055;r0edd9
19 00:05:10,975 [tabletserver.Tablet] TABLET_HIST: 268;r0edd9;r0d645 opened 
19 00:05:15,029 [tabletserver.Tablet] TABLET_HIST: 268;r0edd9;r0d645 import /b-0001azi/I0001azm.rf 17138 0
19 00:05:15,103 [tabletserver.Tablet] DEBUG: Starting MajC 268;r0edd9;r0d645 [/b-0001azi/I0001azm.rf, /b-0001azp/I0001azt.rf, /b-0001azp/I0001azu.rf, /t-0001ale/A0001an3.rf] --> /t-0001apj/A0001bri.rf_tmp
19 00:05:15,339 [tabletserver.Tablet] TABLET_HIST: 268;r0edd9;r0d645 import /b-0001azx/I0001azy.rf 16620 0
19 00:05:15,651 [tabletserver.Compactor] DEBUG: Compaction 268;r0edd9;r0d645 181,080 read | 60,360 written | 553,761 entries/sec |  0.327 secs
19 00:05:15,661 [tabletserver.Tablet] TABLET_HIST: 268;r0edd9;r0d645 MajC [/b-0001azi/I0001azm.rf, /b-0001azp/I0001azt.rf, /b-0001azp/I0001azu.rf, /t-0001ale/A0001an3.rf] --> /t-0001apj/A0001bri.rf
19 00:05:30,672 [tabletserver.Tablet] DEBUG: Starting MajC 268;r0edd9;r0d645 [/b-0001azx/I0001azy.rf] --> /t-0001apj/C0001brn.rf_tmp
19 00:05:30,810 [tabletserver.Compactor] DEBUG: Compaction 268;r0edd9;r0d645 60,360 read | 60,360 written | 534,159 entries/sec |  0.113 secs
19 00:05:30,824 [tabletserver.Tablet] TABLET_HIST: 268;r0edd9;r0d645 MajC [/b-0001azx/I0001azy.rf] --> /t-0001apj/C0001brn.rf
19 00:05:30,943 [tabletserver.Tablet] DEBUG: initiateClose(saveState=true queueMinC=false disableWrites=false) 268;r0edd9;r0d645
19 00:05:30,943 [tabletserver.Tablet] DEBUG: completeClose(saveState=true completeClose=true) 268;r0edd9;r0d645
19 00:05:30,947 [tabletserver.Tablet] TABLET_HIST: 268;r0edd9;r0d645 closed
19 00:05:30,947 [tabletserver.TabletServer] DEBUG: Unassigning 268;r0edd9;r0d645@(null,xxx.xxx.xxx.xxx:9997[134d7425fc59413],null)
19 00:05:30,949 [tabletserver.TabletServer] INFO : unloaded 268;r0edd9;r0d645
19 00:05:30,949 [tabletserver.TabletServer] INFO : unloaded 268;r0edd9;r0d645

{noformat}


For the second range of -1 values [r0f056, r10467], r0f056 corresponds to the split point r0f055.  Howerver, there is no split point corresponding to r10467. All of the tablets w/ a split of r0f055 lived on one tablet server.  

{noformat}
19 00:02:21,262 [tabletserver.Tablet] TABLET_HIST: 268<;r0d645 split 268;r0f055;r0d645 268<;r0f055
19 00:02:21,263 [tabletserver.Tablet] TABLET_HIST: 268;r0f055;r0d645 opened 
19 00:02:21,264 [tabletserver.Tablet] TABLET_HIST: 268<;r0f055 opened 
19 00:02:44,504 [tabletserver.Tablet] TABLET_HIST: 268<;r0f055 split 268;r11da6;r0f055 268<;r11da6
19 00:02:44,505 [tabletserver.Tablet] TABLET_HIST: 268;r11da6;r0f055 opened 
19 00:05:10,974 [tabletserver.Tablet] TABLET_HIST: 268;r0f055;r0d645 split 268;r0edd9;r0d645 268;r0f055;r0edd9
19 00:05:10,975 [tabletserver.Tablet] TABLET_HIST: 268;r0f055;r0edd9 opened 
19 00:05:15,023 [tabletserver.Tablet] TABLET_HIST: 268;r11da6;r0f055 split 268;r0f622;r0f055 268;r11da6;r0f622
19 00:05:15,024 [tabletserver.Tablet] TABLET_HIST: 268;r0f622;r0f055 opened 
{noformat}

All of the tablets mentioned so far were all merged away in the same merge operation, making this operation a possible place were data loss occurred.  However, I can not pinpoint the issue at this point in time.  Below is a little info about the merge from the master logs showing which tablets were involved in the merge.

{noformat}
19 00:05:30,616 [master.EventCoordinator] INFO : Merge state of 268;r10eff;r093b1 set to WAITING_FOR_CHOPPED
19 00:05:30,677 [master.Master] INFO : Asking xxx.xxx.xxx.xxx:9997[134d7425fc5940c] to chop 268;r09927;r0903a
19 00:05:30,678 [master.Master] INFO : Asking xxx.xxx.xxx.xxx:9997[134d7425fc5940c] to chop 268;r0ca9e;r09927
19 00:05:30,678 [master.Master] INFO : Asking xxx.xxx.xxx.xxx:9997[134d7425fc5940a] to chop 268;r0d2b5;r0ca9e
19 00:05:30,678 [master.Master] INFO : Asking xxx.xxx.xxx.xxx:9997[134d7425fc59412] to chop 268;r0d645;r0d2b5
19 00:05:30,678 [master.Master] INFO : Asking xxx.xxx.xxx.xxx:9997[134d7425fc59413] to chop 268;r0edd9;r0d645
19 00:05:30,678 [master.Master] INFO : Asking xxx.xxx.xxx.xxx:9997[134d7425fc59413] to chop 268;r0f055;r0edd9
19 00:05:30,678 [master.Master] INFO : Asking xxx.xxx.xxx.xxx:9997[134d7425fc59413] to chop 268;r0f622;r0f055
19 00:05:30,678 [master.Master] INFO : Asking xxx.xxx.xxx.xxx:9997[134d7425fc59413] to chop 268;r0f68b;r0f622
19 00:05:30,678 [master.Master] INFO : Asking xxx.xxx.xxx.xxx:9997[134d7425fc59413] to chop 268;r10c14;r0f68b
19 00:05:30,678 [master.Master] INFO : Asking xxx.xxx.xxx.xxx:9997[134d7425fc59413] to chop 268;r110f7;r10c14
{noformat}

When this test verifies its data and detects data loss, there is no easy way to determine at what time the data loss occurred.  It might be useful to modify the data in the bulk test such that it is easier to determine the time when data was lost.  For example the continuous ingest test creates linked list and it is possible to determine tight time bounds when a node was ingested.  However that may change the nature of this test and the bugs that it might find.",Running random walk test against 1.4.0-SNAPSHOT on 10 node cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-23 14:09:19.807,,,no_permission,,,,,,,,,,,,224546,,,Wed Jan 25 20:22:30 UTC 2012,,,,,,0|i07nt3:,42623,,,,,,,,"19/Jan/12 22:43;kturner;Looking at the code that generates the bulk files, when it generates six files it has the following start points.

{noformat}
r00000
r0411a
r08234
r0c34e
r10468
r14582
{noformat}

Therefore a file that was bulk imported ended with r10467 and a another file started with r10468. This lines up with the second range of data that was missing in the file.  I may change it to use random start points and print those start points out.  This will help w/ debugging a little bit, can get an idea when the file was ingested if the missing data aligns with a file.","20/Jan/12 16:43;kturner;Ran the test overnight and saw the bug again.  Have not looked into it in detail.  Billie helped me find the offendening ranges easily w/ the following shell command.  John assisted w/ the not zero.

{noformat}
/bin/accumulo shell -u root -p secret -e 'scan -t bulk_xxx_4807_1327038843548 -np' | egrep -C1 ""[^0]$"" | grep -C1 "" 0""
r17ecb cf:009 []    0
r17ecc cf:000 []    1
--
r18132 cf:009 []    1
r18133 cf:000 []    0
{noformat}

I thought this was cool enough to post.  Yesterday there were two bad ranges.  Today there is one.  Although yesterday I only looked for -1, so there could have been more.  This command looks for any non-zero values.
","20/Jan/12 20:40;kturner;I have been look into this second occurrence.  It is similar to the first.  There is one range of data that is wrong [r17ecc,r18132] which perfectly matches a tablet that existed 1hxx;r18132;r17ecb.  This tablet was created by a split, was short lived, and was wiped out by a merge.  All of the files that existed in 1hxx;r18132;r17ecb when it was closed ended up in the tablet created by the merge.  This rules out the merge dropping a file from the tablet.  This seems to leave two possibilities.

 * A bulk import into 1hxx;r18132;r17ecb silently failed, so it did not get a file that other tablets got.
 * The merge did not chop a tablet.

Looking for things that might indicate a failure to bulk import, I found the following.  The timing of the following error was immediately before the split that created 1hxx;r18132;r17ecb. But the range seems unrelated.

{noformat}
20 06:02:39,064 [client.BulkImporter] ERROR: Map file hdfs://xxx:6093/accumulo/tables/1hxx/b-0001zuj/I0001zul.rf failed more than three times, giving up.
20 06:02:39,064 [client.BulkImporter] ERROR: 	hdfs://xxx:6093/accumulo/tables/1hxx/b-0001zuj/I0001zul.rf -> 1hxx;r11fca;r1011f
20 06:02:39,096 [client.BulkImporter] DEBUG: Copying hdfs://xxx:6093/accumulo/tables/1hxx/b-0001zuj/I0001zul.rf to /tmp/bulk_aff331e7-73e2-46c3-a669-f35c73f51499_fail/I0001zul.rf
{noformat}

I looked at the parent tablets files, these files were passed to both siblings and compacted away by both siblings.  So none of the files from the parent of 1hxx;r18132;r17ecb ended up in the merged tablet.  I did not extend this analysis to tablets other than the parent.


  ",20/Jan/12 20:44;kturner;I think a next step is to look at the write ahead log entries for the metadata table related to this merge.  Maybe something obvious will show up like a tablet w/o a chopped flag set being deleted by the merge.,23/Jan/12 14:09;jvines;Eric just made an interesting observation- is it possible that ACCUMULO-338 is at fault here?,"23/Jan/12 14:13;ecn;I think you are right: this is hard to debug.  Perhaps we should add unique columns that are not Combined, so we can quickly identify missing values.","23/Jan/12 19:45;ecn;John, unfortunately the code was using the Aggregator interface, and not the Combiners, so that's unlikely.  I'm going to switch it to Combiners and added a unique row identifier.","25/Jan/12 20:22;kturner;I figured out what caused the second failure I reported by analyzing the write ahead logs.  A file was imported twice.

Below the write ahead logs show that the file I0001zul.rf was imported and then compacted away.

{noformat}
MUTATION 8315 7
1 mutations:
  1hxx;r182fe
      file:/b-0001zuj/I0001zul.rf [system]:727449 [] 2760,0,1327039345954
      loaded:/b-0001zuj/I0001zul.rf [system]:727449 [] 7322888910669682052
      srv:time [system]:727449 [] M1327039345954
      srv:lock [system]:727449 [] tservers/xxx.xxx.xxx.xxx:9997/zlock-0000000000$134d7425fc5ec43

MUTATION 8315 7
1 mutations:
  1hxx;r182fe
      file:/b-0001zkm/I0001zkq.rf [system]:727824 [] <deleted>
      file:/b-0001zky/I0001zl2.rf [system]:727824 [] <deleted>
      file:/b-0001zu3/I0001zu6.rf [system]:727824 [] <deleted>
      file:/b-0001zu7/I0001zu8.rf [system]:727824 [] <deleted>
      file:/b-0001zu9/I0001zui.rf [system]:727824 [] <deleted>
      file:/b-0001zuj/I0001zul.rf [system]:727824 [] <deleted>
      file:/b-0001zv3/I0001zvb.rf [system]:727824 [] <deleted>
      file:/b-0001zvc/I0001zvl.rf [system]:727824 [] <deleted>
      file:/t-0001ygn/A0001ytm.rf [system]:727824 [] <deleted>
      file:/t-0001ygn/C0001ytq.rf [system]:727824 [] <deleted>
      file:/t-0001ygn/A0001ytt.rf [system]:727824 [] 3400,10750
      srv:compact [system]:727824 [] 29
      last:134d7425fc5ec43 [system]:727824 [] xxx.xxx.xxx.xxx:9997
      srv:lock [system]:727824 [] tservers/xxx.xxx.xxx.xxx:9997/zlock-0000000000$134d7425fc5ec43
{noformat}

Then the tablet splits

{noformat}
MUTATION 8315 7
1 mutations:
  1hxx;r182fe
      ~tab:~pr [system]:727850 [] ^Ar18132
      ~tab:splitRatio [system]:727850 [] 0.4
      ~tab:oldprevrow [system]:727850 [] ^Ar17ecb
      chopped:chopped [system]:727850 [] <deleted>
      srv:lock [system]:727850 [] tservers/xxx.xxx.xxx.xxx:9997/zlock-0000000000$134d7425fc5ec43

MUTATION 8315 7
1 mutations:
  1hxx;r18132
      ~tab:~pr [system]:727851 [] ^Ar17ecb
      srv:dir [system]:727851 [] /t-0001ytu
      srv:time [system]:727851 [] M1327039359184
      srv:compact [system]:727851 [] 29
      loc:134d7425fc5ec43 [system]:727851 [] xxx.xxx.xxx.xxx:9997
      future:134d7425fc5ec43 [system]:727851 [] <deleted>
      file:/b-0001zvm/I0001zvq.rf [system]:727851 [] 1020,0,1327039359184
      file:/t-0001ygn/A0001ytt.rf [system]:727851 [] 1360,4300
      srv:lock [system]:727851 [] tservers/xxx.xxx.xxx.xxx:9997/zlock-0000000000$134d7425fc5ec43

MUTATION 8315 7
1 mutations:
  1hxx;r182fe
      ~tab:splitRatio [system]:727852 [] <deleted>
      ~tab:oldprevrow [system]:727852 [] <deleted>
      chopped:chopped [system]:727852 [] <deleted>
      file:/b-0001zvm/I0001zvq.rf [system]:727852 [] 1531,0,1327039359184
      file:/t-0001ygn/A0001ytt.rf [system]:727852 [] 2040,6450
      srv:lock [system]:727852 [] tservers/xxx.xxx.xxx.xxx:9997/zlock-0000000000$134d7425fc5ec43
{noformat}

Then the file is imported again into the new tablet created by the split.

{noformat}
MUTATION 8315 7
1 mutations:
  1hxx;r18132
      file:/b-0001zuj/I0001zul.rf [system]:727885 [] 2760,0,1327039360932
      loaded:/b-0001zuj/I0001zul.rf [system]:727885 [] 7322888910669682052
      srv:time [system]:727885 [] M1327039360932
      srv:lock [system]:727885 [] tservers/xxx.xxx.xxx.xxx:9997/zlock-0000000000$134d7425fc5ec43
{noformat}

I think the solution to this problem is to copy the loaded flags when a split occurs.  
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Back-to-back Security randomwalk tests fail,ACCUMULO-2194,12688870,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,bhavanki,bhavanki,14/Jan/14 22:33,13/Mar/14 14:44,13/Mar/19 22:01,13/Mar/14 14:44,1.4.4,,,,,,,1.4.5,1.5.2,1.6.0,test,,,,,,0,randomwalk,test,,,"When the Security randomwalk test is run twice in a row by a higher-level test (e.g., ShortClean), the second Security test fails relatively quickly. A sample log is attached.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14/Jan/14 22:51;bhavanki;Security_failure_log.txt;https://issues.apache.org/jira/secure/attachment/12623005/Security_failure_log.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-01-14 22:57:17.455,,,no_permission,,,,,,,,,,,,367837,,,Thu Mar 13 14:44:35 UTC 2014,,,,,,0|i1rei7:,368144,,,,,,,,"14/Jan/14 22:57;elserj;I just saw a similar error on 1.5.1 ({{ThriftSecurityException(user:table_host_domain, code:USER_DOESNT_EXIST}}), although, this was the first invocation of the Security module and it was triggered during a call to the validate module ({{org.apache.accumulo.test.randomwalk.security.Validate.validate(Validate.java:108}})","12/Mar/14 13:37;bhavanki;Got this a second time, but different error:

{noformat}
Caused by: org.apache.accumulo.core.client.AccumuloException: User didn't exist when they should (or
 worse- password mismatch)
        at org.apache.accumulo.server.test.randomwalk.security.TableOp.visit(TableOp.java:62)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
{noformat}

The common thread in both cases is that the table user is found to exist when the user was in fact dropped at the end of the prior run. I'm pretty sure, based on similar issues before, that it's just that ZK hasn't had time enough to completely absorb the change. (When starting a new security test, the system user is created but the table user is not, so this is not a problem for the system user account.) This time here, the time between dropping the user and the error is just under one second.","13/Mar/14 14:41;jira-bot;Commit ea86b44dfd6f46d389a630beb33ac49b65d87cd7 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ea86b44 ]

ACCUMULO-2194 Add delay for randomwalk Security teardown

If two Security randomwalk tests run back-to-back, the second test may see that the
table user still exists even though it was removed when the first test was torn down.
This can happen if the user drop does not propagate through Zookeeper quickly enough.
This commit adds a delay to the end of the Security test to give ZK some time.
","13/Mar/14 14:41;jira-bot;Commit ea86b44dfd6f46d389a630beb33ac49b65d87cd7 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ea86b44 ]

ACCUMULO-2194 Add delay for randomwalk Security teardown

If two Security randomwalk tests run back-to-back, the second test may see that the
table user still exists even though it was removed when the first test was torn down.
This can happen if the user drop does not propagate through Zookeeper quickly enough.
This commit adds a delay to the end of the Security test to give ZK some time.
","13/Mar/14 14:41;jira-bot;Commit ea86b44dfd6f46d389a630beb33ac49b65d87cd7 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ea86b44 ]

ACCUMULO-2194 Add delay for randomwalk Security teardown

If two Security randomwalk tests run back-to-back, the second test may see that the
table user still exists even though it was removed when the first test was torn down.
This can happen if the user drop does not propagate through Zookeeper quickly enough.
This commit adds a delay to the end of the Security test to give ZK some time.
","13/Mar/14 14:41;jira-bot;Commit ea86b44dfd6f46d389a630beb33ac49b65d87cd7 in accumulo's branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ea86b44 ]

ACCUMULO-2194 Add delay for randomwalk Security teardown

If two Security randomwalk tests run back-to-back, the second test may see that the
table user still exists even though it was removed when the first test was torn down.
This can happen if the user drop does not propagate through Zookeeper quickly enough.
This commit adds a delay to the end of the Security test to give ZK some time.
","13/Mar/14 14:44;bhavanki;Added 2-second delay to end of Security test. Yes, arbitrary delays stink but the same tactic is used elsewhere in the test, so at least it's consistent.

Tested by running two Security tests back-to-back, observed 2-second delay in logs; tests passed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TabletServerResourceManager MemoryManagementFramework constructor starts threads,ACCUMULO-2319,12693123,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,bhavanki,bhavanki,04/Feb/14 15:43,12/Mar/14 20:59,13/Mar/19 22:01,12/Mar/14 20:59,1.4.4,1.5.0,,,,,,1.4.5,1.5.2,1.6.0,tserver,,,,,,0,this,thread-safety,,,The constructor for the inner class {{MemoryManagementFramework}} in {{TabletServerResourceManager}} starts off a couple of threads in its constructor. This is bad practice as it allows this to escape.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-12 20:55:37.04,,,no_permission,,,,,,,,,,,,371709,,,Wed Mar 12 20:59:25 UTC 2014,,,,,,0|i1s273:,372009,,,,,,,,"12/Mar/14 20:55;jira-bot;Commit d11acbe5dc3f88efcb03b5b08832ecfa9fc15381 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d11acbe ]

ACCUMULO-2319 Move MemoryManagementFramework thread starts out of constructor
","12/Mar/14 20:55;jira-bot;Commit d11acbe5dc3f88efcb03b5b08832ecfa9fc15381 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d11acbe ]

ACCUMULO-2319 Move MemoryManagementFramework thread starts out of constructor
","12/Mar/14 20:55;jira-bot;Commit d11acbe5dc3f88efcb03b5b08832ecfa9fc15381 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d11acbe ]

ACCUMULO-2319 Move MemoryManagementFramework thread starts out of constructor
","12/Mar/14 20:55;jira-bot;Commit d11acbe5dc3f88efcb03b5b08832ecfa9fc15381 in accumulo's branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d11acbe ]

ACCUMULO-2319 Move MemoryManagementFramework thread starts out of constructor
","12/Mar/14 20:59;bhavanki;The fix was very straightforward and confined to {{TabletResourceServerManager}}.

Tested by running tserver and observing that the two threads involved are still started. Also did a small amount of table changes in the shell.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
client code cannot create an RFile without logging a warning,ACCUMULO-2401,12697009,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,24/Feb/14 22:05,11/Mar/14 21:53,13/Mar/19 22:01,26/Feb/14 17:54,1.5.0,,,,,,,1.5.2,1.6.0,,client,,,,,,0,16_qa_bug,,,,"Examining the output of the SimpleProxyIT, I noticed the test was always printing a message about not being able to access accumulo-site.xml.  This is coming from a call to AccumuloConfiguration.getSiteConfiguration() buried down in BCFile.Writer for the encryption stuff.

Client-side code should not be calling getSiteConfiguration().
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2460,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-25 17:26:23.552,,,no_permission,,,,,,,,,,,,375484,,,Tue Mar 11 21:53:17 UTC 2014,,,,,,0|i1spdb:,375780,,,,,,,,"25/Feb/14 17:26;jira-bot;Commit f2de427f74a8a6ffa05c6209e7161e7349458241 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f2de427 ]

ACCUMULO-2401
removed many calls to deprecated AccumuloConfiguration.getSiteConfiguration()
fixed hacky crypto tests that messed with the site configuration
","25/Feb/14 17:26;jira-bot;Commit 840dba269266e4895a12ca2074d36e356076e656 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=840dba2 ]

ACCUMULO-2401 finish removing hacky site-configuration manipulation
","25/Feb/14 17:26;jira-bot;Commit f2de427f74a8a6ffa05c6209e7161e7349458241 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f2de427 ]

ACCUMULO-2401
removed many calls to deprecated AccumuloConfiguration.getSiteConfiguration()
fixed hacky crypto tests that messed with the site configuration
","25/Feb/14 17:26;jira-bot;Commit 840dba269266e4895a12ca2074d36e356076e656 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=840dba2 ]

ACCUMULO-2401 finish removing hacky site-configuration manipulation
","26/Feb/14 22:54;ctubbsii;I'm not sure I quite understand the justification for adding experimental properties to the DefaultConfiguration, where they were previously excluded.",11/Mar/14 17:03;ctubbsii;[~ecn] Any reason why this patch exposed experimental properties in the documentation without labeling them as experimental?,"11/Mar/14 17:47;ecn;It wasn't deliberate.  Since I moved the reference to SiteConfiguration out of rfile, I had to pass a configuration in to lots of places that made rfiles.  I passed in DefaultConfiguration.  One of the places that uses experimental properties was... rfile, so I needed to have them in DefaultConfiguration.

The document generator seems to ignore them.  Are you talking about the javadocs?

","11/Mar/14 21:53;ctubbsii;Sorry, that should have been ""shell config command"", not ""documentation"".

Experimental properties were hidden from the output of the shell config command, unless they were actually used, by excluding them from the DefaultConfiguration. The reason is that the semantics of ""experimental"" imply ""optional"", and ""optional"" implies that it could be null/unset/absent, and still work correctly. While I'm primarily concerned about prominent exposure of experimental properties through the shell and documentation, the same argument applies to anything that uses the DefaultConfiguration, because that's where the semantics of ""experimental"" are communicated to the user (by their omission/lack of prominence).

Because the DefaultConfiguration conveys the semantics about which properties are prominently exposed as available, I think experimental properties should continue to be omitted from it, and we add a test to ensure that the defaults for these are null and excluded. The code that depends on them being otherwise should be changed to handle them being null, or they should not be considered experimental. Alternatively, we'd have to find a better way to convey that certain properties are experimental, in spite of being so prominently exposed (and I can't think of a way to programatically communicate that, other than through omission; I think documentation that says ""don't use this unless you know what you're doing; this is experimental and subject to change"" is insufficient, as it will largely be ignored... if it's there, people will use it and depend on it).

The code change, for reference:
{code}git log -n1 -p -U5 f2de427f -- core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java{code}

I made ACCUMULO-2460, for follow-on.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConcurrentModificationException in master at startup,ACCUMULO-2425,12698513,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,03/Mar/14 21:41,11/Mar/14 11:55,13/Mar/19 22:01,06/Mar/14 21:24,1.5.1,,,,,,,1.5.2,1.6.0,,master,,,,,,0,,,,,"I had brought down my accumulo services hard, immediately ran start-here to bring them up again and the master didn't seem to start. Checked the logs and I had 

{code}2014-03-03 16:38:05,336 [master.Master] ERROR: Unexpected exception, exiting
java.util.ConcurrentModificationException
        at java.util.Hashtable$Enumerator.next(Hashtable.java:1048)
        at org.apache.commons.configuration.AbstractConfiguration.append(AbstractConfiguration.java:1239)
        at org.apache.accumulo.core.conf.Property.getDefaultValue(Property.java:401)
        at org.apache.accumulo.core.conf.DefaultConfiguration.iterator(DefaultConfiguration.java:54)
        at org.apache.accumulo.core.conf.SiteConfiguration.iterator(SiteConfiguration.java:77)
        at org.apache.accumulo.server.conf.ZooConfiguration.iterator(ZooConfiguration.java:127)
        at org.apache.accumulo.server.Accumulo.init(Accumulo.java:125)
        at org.apache.accumulo.server.master.Master.main(Master.java:2303)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:622)
        at org.apache.accumulo.start.Main$1.run(Main.java:103)
        at java.lang.Thread.run(Thread.java:701)
{code}

sitting there, and then it seems the master died. Started it up again and it was fine.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-04 15:43:50.391,,,no_permission,,,,,,,,,,,,376871,,,Tue Mar 11 11:55:02 UTC 2014,,,,,,0|i1sxwn:,377166,,,,,,,,"04/Mar/14 15:43;ecn;These line numbers do not seem to correspond to the 1.5.1 release.  In particular, there is no call to AbstractConfiguration.append on line 401 of Property.java.  Did you have outstanding modifications?
","04/Mar/14 17:25;vines;Ah crud, you're right, I had some added Properties I was playing with around encryption. The corrected stack trace around it would be 
{code}2014-03-03 16:38:05,336 [master.Master] ERROR: Unexpected exception, exiting
java.util.ConcurrentModificationException
        at java.util.Hashtable$Enumerator.next(Hashtable.java:1048)
        at org.apache.commons.configuration.AbstractConfiguration.append(AbstractConfiguration.java:1239)
        at org.apache.accumulo.core.conf.Property.getDefaultValue(Property.java:390)
        at org.apache.accumulo.core.conf.DefaultConfiguration.iterator(DefaultConfiguration.java:54)
        at org.apache.accumulo.core.conf.SiteConfiguration.iterator(SiteConfiguration.java:77)
        at org.apache.accumulo.server.conf.ZooConfiguration.iterator(ZooConfiguration.java:127)
        at org.apache.accumulo.server.Accumulo.init(Accumulo.java:125)
        at org.apache.accumulo.server.master.Master.main(Master.java:2303)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:622)
        at org.apache.accumulo.start.Main$1.run(Main.java:103)
        at java.lang.Thread.run(Thread.java:701){code}


Though if you think that added properties would cause this, go ahead and close it as invalid.",04/Mar/14 17:46;vines;I have also seen this with the Monitor,"05/Mar/14 23:33;jvines@gmail.com;And a tserver now






-- 
Cheers
~John
","06/Mar/14 18:54;vines;Alright, I'm pretty sure the MonitorLog4jWatcher, which calls System.setProperty, is causing this. The CME occurs when there is iteration over the result of System.getProperties, which does no copying for thread safety. I like to think that this should be something handled in Commons configuration (which it's still not in later releases). At the very least, we can address this manually by not relying directly on SystemConfiguration or maybe starting the MonitorLog4jWatcher later","06/Mar/14 21:21;jira-bot;Commit f76b8e07ac1f7247eb7a65ad887dce54b9b6aafd in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f76b8e0 ]

ACCUMULO-2425 - making SystemConfigurations synchronized until addressed in commons configuration
","06/Mar/14 21:23;jira-bot;Commit f76b8e07ac1f7247eb7a65ad887dce54b9b6aafd in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f76b8e0 ]

ACCUMULO-2425 - making SystemConfigurations synchronized until addressed in commons configuration
","06/Mar/14 21:23;jira-bot;Commit f76b8e07ac1f7247eb7a65ad887dce54b9b6aafd in accumulo's branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f76b8e0 ]

ACCUMULO-2425 - making SystemConfigurations synchronized until addressed in commons configuration
",06/Mar/14 21:24;vines;Took out reliance on SystemConfiguration() and instead opted to use SystemProperties manually with synchronization,"06/Mar/14 21:36;vines;Also, I tested it with a loop on  {code}timeout 3 bin/accumulo master; if [ ""$?"" -eq ""1"" ]; then break; fi;{code}","10/Mar/14 21:41;vines;I got a response from the commons configuration folks, and http://commons.apache.org/proper/commons-configuration/userguide/howto_basicfeatures.html#Variable_Interpolation was pointed out to me. Changing VFS_CLASSLOADER_CACHE_DIR's default value to have a sys: in front of the two variables allowed me to change getDefaultValue() to
{code}
  public String getDefaultValue() {
    if (this.interpolated) {
      PropertiesConfiguration pconf = new PropertiesConfiguration();
      pconf.addProperty(""hack_default_value"", this.defaultValue);
      String v = pconf.getString(""hack_default_value"");
      if (this.type == PropertyType.ABSOLUTEPATH)
        return new File(v).getAbsolutePath();
      else
        return v;
    } else {
      return getRawDefaultValue();
    }
  }
{code}

Theoretically, we could just make it
{code}
  public String getDefaultValue() {
      PropertiesConfiguration pconf = new PropertiesConfiguration();
      pconf.addProperty(""hack_default_value"", this.defaultValue);
      String v = pconf.getString(""hack_default_value"");
      if (this.type == PropertyType.ABSOLUTEPATH)
        return new File(v).getAbsolutePath();
      else
        return v;
  }
{code}

and just squelch interpolation entirely. However, I'm hesitant to even make just the first fix because that would actually change the parsing behavior for that one property. We'd need to make it clear that that's how system properties need to be set up.",10/Mar/14 21:48;elserj;I like that a lot better.,"10/Mar/14 22:04;vines;I'm not sure if trimming it down to my latter example is a concern though. I'm not really worried about users having system variables in their site-xml that they're not using, and the VFS_CLASSLOADER_CACHE_DIR can't be overridden in a similar manner (https://issues.apache.org/jira/browse/ACCUMULO-2449), so I think adding this as a feature is extremely low risk.","10/Mar/14 22:10;vines;Actually, further thought- interpolation is ONLY used for defaultValues. What was going on here when that was written? Why do we not want interpolation with user defined settings?","11/Mar/14 11:55;ctubbsii;{quote}What was going on here when that was written?{quote}

Interpolation was added to *document* the default value only. Originally, VFS_CLASSLOADER_CACHE_DIR just declared System.getProperty(""java.io.tmpdir"") as part of its value, but that screwed up the auto-generated documentation, by hard-coding the values for the system on which it was built, rather than the values which would actually be used at runtime. This was just a hack to get the documentation correct.

{quote}Why do we not want interpolation with user defined settings?{quote}

I think we do, but that hasn't been added yet. I think that's best done by transitioning the whole configuration to commons-configuration.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Renaming table don't require namespace,ACCUMULO-2318,12692962,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,03/Feb/14 21:45,09/Mar/14 16:52,13/Mar/19 22:01,05/Mar/14 18:43,,,,,,,,1.6.0,,,client,,,,,,0,,,,,"If you rename a table, the old table name must be fully qualified. But the destination table does not require the namespace prefix. First of all, this doesn't seem intuitive. Secondly, it will makes things monumentally difficult should we support renaming across namespaces.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2316,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-03 23:29:09.314,,,no_permission,,,,,,,,,,,,371548,,,Sun Mar 09 16:52:58 UTC 2014,,,,,,0|i1s17b:,371850,,,,,,,,"03/Feb/14 23:29;jira-bot;Commit 17324b9d00c30b2e1e31d9dfe5aaae369e832873 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=17324b9 ]

ACCUMULO-2318 making rename's second argument require a namespace
","03/Feb/14 23:40;jira-bot;Commit 17324b9d00c30b2e1e31d9dfe5aaae369e832873 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=17324b9 ]

ACCUMULO-2318 making rename's second argument require a namespace
","06/Feb/14 02:41;ctubbsii;The principle for the previous behavior, prior to this ticket, was, by analogy that ""Rename Christopher Tubbs to Michael"" was intuitive enough, and that one shouldn't have to say ""Rename Christopher Tubbs to Michael Tubbs"". Likewise, the first parameter could be fully-qualified, because it needed enough information to identify the table to change, and the second parameter was simply the new name to give the identified table (not a new location/namespace... simply a new name).

I feel it's non-intuitive that a rename doesn't just update the name of the table, but might also move it. By expecting unqualified names, it's clear that this behavior is not possible, but we also allowed fully-qualified names, as long as it was referring to the same namespace, so users weren't surprised if they always used fully-qualified names.

So, I'm not convinced this was any more intuitive than the documented behavior, but I'm not strongly tied to either one, as far as intuitive-ness. However, it was made quite clear in the javadoc how it was expected to work, and the previous implementation followed the documented behavior. It now no longer does. If this change is acceptable, then it needs a corresponding javadoc update.
","06/Feb/14 02:43;ctubbsii;Also, a test should be added to NamespacesIT that explicitly tests that it will not work if unqualified.",06/Feb/14 02:44;vines;Javadocs need to be updated,26/Feb/14 16:23;kturner;[~vines] are you planning on updating the javadocs?,"26/Feb/14 16:53;vines;Yeah, I'll be getting to it next week",09/Mar/14 16:52;ctubbsii;Commit which fixed this: https://git-wip-us.apache.org/repos/asf?p=accumulo.git;a=commitdiff;h=4e499f35,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Shell does not clean up JLine ConsoleReader, leaks threads",ACCUMULO-2429,12698874,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,bhavanki,bhavanki,05/Mar/14 14:19,07/Mar/14 16:28,13/Mar/19 22:01,07/Mar/14 16:28,,,,,,,,1.6.0,1.7.0,,shell,,,,,,0,memory-leak,shell,threads,,"The shell uses the JLine {{ConsoleReader}} class. That class spawns a thread on construction (tsk-tsk) for its internal non-blocking input stream representation. If the {{ConsoleReader}} is not shut down properly, the thread keeps running. This is particularly a problem when running {{ShellServerIT}} under 1.6 and later; the JVM can run out of memory to allocate threads and fail the test.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-05 16:46:00.06,,,no_permission,,,,,,,,,,,,377221,,,Fri Mar 07 16:27:47 UTC 2014,,,,,,0|i1t02f:,377516,,,,,,,,"05/Mar/14 16:30;bhavanki;Review up, pretty simple.",05/Mar/14 16:46;elserj;Does the same issue affect ShellServerTest in 1.5 (and 1.4 maybe)?,"05/Mar/14 16:48;elserj;Sorry for dbl comment: meant from a ""should this also be fixed in those earlier branches"" standpoint. Anything to make those tests better is good IMO. ","05/Mar/14 16:52;bhavanki;Good question. I had expected so, but 1.4 and 1.5 use older versions of JLine (0.9.94 and 1.0, respectively) that don't have the thread / shutdown feature. I expect they are OK.",05/Mar/14 18:10;elserj;Okay. I suspected that might be the case but wanted to mention it before I forgot :),"07/Mar/14 16:27;jira-bot;Commit 8acdf534ceb92627075a1417e61c5e14790ee9d8 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8acdf53 ]

ACCUMULO-2429 Add shell shutdown for thread cleanup

The JLine 2 ConsoleReader used by Shell spawns a thread which should be cleaned up when
done with the Shell. Otherwise, the thread leaks, taking up resources when the shell is
used programmatically. This commit adds a shutdown() method to Shell for cleaning up the
thread. This enables ShellServerIT to pass reliably and not flood the OS with leaked
threads.
","07/Mar/14 16:27;jira-bot;Commit 8acdf534ceb92627075a1417e61c5e14790ee9d8 in accumulo's branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8acdf53 ]

ACCUMULO-2429 Add shell shutdown for thread cleanup

The JLine 2 ConsoleReader used by Shell spawns a thread which should be cleaned up when
done with the Shell. Otherwise, the thread leaks, taking up resources when the shell is
used programmatically. This commit adds a shutdown() method to Shell for cleaning up the
thread. This enables ShellServerIT to pass reliably and not flood the OS with leaked
threads.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bulk import thread pool initialized in non-static method.,ACCUMULO-2270,12691698,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vickyuec,kturner,kturner,28/Jan/14 19:05,07/Mar/14 15:58,13/Mar/19 22:01,07/Mar/14 15:58,1.5.0,,,,,,,1.5.2,1.6.0,1.7.0,,,,,,,0,,,,,In 1.5 org.apache.accumulo.server.master.tableOps.BulkImport.LoadFiles has a static thread pool. This static thread pool is initialized with a non-static syncronized method.  1.4 initializes in a static code block.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29/Jan/14 07:32;vickyuec;ACCUMULO-2270.v1.patch.txt;https://issues.apache.org/jira/secure/attachment/12625814/ACCUMULO-2270.v1.patch.txt,06/Mar/14 20:30;vickyuec;ACCUMULO-2270.v2.patch.txt;https://issues.apache.org/jira/secure/attachment/12633220/ACCUMULO-2270.v2.patch.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2014-01-29 07:32:44.325,,,no_permission,,,,,,,,,,,,370443,,,Fri Mar 07 15:57:58 UTC 2014,,,,,,0|i1ruk7:,370764,,,,,,,,29/Jan/14 07:32;vickyuec;Attached patch against master.,"03/Mar/14 16:25;bhavanki;That method should definitely be made {{static}} and {{private}}. However, more work needs to be done here, because there is a reference to {{threadPool}} in the {{call()}} method that is not thread-safe. Even though creation of the thread pool is synchronized, another thread may see the pool in a partially constructed state. The [lazy initialization holder class idiom|http://blog.crazybob.org/2007/01/lazy-loading-singletons.html] should be used here.

This wouldn't have been an issue in 1.4 because static code blocks give you safe publication.",06/Mar/14 20:30;vickyuec;Incorporated feedback from Bill.,"07/Mar/14 15:54;jira-bot;Commit 18006d245372640472ecc9f987a32cb989cb3be6 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=18006d2 ]

ACCUMULO-2270 Make initialization of static threadpool thread-safe

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Mar/14 15:54;jira-bot;Commit 9231648ae1d7795456970f858b37f6bfc110e6ca in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9231648 ]

ACCUMULO-2270 Make initialization of static threadpool thread-safe

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Mar/14 15:54;jira-bot;Commit 7b0e4635b82bc2efd6893de28a04bd574381c6fd in accumulo's branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7b0e463 ]

ACCUMULO-2270 Make initialization of static threadpool thread-safe

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Mar/14 15:56;jira-bot;Commit 18006d245372640472ecc9f987a32cb989cb3be6 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=18006d2 ]

ACCUMULO-2270 Make initialization of static threadpool thread-safe

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Mar/14 15:56;jira-bot;Commit 18006d245372640472ecc9f987a32cb989cb3be6 in accumulo's branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=18006d2 ]

ACCUMULO-2270 Make initialization of static threadpool thread-safe

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Mar/14 15:56;jira-bot;Commit 9231648ae1d7795456970f858b37f6bfc110e6ca in accumulo's branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9231648 ]

ACCUMULO-2270 Make initialization of static threadpool thread-safe

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Mar/14 15:57;bhavanki;Thanks Vikram!

Note on commits: I backported Vikram's patch for 1.5.x; his original patch applied cleanly to 1.6.x and master. (I also neglected to merge forward initially, but did so after the first round of commits that included the patch.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Configuration documentation generation (docs/config.html) should not interpolate properties,ACCUMULO-1440,12648495,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,20/May/13 20:10,06/Mar/14 20:32,13/Mar/19 22:01,21/May/13 01:56,,,,,,,,1.5.0,,,,,,,,,0,,,,,Default configuration properties are being interpolated with Java system properties. This should not be happening when generating documentation.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2425,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-21 00:55:29.017,,,no_permission,,,,,,,,,,,,328850,,,Tue May 21 06:41:52 UTC 2013,,,,,,0|i1kqkf:,329192,,,,,,,,"21/May/13 00:55;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #130 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/130/])
    ACCUMULO-1440 Separate variable interpolation in properties at runtime from the documentation generated at compile time (Revision 1484620)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/conf/PropertyTest.java
","21/May/13 00:57;hudson;Integrated in Accumulo-1.5 #128 (See [https://builds.apache.org/job/Accumulo-1.5/128/])
    ACCUMULO-1440 Separate variable interpolation in properties at runtime from the documentation generated at compile time (Revision 1484620)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/conf/PropertyTest.java
","21/May/13 06:31;hudson;Integrated in Accumulo-Trunk #883 (See [https://builds.apache.org/job/Accumulo-Trunk/883/])
    ACCUMULO-1440, ACCUMULO-1436 merge to trunk (Revision 1484639)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/conf/PropertyTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
","21/May/13 06:41;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #242 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/242/])
    ACCUMULO-1440, ACCUMULO-1436 merge to trunk (Revision 1484639)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/conf/PropertyTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Table based Security operations should throw Table not found exceptions over namespace not found,ACCUMULO-2316,12692947,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,03/Feb/14 20:25,06/Mar/14 20:06,13/Mar/19 22:01,06/Mar/14 19:04,,,,,,,,1.6.0,,,client,,,,,,0,,,,,"A majority of the table api around security operations will do table checks which, if the table is not found, will throw a Namespace not found exceptions if the namespace also does not exist. This isn't really intuitive and should be changed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-03 23:29:10.007,,,no_permission,,,,,,,,,,,,371533,,,Thu Mar 06 20:06:26 UTC 2014,,,,,,0|i1s13z:,371835,,,,,,,,"03/Feb/14 23:29;jira-bot;Commit 98e374b0ea342136d4ef68cd3a266653ea07de11 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=98e374b ]

ACCUMULO-2316 No more namespacenotfound for table requests
","03/Feb/14 23:40;jira-bot;Commit 98e374b0ea342136d4ef68cd3a266653ea07de11 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=98e374b ]

ACCUMULO-2316 No more namespacenotfound for table requests
","06/Feb/14 02:08;ctubbsii;I don't think the changes to the NamespacesIT test are correct in the prior commit.

Abbreviations:
TableNotFoundException is TNFE; NamespaceNotFoundException is NSNFE; AccumuloException is AE; ""<="" is ""caused by""

In one case, where we were checking to ensure those methods threw a (TNFE <= NSNFE), to ensure users knew why the table wasn't found, you changed it to allow either a (TNFE) *or* (any exception <= NSNFE).

In other place, we were explicitly checking older APIs that could only throw AE, to ensure that they threw precisely an (AE <= TNFE <= NSNFE). Those now permit (TNFE) *or* any (AE <= TNFE), even if it was not caused by a NSFE.

Also, the entire block of code checking to ensure renames for unqualified table names as the second param work was simply removed. That, in spite of the javadoc explicitly describing this being expected behavior. It seems to me that if we document we can do it, we should keep the test that ensures it works.",06/Feb/14 02:11;vines;We removed the renamed to unqualified table is assumed to be in the same namespace. The javadoc needs to be updated though.,06/Feb/14 02:45;vines;Need to address 2 of the issues Christopher brought up,"06/Feb/14 19:35;ctubbsii;Specifically, the first two, regarding exceptions. The third issue is ACCUMULO-2318 and just needs a javadoc/test update to complete, but the behavior change was satisfactorily justified in that ticket.",26/Feb/14 17:53;kturner;Whats the status of this ticket?,26/Feb/14 18:01;vines;I will be working on it come next week,"06/Mar/14 19:03;jira-bot;Commit 5c0ca2cb78f11efb9a46ec328c633aa7a79f34ba in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c0ca2c ]

Revert ""ACCUMULO-2316 No more namespacenotfound for table requests""

This reverts commit 98e374b0ea342136d4ef68cd3a266653ea07de11.

Conflicts:
	test/src/test/java/org/apache/accumulo/test/NamespacesIT.java
","06/Mar/14 19:03;jira-bot;Commit 68afb1efb85b80068bbe67b30a4b9aba41c502c1 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=68afb1e ]

ACCUMULO-2316 a simpler approach for property security exceptions
","06/Mar/14 19:04;vines;Went with a simpler approach to simply handle those error in the 3 table commands. Dirtier, but simpler as well.","06/Mar/14 20:06;jira-bot;Commit 5c0ca2cb78f11efb9a46ec328c633aa7a79f34ba in accumulo's branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c0ca2c ]

Revert ""ACCUMULO-2316 No more namespacenotfound for table requests""

This reverts commit 98e374b0ea342136d4ef68cd3a266653ea07de11.

Conflicts:
	test/src/test/java/org/apache/accumulo/test/NamespacesIT.java
","06/Mar/14 20:06;jira-bot;Commit 68afb1efb85b80068bbe67b30a4b9aba41c502c1 in accumulo's branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=68afb1e ]

ACCUMULO-2316 a simpler approach for property security exceptions
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TraceProxy.trace should not throw InvocationTargetException,ACCUMULO-2390,12696606,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mdrob,mdrob,mdrob,21/Feb/14 18:32,06/Mar/14 14:49,13/Mar/19 22:01,24/Feb/14 17:35,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,trace,,,,,,0,logging,,,,"In {{TraceProxy.trace}} there is the following code snippet:
{code}
        try {
          return method.invoke(instance, args);
        } catch (Throwable ex) {
          ex.printStackTrace();
          throw ex;
        }
{code}
When this is an InvocationTargetException, it can really mess with the calling code's exception handling logic.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-24 17:32:48.185,,,no_permission,,,,,,,,,,,,375082,,,Mon Feb 24 17:32:50 UTC 2014,,,,,,0|i1smwn:,375381,,,,,,,,"24/Feb/14 17:32;jira-bot;Commit 2829426618b6e7d1487a4c88dd7b09186b9898d5 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2829426 ]

ACCUMULO-2390 InvocationTargetEx in TraceProxy

Handle InvocationTargetException specifically in TraceProxy, instead
of letting it get propogated up the call stack. In some cases this is
very bad as it turned into an UndeclaredThrowableException and made
debugging more difficult than necessary.

Added unit test to verify behaviour.
","24/Feb/14 17:32;jira-bot;Commit 2829426618b6e7d1487a4c88dd7b09186b9898d5 in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2829426 ]

ACCUMULO-2390 InvocationTargetEx in TraceProxy

Handle InvocationTargetException specifically in TraceProxy, instead
of letting it get propogated up the call stack. In some cases this is
very bad as it turned into an UndeclaredThrowableException and made
debugging more difficult than necessary.

Added unit test to verify behaviour.
","24/Feb/14 17:32;jira-bot;Commit 2829426618b6e7d1487a4c88dd7b09186b9898d5 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2829426 ]

ACCUMULO-2390 InvocationTargetEx in TraceProxy

Handle InvocationTargetException specifically in TraceProxy, instead
of letting it get propogated up the call stack. In some cases this is
very bad as it turned into an UndeclaredThrowableException and made
debugging more difficult than necessary.

Added unit test to verify behaviour.
","24/Feb/14 17:32;jira-bot;Commit 2829426618b6e7d1487a4c88dd7b09186b9898d5 in accumulo's branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2829426 ]

ACCUMULO-2390 InvocationTargetEx in TraceProxy

Handle InvocationTargetException specifically in TraceProxy, instead
of letting it get propogated up the call stack. In some cases this is
very bad as it turned into an UndeclaredThrowableException and made
debugging more difficult than necessary.

Added unit test to verify behaviour.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Main.main can log cleaner messages when underlying process has errors,ACCUMULO-2404,12697135,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mdrob,mdrob,mdrob,25/Feb/14 15:51,06/Mar/14 14:49,13/Mar/19 22:01,25/Feb/14 19:54,1.4.0,,,,,,,1.4.5,1.5.2,1.6.0,start,,,,,,0,logging,,,,"When the main process invoked by {{org.apache.accumulo.start.Main.main()}} has error, then they usually show up as an {{InvocationTargetException}}. This creates extra noise for people trying to debug, and hides the actual error in the middle of the stack trace instead of bringing it to the top.

The solution is similar to that in ACCUMULO-2390",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-25 19:53:09.043,,,no_permission,,,,,,,,,,,,375609,,,Tue Feb 25 19:53:11 UTC 2014,,,,,,0|i1sq4v:,375905,,,,,,,,25/Feb/14 16:49;mdrob;Review available at https://reviews.apache.org/r/18467/,"25/Feb/14 19:53;jira-bot;Commit 1543d65fb2ff54ede7785f591f30f3764622b4df in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1543d65 ]

ACCUMULO-2404 Better error logging in start.Main

Propogate original exceptions instead of the wrapping
InvocationTargetException when possible, when starting processes
through o.a.a.start.Main
","25/Feb/14 19:53;jira-bot;Commit 1543d65fb2ff54ede7785f591f30f3764622b4df in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1543d65 ]

ACCUMULO-2404 Better error logging in start.Main

Propogate original exceptions instead of the wrapping
InvocationTargetException when possible, when starting processes
through o.a.a.start.Main
","25/Feb/14 19:53;jira-bot;Commit 1543d65fb2ff54ede7785f591f30f3764622b4df in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1543d65 ]

ACCUMULO-2404 Better error logging in start.Main

Propogate original exceptions instead of the wrapping
InvocationTargetException when possible, when starting processes
through o.a.a.start.Main
","25/Feb/14 19:53;jira-bot;Commit 1543d65fb2ff54ede7785f591f30f3764622b4df in accumulo's branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1543d65 ]

ACCUMULO-2404 Better error logging in start.Main

Propogate original exceptions instead of the wrapping
InvocationTargetException when possible, when starting processes
through o.a.a.start.Main
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Monitor should not list jetty as provided,ACCUMULO-2301,12692579,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mdrob,busbey,busbey,31/Jan/14 19:57,05/Mar/14 03:49,13/Mar/19 22:01,04/Mar/14 21:01,1.4.4,1.5.0,,,,,,1.4.5,1.5.2,,build,,,,,,0,newbie,,,,"We list hadoop-client as our dependency for Hadoop 2 and Monitor assumes jetty will be provided.

Users should be able to just add hadoop-client in their classpath to have things work. hadoop-client does not include jetty.

We should instead include jetty in the packaged libs for Monitor.

(ACCUMULO-1853 fixed this in 1.6.0-SNAPSHOT)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-04 21:00:42.908,,,no_permission,,,,,,,,,,,,371174,,,Wed Mar 05 03:49:10 UTC 2014,,,,,,0|i1ryxb:,371478,,,,,,,,"04/Mar/14 21:00;jira-bot;Commit 0f2324573afd1118854c305f4e775882df21021a in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0f23245 ]

ACCUMULO-2301 Add Jetty to packaging

Add Jetty to packaging list. Remove duplicate entry in server pom.
","04/Mar/14 21:00;jira-bot;Commit 0f2324573afd1118854c305f4e775882df21021a in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0f23245 ]

ACCUMULO-2301 Add Jetty to packaging

Add Jetty to packaging list. Remove duplicate entry in server pom.
","04/Mar/14 21:00;jira-bot;Commit 0f2324573afd1118854c305f4e775882df21021a in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0f23245 ]

ACCUMULO-2301 Add Jetty to packaging

Add Jetty to packaging list. Remove duplicate entry in server pom.
","05/Mar/14 03:49;jira-bot;Commit 0f2324573afd1118854c305f4e775882df21021a in accumulo's branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0f23245 ]

ACCUMULO-2301 Add Jetty to packaging

Add Jetty to packaging list. Remove duplicate entry in server pom.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Race condition in MetadataIT.mergeMeta(),ACCUMULO-2405,12697154,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,25/Feb/14 17:28,27/Feb/14 17:15,13/Mar/19 22:01,27/Feb/14 17:15,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Saw the following error while running ITs.

{noformat}
mergeMeta(org.apache.accumulo.test.functional.MetadataIT)  Time elapsed: 10.39 sec  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.accumulo.test.functional.MetadataIT.mergeMeta(MetadataIT.java:103)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}

Looking at the test it merges the metadata table, sleeps for 2 secs, and then scans for delete entries. Looking in the logs I think the AGC deleted the delete entries while the test was sleeping.

Saw the following in the master log

{noformat}
2014-02-25 12:06:36,981 [master.EventCoordinator] INFO : Merge state of !0<< set to MERGING
2014-02-25 12:06:37,047 [master.EventCoordinator] INFO : Merge state of !0<< set to COMPLETE
2014-02-25 12:06:37,169 [state.MergeStats] INFO : Computing next merge state for !0<< which is presently COMPLETE isDelete : false
2014-02-25 12:06:37,189 [master.EventCoordinator] INFO : Merge state of !0<< set to NONE
2014-02-25 12:06:37,212 [tableOps.MasterRepo] INFO : removing merge information No Merge in progress
2014-02-25 12:06:37,213 [master.EventCoordinator] INFO : Merge state of !0 cleared
{noformat}

Then saw the following in the AGC logs.

{noformat}
2014-02-25 12:06:39,335 [gc.SimpleGarbageCollector] DEBUG: Deleting file:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.SimpleMacIT/1393347971697_26818/accumulo/tables/!0/t-000003u
2014-02-25 12:06:39,335 [gc.SimpleGarbageCollector] DEBUG: Deleting file:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.SimpleMacIT/1393347971697_26818/accumulo/tables/!0/t-000003v
2014-02-25 12:06:39,335 [fs.TrashPolicyDefault] INFO : Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
2014-02-25 12:06:39,335 [gc.SimpleGarbageCollector] DEBUG: Deleting file:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.SimpleMacIT/1393347971697_26818/accumulo/tables/!0/t-000003w
2014-02-25 12:06:39,336 [gc.SimpleGarbageCollector] DEBUG: Deleting file:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.SimpleMacIT/1393347971697_26818/accumulo/tables/!0/t-000003y
2014-02-25 12:06:39,336 [gc.SimpleGarbageCollector] DEBUG: Deleting file:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.SimpleMacIT/1393347971697_26818/accumulo/tables/!0/table_info
2014-02-25 12:06:39,336 [gc.SimpleGarbageCollector] DEBUG: Deleting file:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.SimpleMacIT/1393347971697_26818/accumulo/tables/!0/t-000003x
  .
  .
  .
2014-02-25 12:06:39,343 [impl.RootTabletLocator] TRACE: tid=12 oid=91  Found root tablet at host1:40158|1446a02ccfe0002 in 0.000 secs
2014-02-25 12:06:39,344 [impl.TabletServerBatchWriter] TRACE: Started sending 15 mutations to 1 tablet servers
2014-02-25 12:06:39,344 [impl.ThriftTransportPool] TRACE: Using existing connection to host1:40158
2014-02-25 12:06:39,366 [impl.ThriftTransportPool] TRACE: Returned connection host1:40158 (120000) ioCount : 586
2014-02-25 12:06:39,367 [impl.TabletServerBatchWriter] TRACE: sent 15 mutations to host1:40158 in 0.02 secs (681.82 mutations/sec) with 0 failures
{noformat}",2ef2d88598f5e14f8f96b77fecca66dcd7196448 ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-27 15:59:18.404,,,no_permission,,,,,,,,,,,,375628,,,Thu Feb 27 17:15:42 UTC 2014,,,,,,0|i1sq93:,375924,,,,,,,,"27/Feb/14 15:59;jira-bot;Commit c530f389cc9b3504d469f0c9a974b4a7ed415b9f in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c530f38 ]

ACCUMULO-2405 check more frequently for the delete entries
","27/Feb/14 15:59;jira-bot;Commit c530f389cc9b3504d469f0c9a974b4a7ed415b9f in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c530f38 ]

ACCUMULO-2405 check more frequently for the delete entries
","27/Feb/14 16:32;mdrob;Instead of:

{code}
    while (true) {
      Scanner s = c.createScanner(RootTable.NAME, Authorizations.EMPTY);
      s.setRange(MetadataSchema.DeletesSection.getRange());
      if (FunctionalTestUtils.count(s) > 0)
        break;
      UtilWaitThread.sleep(100);
    }
{code}

would this be a cleaner invocation?

{code}
    Scanner s = c.createScanner(RootTable.NAME, Authorizations.EMPTY);
    s.setRange(MetadataSchema.DeletesSection.getRange());
    while (FunctionalTestUtils.count(s) == 0) {
      UtilWaitThread.sleep(100);
    }
{code}","27/Feb/14 17:14;jira-bot;Commit 948216cbf54df5caf119b5e4c84cfdc114da3507 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=948216c ]

ACCUMULO-2405 use a simpler loop
","27/Feb/14 17:14;jira-bot;Commit 948216cbf54df5caf119b5e4c84cfdc114da3507 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=948216c ]

ACCUMULO-2405 use a simpler loop
","27/Feb/14 17:15;ecn;Yes, yes it is. :-)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failures when using two namenodes and viewfs://,ACCUMULO-2047,12685301,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,18/Dec/13 03:17,27/Feb/14 00:57,13/Mar/19 22:01,27/Feb/14 00:57,,,,,,,,1.6.0,,,,,,,,,0,,,,,"I was trying to use viewfs:// with hadoop 2.2.0 and two namenodes.  I saw multiple failures when trying to do this.   I will open subtickets for specific failures.

I had the following in my hadoop core-site.xml

{noformat}
<configuration>
  <property>
    <name>fs.default.name</name>
    <value>viewfs:///</value>
  </property>
  <property>
    <name>fs.viewfs.mounttable.default.link./nn1</name>
    <value>hdfs://ip-10-1-3-10:9000</value>
  </property>
  <property>
    <name>fs.viewfs.mounttable.default.link./nn2</name>
    <value>hdfs://ip-10-1-3-11:9000</value>
  </property>
</configuration>
{noformat}

I had the following in my accumulo-site.xml

{noformat}
  <property>
    <name>instance.volumes</name>
    <value>viewfs:///nn1,viewfs:///nn2</value>
  </property>
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,364378,,,2013-12-18 03:17:14.0,,,,,,0|i1qt1r:,364678,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DeleteTableDuringSplitIT failed,ACCUMULO-2393,12696674,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,22/Feb/14 00:00,27/Feb/14 00:29,13/Mar/19 22:01,24/Feb/14 17:20,,,,,,,,1.6.0,,,,,,,,,0,16_qa_bug,,,,"ran {{mvn -Dhadoop.profile=1 -Dhadoop.version=1.2.1 clean verify}} and DeleteTableDuringSplitIT failed w/ following error.

{noformat}
java.util.concurrent.ExecutionException: java.lang.RuntimeException: DeleteTableDuringSplitIT_test0
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:188)
	at org.apache.accumulo.test.functional.DeleteTableDuringSplitIT.test(DeleteTableDuringSplitIT.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.lang.RuntimeException: DeleteTableDuringSplitIT_test0
	at org.apache.accumulo.test.functional.DeleteTableDuringSplitIT$1.run(DeleteTableDuringSplitIT.java:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.apache.accumulo.core.client.impl.AccumuloServerException: Error on server host1:58039
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.addSplits(TableOperationsImpl.java:504)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.access$300(TableOperationsImpl.java:123)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl$SplitTask.run(TableOperationsImpl.java:386)
	... 7 more
Caused by: org.apache.thrift.TApplicationException: Internal error processing splitTablet
	at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:71)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_splitTablet(TabletClientService.java:614)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.splitTablet(TabletClientService.java:598)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.addSplits(TableOperationsImpl.java:492)
	... 9 more
{noformat}

Saw the following in tserver logs 

{noformat}
2014-02-21 18:21:25,720 [thrift.ProcessFunction] ERROR: Internal error processing splitTablet
java.lang.IllegalArgumentException: Table with id 1a does not exist
        at org.apache.accumulo.core.client.impl.Tables.getNamespaceId(Tables.java:303)
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.splitTablet(TabletServer.java:2090)
        at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at com.sun.proxy.$Proxy9.splitTablet(Unknown Source)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$splitTablet.getResult(TabletClientService.java:2531)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$splitTablet.getResult(TabletClientService.java:2515)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:744)
{noformat}

saw the following in the other tserver logs

{noformat}
2014-02-21 18:21:27,035 [thrift.ProcessFunction] ERROR: Internal error processing splitTablet
java.lang.IllegalArgumentException: Table with id 1 does not exist
        at org.apache.accumulo.core.client.impl.Tables.getNamespaceId(Tables.java:303)
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.splitTablet(TabletServer.java:2090)
        at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at com.sun.proxy.$Proxy9.splitTablet(Unknown Source)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$splitTablet.getResult(TabletClientService.java:2531)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$splitTablet.getResult(TabletClientService.java:2515)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:744)
{noformat}",ce1d965c67bdb13647acd683f5e3a94c53999e6c ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2087,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-24 17:19:58.678,,,no_permission,,,,,,,,,,,,375150,,,Mon Feb 24 17:20:04 UTC 2014,,,,,,0|i1snbb:,375447,,,,,,,,"24/Feb/14 17:19;jira-bot;Commit 812df5898989774e171e39f3c1e5b94f84cff82c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=812df58 ]

ACCUMULO-2393 handle table deletion race condition
","24/Feb/14 17:20;jira-bot;Commit 812df5898989774e171e39f3c1e5b94f84cff82c in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=812df58 ]

ACCUMULO-2393 handle table deletion race condition
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Master does not close TabletServerBatchReader,ACCUMULO-2354,12694642,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,mdrob,mdrob,12/Feb/14 01:02,26/Feb/14 17:56,13/Mar/19 22:01,26/Feb/14 17:56,,,,,,,,1.6.0,,,master,,,,,,0,,,,,"Saw the following in the Master logs:
{noformat}
2014-02-11 16:55:10,820 [impl.TabletServerBatchReader] WARN : TabletServerBatchReader not shutdown; did you forget to call close()?
java.lang.Throwable
        at org.apache.accumulo.core.client.impl.TabletServerBatchReader.<init>(TabletServerBatchReader.java:69)
        at org.apache.accumulo.core.client.impl.ConnectorImpl.createBatchScanner(ConnectorImpl.java:98)
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.<init>(MetaDataTableScanner.java:63)
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.<init>(MetaDataTableScanner.java:56)
        at org.apache.accumulo.server.master.state.MetaDataStateStore.iterator(MetaDataStateStore.java:70)
        at org.apache.accumulo.master.TabletGroupWatcher.run(TabletGroupWatcher.java:148)
{noformat}

This happened shortly after a tablet server had died and it's tablets were in the process of being recovered elsewhere.","cdh4.5.0, accumulo f9a196f",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-12 01:54:14.772,,,no_permission,,,,,,,,,,,,373150,,,Wed Feb 19 18:36:00 UTC 2014,,,,,,0|i1sb0v:,373451,,,,,,,,"12/Feb/14 01:35;mdrob;Looking at the code makes me think that the message has nothing to do with the tablet server's demise. I believe the problem is that {{org.apache.accumulo.server.master.state.MetaDataStateStore.iterator()}} provides no way to close the Scanner that it creates because the return type is just {{Iterator<TabletLocationState>}}. We _could_ change that to something like a [CloseableIterator|http://stackoverflow.com/a/17539843/370585] but that seems like it might be overkill.

Anybody else have thoughts on this?",12/Feb/14 01:54;elserj;Why not just return ScannerBase? That has a close() method common to both the Scanner and BatchScanner impls.,"12/Feb/14 01:58;mdrob;Because {{TabletGroupWatcher}} has a {{TabletStateStore}}, not a {{MetaDataTableStore}}. The other implementation, {{ZooTabletStateStore}} returns a custom iterator with no close method and looks nothing like {{ScannerBase}}.",12/Feb/14 07:29;vickyuec;[~mdrob] MetaDataTableScanner does close TabletServerBatchReader whenever hasNext() returns false (and its finalize also). So maybe the intended design was that TabletServerBatchReader should be closed from MetaDataTableScanner only?,"19/Feb/14 18:29;jira-bot;Commit aab22b2e586267823d6aff64269ad996dc870e95 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=aab22b2 ]

ACCUMULO-2354 ensure that the TabletLocationState iterator is closed
","19/Feb/14 18:29;jira-bot;Commit 0da9a567762cb79b6fb506310d366193f4953766 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0da9a56 ]

ACCUMULO-2354 ensure that the TabletLocationState iterator is closed
","19/Feb/14 18:29;jira-bot;Commit aab22b2e586267823d6aff64269ad996dc870e95 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=aab22b2 ]

ACCUMULO-2354 ensure that the TabletLocationState iterator is closed
","19/Feb/14 18:29;jira-bot;Commit 0da9a567762cb79b6fb506310d366193f4953766 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0da9a56 ]

ACCUMULO-2354 ensure that the TabletLocationState iterator is closed
","19/Feb/14 18:36;mdrob;Guess I had the right idea. Thanks for looking at this, Eric!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
values returned by MiniAccumuloConfig getters can change w/o set,ACCUMULO-2246,12690861,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,23/Jan/14 19:31,26/Feb/14 17:50,13/Mar/19 22:01,26/Feb/14 17:50,,,,,,,,1.6.0,,,,,,,,,0,,,,,In MiniAccumuloConfig the values returned by some getters will change if MiniAccumuloConfig is passed to MiniAccumulo. This is strange behavior.  The methods should always return the config set by the user.  There are at least two methods that have this behavior {{getZookeeperPort()}} and {{getSiteConfig{}}}.  For {{getSiteConfig()}} this is a change in behavior from 1.4 and 1.5.  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-29 21:57:16.682,,,no_permission,,,,,,,,,,,,369600,,,Wed Feb 26 17:48:59 UTC 2014,,,,,,0|i1rpbr:,369905,,,,,,,,29/Jan/14 21:57;vines;Sounds like MiniAccumuloClusterImpl should copy the MiniAccumuloConfigImpl and use that for everything.,"26/Feb/14 17:48;jira-bot;Commit b5b38d889b8d873041595eec6969000f3711aa96 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b5b38d8 ]

ACCUMULO-2246 made MiniAccumloConfig getters return what was set
","26/Feb/14 17:48;jira-bot;Commit b5b38d889b8d873041595eec6969000f3711aa96 in accumulo's branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b5b38d8 ]

ACCUMULO-2246 made MiniAccumloConfig getters return what was set
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GarbageCollectorIT.dontGCRootLog() fails,ACCUMULO-2406,12697205,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,25/Feb/14 20:09,25/Feb/14 21:13,13/Mar/19 22:01,25/Feb/14 21:13,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Saw the following failure while running ITs.  The test is not using MiniDFS, which is what caused the problem.  Because minidfs was not used, recent walog updates were lost.  Below are my notes from investigating.  To fix this I am going to look into using RawLocalFS like I did w/ VolumeIT.

{noformat}
dontGCRootLog(org.apache.accumulo.test.functional.GarbageCollectorIT)  Time elapsed: 108.685 sec  <<< ERROR!
java.lang.RuntimeException: org.apache.accumulo.core.client.impl.AccumuloServerException: Error on server rd6ul-14723v.infosec.tycho.ncsc.mil:34130
	at org.apache.accumulo.core.client.impl.ScannerIterator.hasNext(ScannerIterator.java:187)
	at org.apache.accumulo.test.functional.GarbageCollectorIT.dontGCRootLog(GarbageCollectorIT.java:163)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.accumulo.core.client.impl.AccumuloServerException: Error on server rd6ul-14723v.infosec.tycho.ncsc.mil:34130
	at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:285)
	at org.apache.accumulo.core.client.impl.ScannerIterator$Reader.run(ScannerIterator.java:84)
	at org.apache.accumulo.core.client.impl.ScannerIterator.hasNext(ScannerIterator.java:177)
	... 10 more
Caused by: org.apache.thrift.TApplicationException: Internal error processing startScan
	at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:71)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_startScan(TabletClientService.java:226)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.startScan(TabletClientService.java:202)
	at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:399)
	at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:277)
	... 12 more
{noformat}

Looking in the tserver logs, I found this error was caused by a missing file.

{noformat}
TabletServer_1756174045.out:java.io.IOException: Failed to open V/accumulo/tables/!0/table_info/A0000004.rf
{noformat}

The file was garbage collected

{noformat}
SimpleGarbageCollector_1083069032.out:2014-02-25 12:48:12,897 [gc.SimpleGarbageCollector] DEBUG: Deleting V/accumulo/tables/!0/table_info/A0000004.rf
{noformat}

The file was created on another tablet server and compacted away.  That tablet server was killed by the test code right after doing the compaction.  The tserver is killed shortly after compaction 4 into 5.

{noformat}
TabletServer_1242447446.out:2014-02-25 12:48:07,256 [tserver.Tablet] DEBUG: Starting MajC !0;~< (USER) [V/accumulo/tables/!0/table_info/A0000003.rf] --> V/accumulo/tables/!0/table_info/A0000004.rf_tmp  []
TabletServer_1242447446.out:2014-02-25 12:48:07,290 [tserver.Tablet] TABLET_HIST: !0;~< MajC [V/accumulo/tables/!0/table_info/A0000003.rf] --> V/accumulo/tables/!0/table_info/A0000004.rf
TabletServer_1242447446.out:2014-02-25 12:48:10,007 [tserver.Tablet] DEBUG: Starting MajC !0;~< (USER) [V/accumulo/tables/!0/table_info/A0000004.rf] --> V/accumulo/tables/!0/table_info/A0000005.rf_tmp  []
TabletServer_1242447446.out:2014-02-25 12:48:10,044 [tserver.Tablet] TABLET_HIST: !0;~< MajC [V/accumulo/tables/!0/table_info/A0000004.rf] --> V/accumulo/tables/!0/table_info/A0000005.rf
{noformat}

So when the root tablet recovered it brought back old data. Looking in the root tablet write ahead log, it only contained the following after the crash.  This is why A0000004.rf was brought back and A0000005.rf was forgotten.

{noformat}
COMPACTION_START 1 8 file:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.GarbageCollectorIT_dontGCRootLog/accumulo/tables/+r/root_tablet/F000004m.rf

COMPACTION_FINISH 1 9

DEFINE_TABLET 1 9 +r<<

MANY_MUTATIONS 1 9
1 mutations:
  ~delfile:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.GarbageCollectorIT_dontGCRootLog/accumulo/tables/!0/table_info/A0000002.rf
      : [system]:23 [] <deleted>

MANY_MUTATIONS 1 9
1 mutations:
  !0<
      srv:flush [system]:24 [] 4
      srv:lock [system]:24 [] tservers/host1:44035/zlock-0000000000$1446a28bfef0003

MANY_MUTATIONS 1 9
1 mutations:
  !0;~
      srv:flush [system]:25 [] 4
      srv:lock [system]:25 [] tservers/host1:57501/zlock-0000000000$1446a28bfef0001

MANY_MUTATIONS 1 9
1 mutations:
  !0<
      srv:compact [system]:26 [] 4
      srv:lock [system]:26 [] tservers/host1:44035/zlock-0000000000$1446a28bfef0003

MANY_MUTATIONS 1 9
1 mutations:
  ~delfile:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.GarbageCollectorIT_dontGCRootLog/accumulo/tables/!0/table_info/A0000003.rf
      : [system]:27 [] 

MANY_MUTATIONS 1 9
1 mutations:
  !0;~
      file:file:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.GarbageCollectorIT_dontGCRootLog/accumulo/tables/!0/table_info/A0000003.rf [system]:28 [] <deleted>
      file:file:/local/disk1/jenkins/workspace/accumulo16/test/target/mini-tests/org.apache.accumulo.test.functional.GarbageCollectorIT_dontGCRootLog/accumulo/tables/!0/table_info/A0000004.rf [system]:28 [] 578,5
      srv:compact [system]:28 [] 4
      last:1446a28bfef0001 [system]:28 [] host1:57501
      srv:lock [system]:28 [] tservers/host1:57501/zlock-0000000000$1446a28bfef0001

{noformat}

below is some info about the root tablet recovery from the tserver logs

{noformat}
2014-02-25 12:49:26,353 [tserver.Tablet] INFO : Starting Write-Ahead Log recovery for +r<<
2014-02-25 12:49:26,356 [tserver.TabletServer] INFO : Looking for V/accumulo/recovery/770c5d8a-c598-4e3c-8b22-9ce27eee5f40/finished
2014-02-25 12:49:26,360 [log.SortedLogRecovery] INFO : Looking at mutations from V/accumulo/recovery/770c5d8a-c598-4e3c-8b22-9ce27eee5f40 for +r<<
2014-02-25 12:49:26,376 [log.SortedLogRecovery] DEBUG: Found tid, seq 1 1
2014-02-25 12:49:26,378 [log.SortedLogRecovery] DEBUG: minor compaction into V/accumulo/tables/+r/root_tablet/F000004g.rf finished, but was still in the METADATA
2014-02-25 12:49:26,378 [log.SortedLogRecovery] DEBUG: minor compaction into V/accumulo/tables/+r/root_tablet/F000004i.rf finished, but was still in the METADATA
2014-02-25 12:49:26,378 [log.SortedLogRecovery] DEBUG: minor compaction into V/accumulo/tables/+r/root_tablet/F000004k.rf finished, but was still in the METADATA
2014-02-25 12:49:26,378 [log.SortedLogRecovery] DEBUG: minor compaction into V/accumulo/tables/+r/root_tablet/F000004m.rf finished, but was still in the METADATA
2014-02-25 12:49:26,382 [log.SortedLogRecovery] INFO : Scanning for mutations starting at sequence number 8 for tid 1
2014-02-25 12:49:26,386 [log.SortedLogRecovery] INFO : Recovery complete for +r<< using V/accumulo/recovery/770c5d8a-c598-4e3c-8b22-9ce27eee5f40
2014-02-25 12:49:26,387 [tserver.Tablet] INFO : Write-Ahead Log recovery complete for +r<< (6 mutations applied, 13 entries created)
2014-02-25 12:49:26,396 [tserver.Tablet] TABLET_HIST: +r<< opened
{noformat}",2ef2d88598f5e14f8f96b77fecca66dcd7196448,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-25 21:09:45.101,,,no_permission,,,,,,,,,,,,375679,,,Tue Feb 25 21:12:04 UTC 2014,,,,,,0|i1sqkf:,375975,,,,,,,,"25/Feb/14 21:09;jira-bot;Commit b23408faea79a9839cbb39932004254229beac79 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b23408f ]

ACCUMULO-2406 make GarbageCollectorIT use RawLocalFileSystem so walog writes are not lost
","25/Feb/14 21:12;jira-bot;Commit b23408faea79a9839cbb39932004254229beac79 in accumulo's branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b23408f ]

ACCUMULO-2406 make GarbageCollectorIT use RawLocalFileSystem so walog writes are not lost
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
race condition in ExamplesIT,ACCUMULO-2400,12697006,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,24/Feb/14 21:43,25/Feb/14 18:02,13/Mar/19 22:01,25/Feb/14 18:02,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Saw ExamplesIT fail with the following exception.  Looking at the code I think there is a race condition.  The test calls the MAC.exec() function to create a process and then reads from stdout of the process.  The MAC exec function starts a background thread to read from stdout.  If this background thread reads stdout before the test I think it will fail in the following way.  Probably need to fix everywhere MAC exec is used in this way.  Could either read from the file MAC creates or pass an option to MAC.exec() to not start the background thread.

{noformat}
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:325)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:283)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:325)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:177)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:154)
	at java.io.BufferedReader.readLine(BufferedReader.java:317)
	at java.io.BufferedReader.readLine(BufferedReader.java:382)
	at org.apache.accumulo.test.functional.ExamplesIT.testClasspath(ExamplesIT.java:172)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}",6395840418046d8b3a923a4bfb3e4ba486c5dcd0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-25 06:56:39.836,,,no_permission,,,,,,,,,,,,375481,,,Tue Feb 25 17:36:25 UTC 2014,,,,,,0|i1spcn:,375777,,,,,,,,"24/Feb/14 21:58;kturner;I was thinking for debugging purposes it would be nice if the process output was written to a file.  In the case where a test fails because the output was not as expected, it would be nice to know what the output was.    I was was looking for something like tee and found  {{org.apache.commons.io.input.TeeInputStream}}  Maybe a version of the MAC.exec function could be created that returns teed inputstreams ","25/Feb/14 06:56;vickyuec;[~kturner] exec already does the logging using {{LogWriter}} :
{noformat}
Process process = builder.start();

    LogWriter lw;
    lw = new LogWriter(process.getErrorStream(), new File(config.getLogDir(), clazz.getSimpleName() + ""_"" + process.hashCode() + "".err""));
    logWriters.add(lw);
    lw.start();
    lw = new LogWriter(process.getInputStream(), new File(config.getLogDir(), clazz.getSimpleName() + ""_"" + process.hashCode() + "".out""));
    logWriters.add(lw);
    lw.start();
{noformat}

Are you looking for something more? (BTW, the log file names can be improved)","25/Feb/14 15:18;kturner;LogWriter extends Daemon which extends Thread.   LogWriter is passed process.getInputStream() and then lw.start() is called which starts the thread.  After exec returns the test reads from process.getInputStream().   If the LogWriter thread has already read from process.getInputStream(), then the test will fail.  I was thinking of having another exec method that does not start log writer threads, instead it returns something like the following :

{code:java}
  class ProcessStreams{
     InputStream stdout;
     InputStream stderr;
  }
   
  public ProcessStreams exec(...){
    //tee stdout
    String logFileNAme = ..;
    new TeeInputStream(process.getInputStream(), new FileOutputStream(logFileName)) {
       public void close(){
             //overidde this method to read all data not read by test before closing... test need to close in finally block
       }
    }
 
    //also tee stder

   return new ProcessStreams(...)
  }
{code}

","25/Feb/14 17:36;jira-bot;Commit 0e746a29aba50d67d42d09d4a6be5fcb4b951b91 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0e746a2 ]

ACCUMULO-2400 read the output file, not stdout
","25/Feb/14 17:36;jira-bot;Commit 0e746a29aba50d67d42d09d4a6be5fcb4b951b91 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0e746a2 ]

ACCUMULO-2400 read the output file, not stdout
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
unique server id is not constructed consistently,ACCUMULO-11,12526078,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,ecn,ecn,06/Oct/11 17:05,21/Feb/14 01:19,13/Mar/19 22:01,01/Nov/11 18:27,1.3.5-incubating,,,,,,,1.4.0,,,master,,,,,,0,,,,,"In LiveTServerSet.scanServers() the server address is read from zookeeper, then a session is read from zookeeper.  Both of these red data from the minimum ephemeral node. However, there is no guarantee the minimum node is the same node for the two reads.
 ",,,,,,,,,,,,,,,,,,,,,,,,7200,7200,,0%,7200,7200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,49645,,,2011-10-06 17:05:24.0,,,,,,0|i07prr:,42941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
problems found in accumulo_sample,ACCUMULO-230,12536187,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,22/Dec/11 18:35,21/Feb/14 01:07,13/Mar/19 22:01,22/Dec/11 20:25,,,,,,,,1.4.0,,,contrib,,,,,,0,,,,,"I've been working on a presentation on the accumulo sample, which will show off some of the accumulo-specific features.  But when I ran it, I found very poor performance on some queries, and inconsistent results when I changed the user's authorizations.

Some queries like ""three little pigs"" ran with sub-second response times.  Other queries such as ""old man sea"" would take as long as 8 minutes.

If I searched english-only articles, I would get more results than if I searched all the samples.  Again, this only happens on some queries: the majority ran fine.  ""old man sea"" would consistently show broken behavior.","Searching all of english, german and spanish indexed wikipedia articles using the accumulo sample on a 10-node cluster.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,221870,,,2011-12-22 18:35:40.0,,,,,,0|i07ofr:,42725,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
client code for TableConfiguration has problems,ACCUMULO-240,12536738,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,afuchs,afuchs,afuchs,31/Dec/11 15:09,21/Feb/14 00:55,13/Mar/19 22:01,18/Dec/12 19:28,1.3.5-incubating,,,,,,,1.4.2,,,client,,,,,,1,,,,,"There are a number of problems with accessing TableConfiguration object from client code, the first being that TableOperationImpl uses code that relies on a hidden HDFSZooInstance in client configuration. If the client is not running with access to the HDFS Accumulo directory, or if the HDFS setup on the client differs from the Accumulo instance, then this call will fail:

{noformat}
Exception in thread ""main"" java.lang.ExceptionInInitializerError
Caused by: org.apache.accumulo.core.client.impl.HdfsZooInstance$AccumuloNotInitializedException: Accumulo not initialized, there is no instance id at /accumulo/instance_id
	at org.apache.accumulo.core.client.impl.HdfsZooInstance._getInstanceID(HdfsZooInstance.java:136)
	at org.apache.accumulo.core.client.impl.HdfsZooInstance.getInstanceID(HdfsZooInstance.java:123)
	at org.apache.accumulo.core.conf.ZooConfiguration.getInstanceId(ZooConfiguration.java:65)
	at org.apache.accumulo.core.conf.ZooConfiguration.iterator(ZooConfiguration.java:132)
	at org.apache.accumulo.core.conf.TableConfiguration.iterator(TableConfiguration.java:129)
	at org.apache.accumulo.core.conf.ConfigSanityCheck.validate(ConfigSanityCheck.java:29)
	at org.apache.accumulo.core.conf.AccumuloConfiguration.getTableConfiguration(AccumuloConfiguration.java:150)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.getProperties(TableOperationsImpl.java:544)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.setLocalityGroups(TableOperationsImpl.java:583)
{noformat}

Another problem is that the ZooConfiguration object uses static instance information, negating the possibility of using multiple instances in the same JVM.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-01 03:45:18.094,,,no_permission,,,,,,,,,,,,222421,,,Sun Jan 01 03:45:18 UTC 2012,,,,,,0|i07odj:,42715,,,,,,,,"01/Jan/12 03:45;jaredwinick;I believe this bug describes the same issue as ACCUMULO-225, but in a more general way. If you agree, feel free to close ACCUMULO-225.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Misconfigured aggregator can block table deletion,ACCUMULO-58,12527986,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,vines,jvines,20/Oct/11 17:38,20/Feb/14 23:31,13/Mar/19 22:01,29/May/12 21:41,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,tserver,,,,,,0,delete,regression,,,"If you misconfigure an aggregator such that it can't be loaded, it will cause a tablet to indefinitely attempt to minor/major compact. If you attempt to delete the table with this problem the tablet will never break out of the compaction attempt to a point where it will detect it needs to delete. The only way to break out of the loop is kill any tservers who are hosting tablets attempts to be compacted. This definately exists in 1.3, fairly confident it affects the other versions as well. We would need to have the compaction loops check somehow to detect if the tablet needs to be deleted before reattempting.

Additionally, a functional test should be written to exercise this error to prevent regression.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-10-24 19:21:25.753,,,no_permission,,,,,,,,,,,,92451,,,Tue May 29 20:42:14 UTC 2012,,,,,,0|i07phb:,42894,,,,,,,,"24/Oct/11 19:21;kturner;I think minor compactions that fail, retry forever.  Before retrying, could check the table state in zookeeper and abort if it is deleting.",29/May/12 20:42;kturner;Another work around for this issue besides killing tablet servers is to remove the offending iterators/aggregators from the table being deleted.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bulk importing Keys with invalid ColumnVisibility doesn't fail until scan,ACCUMULO-360,12540734,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,billie.rinaldi,billie.rinaldi,01/Feb/12 15:47,20/Feb/14 23:29,13/Mar/19 22:01,27/Dec/12 21:06,1.3.5-incubating,,,,,,,1.5.0,,,client,,,,,,0,bulk,visibility,,,"A Key is allowed to have an invalid ColumnVisibility so it can be used in a Range (see ACCUMULO-193).  Also, we don't want Key to create a ColumnVisibility object to test the validity of a supplied Text, CharSequence, or byte[] visibility due to the large amount of overhead in doing so.  This isn't a problem when writing Mutations to Accumulo, but during bulk import Keys are written directly to files.  Thus the user doesn't receive an error for the invalid ColumnVisibility until scanning the table.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-02-10 17:04:09.831,,,no_permission,,,,,,,,,,,,226129,,,Thu Dec 27 21:25:05 UTC 2012,,,,,,0|i07nnj:,42598,,,,,,,,10/Feb/12 17:04;kturner;Could modify the AccumuloFileOutputFormat to do this sanity check.  To make it efficient could use a LRUHashMap of recently seen visibilities that were previously verified.  Could also a sanity check of the time stamp to make sure its not MAX_LONG.   ,"27/Dec/12 21:25;hudson;Integrated in Accumulo-Trunk #593 (See [https://builds.apache.org/job/Accumulo-Trunk/593/])
    ACCUMULO-360 made AccumuloFileOutputFormat reject bad visibilities (Revision 1426328)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormatTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CloudStone Code Has Issues,ACCUMULO-827,12612897,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,21/Oct/12 22:54,20/Feb/14 23:22,13/Mar/19 22:01,11/Nov/12 00:56,1.4.1,,,,,,,1.5.0,,,test,,,,,,0,,,,,"A couple of things:

# ClassNotFound on AccumuloOutputFormat http://mail-archives.apache.org/mod_mbox/accumulo-user/201210.mbox/%3CCAM+ZXRmJkpK9Piako+nRfyYfP5JyKX7qgQCJRcNe+2eNC2uJkw@mail.gmail.com%3E
# ClassNotFound for cloudtrace for me (probably the same thing as above)
# Test succeeded for me despite the mapreduce job failing.",Single Linux host,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-897,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-04 11:45:31.567,,,no_permission,,,,,,,,,,,,250209,,,Sun Nov 11 00:56:28 UTC 2012,,,,,,0|i0auof:,61243,,,,,,,,22/Oct/12 01:28;elserj;CloudStone7 appears to suffer from the same cloudtrace issue.,"04/Nov/12 11:45;hudson;Integrated in Accumulo-Trunk #542 (See [https://builds.apache.org/job/Accumulo-Trunk/542/])
    ACCUMULO-827 Fix libjars for CloudStone3 (Revision 1405498)
ACCUMULO-827 Fix IngestBenchmark to properly create/delete its table (Revision 1405493)
ACCUMULO-827 Fixed up CloudStone1
- Fixed accumulo shell command
- Added assertion to CloudStone1
- Added pyc files to .gitignore (Revision 1405492)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/trunk/test/system/bench/lib/Benchmark.py
* /accumulo/trunk/test/system/bench/lib/TeraSortBenchmark.py

elserj : 
Files : 
* /accumulo/trunk/test/system/bench/lib/IngestBenchmark.py

elserj : 
Files : 
* /accumulo/trunk/.gitignore
* /accumulo/trunk/test/system/bench/cloudstone1/cloudstone1.py
* /accumulo/trunk/test/system/bench/lib/cloudshell.py
","05/Nov/12 02:31;hudson;Integrated in Accumulo-Trunk #543 (See [https://builds.apache.org/job/Accumulo-Trunk/543/])
    ACCUMULO-827 Make CloudStone5 clean up after itself properly (Revision 1405686)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/trunk/test/system/bench/lib/TableSplitsBenchmark.py
","10/Nov/12 20:07;hudson;Integrated in Accumulo-Trunk #546 (See [https://builds.apache.org/job/Accumulo-Trunk/546/])
    ACCUMULO-827 Fix up Accumulo table code used by CloudStone6 (Revision 1407873)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/trunk/test/system/bench/lib/CreateTablesBenchmark.py
","11/Nov/12 00:35;hudson;Integrated in Accumulo-Trunk #547 (See [https://builds.apache.org/job/Accumulo-Trunk/547/])
    ACCUMULO-827 Get all CloudStone tests running again
- Fix table code in CloudStone 7 and 8
- Fix options in README (Revision 1407902)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/trunk/test/system/bench/README
* /accumulo/trunk/test/system/bench/lib/RowHashBenchmark.py
* /accumulo/trunk/test/system/bench/lib/TeraSortBenchmark.py
",11/Nov/12 00:56;elserj;Can now run all cloudstone tests without issue on trunk.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update jar regex in examples and scripts,ACCUMULO-889,12618356,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,billie.rinaldi,billie.rinaldi,30/Nov/12 18:00,20/Feb/14 23:21,13/Mar/19 22:01,19/Dec/12 20:33,1.4.2,,,,,,,1.4.3,1.5.0,,docs,,,,,,0,,,,,"I tried running the example in README.mapred for 1.4.2 and got an error on the command
{noformat}
$ bin/tool.sh lib/examples-simple*[^c].jar ...
Exception in thread ""main"" java.lang.ClassNotFoundException: lib.examples-simple-1.4.2-sources.jar
{noformat}

The jar regex need to be updated to exclude the sources jar (currently it just excludes the javadoc jar).  We should check other jar regex to make sure they're up to date as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-01 05:15:14.579,,,no_permission,,,,,,,,,,,,293017,,,Wed Dec 19 23:00:03 UTC 2012,,,,,,0|i0srdz:,165914,,,,,,,,"01/Dec/12 05:15;hudson;Integrated in Accumulo-Trunk #570 (See [https://builds.apache.org/job/Accumulo-Trunk/570/])
    ACCUMULO-889 Update jar regex in examples, scripts (Revision 1415914)

     Result = SUCCESS
drew : 
Files : 
* /accumulo/trunk/docs/examples/README.bulkIngest
* /accumulo/trunk/docs/examples/README.filedata
* /accumulo/trunk/docs/examples/README.mapred
","18/Dec/12 15:40;ctubbsii;Check 1.4 branch to see if this was backported for 1.4.3, and update functional tests and benchmarks.",19/Dec/12 20:33;ecn;back-ported for 1.4.3,"19/Dec/12 23:00;hudson;Integrated in Accumulo-1.4.x #256 (See [https://builds.apache.org/job/Accumulo-1.4.x/256/])
    ACCUMULO-889 merge from trunk (Revision 1424088)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/docs/examples/README.bulkIngest
* /accumulo/branches/1.4/docs/examples/README.filedata
* /accumulo/branches/1.4/docs/examples/README.mapred
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/server
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Compaction warning on fresh install,ACCUMULO-1978,12683230,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,vines,vines,07/Dec/13 00:18,20/Feb/14 22:56,13/Mar/19 22:01,12/Dec/13 18:16,,,,,,,,1.6.0,,,master,,,,,,0,,,,,"Master is reporting in the monitor-
{code} 
Failed to execute Repo, tid=04a117a43b9bcadf
	java.lang.IllegalArgumentException: Range [+r<%00; : [] 9223372036854775807 false,+inf) does not overlap [!0; : [] 9223372036854775807 false,!0<%00; : [] 9223372036854775807 false)
		at org.apache.accumulo.core.data.Range.clip(Range.java:439)
		at org.apache.accumulo.core.data.Range.clip(Range.java:409)
		at org.apache.accumulo.master.tableOps.CompactionDriver.isReady(CompactRange.java:105)
		at org.apache.accumulo.master.tableOps.CompactionDriver.isReady(CompactRange.java:65)
		at org.apache.accumulo.master.tableOps.TraceRepo.isReady(TraceRepo.java:44)
		at org.apache.accumulo.fate.Fate$TransactionRunner.run(Fate.java:64)
		at org.apache.accumulo.fate.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at java.lang.Thread.run(Thread.java:701)
06 19:14:08,0236	gc:john-P15xEMx	1	
WARN
org.apache.accumulo.core.client.AccumuloException: Internal error processing waitForTableOperation
	org.apache.accumulo.core.client.AccumuloException: Internal error processing waitForTableOperation
		at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:330)
		at org.apache.accumulo.core.client.admin.TableOperationsImpl.compact(TableOperationsImpl.java:826)
		at org.apache.accumulo.core.client.admin.TableOperationsImpl.compact(TableOperationsImpl.java:807)
		at org.apache.accumulo.gc.SimpleGarbageCollector.run(SimpleGarbageCollector.java:474)
		at org.apache.accumulo.gc.SimpleGarbageCollector.main(SimpleGarbageCollector.java:144)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:622)
		at org.apache.accumulo.start.Main$1.run(Main.java:137)
		at java.lang.Thread.run(Thread.java:701)
	Caused by: org.apache.thrift.TApplicationException: Internal error processing waitForTableOperation
		at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
		at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:71)
		at org.apache.accumulo.core.master.thrift.MasterClientService$Client.recv_waitForTableOperation(MasterClientService.java:610)
		at org.apache.accumulo.core.master.thrift.MasterClientService$Client.waitForTableOperation(MasterClientService.java:595)
		at org.apache.accumulo.core.client.admin.TableOperationsImpl.waitForTableOperation(TableOperationsImpl.java:268)
		at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:310)
		... 10 more{code}


Seems to correspond to this from the monitor-
{code}
org.apache.accumulo.core.client.AccumuloException: Internal error processing waitForTableOperation
	org.apache.accumulo.core.client.AccumuloException: Internal error processing waitForTableOperation
		at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:330)
		at org.apache.accumulo.core.client.admin.TableOperationsImpl.compact(TableOperationsImpl.java:826)
		at org.apache.accumulo.core.client.admin.TableOperationsImpl.compact(TableOperationsImpl.java:807)
		at org.apache.accumulo.gc.SimpleGarbageCollector.run(SimpleGarbageCollector.java:474)
		at org.apache.accumulo.gc.SimpleGarbageCollector.main(SimpleGarbageCollector.java:144)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.lang.reflect.Method.invoke(Method.java:622)
		at org.apache.accumulo.start.Main$1.run(Main.java:137)
		at java.lang.Thread.run(Thread.java:701)
	Caused by: org.apache.thrift.TApplicationException: Internal error processing waitForTableOperation
		at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
		at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:71)
		at org.apache.accumulo.core.master.thrift.MasterClientService$Client.recv_waitForTableOperation(MasterClientService.java:610)
		at org.apache.accumulo.core.master.thrift.MasterClientService$Client.waitForTableOperation(MasterClientService.java:595)
		at org.apache.accumulo.core.client.admin.TableOperationsImpl.waitForTableOperation(TableOperationsImpl.java:268)
		at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:310)
		... 10 more{code}

Which is a bit strange, because it's forcing a compaction of the metadata table, but is complaining about the root tablet as part of the range?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-12 18:15:00.408,,,no_permission,,,,,,,,,,,,362482,,,Thu Dec 12 19:08:53 UTC 2013,,,,,,0|i1qhe7:,362776,,,,,,,,"07/Dec/13 00:27;vines;{code}
    if (tableId.equals(MetadataTable.ID))
      range = range.clip(new Range(RootTable.EXTENT.getMetadataEntry(), false, null, true));
{code}

This is unecessary now, I'm pretty sure. And it's what's causing problems.","12/Dec/13 18:15;jira-bot;Commit 02275812b6ed7cec6c4923183f2f75011f4c4f4a in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0227581 ]

ACCUMULO-1978 fixed compaction and flush of metadata table and added test
",12/Dec/13 18:16;kturner;I fixed this issue.  I realized while working on it that compacting and flushing the root table does not work properly.  But this did not work properly in 1.4 or 1.5.  I am going to open a separate ticket for this issue.  ,"12/Dec/13 19:08;jira-bot;Commit 02275812b6ed7cec6c4923183f2f75011f4c4f4a in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0227581 ]

ACCUMULO-1978 fixed compaction and flush of metadata table and added test
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bootstrap_hdfs.sh doesn't read list of slaves and accumulo-site.xml from ACCUMULO_CONF_DIR,ACCUMULO-2387,12696172,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vickyuec,vickyuec,vickyuec,20/Feb/14 07:21,20/Feb/14 17:36,13/Mar/19 22:01,20/Feb/14 17:36,1.5.0,,,,,,,1.5.1,,,scripts,,,,,,0,,,,,It still expects the files to be $ACCUMULO_HOME/conf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20/Feb/14 07:28;vickyuec;ACCUMULO-2387.v1.patch.txt;https://issues.apache.org/jira/secure/attachment/12630008/ACCUMULO-2387.v1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-02-20 14:14:15.619,,,no_permission,,,,,,,,,,,,374648,,,Thu Feb 20 17:35:30 UTC 2014,,,,,,0|i1sk8f:,374948,,,,,,,,20/Feb/14 07:28;vickyuec;Attached patch.,"20/Feb/14 14:14;jira-bot;Commit 1a796777c2523923db806e6f692d69d9ddec698c in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1a79677 ]

ACCUMULO-2387 Use ACCUMULO_CONF_DIR to find config files in bootstrap_hdfs.sh

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","20/Feb/14 14:14;jira-bot;Commit 1a796777c2523923db806e6f692d69d9ddec698c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1a79677 ]

ACCUMULO-2387 Use ACCUMULO_CONF_DIR to find config files in bootstrap_hdfs.sh

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","20/Feb/14 14:14;jira-bot;Commit 1a796777c2523923db806e6f692d69d9ddec698c in accumulo's branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1a79677 ]

ACCUMULO-2387 Use ACCUMULO_CONF_DIR to find config files in bootstrap_hdfs.sh

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",20/Feb/14 17:35;elserj;No reason to not get this picked up in the next 1.5.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DistributedWorkQueue#waitUntilDone() shouldn't synchronize on String object,ACCUMULO-2324,12693270,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,yuzhihong@gmail.com,yuzhihong@gmail.com,05/Feb/14 00:29,20/Feb/14 00:47,13/Mar/19 22:01,19/Feb/14 18:53,1.5.0,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,"Synchronization is done on condVar, a String.
This is not good practice.

See http://stackoverflow.com/questions/133988/problem-with-synchronizing-on-string-objects",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-19 18:52:43.009,,,no_permission,,,,,,,,,,,,371855,,,Thu Feb 20 00:47:30 UTC 2014,,,,,,0|i1s333:,372159,,,,,,,,"19/Feb/14 18:52;jira-bot;Commit 39613b4b9191ddba241726c8efe6e6d51dea53f4 in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=39613b4 ]

ACCUMULO-2324 synchronize on plain old Object, and not a String
","19/Feb/14 18:52;jira-bot;Commit 39613b4b9191ddba241726c8efe6e6d51dea53f4 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=39613b4 ]

ACCUMULO-2324 synchronize on plain old Object, and not a String
","19/Feb/14 18:53;jira-bot;Commit 39613b4b9191ddba241726c8efe6e6d51dea53f4 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=39613b4 ]

ACCUMULO-2324 synchronize on plain old Object, and not a String
",20/Feb/14 00:47;elserj;Update fixVersion from 1.5.2 to 1.5.1 since the most recent RC failed and any new RC will contain this fix.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Tablet constructor leaks this, part 2",ACCUMULO-2322,12693200,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,bhavanki,bhavanki,04/Feb/14 20:07,19/Feb/14 20:09,13/Mar/19 22:01,04/Feb/14 20:53,,,,,,,,,,,tserver,,,,,,0,this,thread-safety,,,"[~kturner] noted during review of ACCUMULO-1948 that there is a second leaking of this in the {{Tablet}} constructor at the line:

{code}
tabletServer.recover(this.tabletServer.getFileSystem(), this, logEntries, absPaths, new MutationReceiver() { ...
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-04 20:52:23.758,,,no_permission,,,,,,,,,,,,371786,,,Wed Feb 19 20:09:54 UTC 2014,,,,,,0|i1s2nr:,372085,,,,,,,,"04/Feb/14 20:52;jira-bot;Commit 47cdb92275126ba27157dd8fefa54b30c446c3c8 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=47cdb92 ]

ACCUMULO-2322 Tablet constructor no longer leaks this to recovery process

The method signatures for TabletServer.recover() and TabletServerLogger.recover()
were modified so that the Tablet constructor no longer needs to pass this.
","04/Feb/14 20:53;bhavanki;This was a simple enough transformation that I think I can skip review. [~kturner], you might want to peek at it just to make sure, but I reached the same conclusion you did, that only the extent and configuration were needed.","19/Feb/14 20:09;jira-bot;Commit dcc19ccbada8c2f0a206ec797455294015e8ca6d in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=dcc19cc ]

ACCUMULO-1961 Re-apply inadvertently dropped 4abb3f1 to master branch

  Fixes trivial warnings and broken javadocs which have been recently
  introduced. Specifically, removes references to private and
  package-private (default) classes in public javadoc comments (internal
  details aren't relevant to the API and subject to change). Another
  common warning was unused imports and javadoc param tags that refer to
  non-existent parameters.

  Commits against the following JIRA issues introduced these:
  ACCUMULO-1948, ACCUMULO-1974, ACCUMULO-2021, ACCUMULO-2136,
  ACCUMULO-2322, ACCUMULO-2334, ACCUMULO-2350
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
os.getlogin is not portable python code,ACCUMULO-915,12624528,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,18/Dec/12 20:35,19/Feb/14 13:35,13/Mar/19 22:01,18/Dec/12 20:41,1.4.2,,,,,,,1.4.3,1.5.0,,test,,,,,,0,,,,,"http://mail.python.org/pipermail/python-bugs-list/2002-July/012691.html

Switching it to os.getenv('LOGNAME')",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2378,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-18 21:16:58.227,,,no_permission,,,,,,,,,,,,300349,,,Tue Dec 18 21:26:57 UTC 2012,,,,,,0|i167dr:,244328,,,,,,,,"18/Dec/12 21:16;hudson;Integrated in Accumulo-1.4.x #255 (See [https://builds.apache.org/job/Accumulo-1.4.x/255/])
    ACCUMULO-915 - stupid nonportable code (Revision 1423629)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.4/test/system/auto/TestUtils.py
","18/Dec/12 21:26;hudson;Integrated in Accumulo-Trunk #584 (See [https://builds.apache.org/job/Accumulo-Trunk/584/])
    Merging ACCUMULO-915 (Revision 1423634)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/auto/TestUtils.py
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Concurrent random walk fails to rename across namespaces,ACCUMULO-2091,12686320,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,kturner,kturner,24/Dec/13 19:29,13/Feb/14 23:06,13/Mar/19 22:01,13/Feb/14 23:06,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Saw the following walker log.   I think we should modify the test to detect when its attempting to rename across namespaces and make it expect an error.  Probably should not be getting an Accumulo exception.

{noformat}
24 17:45:03,730 [randomwalk.Module] DEBUG:   users: [user000, user001, user002, user003, user004]
24 17:45:03,731 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Concurrent.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.start.Main$1.run(Main.java:137)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.Exception: Error running node ct.RenameTable
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloException: Internal error processing waitForTableOperation
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:334)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:300)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.rename(TableOperationsImpl.java:773)
        at org.apache.accumulo.test.randomwalk.concurrent.RenameTable.visit(RenameTable.java:44)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 9 more
Caused by: org.apache.thrift.TApplicationException: Internal error processing waitForTableOperation
        at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:71)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Client.recv_waitForTableOperation(MasterClientService.java:610)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Client.waitForTableOperation(MasterClientService.java:595)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.waitForTableOperation(TableOperationsImpl.java:272)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:314)
        ... 13 more
{noformat}

Saw following in master log

{noformat}
2013-12-24 17:45:03,941 [thrift.ProcessFunction] ERROR: Internal error processing waitForTableOperation
java.lang.IllegalArgumentException: Namespace in new table name does not match the old table name
        at org.apache.accumulo.master.tableOps.RenameTable.call(RenameTable.java:67)
        at org.apache.accumulo.master.tableOps.RenameTable.call(RenameTable.java:37)
        at org.apache.accumulo.master.tableOps.TraceRepo.call(TraceRepo.java:54)
        at org.apache.accumulo.fate.Fate$TransactionRunner.run(Fate.java:67)
        at org.apache.accumulo.fate.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:744)
{noformat}",db746960fbcafb1651c15ec2e5493d56acb5065c,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2070,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-27 02:44:36.763,,,no_permission,,,,,,,,,,,,365300,,,Thu Feb 13 23:06:00 UTC 2014,,,,,,0|i1qyqv:,365603,,,,,,,,"27/Dec/13 02:44;jira-bot;Commit ccb6093bbc33bb5ec8155aca7a594c5c58719ca4 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ccb6093 ]

ACCUMULO-2091 Catch AccumuloException in RW RenameTable.

When we rename a table, we might attempt to rename it to a different namespace. This should cause an error, so check for
this.
","27/Dec/13 02:45;jira-bot;Commit ccb6093bbc33bb5ec8155aca7a594c5c58719ca4 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ccb6093 ]

ACCUMULO-2091 Catch AccumuloException in RW RenameTable.

When we rename a table, we might attempt to rename it to a different namespace. This should cause an error, so check for
this.
","02/Jan/14 20:20;kturner;When this occurs the client is seeing ""
Internal error processing waitForTableOperation"".  On the server side we see the error message ""Namespace in new table name does not match the old table name"", but this does not make it back to the client in any way.  I think it should, but I am not sure how.  [~ctubbsii], how should this propagate back to the client?","02/Jan/14 20:29;elserj; From ACCUMULO-1965, I would imagine that it's *supposed* to be an AccumuloException wrapping a Namespace exception.

Are you still seeing this, Keith?",02/Jan/14 20:34;kturner;I have not tried running it again.  I reopened because the exception handling for this case did not seem right.   ,"02/Jan/14 20:38;kturner;[~elserj] do you know what the current status is, does the code still throw an AccumuloException wrapping a TApplicationException when this occurs?   If its supposed to throw  an AccumuloException wrapping a Namespace, then the test should probably check for that.","02/Jan/14 20:42;elserj;I need to double check, but IIRC talking to Christopher, we shoudl get an accumulo exception wrapping something else. I don't recall what that 'something else' should be in this case.

Christopher did give me fair warning after he made the changes he made in ACCUMULO-1965 didn't touch any RW code and thus there were likely breakages there.

bq. the test should probably check for that.

Agreed - the changes on this ticket were before ACCUMULO-1965 was done, I believe. I'll poke through what should be happening.","02/Jan/14 20:46;elserj;You'll currently get: AccumuloException(ThriftTableOperationException). (no inner Namespace exception in this case)

IMO, there should be an exception specifically for the INVALID_NAME error code coming out of TableOperationsImpl when we catch the ThriftTableOperationException.

Would you agree?","02/Jan/14 21:44;kturner;I have the following concerns

 # I would like to see the test check for the most specific thing possible w/ the exception, so that it does not ignore an AccumuloException that has nothing to do with this issue.
 # The exception should be informative to the user.

I think we can address the 1st concern, however the 2nd issue is still not addressed.   The user does not know from the exception why the rename failed, that they were trying to rename across namespace.  I spoke w/ [~ctubbsii] and he may have some work in progress to make the exception more informative.


","02/Jan/14 21:49;elserj;Edit: I talked to [~ctubbsii] on IRC who told me that he already has a WIP so I've stopped looking at this until he commits his changes.

I have a quick patch sitting locally which creates an InvalidNamespaceNameException and wraps it with an AccumuloException instead of what currently exists which is a bit cleaner to me.

This would satisfy your concerns as we have a specific exception to catch and the exception contains the message that they tried to rename a table across namespaces. I tried to lift up the above InvalidNamespaceNameException to the interface but got a little worried about the impact with all the try/catch's which just eat certain Exceptions and throw an AssertionException instead.",13/Feb/14 23:06;elserj;Seems happy now.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Concurrent random walk test fails to rename table,ACCUMULO-2090,12686319,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,kturner,kturner,24/Dec/13 19:23,13/Feb/14 23:05,13/Mar/19 22:01,13/Feb/14 23:05,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Saw the following random walker log

{noformat}
24 17:44:13,374 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Concurrent.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.start.Main$1.run(Main.java:137)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.Exception: Error running node ct.RenameTable
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloException: Internal error processing waitForTableOperation
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:334)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:300)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.rename(TableOperationsImpl.java:773)
        at org.apache.accumulo.test.randomwalk.concurrent.RenameTable.visit(RenameTable.java:44)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 9 more
Caused by: org.apache.thrift.TApplicationException: Internal error processing waitForTableOperation
        at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:71)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Client.recv_waitForTableOperation(MasterClientService.java:610)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Client.waitForTableOperation(MasterClientService.java:595)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.waitForTableOperation(TableOperationsImpl.java:272)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:314)
        ... 13 more
{noformat}

Saw the following in master log.

{noformat}
2013-12-24 17:44:13,342 [thrift.ProcessFunction] ERROR: Internal error processing waitForTableOperation
java.lang.RuntimeException: org.apache.accumulo.core.client.NamespaceNotFoundException: Namespace nspc_000 does not exist (getNamespaceId() failed to find namespace)
        at org.apache.accumulo.master.Master$MasterClientServiceHandler.waitForTableOperation(Master.java:1163)
        at sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at com.sun.proxy.$Proxy16.waitForTableOperation(Unknown Source)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Processor$waitForTableOperation.getResult(MasterClientService.java:2119)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Processor$waitForTableOperation.getResult(MasterClientService.java:2103)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:744)
Caused by: org.apache.accumulo.core.client.NamespaceNotFoundException: Namespace nspc_000 does not exist (getNamespaceId() failed to find namespace)
        at org.apache.accumulo.core.client.impl.Namespaces.getNamespaceId(Namespaces.java:64)
        at org.apache.accumulo.master.tableOps.RenameTable.call(RenameTable.java:66)
        at org.apache.accumulo.master.tableOps.RenameTable.call(RenameTable.java:37)
        at org.apache.accumulo.master.tableOps.TraceRepo.call(TraceRepo.java:54)
        at org.apache.accumulo.fate.Fate$TransactionRunner.run(Fate.java:67)
        at org.apache.accumulo.fate.util.LoggingRunnable.run(LoggingRunnable.java:34)
{noformat}",db746960fbcafb1651c15ec2e5493d56acb5065c,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-24 20:05:30.126,,,no_permission,,,,,,,,,,,,365299,,,Thu Feb 13 23:05:46 UTC 2014,,,,,,0|i1qyqn:,365602,,,,,,,,24/Dec/13 19:34;kturner;Are you sure this is a duplicate?  The error messages in the master logs in the two tickets are different.  I am not familiar w/ the code.,24/Dec/13 20:05;elserj;My bad. I didn't read fully down to the Master log to see that there are different errors that just presented themselves in the same fashion.,"03/Jan/14 20:36;jira-bot;Commit 29bdceb4e601ba6ebaaa80e93ef676b4d28b2699 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=29bdceb ]

ACCUMULO-2090 Add a slightly better exception catching on randomwalk RenameTable

We know a few things when we catch this exception, but we can't definitely
make assertions about what was correct/incorrect because the namespaces could
be created or deleted while we're running this test. Best we can do is properly log.
","03/Jan/14 20:37;jira-bot;Commit 29bdceb4e601ba6ebaaa80e93ef676b4d28b2699 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=29bdceb ]

ACCUMULO-2090 Add a slightly better exception catching on randomwalk RenameTable

We know a few things when we catch this exception, but we can't definitely
make assertions about what was correct/incorrect because the namespaces could
be created or deleted while we're running this test. Best we can do is properly log.
","03/Jan/14 20:38;elserj;I think I've made the only change that we can given what the Concurrent RW test package does. It should be sufficient to keep the test from failing at the moment, but I'm not going to close it until I can verify after the next round of namespace exception handling changes.",13/Feb/14 23:05;elserj;Seems happy now.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SimpleGarbageCollector doesn't process address correctly,ACCUMULO-2332,12693496,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,06/Feb/14 04:23,10/Feb/14 21:13,13/Mar/19 22:01,10/Feb/14 18:56,1.5.0,,,,,,,1.5.1,,,gc,,,,,,0,,,,,"Two things stood out at me so far:

# The correct address is not always placed into ZooKeeper (e.g. a value of ""localhost"" will result in ""localhost"" and a value of ""0.0.0.0"" will result in ""0.0.0.0"").
# ""localhost"" is always passed to {{Accumulo.enableTracing}} which will ultimately write ""localhost"" instead of the actual host running the GC",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-10 18:56:43.384,,,no_permission,,,,,,,,,,,,372081,,,Mon Feb 10 21:13:30 UTC 2014,,,,,,0|i1s4hj:,372386,,,,,,,,"10/Feb/14 18:56;jira-bot;Commit 30799163e3eabcf00199989f472c027a3c823132 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3079916 ]

ACCUMULO-2332 Rework how address parsing is currently done by the GC.

Try to reduce the number of creations of an InetSocketAddress and ensure
that an externally addressable hostname/address is placed in zookeeper.
Also, replace 0.0.0.0 with the hostname for the machine when provided
as the address
","10/Feb/14 18:56;jira-bot;Commit 30799163e3eabcf00199989f472c027a3c823132 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3079916 ]

ACCUMULO-2332 Rework how address parsing is currently done by the GC.

Try to reduce the number of creations of an InetSocketAddress and ensure
that an externally addressable hostname/address is placed in zookeeper.
Also, replace 0.0.0.0 with the hostname for the machine when provided
as the address
","10/Feb/14 18:56;jira-bot;Commit 30799163e3eabcf00199989f472c027a3c823132 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3079916 ]

ACCUMULO-2332 Rework how address parsing is currently done by the GC.

Try to reduce the number of creations of an InetSocketAddress and ensure
that an externally addressable hostname/address is placed in zookeeper.
Also, replace 0.0.0.0 with the hostname for the machine when provided
as the address
","10/Feb/14 21:01;jira-bot;Commit 24c0445054f4fe8947bd3c0d25dea333933cfb1f in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=24c0445 ]

ACCUMULO-2332 More whitespace altercations
","10/Feb/14 21:01;jira-bot;Commit 24c0445054f4fe8947bd3c0d25dea333933cfb1f in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=24c0445 ]

ACCUMULO-2332 More whitespace altercations
","10/Feb/14 21:01;jira-bot;Commit 24c0445054f4fe8947bd3c0d25dea333933cfb1f in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=24c0445 ]

ACCUMULO-2332 More whitespace altercations
","10/Feb/14 21:13;bhavanki;This is one of my new favorite commit messages, as we all often fight with whitespace.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
duplicate locations,ACCUMULO-2261,12691385,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,27/Jan/14 14:24,07/Feb/14 15:45,13/Mar/19 22:01,28/Jan/14 19:29,1.5.0,,,,,,,1.5.1,1.6.0,,master,tserver,,,,,0,,,,,"Anthony F reports the following:

bq. I have observed a loss of data when tservers fail during bulk ingest.  The keys that are missing are right around the table's splits indicating that data was lost when a tserver died during a split.  I am using Accumulo 1.5.0.  At around the same time, I observe the master logging a message about ""Found two locations for the same extent"". 

And:

bq.  I'm currently digging through the logs and will report back.  Keep in mind, I'm using Accumulo 1.5.0 on a Hadoop 2.2.0 stack.  To determine data loss, I have a 'ConsistencyCheckingIterator' that verifies each row has the expected data (it takes a long time to scan the whole table).  Below is a quick summary of what happened.  The tablet in question is ""d;72~gcm~201304"".  Notice that it is assigned to 192.168.2.233:9997[343bc1fa155242c] at 2014-01-25 09:49:36,233.  At 2014-01-25 09:49:54,141, the tserver goes away.  Then, the tablet gets assigned to 192.168.2.223:9997[143bc1f14412432] and shortly after that, I see the BadLocationStateException.  The master never recovers from the BLSE - I have to manually delete one of the offending locations.

{noformat}
2014-01-25 09:49:36,233 [master.Master] DEBUG: Normal Tablets assigning tablet d;72~gcm~201304;72=192.168.2.233:9997[343bc1fa155242c]
2014-01-25 09:49:36,233 [master.Master] DEBUG: Normal Tablets assigning tablet p;18~thm~2012101;18=192.168.2.233:9997[343bc1fa155242c]
2014-01-25 09:49:54,141 [master.Master] WARN : Lost servers [192.168.2.233:9997[343bc1fa155242c]]
2014-01-25 09:49:56,866 [master.Master] DEBUG: 42 assigned to dead servers: [d;03~u36~201302;03~thm~2012091@(null,192.168.2.233:9997[343bc1fa155242c],null), d;06~u36~2013;06~thm~2012083@(null,192.168.2.233:9997[343bc1fa155242c],null), d;25;24~u36~2013@(null,192.168.2.233:9997[343bc1fa155242c],null), d;25~u36~201303;25~thm~201209@(null,192.168.2.233:9997[343bc1fa155242c],null), d;27~gcm~2013041;27@(null,192.168.2.233:9997[343bc1fa155242c],null), d;30~u36~2013031;30~thm~2012082@(null,192.168.2.233:9997[343bc1fa155242c],null), d;34~thm;34~gcm~2013022@(null,192.168.2.233:9997[343bc1fa155242c],null), d;39~thm~20121;39~gcm~20130418@(null,192.168.2.233:9997[343bc1fa155242c],null), d;41~thm;41~gcm~2013041@(null,192.168.2.233:9997[343bc1fa155242c],null), d;42~u36~201304;42~thm~20121@(null,192.168.2.233:9997[343bc1fa155242c],null), d;45~thm~201208;45~gcm~201303@(null,192.168.2.233:9997[343bc1fa155242c],null), d;48~gcm~2013052;48@(null,192.168.2.233:9997[343bc1fa155242c],null), d;60~u36~2013021;60~thm~20121@(null,192.168.2.233:9997[343bc1fa155242c],null), d;68~gcm~2013041;68@(null,192.168.2.233:9997[343bc1fa155242c],null), d;72;71~u36~2013@(null,192.168.2.233:9997[343bc1fa155242c],null), d;72~gcm~201304;72@(192.168.2.233:9997[343bc1fa155242c],null,null), d;75~thm~2012101;75~gcm~2013032@(null,192.168.2.233:9997[343bc1fa155242c],null), d;78;77~u36~201305@(null,192.168.2.233:9997[343bc1fa155242c],null), d;90~u36~2013032;90~thm~2012092@(null,192.168.2.233:9997[343bc1fa155242c],null), d;91~thm;91~gcm~201304@(null,192.168.2.233:9997[343bc1fa155242c],null), d;93~u36~2013012;93~thm~20121@(null,192.168.2.233:9997[343bc1fa155242c],null), m;20;19@(null,192.168.2.233:9997[343bc1fa155242c],null), m;38;37@(null,192.168.2.233:9997[343bc1fa155242c],null), m;51;50@(null,192.168.2.233:9997[343bc1fa155242c],null), m;60;59@(null,192.168.2.233:9997[343bc1fa155242c],null), m;92;91@(null,192.168.2.233:9997[343bc1fa155242c],null), o;01<@(null,192.168.2.233:9997[343bc1fa155242c],null), o;04;03@(null,192.168.2.233:9997[343bc1fa155242c],null), o;50;49@(null,192.168.2.233:9997[343bc1fa155242c],null), o;63;62@(null,192.168.2.233:9997[343bc1fa155242c],null), o;74;73@(null,192.168.2.233:9997[343bc1fa155242c],null), o;97;96@(null,192.168.2.233:9997[343bc1fa155242c],null), p;08~thm~20121;08@(null,192.168.2.233:9997[343bc1fa155242c],null), p;09~thm~20121;09@(null,192.168.2.233:9997[343bc1fa155242c],null), p;10;09~thm~20121@(null,192.168.2.233:9997[343bc1fa155242c],null), p;18~thm~2012101;18@(192.168.2.233:9997[343bc1fa155242c],null,null), p;21;20~thm~201209@(null,192.168.2.233:9997[343bc1fa155242c],null), p;22~thm~2012091;22@(null,192.168.2.233:9997[343bc1fa155242c],null), p;23;22~thm~2012091@(null,192.168.2.233:9997[343bc1fa155242c],null), p;41~thm~2012111;41@(null,192.168.2.233:9997[343bc1fa155242c],null), p;42;41~thm~2012111@(null,192.168.2.233:9997[343bc1fa155242c],null), p;58~thm~201208;58@(null,192.168.2.233:9997[343bc1fa155242c],null)]...
2014-01-25 09:49:59,706 [master.Master] DEBUG: Normal Tablets assigning tablet d;72~gcm~201304;72=192.168.2.223:9997[143bc1f14412432]
2014-01-25 09:50:13,515 [master.EventCoordinator] INFO : tablet d;72~gcm~201304;72 was loaded on 192.168.2.223:9997
2014-01-25 09:51:20,058 [state.MetaDataTableScanner] ERROR: java.lang.RuntimeException: org.apache.accumulo.server.master.state.TabletLocationState$BadLocationStateException: found two locations for the same extent d;72~gcm~201304: 192.168.2.223:9997[143bc1f14412432] and 192.168.2.233:9997[343bc1fa155242c]
java.lang.RuntimeException: org.apache.accumulo.server.master.state.TabletLocationState$BadLocationStateException: found two locations for the same extent d;72~gcm~201304: 192.168.2.223:9997[143bc1f14412432] and 192.168.2.233:9997[343bc1fa155242c]
{noformat}
",hadoop 2.2.0 and zookeeper 3.4.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-27 15:21:25.775,,,no_permission,,,,,,,,,,,,370130,,,Fri Feb 07 15:45:13 UTC 2014,,,,,,0|i1rsjz:,370432,,,,,,,,"27/Jan/14 14:42;ecn; In this case, a tablet was assigned to server A, and that server was considered down before the tablet was loaded.  It was then assigned to server B.  But both server A and B updated the location information.  And both servers are running on the same computer (since they have the same IP).

There are several mechanisms used to avoid this problem:

# Port number: two processes should not be able to open the same address on a unix-like system.
# zookeeper lock.  Server B should not have been able to get a lock if Server A had the lock
# updates to the !METADATA table (which hold the assigned and current location) are protected by a constraint that verifies that the server still holds its lock
# the tablet server checks that the tablet is assigned to it before it loads the tablet

Decoding the write-ahead logs of the !METADATA tablet would give us a clearer idea of what order things happened.  If this happens again, please copy the !METADATA walog files for post-analysis.  Look for these entries:

{noformat}
shell> scan -b !0; -e !0< -c log
{noformat}

For this to have happened, the master needed to see the zookeeper lock of A expire, read the old status of ""assigned,""  the server B had to start and be noticed by the master, the old server had to write a last-gasp update the the !METADATA table and server serving the !METADATA table had to read a cached, old lock from zookeeper.

Are you automatically restarting your tservers, by any chance?
",27/Jan/14 15:21;anthonyf;The tservers do not have the same IP.  Server A is 192.168.2.233 while server B is 192.168.2.223 - off by ten which is admittedly a bit confusing.,"27/Jan/14 15:39;ecn;Oh,. you're right.  Do you have the end of the log for Server A?  And, are the times across your system synchronized?  I'm trying to establish how this happened, to see if there's another check we can add to mitigate it.
","27/Jan/14 16:24;anthonyf;We have ntp setup to synchronize system clocks.  Here's the log from 192.168.2.233.

_applied jira formatting_
{noformat}
2014-01-25 09:49:11,708 [cache.LruBlockCache] DEBUG: Cache Stats: Sizes: Total=483.68814MB (507183784), Free=1564.3119MB (1640299864), Max=2048.0MB (2147483648), Counts: Blocks=835, Access=30151167, Hit=30150280, 
Miss=887, Evictions=0, Evicted=0, Ratios: Hit Ratio=99.9970555305481%, Miss Ratio=0.0029418428312055767%, Evicted/Run=NaN, Duplicate Reads=18
2014-01-25 09:49:11,711 [cache.LruBlockCache] DEBUG: Cache Stats: Sizes: Total=6742.9854MB (7070532384), Free=1449.0149MB (1519402208), Max=8192.0MB (8589934592), Counts: Blocks=68811, Access=43909183, Hit=4336353
1, Miss=545652, Evictions=57, Evicted=476838, Ratios: Hit Ratio=98.75731468200684%, Miss Ratio=1.242683082818985%, Evicted/Run=8365.5791015625, Duplicate Reads=0
2014-01-25 09:49:11,712 [tabletserver.TabletServer] DEBUG: gc ParNew=897.13(+17.22) secs ConcurrentMarkSweep=6.22(+0.00) secs freemem=4,064,834,072(+1,745,404,552) totalmem=12,777,553,920
2014-01-25 09:49:17,455 [tabletserver.TabletServer] DEBUG: gc ParNew=901.79(+4.67) secs ConcurrentMarkSweep=6.22(+0.00) secs freemem=3,913,871,704(+667,572,648) totalmem=12,777,553,920
2014-01-25 09:49:17,871 [cache.LruBlockCache] DEBUG: Block cache LRU eviction started.  Attempting to free 859003704 bytes
2014-01-25 09:49:17,942 [cache.LruBlockCache] DEBUG: Block cache LRU eviction completed. Freed 859019280 bytes.  Priority Sizes: Single=2512.0676MB (2634093856), Multi=4456.495MB (4672973712),Memory=0.0MB (0)
2014-01-25 09:49:19,569 [tabletserver.TabletServer] DEBUG: gc ParNew=903.09(+1.30) secs ConcurrentMarkSweep=6.22(+0.00) secs freemem=3,733,299,800(-180,571,904) totalmem=12,777,553,920
2014-01-25 09:49:21,472 [tabletserver.TabletServer] DEBUG: gc ParNew=904.08(+0.99) secs ConcurrentMarkSweep=6.22(+0.00) secs freemem=3,574,451,336(-158,848,464) totalmem=12,777,553,920
2014-01-25 09:49:44,408 [tabletserver.TabletServer] DEBUG: Got loadTablet message from user: !SYSTEM
2014-01-25 09:49:44,408 [tabletserver.TabletServer] INFO : Loading tablet d;72~gcm~201304;72
2014-01-25 09:49:44,408 [tabletserver.TabletServer] INFO : dcloud18/192.168.2.233:9997: got assignment from master: d;72~gcm~201304;72
2014-01-25 09:49:44,408 [tabletserver.TabletServer] DEBUG: Loading extent: d;72~gcm~201304;72
2014-01-25 09:49:44,409 [tabletserver.TabletServer] DEBUG: verifying extent d;72~gcm~201304;72
2014-01-25 09:49:44,418 [tabletserver.TabletServer] DEBUG: Got loadTablet message from user: !SYSTEM
2014-01-25 09:49:44,418 [tabletserver.TabletServer] INFO : Loading tablet p;18~thm~2012101;18
2014-01-25 09:49:44,456 [tabletserver.TabletServer] DEBUG: Got loadTablet message from user: !SYSTEM
2014-01-25 09:49:44,557 [tabletserver.Tablet] DEBUG: Looking at metadata {d;72~gcm~201304 file:/b-00028xn/I0002i57.rf [] 40757550 false=1625685,0,1389849852187, d;72~gcm~201304 file:/b-00028xn/I0002i5f.rf [] 40757699 false=1592695,0,1389849860660, d;72~gcm~201304 file:/t-0001ect/C0001nrv.rf [] 40418333 false=178655073,3168593, d;72~gcm~201304 file:/t-0001rzt/C0001u7r.rf [] 40441613 false=232169298,4085196, d;72~gcm~201304 file:/t-0001rzt/C0002evg.rf [] 40708788 false=281016452,4939001, d;72~gcm~201304 file:/t-0001rzt/C0002j3b.rf [] 40750189 false=36970878,670358, d;72~gcm~201304 file:/t-0001rzt/C0002j5f.rf [] 40756562 false=22086620,394464, d;72~gcm~201304 future:343bc1fa155242c [] 41048300 false=192.168.2.233:9997, d;72~gcm~201304 last:3438da6a936264c [] 40756562 false=192.168.2.225:9997, d;72~gcm~201304 srv:dir [] 40418333 false=/t-0001rzt, d;72~gcm~201304 srv:flush [] 40825738 false=9, d;72~gcm~201304 srv:lock [] 40825738 false=tservers/192.168.2.223:9997/zlock-0000000001$243b1084d9e1273, d;72~gcm~201304 srv:time [] 40757699 false=M1389849860660, d;72~gcm~201304 ~tab:~pr [] 40418333 false=^A72}
2014-01-25 09:49:44,557 [tabletserver.Tablet] DEBUG: got [] for logs for d;72~gcm~201304;72
2014-01-25 09:49:44,557 [tabletserver.TabletServer] DEBUG: Got loadTablet message from user: !SYSTEM
2014-01-25 09:49:44,557 [zookeeper.ZooLock] DEBUG: Unexpected event watching lock node WatchedEvent state:Disconnected type:None path:null /accumulo/f76cacfa-e117-4999-893a-1eba79920f2c/tservers/192.168.2.233:9997/zlock-0000000000
2014-01-25 09:49:44,560 [tabletserver.TabletServer] DEBUG: gc ParNew=926.22(+22.14) secs ConcurrentMarkSweep=6.25(+0.03) secs freemem=3,477,953,072(-96,498,264) totalmem=12,777,553,920
2014-01-25 09:49:44,560 [tabletserver.TabletServer] DEBUG: Got loadTablet message from user: !SYSTEM
2014-01-25 09:50:09,984 [cache.LruBlockCache] DEBUG: Cache Stats: Sizes: Total=6630.77MB (6952866144), Free=1561.2301MB (1637068448), Max=8192.0MB (8589934592), Counts: Blocks=67662, Access=43916676, Hit=43363810, Miss=552866, Evictions=58, Evicted=485201, Ratios: Hit Ratio=98.74109625816345%, Miss Ratio=1.2588976882398129%, Evicted/Run=8365.5341796875, Duplicate Reads=0
2014-01-25 09:50:09,984 [cache.LruBlockCache] DEBUG: Cache Stats: Sizes: Total=513.6937MB (538646880), Free=1534.3063MB (1608836768), Max=2048.0MB (2147483648), Counts: Blocks=845, Access=30157409, Hit=30156512, Miss=897, Evictions=0, Evicted=0, Ratios: Hit Ratio=99.99703168869019%, Miss Ratio=0.0029743934646830894%, Evicted/Run=NaN, Duplicate Reads=18
2014-01-25 09:50:28,730 [zookeeper.ZooCache] WARN : Zookeeper error, will retry
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /accumulo/f76cacfa-e117-4999-893a-1eba79920f2c/config/tserver.client.timeout
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
        at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1041)
        at org.apache.accumulo.fate.zookeeper.ZooCache$2.run(ZooCache.java:208)
{noformat}","27/Jan/14 17:36;ecn;Master assigns the tablet:
{noformat}
2014-01-25 09:49:36,233 [master.Master] DEBUG: Normal Tablets assigning tablet d;72~gcm~201304;72=192.168.2.233:9997[343bc1fa155242c]
{noformat}

Tablet server loads the tablet
{noformat}
2014-01-25 09:49:21,472 [tabletserver.TabletServer] DEBUG: gc ParNew=904.08(+0.99) secs ConcurrentMarkSweep=6.22(+0.00) secs freemem=3,574,451,336(-158,848,464) totalmem=12,777,553,920
2014-01-25 09:49:44,408 [tabletserver.TabletServer] INFO : Loading tablet d;72~gcm~201304;72
{noformat}

tablet server loses its lock
{noformat}
2014-01-25 09:49:44,560 [tabletserver.TabletServer] DEBUG: gc ParNew=926.22(+22.14) secs ConcurrentMarkSweep=6.25(+0.03) secs freemem=3,477,953,072(-96,498,264) totalmem=12,777,553,920
2014-01-25 09:49:54,141 [master.Master] WARN : Lost servers [192.168.2.233:9997[343bc1fa155242c]]
{noformat}

That last line with GC debugging say that the ParNew gc took over 22 seconds, and ParNew is a stop-the-world GC and caused the server to lose its lock.  Yet it continued to run for 15 more seconds.

The master reassigns the tablet.
{noformat}
2014-01-25 09:49:59,706 [master.Master] DEBUG: Normal Tablets assigning tablet d;72~gcm~201304;72=192.168.2.223:9997[143bc1f14412432]
{noformat}

It looks like a race between the dying tserver and the zookeeper cache update.  [~kturner] and I discussed fixing this in 1.6 using conditional mutations.  In 1.5 we would have to make a full zookeeper check in the METADATA table constraint, which could be performance issue.  We could also have the master fix the !METADATA table instead of leaving the system crippled.

[~anthonyf] are you having issues with tservers frequently losing their locks?  A few things to check: make sure swappiness is set to zero, make sure the size of the ParNew is limited (-XX:NewSize=1G -XX:MaxNewSize=1G), and check to make sure that system memory isn't oversubscribed.","27/Jan/14 17:55;anthonyf;System swappiness is set to zero

{noformat}
$ cat /proc/sys/vm/swappiness 
0
{noformat}

Tserver opts are:

{noformat}
ACCUMULO_TSERVER_OPTS=""${POLICY} -Xmx12g -Xms12g -XX:NewSize=1G -XX:MaxNewSize=1G ""
{noformat}","28/Jan/14 01:04;ecn;[~anthonyf]] are you sure that the other processes on your nodes wouldn't push a tserver into swap?  If you are really this unlucky, I want you to help test all future releases. 

I've written a fix using conditional mutations, but I'm going to leave it for 1.7.  Conditional mutations are new and the METADATA table is a tricky beast.  And we still need a fix for the root table pointer.   Instead, I'll have the master repair the metadata information if it finds it is relatively safe to do so.  So, if it sees multiple locations, and one is a dead tserver, it will remove the entry.  I'll back-port it to 1.5, too.

I'm decreasing the severity because there is a known work-around (removing the entry in the !METADATA table by hand).  Feel free to raise it back up if you disagree.","28/Jan/14 01:13;elserj;bq. It looks like a race between the dying tserver and the zookeeper cache update. Keith Turner and I discussed fixing this in 1.6 using conditional mutations. In 1.5 we would have to make a full zookeeper check in the METADATA table constraint, which could be performance issue.

I was poking around at this. Isn't another possibility to circumvent the ZooCache in the TabletServer before calling {{TabletStateStore.setLocation(assignment);}} or verify that the lock is held before invoking that setLocation method? Instead of trying to push that down to a constraint, we could make sure that we don't do a cached read of ZK. If it weren't in the constraint, it shouldn't cause a performance loss on the METADATA table, but just slow down assignments instead, no?

I'm not really sure of relative performance impact of a full zk check over what ZooCache/ZooLock provides. A lot of our ZK wrapper classes tends to make my head spin.","28/Jan/14 02:50;ecn;bq.  Isn't another possibility to circumvent the ZooCache in the TabletServer 

That's what I meant with this:

bq. have to make a full zookeeper check in the METADATA table constraint

We need to test it in the context of the only place where updates to metadata table information is atomic: at the tablet server serving the metadata tablet (root table excluded).

We need to test it.  I been thinking for the last hour thinking of what I would expect the performance to be in a cold-start... and I really don't know what to expect.  I know there's network latency to make the RPC call, but zookeeper can perform batches of read-only operations on slave nodes.  Do we have to make a sync() call to ensure we have the most up-to-date information?  What does that require?  We need a scale test (perhaps there's a benchmark out there), to tell us what the cost would be.
","28/Jan/14 03:14;elserj;bq. That's what I meant with this:
bq. have to make a full zookeeper check in the METADATA table constraint

Right, I was just making the distinction between making the check in the AssignmentHandler and in the MetadataConstraints.

Regarding testing, let me know -- would be more than happy to help write/test/research/etc.","28/Jan/14 17:43;kturner;[~elserj]

bq. Right, I was just making the distinction between making the check in the AssignmentHandler and in the MetadataConstraints.

Doing the check in the metadata constraint means it will be done later.   If the assignment handler does the check and then issues a metadata table update, the actual update could take place much later (even after the requesting tserver has died).  Ifs also possible that the lock could be lost when doing the check in the constraint.   The check in the constraint is sanity check, but it does not prevent all problems.   Doing the sanity check as a late as possible is better.  Note that even if zoocache is not used, there is still a race condition.  If the lock is lost after zookeeper is checked directly, then its a problem.   Using conditional mutations (and CAS in zookeeper) is a better solution.  It allows us to only make the mutation is future and current locations are in the expected state.

[~ecn] I don't think we should make 1.7 use conditional mutations for this case.  I thnik 1.7 should have  a ticket to make one big change to make all metadata operations use CAS w/ zookeeper and metadata table in places where it makes sense.  Seems like it would be nice to do this in a branch and work out the kinks and then merge it in.   I will open a ticket.  This is something I was thinking of donig for 1.6, but never got around to it.

","28/Jan/14 18:46;jira-bot;Commit f5c35b9502ba107b8384a0760b1b9ba8e056ef85 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f5c35b9 ]

ACCUMULO-2261 remove unexpected future and loc entries for dead servers from the metadata tables
","28/Jan/14 18:46;jira-bot;Commit f5c35b9502ba107b8384a0760b1b9ba8e056ef85 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f5c35b9 ]

ACCUMULO-2261 remove unexpected future and loc entries for dead servers from the metadata tables
","28/Jan/14 19:22;jira-bot;Commit 772ca16bc8cbaef6db4bbd440145dc744947fedb in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=772ca16 ]

ACCUMULO-2261 cherry pick back 1.5
","28/Jan/14 19:22;jira-bot;Commit 772ca16bc8cbaef6db4bbd440145dc744947fedb in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=772ca16 ]

ACCUMULO-2261 cherry pick back 1.5
","28/Jan/14 19:22;jira-bot;Commit 772ca16bc8cbaef6db4bbd440145dc744947fedb in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=772ca16 ]

ACCUMULO-2261 cherry pick back 1.5
","06/Feb/14 17:15;bills;I've seen this twice in the past two days on a 1.5.0 instance on AWS. The first time I could repair it because it was on a user table, but now this happened on the !METADATA table.

I'm unable to scan the !METADATA table, so I had to offline it and dig through some of its RFiles. In the {{root_tablet}} directory, I found:

{noformat}
!!~del/!0/default_tablet/A00006zz.rf : [] 8189 false ->
!!~del/!0/table_info/A00006zx.rf : [] 8186 false ->
!!~del/!0/table_info/F0000704.rf : [] 8187 false ->
!0;!0< srv:dir [] 0 false -> /root_tablet
!0;!0< ~tab:~pr [] 0 false -> ^@
!0;~ file:/table_info/A0000706.rf [] 8188 false -> 4457,270
!0;~ last:144060a192d001b [] 8188 false -> 10.157.33.251:9997
!0;~ loc:144060a192d001b [] 7251 false -> 10.157.33.251:9997
!0;~ loc:244060a193e001d [] 7256 false -> 10.157.42.152:9997
!0;~ srv:compact [] 8188 false -> 673
!0;~ srv:dir [] 0 false -> /table_info
!0;~ srv:flush [] 8185 false -> 674
!0;~ srv:lock [] 8188 false -> tservers/10.157.33.251:9997/zlock-0000000003$144060a192d001b
!0;~ srv:time [] 8185 false -> L3060
!0;~ ~tab:~pr [] 0 false -> ^A!0<
!0< file:/default_tablet/A0000707.rf [] 8190 false -> 310,3
!0< last:144060a192d001b [] 8190 false -> 10.157.33.251:9997
!0< loc:144060a192d001b [] 7244 false -> 10.157.33.251:9997
!0< srv:compact [] 8190 false -> 674
!0< srv:dir [] 0 false -> /default_tablet
!0< srv:flush [] 8184 false -> 674
!0< srv:lock [] 8190 false -> tservers/10.157.33.251:9997/zlock-0000000003$144060a192d001b
!0< srv:time [] 7624 false -> L2284
!0< ~tab:~pr [] 0 false -> ^A~
{noformat}

Unfortunately I don't have any logs due to a configuration issue. I do believe that both of those servers were actually alive at the time the issue was noticed. I talked to [~ecn] yesterday when this was on a user table, and he told me if both servers are alive, I should delete both {{loc}} entries. What are the effects of doing that? Are they different when they occur on the root tablet?","07/Feb/14 15:45;ecn;Actually, I don't recommend deleting both loc entries... only last entries.  If you have two loc's we'll want to know why.

Since 10.157.33.251:9997 had just recompacted the tablet !0;~, I would kill 10.157.42.152:9997 and remove the entry:

!0;~ loc:244060a193e001d

But that's just playing the odds... if you can reproduce this and provide logs, please let me know.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Seeing spurious error message about namespace that does not exist,ACCUMULO-2092,12686321,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,kturner,kturner,24/Dec/13 19:32,06/Feb/14 00:30,13/Mar/19 22:01,06/Feb/14 00:17,,,,,,,,1.6.0,,,,,,,,,0,,,,,"In the conditional random walk test the following spurious error message occurred.  The test did not fail, it was running fine.

{noformat}
24 17:43:45,065 [conditional.Setup] DEBUG: created table banks
24 17:43:45,101 [conditional.Setup] DEBUG: set table.cache.block.enable false
24 17:43:45,148 [impl.Tables] ERROR: Table (d) contains reference to namespace () that doesn't exist
24 17:43:47,012 [conditional.Init] DEBUG: Added splits [b100, b200, b300, b400, b500, b600, b700, b800, b900]
24 17:44:00,394 [conditional.Init] DEBUG: Added bank b259 9
{noformat}",db746960fbcafb1651c15ec2e5493d56acb5065c,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-24 21:08:08.458,,,no_permission,,,,,,,,,,,,365301,,,Thu Feb 06 00:30:31 UTC 2014,,,,,,0|i1qyr3:,365604,,,,,,,,"24/Dec/13 21:08;vines;So in the clone code, it did the clone ZK and then set the namespace after the majority of the ZK clone work occured. I fixed this by making namespace addition PART of that code. I wonder if create() suffers from a similar race issue.","24/Dec/13 21:13;ctubbsii;No, we believe the problem is that createTable fails because the table exists, but it's Tables cache isn't updated, so it doesn't actually see that the table exists when it checks zookeeper itself. A related problem is ACCUMULO-2093. What needs to happen is that the Tables cache needs to be cleared after every table/fate operation.",24/Dec/13 21:27;vines;This ticket isn't about a createTable failing...,"24/Dec/13 22:34;kturner;[~ctubbsii] and I were looking into this.  We think the following happened 

 # Walker 1 is creating table banks
 # Walker 2 attempted to create table banks, but got a Table Exist exception
 # Walker 2 performs another table operation, but the info in zoocache is not fully updated and the error is emitted

In step 2 above the doTableOperation code could clear the client side table cache in the case of exceptions.  Currently doTableOperation only clears the cache when the table operation is successful. ",24/Dec/13 22:36;kturner;I am not sure if clearing the cache is enough because the table info is stored in multiple nodes.   In step 3 the client could retry if it sees incomplete information with the expectation that the table information will eventually converge to deleted or complete. ,"25/Dec/13 00:02;ctubbsii;[~vines] Right, but it seems to be happening because the client has an inconsistent view of the table's existence after the Master reports that a create table failed, due to it already existing.","28/Jan/14 04:39;vines;Or we make it part of the client API that there is a propagation delay, there is a similar behavior for some of the other permissions.","06/Feb/14 00:16;jira-bot;Commit b0b2c49925735ca02019773e31c0ebee0e4a4260 in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b0b2c49 ]

ACCUMULO-2092 Make client view of table existence consistent

  Clear the cache after exceptions, instead of just successful fate
  operations. This ensures that a failure as the result of a
  TableNotFoundException or TableExistsException will be consistent with
  the client's view, if they check it right after the failure.
",06/Feb/14 00:17;ctubbsii;Fixed by a combination of ACCUMULO-2093 and this ticket.,"06/Feb/14 00:30;jira-bot;Commit b0b2c49925735ca02019773e31c0ebee0e4a4260 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b0b2c49 ]

ACCUMULO-2092 Make client view of table existence consistent

  Clear the cache after exceptions, instead of just successful fate
  operations. This ensures that a failure as the result of a
  TableNotFoundException or TableExistsException will be consistent with
  the client's view, if they check it right after the failure.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Can't configure (default) namespace parameters from shell,ACCUMULO-1989,12683635,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,cmccubbin,cmccubbin,09/Dec/13 17:15,06/Feb/14 00:30,13/Mar/19 22:01,06/Feb/14 00:01,,,,,,,,1.6.0,,,,,,,,,0,,,,,"The shell has a problem with parentheses, this makes it impossible to, e.g. remove an iterator from the (default) namespace.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-31 02:15:42.659,,,no_permission,,,,,,,,,,,,362707,,,Thu Feb 06 00:30:30 UTC 2014,,,,,,0|i1qirz:,363001,,,,,,,,"09/Dec/13 17:35;cmccubbin;Using the API, I can alter the dafault namespace by passing in an empty string for the namespace, but this is non-intuitive and doesn't match with the description of that namespace's name in the shell.","31/Dec/13 02:15;ctubbsii;The default namespace is the empty string, similar to java's default package. Namespaces allow tables to be fully qualified. So, tables in the default namespace are fully qualified without a namespace prefix. The problem is, that doesn't show up well in the shell when we list namespaces. The string ""(default)"" was chosen as a placeholder, because we can't show an empty string (Eclipse, and other IDEs do something similar to show the ""(default package)"").

Do you have a suggestion that is more intuitive? One option might be to have a separate flag ""--default-namespace"" to expose it more obviously.","31/Dec/13 02:20;cmccubbin;Yeah, [~vines] and I figured it out after some experimentation. Maybe it could remain as """" if an example is given in the shell help (and maybe in the error message if someone attempts to configure ""default"") ?","31/Dec/13 20:19;ctubbsii;Yeah, we can certainly add a quick blurb to the help, and error messages in the case of {{`-ns ""(default)""`}}.

Do you know if the shell has problems with parentheses in quotes?","01/Jan/14 14:47;cmccubbin;It looks like parens inside quotes is ok:

{code}
root@sqrrl test> deleteiter -ns ""(default)"" -n ""vers"" -scan
2014-01-01 09:46:07,923 [shell.Shell] ERROR: org.apache.accumulo.core.client.NamespaceNotFoundException: Namespace (default) (Id=(default)) does not exist (specified namespace that doesn't exist)
root@sqrrl test>
{code}","29/Jan/14 20:58;vines;perhaps instead of listing it as (default) we list it as an empty string. And in the case of the shell, we put quotes around it. That way it's displaying exactly what it is and how it can be accessed.","06/Feb/14 00:01;jira-bot;Commit a8f154e45d60304827e681d6a74cc7f9dc3aab94 in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a8f154e ]

ACCUMULO-1989 Use default namespace name explicitly in shell
","06/Feb/14 00:30;jira-bot;Commit a8f154e45d60304827e681d6a74cc7f9dc3aab94 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a8f154e ]

ACCUMULO-1989 Use default namespace name explicitly in shell
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
accumulo-site.xml cannot be loaded from $ACCUMULO_CONF_DIR,ACCUMULO-1577,12658338,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mberman,mberman,mberman,17/Jul/13 19:08,04/Feb/14 18:15,13/Mar/19 22:01,17/Jul/13 19:34,1.5.0,,,,,,,1.5.1,1.6.0,,start,,,,,,0,,,,,"Works fine if $ACCUMULO_CONF_DIR isn't set in the environment and it falls back to $ACCUMULO_HOME, but when $ACCUMULO_CONF_DIR _is_ set, the code tries to load the config out of the directory itself, rather than the file within the directory.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1550,,,,,,,,,17/Jul/13 19:12;mberman;ACCUMULO-1577.patch;https://issues.apache.org/jira/secure/attachment/12592828/ACCUMULO-1577.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-07-17 19:34:11.834,,,no_permission,,,,,,,,,,,,338532,,,Wed Jul 24 01:53:47 UTC 2013,,,,,,0|i1me27:,338852,,,,,,,,"17/Jul/13 19:11;mberman;diff --git a/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java b/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java
index ccd85a6..a68ce0e 100644
--- a/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java
+++ b/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java
@@ -76,7 +76,7 @@ public class AccumuloClassLoader {
     String configFile = System.getProperty(""org.apache.accumulo.config.file"", ""accumulo-site.xml"");
     if (System.getenv(""ACCUMULO_CONF_DIR"") != null) {
       // accumulo conf dir should be set
-      SITE_CONF = System.getenv(""ACCUMULO_CONF_DIR"");
+      SITE_CONF = System.getenv(""ACCUMULO_CONF_DIR"") + ""/"" + configFile;
     } else if (System.getenv(""ACCUMULO_HOME"") != null) {
       // if no accumulo conf dir, try accumulo home default
       SITE_CONF = System.getenv(""ACCUMULO_HOME"") + ""/conf/"" + configFile;
","17/Jul/13 19:34;jira-bot;Commit f8b9145d4c9feb12de9093a75720697f12d0b3b3 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f8b9145 ]

ACCUMULO-1577 committing Michael Berman's patch
",17/Jul/13 19:34;ecn;Patch applied. Thanks!,17/Jul/13 20:43;jmhsieh;Nice catch! Looks like I missed that when I ported to trunk.  It was correct in the 1.4.x version.,17/Jul/13 21:08;mberman;Looks like 1.5.1-SNAPSHOT has the same bug.  Can that same patch be applied over there as well?,17/Jul/13 21:25;jmhsieh;Should be able to -- the trunk and 1.5 versions came from the same patch.,"17/Jul/13 22:23;jira-bot;Commit 35c7591a3c86f3518833efca1921dcded227e961 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=35c7591 ]

ACCUMULO-1577 committing Michael Berman's patch to 1.5
",17/Jul/13 22:23;ecn;Done. Thanks for checking 1.5 for me.,"24/Jul/13 01:53;jira-bot;Commit 35c7591a3c86f3518833efca1921dcded227e961 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=35c7591 ]

ACCUMULO-1577 committing Michael Berman's patch to 1.5
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stack overflow MilliSpan.java:113,ACCUMULO-1605,12659603,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,24/Jul/13 15:43,04/Feb/14 18:15,13/Mar/19 22:01,24/Jul/13 16:31,1.4.0,1.4.1,1.4.2,1.4.3,1.5.0,,,1.4.4,1.5.1,1.6.0,trace,,,,,,0,,,,,"In some strange cases, the recursive call to find a span's trace id blows the stack, on MilliSpan.java, line 113.  [~kturner] and [~ecn] have reviewed the code, and nothing is obvious.  Replace the recursive implementation with something more conservative.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-24 16:01:30.207,,,no_permission,,,,,,,,,,,,339796,,,Mon Aug 05 12:20:59 UTC 2013,,,,,,0|i1mlun:,340115,,,,,,,,"24/Jul/13 16:01;jira-bot;Commit 3e971675cb20248f2d4747219e97d7e28d185e08 in branch refs/heads/1.4.4-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3e97167 ]

ACCUMULO-1605 avoid recursion in Span#traceId
","24/Jul/13 16:30;jira-bot;Commit b978900ba7361db6cb021be380632fa3d1611a19 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b978900 ]

ACCUMULO-1605 avoid recursion in Span#traceId
","24/Jul/13 16:31;jira-bot;Commit b978900ba7361db6cb021be380632fa3d1611a19 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b978900 ]

ACCUMULO-1605 avoid recursion in Span#traceId
","31/Jul/13 01:59;jira-bot;Commit 3e971675cb20248f2d4747219e97d7e28d185e08 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3e97167 ]

ACCUMULO-1605 avoid recursion in Span#traceId
","02/Aug/13 20:33;jira-bot;Commit af6c7e8d49b71ab1d9ac8a54572df589f627a9c1 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=af6c7e8 ]

ACCUMULO-1605 close more spans with finally clauses
","05/Aug/13 12:20;jira-bot;Commit ff226a78995057518ac354e671d90f1bb4c30884 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ff226a7 ]

ACCUMULO-1605

Added many finally clauses to close spans in the presence of exceptions.

I suspect that the extreme depth of the traces is caused by traces that
are started and never stopped.  This most likely happens in the presence
of errors, where exceptions jump around the the span.stop calls.
In particular, when a file is missing for a compaction.  This is known
to occur in 1.4 when bulk imports fail.  See ACCUMULO-1044.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accumulo gc cannot identify as non localhost address,ACCUMULO-1630,12661174,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,vines,vines,01/Aug/13 17:31,04/Feb/14 18:15,13/Mar/19 22:01,07/Aug/13 14:14,1.5.0,,,,,,,1.5.1,1.6.0,,gc,,,,,,0,,,,,"We have the ability to pass in an IP address to the various services to help them use the proper IP to ID themselves. However, in the gc at the very least, there is some bad logic which breaks this.

Specifically, the option's parser for the gc only checks checked to verify it is not set. This makes it so the only options for the gc's bind port are localhost if -a isn't set or localhost if it's set.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1601,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-08-07 14:09:24.56,,,no_permission,,,,,,,,,,,,341363,,,Wed Aug 07 14:12:53 UTC 2013,,,,,,0|i1mvhz:,341681,,,,,,,,"07/Aug/13 14:09;jira-bot;Commit fb6b3c3573183b949c1cddfabd5884e30361bd9f in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fb6b3c3 ]

ACCUMULO-1630 use passed cmd-line parameter
","07/Aug/13 14:12;jira-bot;Commit f23e943f9949e96aced9bc63fe929b67f2005c18 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f23e943 ]

ACCUMULO-1630 use passed cmd-line parameter
","07/Aug/13 14:12;jira-bot;Commit fb6b3c3573183b949c1cddfabd5884e30361bd9f in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fb6b3c3 ]

ACCUMULO-1630 use passed cmd-line parameter
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master recovers new WAL on recovering tablets,ACCUMULO-1821,12676204,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,28/Oct/13 19:45,04/Feb/14 18:14,13/Mar/19 22:01,28/Oct/13 21:11,1.4.0,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,,1.4.5,1.5.1,,tserver,,,,,,0,,,,,"During root tablet assignment, unflushed mutations are recovered from the WAL, and then compacted out.  This records a new WAL entry for the root tablet, and recovery is immediately started.  This interferes with writing out the minorCompaction started and minorCompactionComplete flags.  We don't want to write out anything to the WALog until the tablet has been brought online.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-28 19:52:07.668,,,no_permission,,,,,,,,,,,,355701,,,Mon Oct 28 20:04:04 UTC 2013,,,,,,0|i1pbl3:,355989,,,,,,,,"28/Oct/13 19:52;jira-bot;Commit 4d493b467ed0c695616bb98878ba929f67ca586e in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4d493b4 ]

ACCUMULO-1821 don't record log events if the tablet is not online
","28/Oct/13 19:52;jira-bot;Commit 4d493b467ed0c695616bb98878ba929f67ca586e in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4d493b4 ]

ACCUMULO-1821 don't record log events if the tablet is not online
","28/Oct/13 20:04;jira-bot;Commit 4d493b467ed0c695616bb98878ba929f67ca586e in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4d493b4 ]

ACCUMULO-1821 don't record log events if the tablet is not online
","28/Oct/13 20:04;jira-bot;Commit 73b39a0cd5c39afb883dc81f2cc8f0a03177d0b7 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=73b39a0 ]

ACCUMULO-1821 don't record log events if the tablet is not online
","28/Oct/13 20:04;jira-bot;Commit 8683295fcf4e8732e8dc7625f97725cfe0662e1f in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8683295 ]

ACCUMULO-1821 don't record log events if the tablet is not online
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE running Concurrent randomwalk,ACCUMULO-2312,12692925,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,03/Feb/14 19:01,03/Feb/14 23:40,13/Mar/19 22:01,03/Feb/14 23:39,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"{code}[randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node ct.ChangePermissions
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:622)
        at org.apache.accumulo.start.Main$1.run(Main.java:137)
        at java.lang.Thread.run(Thread.java:701)
Caused by: java.lang.NullPointerException
        at org.apache.accumulo.test.randomwalk.concurrent.ChangePermissions.visit(ChangePermissions.java:70)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-03 19:39:36.433,,,no_permission,,,,,,,,,,,,371511,,,Mon Feb 03 23:40:37 UTC 2014,,,,,,0|i1s0z3:,371813,,,,,,,,"03/Feb/14 19:03;vines;Corresponding error in master-
{code}2014-02-03 14:00:55,228 [fate.Fate] WARN : Failed to execute Repo, tid=26ada983e7c435fc
ThriftTableOperationException(tableId:null, tableName:nspc_000.ctt_000, op:CREATE, type:EXISTS, description:null)
        at org.apache.accumulo.master.tableOps.Utils.checkTableDoesNotExist(Utils.java:49)
        at org.apache.accumulo.master.tableOps.PopulateZookeeper.call(CreateTable.java:213)
        at org.apache.accumulo.master.tableOps.PopulateZookeeper.call(CreateTable.java:189)
        at org.apache.accumulo.master.tableOps.TraceRepo.call(TraceRepo.java:54)
        at org.apache.accumulo.fate.Fate$TransactionRunner.run(Fate.java:67)
        at org.apache.accumulo.fate.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:701)
{code}",03/Feb/14 19:14;vines;Those don't actually correspond...,"03/Feb/14 19:39;jira-bot;Commit 722d6be1d05cdafac17a424c5e91bc166d622231 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=722d6be ]

ACCUMULO-2312 test was expecting overly wrapped errors
","03/Feb/14 20:26;vines;ACCUMULO-2316 needs to be resolved first, that may be the factor at hand","03/Feb/14 20:32;jira-bot;Commit 44eb7d4f284a6e4b2daf39be966cd4e29cce70f2 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=44eb7d4 ]

Revert ""ACCUMULO-2312 test was expecting overly wrapped errors""

This reverts commit 722d6be1d05cdafac17a424c5e91bc166d622231.
","03/Feb/14 20:48;jira-bot;Commit 722d6be1d05cdafac17a424c5e91bc166d622231 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=722d6be ]

ACCUMULO-2312 test was expecting overly wrapped errors
","03/Feb/14 23:39;jira-bot;Commit b33fbf40d0b16ee59d74341e568fab4abb160017 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b33fbf4 ]

ACCUMULO-2312 NPE fixed by 2316/2318, but making message better
","03/Feb/14 23:40;jira-bot;Commit b33fbf40d0b16ee59d74341e568fab4abb160017 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b33fbf4 ]

ACCUMULO-2312 NPE fixed by 2316/2318, but making message better
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ClientConfiguration needs javadocs,ACCUMULO-1917,12680588,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,kturner,kturner,21/Nov/13 20:30,03/Feb/14 17:21,13/Mar/19 22:01,03/Feb/14 17:21,,,,,,,,1.6.0,,,,,,,,,0,Documentation,,,,The new ClientConfiguration class needs javadocs.  Especially the methods related to loading it from files like {{loadDefaults()}}.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-30 23:56:10.951,,,no_permission,,,,,,,,,,,,359853,,,Mon Feb 03 17:21:32 UTC 2014,,,,,,0|i1q18n:,360152,,,,,,,,"30/Jan/14 23:56;jira-bot;Commit b178784b9931028b697a49f52c63d73f6bf99bb7 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b178784 ]

ACCUMULO-1917 adding ClientConfiguration javadoc
","30/Jan/14 23:56;jira-bot;Commit b178784b9931028b697a49f52c63d73f6bf99bb7 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b178784 ]

ACCUMULO-1917 adding ClientConfiguration javadoc
","31/Jan/14 18:24;kturner;the javadoc leaves me w/ a lot of questions.. for loadDefaults() should ACCUMULO_CLIENT_CONF_PATH be a list of directories or a list of file names?  Whats the separator char?   If its a list of dirs, what file name will it look for in the dirs?  

for loadDefault(String overridePropertiesFilename) .. I have no clue what this method does after looking at javadocs.  Can you link to PropertiesConfiguration in the javadoc?  What supposed to be in the file that this filename points to?","31/Jan/14 18:31;ctubbsii;Also, I would say that if a class ""needs javadocs"", then those javadocs should add value... @param and @return and @throws statements that don't actually have a description are completely worthless and serve no purpose but to add lines to the code, hurting readability. The javadoc tool already knows that the method has those params, exceptions, and that it will return.","03/Feb/14 17:21;jira-bot;Commit 3a52b2a0666064e4abae48cb4235aef4f2c5aee2 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3a52b2a ]

ACCUMULO-1917 - updated loadDefault javadocs and cleans spurious @param, @return, and @throws tags
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SslWithClientAuthIT.bulk consistently fails in parallel,ACCUMULO-2306,12692623,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,31/Jan/14 23:48,01/Feb/14 02:32,13/Mar/19 22:01,01/Feb/14 02:32,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"{code}
bulk(org.apache.accumulo.test.functional.SslWithClientAuthIT)  Time elapsed: 98 sec  <<< ERROR!
java.io.IOException: File already exists: target/accumulo-maven-plugin/testrf/rf03.rf
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:276)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:269)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:384)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:424)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:905)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:886)
	at org.apache.accumulo.core.file.rfile.RFileOperations.openWriter(RFileOperations.java:124)
	at org.apache.accumulo.core.file.DispatchingFileFactory.openWriter(FileOperations.java:80)
	at org.apache.accumulo.test.TestIngest.ingest(TestIngest.java:223)
	at org.apache.accumulo.test.functional.BulkIT.runTest(BulkIT.java:63)
	at org.apache.accumulo.test.functional.SslIT.bulk(SslIT.java:54)
	at org.apache.accumulo.test.functional.SslWithClientAuthIT.bulk(SslWithClientAuthIT.java:63)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-01 02:31:23.658,,,no_permission,,,,,,,,,,,,371218,,,Sat Feb 01 02:31:34 UTC 2014,,,,,,0|i1rz6v:,371521,,,,,,,,"01/Feb/14 02:31;jira-bot;Commit 1e7f883c198d4424153c02b5b1536dc6d664f2c3 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1e7f883 ]

ACCUMULO-2306 - Adding prefix for the files
","01/Feb/14 02:31;jira-bot;Commit 1e7f883c198d4424153c02b5b1536dc6d664f2c3 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1e7f883 ]

ACCUMULO-2306 - Adding prefix for the files
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ExamplesIT should be chunked into several smaller tests,ACCUMULO-2298,12692414,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,31/Jan/14 00:23,01/Feb/14 02:31,13/Mar/19 22:01,01/Feb/14 02:31,,,,,,,,1.6.0,,,test,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-31 18:43:36.324,,,no_permission,,,,,,,,,,,,371009,,,Sat Feb 01 02:31:34 UTC 2014,,,,,,0|i1rxx3:,371314,,,,,,,,31/Jan/14 18:43;ecn;Why?,"31/Jan/14 19:05;elserj;Looks like the ExamplesIT has a single test case, but it tests multiple, non-related things. It seems like it would make debugging those tests much easier in their own methods instead of one monolithic method and log messages to break up the test.",31/Jan/14 19:13;vines;What [~elserj] said. It makes no sense to test all of them together.,"01/Feb/14 02:31;jira-bot;Commit be152d8505e24591c3dac484787b2dfc9f6c0058 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=be152d8 ]

ACCUMULO-2298 chunking up ExamplesIT
","01/Feb/14 02:31;jira-bot;Commit be152d8505e24591c3dac484787b2dfc9f6c0058 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=be152d8 ]

ACCUMULO-2298 chunking up ExamplesIT
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Various ITs timing too sensitive,ACCUMULO-2295,12692386,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,30/Jan/14 21:56,01/Feb/14 02:31,13/Mar/19 22:01,01/Feb/14 02:31,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"There are several ITs which have such tight timing that they routinely fail with multiple test threads but run perfectly fine when run solo. Some of these include-
# ConfigurableMajorCompactionIT.java
# BatchWriterFlushIT.java
# BulkSplitOptimizationIT.java
# ReadWriteIT.java
# SslIT.java
# StartIT.java
# TimeoutIT.java
# WriteLotsIT.java


There are some others which time out, but they already have a large timeout so I'm a bit weary to chalk them up to their timing being too tight.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-30 21:57:22.576,,,no_permission,,,,,,,,,,,,370981,,,Sat Feb 01 02:31:34 UTC 2014,,,,,,0|i1rxqv:,371286,,,,,,,,"30/Jan/14 21:57;jira-bot;Commit 2611cba3bce0b3db3a7a61af405f9c2ac8ac97c1 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2611cba ]

ACCUMULO-2295 adjusting test timeouts
","30/Jan/14 21:57;jira-bot;Commit 2611cba3bce0b3db3a7a61af405f9c2ac8ac97c1 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2611cba ]

ACCUMULO-2295 adjusting test timeouts
",30/Jan/14 22:06;bhavanki;You might want to consider integrating a timeout factor mechanism like the ones introduced in ACCUMULO-1789 and ACCUMULO-2005.,"31/Jan/14 20:31;vines;I don't think that's feasible for junit's timeout test. I could be wrong, I've done 0 research.

At the very least, that would be more applicable if the current timing settings for all the tests were in the same realm of accuracy, which is what I'm really trying to deal with right now.","31/Jan/14 20:42;vines;Found additional issues in
# GarbageCollectorIT.gcTest
# ReadWriteIT.localityGroupChange","31/Jan/14 23:44;vines;I'm also gonna throw in BloomFilterIT even though I originally lumped it in under ""it already has a large timeout so there's another issue""","01/Feb/14 02:31;jira-bot;Commit 6a88722c3bbea4f40d01b9f94ab667aa55bee8ed in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6a88722 ]

ACCUMULO-2295 IT timing adjustments
","01/Feb/14 02:31;jira-bot;Commit 6a88722c3bbea4f40d01b9f94ab667aa55bee8ed in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6a88722 ]

ACCUMULO-2295 IT timing adjustments
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CloudStone Benchmarks do not respect ACCUMULO_CONF_DIR,ACCUMULO-2220,12689571,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,mdrob,mdrob,17/Jan/14 21:42,30/Jan/14 23:29,13/Mar/19 22:01,30/Jan/14 23:29,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,test,,,,,,0,newbie,,,,"{noformat}
Traceback (most recent call last):
  File ""/usr/lib/accumulo-1.4.4/test/system/bench/lib/IngestBenchmark.py"", line 59, in runTest
    for i, s in enumerate(slaveNames()):
  File ""/usr/lib/accumulo-1.4.4/test/system/bench/lib/slaves.py"", line 27, in slaveNames
    return [s.strip() for s in open(accumulo('conf', 'slaves'))]
IOError: [Errno 2] No such file or directory: '/usr/lib/accumulo/conf/slaves'

----------------------------------------------------------------------
Ran 1 test in 7.580s

FAILED (errors=1)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-30 23:28:01.324,,,no_permission,,,,,,,,,,,,368538,,,Thu Jan 30 23:29:21 UTC 2014,,,,,,0|i1rirz:,368842,,,,,,,,"30/Jan/14 23:28;jira-bot;Commit 4d8977c891017701d4ff2873439fc884b4a4ea57 in branch refs/heads/1.4.5-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4d8977c ]

ACCUMULO-2220 supporting ACCUMULO_CONF_DIR in test/system/bench
","30/Jan/14 23:28;jira-bot;Commit 4d8977c891017701d4ff2873439fc884b4a4ea57 in branch refs/heads/1.5.1-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4d8977c ]

ACCUMULO-2220 supporting ACCUMULO_CONF_DIR in test/system/bench
","30/Jan/14 23:29;jira-bot;Commit 4d8977c891017701d4ff2873439fc884b4a4ea57 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4d8977c ]

ACCUMULO-2220 supporting ACCUMULO_CONF_DIR in test/system/bench
","30/Jan/14 23:29;jira-bot;Commit 4d8977c891017701d4ff2873439fc884b4a4ea57 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4d8977c ]

ACCUMULO-2220 supporting ACCUMULO_CONF_DIR in test/system/bench
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Correct Tables.getNamespace to clarify namespace name or ID,ACCUMULO-2289,12692330,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,30/Jan/14 17:22,30/Jan/14 22:01,13/Mar/19 22:01,30/Jan/14 22:01,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Tables.getNamespace is not clear on what it returned, whether namespace id or name. This needs to be corrected.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-30 21:57:20.1,,,no_permission,,,,,,,,,,,,370925,,,Thu Jan 30 21:57:55 UTC 2014,,,,,,0|i1rxef:,371230,,,,,,,,"30/Jan/14 21:57;jira-bot;Commit 939a4f9d2cc41e7734bfbc1da0180b394e142014 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=939a4f9 ]

ACCUMULO-2289 Correcting Tables.getNamespace to Tables.getNamespaceId
","30/Jan/14 21:57;jira-bot;Commit 939a4f9d2cc41e7734bfbc1da0180b394e142014 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=939a4f9 ]

ACCUMULO-2289 Correcting Tables.getNamespace to Tables.getNamespaceId
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
randomwalk AlterTable uses table name instead of ID,ACCUMULO-2096,12686429,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,elserj,elserj,26/Dec/13 16:51,30/Jan/14 22:00,13/Mar/19 22:01,30/Jan/14 22:00,,,,,,,,1.6.0,,,test,,,,,,0,16_qa_bug,,,,RW test uses the table name instead of table ID at org.apache.accumulo.test.randomwalk.security.AlterTable.visit(AlterTable.java:40),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-26 21:39:26.996,,,no_permission,,,,,,,,,,,,365419,,,Thu Jan 30 22:00:48 UTC 2014,,,,,,0|i1qzh3:,365721,,,,,,,,"26/Dec/13 21:39;jira-bot;Commit 9f59c0022777fc86d0b269d064bcc898b27c9b23 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9f59c00 ]

ACCUMULO-2096 Clean up the security RW tests.

Ensure that tableID is used where necessary and ensure that the correct SecurityErrorCode is used when using the
internal method calls (that throw ThriftSecurityException and not AccumuloSecurityException) so the assertions work
correctly.
","26/Dec/13 21:48;jira-bot;Commit 9f59c0022777fc86d0b269d064bcc898b27c9b23 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9f59c00 ]

ACCUMULO-2096 Clean up the security RW tests.

Ensure that tableID is used where necessary and ensure that the correct SecurityErrorCode is used when using the
internal method calls (that throw ThriftSecurityException and not AccumuloSecurityException) so the assertions work
correctly.
","31/Dec/13 01:51;ctubbsii;Renamed subject, because I don't know what ""RW"" is at first glance, and this is an unnecessary barrier to addressing the issue.","30/Jan/14 16:19;vines;I disagree with this ticket. The state information for the security randomwalk was pegged on tablenames to prevent race conditions with the tableid mapping from updating in zookeeper on the walker's side. The only real conditions where this could be considered an issue is renameTable, but that updates the table information","30/Jan/14 21:57;jira-bot;Commit 90e1f22a1833baad0f986f2100c6ecb5662a8a8f in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=90e1f22 ]

ACCUMULO-1479 ACCUMULO-2086 ACCUMULO-2096 refactoring namespace translation out of security operations to fix security randomwalk
","30/Jan/14 21:57;jira-bot;Commit 3d8a1161e88b613e48b23e16cca12699d0ba0bf7 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3d8a116 ]

ACCUMULO-2086 ACCUMULO-2096 ACCUMULO-2286 Some more initial namespace support
","30/Jan/14 21:57;jira-bot;Commit 90e1f22a1833baad0f986f2100c6ecb5662a8a8f in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=90e1f22 ]

ACCUMULO-1479 ACCUMULO-2086 ACCUMULO-2096 refactoring namespace translation out of security operations to fix security randomwalk
","30/Jan/14 21:57;jira-bot;Commit 3d8a1161e88b613e48b23e16cca12699d0ba0bf7 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3d8a116 ]

ACCUMULO-2086 ACCUMULO-2096 ACCUMULO-2286 Some more initial namespace support
",30/Jan/14 22:00;vines;Tests should be kosher now. Changes made in the previous commit were reverted.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE on Security Randomwalk with Namespaces,ACCUMULO-2086,12686233,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,elserj,elserj,23/Dec/13 23:32,30/Jan/14 22:00,13/Mar/19 22:01,30/Jan/14 22:00,,,,,,,,1.6.0,,,test,,,,,,0,16_qa_bug,,,,"{noformat}
20 17:49:02,144 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Security.xml
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
	at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
	at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.accumulo.start.Main$1.run(Main.java:137)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.Exception: Error running node security.TableOp
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
	... 8 more
Caused by: java.lang.NullPointerException
	at java.lang.String.<init>(String.java:505)
	at org.apache.accumulo.core.client.impl.Tables.getNamespace(Tables.java:201)
	at org.apache.accumulo.server.security.SecurityOperation.hasNamespacePermissionForTableId(SecurityOperation.java:330)
	at org.apache.accumulo.server.security.SecurityOperation.canWrite(SecurityOperation.java:410)
	at org.apache.accumulo.test.randomwalk.security.TableOp.visit(TableOp.java:143)
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
	... 9 more
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2087,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-24 03:53:34.735,,,no_permission,,,,,,,,,,,,365206,,,Thu Jan 30 22:00:33 UTC 2014,,,,,,0|i1qy6f:,365511,,,,,,,,"24/Dec/13 03:53;jira-bot;Commit e8c9aae904380f22e55a31e3a7422ecd4597b0b0 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e8c9aae ]

ACCUMULO-2086 Use the tableID instead of the tableName where necessary.
","24/Dec/13 05:04;jira-bot;Commit 0d294ad64ed5a12c44e1c33bc5561897e3aef512 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0d294ad ]

ACCUMULO-2087 ACCUMULO-2086 Fixing formatting.
","24/Dec/13 06:20;jira-bot;Commit 0d294ad64ed5a12c44e1c33bc5561897e3aef512 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0d294ad ]

ACCUMULO-2087 ACCUMULO-2086 Fixing formatting.
",30/Jan/14 16:20;vines;Same as my comment on ACCUMULO-2096,"30/Jan/14 21:57;jira-bot;Commit 90e1f22a1833baad0f986f2100c6ecb5662a8a8f in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=90e1f22 ]

ACCUMULO-1479 ACCUMULO-2086 ACCUMULO-2096 refactoring namespace translation out of security operations to fix security randomwalk
","30/Jan/14 21:57;jira-bot;Commit 3d8a1161e88b613e48b23e16cca12699d0ba0bf7 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3d8a116 ]

ACCUMULO-2086 ACCUMULO-2096 ACCUMULO-2286 Some more initial namespace support
","30/Jan/14 21:57;jira-bot;Commit 90e1f22a1833baad0f986f2100c6ecb5662a8a8f in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=90e1f22 ]

ACCUMULO-1479 ACCUMULO-2086 ACCUMULO-2096 refactoring namespace translation out of security operations to fix security randomwalk
","30/Jan/14 21:57;jira-bot;Commit 3d8a1161e88b613e48b23e16cca12699d0ba0bf7 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3d8a116 ]

ACCUMULO-2086 ACCUMULO-2096 ACCUMULO-2286 Some more initial namespace support
",30/Jan/14 22:00;vines;Tests should be kosher now. Changes made in the previous commit were reverted.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
createnamespace option should not copy config from a table,ACCUMULO-2260,12691249,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,ctubbsii,ctubbsii,26/Jan/14 07:23,30/Jan/14 21:57,13/Mar/19 22:01,28/Jan/14 22:10,,,,,,,,1.6.0,,,shell,,,,,,0,,,,,"The shell command to create a new namespace, CreateNamespaceCommand, has an option to copy configuration from a table, as a template. This was modeled after the CreateTableCommand, which has the same feature.

If this option is available at all, it should copy from another namespace, not a table.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-28 22:10:25.938,,,no_permission,,,,,,,,,,,,369994,,,Thu Jan 30 21:57:17 UTC 2014,,,,,,0|i1rrpr:,370296,,,,,,,,"28/Jan/14 22:10;jira-bot;Commit 07d7ececf31cf123029136f028bce5eb776a19cb in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=07d7ece ]

ACCUMULO-2260 removing table copy flag from createnamespace
","28/Jan/14 22:57;jira-bot;Commit 07d7ececf31cf123029136f028bce5eb776a19cb in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=07d7ece ]

ACCUMULO-2260 removing table copy flag from createnamespace
","30/Jan/14 21:57;jira-bot;Commit f0448ffa710ce5e598c204002eabf3a91210d8e8 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f0448ff ]

ACCUMULO-2260 removing table config copy test
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cloning the metadata table fails with faulty error,ACCUMULO-2012,12684559,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,13/Dec/13 22:13,30/Jan/14 00:06,13/Mar/19 22:01,29/Jan/14 22:56,,,,,,,,1.6.0,,,client,master,,,,,0,,,,,"{code}
Failed to execute Repo, tid=5d7e9a01796a6b64
	java.lang.RuntimeException:  table deleted during clone?  srcTableId = !0
		at org.apache.accumulo.server.util.MetadataTableUtil.initializeClone(MetadataTableUtil.java:681)
		at org.apache.accumulo.server.util.MetadataTableUtil.cloneTable(MetadataTableUtil.java:783)
		at org.apache.accumulo.master.tableOps.CloneMetadata.call(CloneTable.java:119)
		at org.apache.accumulo.master.tableOps.CloneMetadata.call(CloneTable.java:97)
		at org.apache.accumulo.master.tableOps.TraceRepo.call(TraceRepo.java:54)
		at org.apache.accumulo.fate.Fate$TransactionRunner.run(Fate.java:67)
		at org.apache.accumulo.fate.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at java.lang.Thread.run(Thread.java:701)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1481,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-13 22:18:11.239,,,no_permission,,,,,,,,,,,,363631,,,Thu Jan 30 00:06:40 UTC 2014,,,,,,0|i1qohj:,363937,,,,,,,,"13/Dec/13 22:18;mdrob@cloudera.com;Is cloning the !METADATA table even allowed?



","13/Dec/13 22:24;vines;I'm uncertain. I think it should be, but at the very least this error is wonky.

Now cloning the root table, that's weird...","13/Dec/13 22:29;mdrob;Cloning the !METADATA table involves writes to the !METADATA table, to know where the new tablets are, and those changes can't be reflected in the clone. Cloning the root table might be easier, since while that also involves changes to the !METADATA table, I don't think it will necessarily propagate into changes on the original root table.","13/Dec/13 22:51;vines;It is well known that cloning doesn't take into account the in memory map, so I don't see why that should preclude the metadata table.","29/Jan/14 22:55;jira-bot;Commit d4c9ee1c529ebef80368d587db31e331d911953f in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d4c9ee1 ]

ACCUMULO-2012 Cloning accumulo.metadata works, accumulo.root will have a better error
",29/Jan/14 22:56;vines;cloning accumulo.metadata now functions. Attempts to clone accumulo.root will have a better error.,"30/Jan/14 00:06;jira-bot;Commit d4c9ee1c529ebef80368d587db31e331d911953f in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d4c9ee1 ]

ACCUMULO-2012 Cloning accumulo.metadata works, accumulo.root will have a better error
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rename client.instance.name to instance.name,ACCUMULO-2121,12687004,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,kturner,kturner,02/Jan/14 17:41,28/Jan/14 21:58,13/Mar/19 22:01,28/Jan/14 21:58,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Given discussion on ACCUMULO-1771 and ACCUMULO-2076, it seems like it would be a good idea to rename client.instance.name to instance.name in ClientConfiguration.  This should probably be done for 1.6.0 even if nothing is done for ACCUMULO-2076 for 1.6.0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2076,ACCUMULO-1771,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-28 21:58:16.909,,,no_permission,,,,,,,,,,,,365999,,,Tue Jan 28 21:58:16 UTC 2014,,,,,,0|i1r37b:,366306,,,,,,,,"28/Jan/14 21:58;jira-bot;Commit 4cdd6d51acff0d5335538dd6e209c6e9be391e1c in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cdd6d5 ]

ACCUMULO-2121 remove client. prefix from ClientConfiguration properties
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NoNodeException error in master,ACCUMULO-2154,12687886,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vickyuec,vines,vines,08/Jan/14 15:57,27/Jan/14 23:33,13/Mar/19 22:01,27/Jan/14 23:33,,,,,,,,1.6.0,,,master,,,,,,0,PatchAvailable,,,,"I have a test that brings accumulo down hard after a minute and then brings it back up again. I was running it overnight and I saw this stack trace once. Not sure if it's a problem or not though.

{code}org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /accumulo/617ee3a7-98b9-4f5f-af13-8894afe7c33c/dead/tservers/10.10.1.148:9997
	org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /accumulo/617ee3a7-98b9-4f5f-af13-8894afe7c33c/dead/tservers/10.10.1.148:9997
		at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
		at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
		at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1151)
		at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1180)
		at org.apache.accumulo.fate.zookeeper.ZooReader.getData(ZooReader.java:45)
		at org.apache.accumulo.server.master.state.DeadServerList.getList(DeadServerList.java:52)
		at org.apache.accumulo.master.MasterClientServiceHandler.getMasterStats(MasterClientServiceHandler.java:268)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
		at java.lang.reflect.Method.invoke(Method.java:597)
		at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
		at com.sun.proxy.$Proxy11.getMasterStats(Unknown Source)
		at org.apache.accumulo.core.master.thrift.MasterClientService$Processor$getMasterStats.getResult(MasterClientService.java:1414)
		at org.apache.accumulo.core.master.thrift.MasterClientService$Processor$getMasterStats.getResult(MasterClientService.java:1398)
		at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
		at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
		at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
		at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
		at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
		at java.lang.Thread.run(Thread.java:662){code}",1.6.0 sha 417902e218c566333b6ea5ac492186ae305e5e16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,17/Jan/14 09:33;vickyuec;ACCUMULO-2154.v1.patch.txt;https://issues.apache.org/jira/secure/attachment/12623614/ACCUMULO-2154.v1.patch.txt,23/Jan/14 10:45;vickyuec;ACCUMULO-2154.v2.patch.txt;https://issues.apache.org/jira/secure/attachment/12624781/ACCUMULO-2154.v2.patch.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2014-01-17 09:02:20.921,,,no_permission,,,,,,,,,,,,366893,,,Thu Jan 23 17:15:11 UTC 2014,,,,,,0|i1r8qf:,367204,,,,,,,,17/Jan/14 09:02;vickyuec;I think it's happening because DeadServerList.getList first gets the list of paths using zoo.getChildren and then iterates over them without any lock to ensure any path doesn't get deleted while the loop is running.,17/Jan/14 09:33;vickyuec;Attached patch.,"17/Jan/14 16:38;kturner;Why not catch and ignore KeeperException$NoNodeException in DeadServerList.getList()?  Seems like would only want to do this for children.  Currently getList() is only called by a single process, but if it were called by multiple processes in the future then this would be a more robust solution.","18/Jan/14 06:42;vickyuec;getList() getting called by multiple processes isn't the issue here. This exception comes happens MasterClientServiceHandler is calling getList and at the same time, one of the other 2 call sites call delete. So we do need to ensure getList() exits before delete() is called. I've made post() also synchronized so that getList() doesn't miss any dead servers that get added after zoo.getChildren() is called.
","21/Jan/14 16:11;kturner;I realize that synchronization will fix this if we assume only one process and one object in that process access this resource.  But simply catching and ignoring no-node exception will also fix the problem w/o those assumptions.   Synchronization is great when the resource being protected is private process memory, however thats not true in this case.  ZooKeeper is a cluster wide resource and its possible that any other process in the cluster could mutate zookeeper at any time.  The way I see there are at least three options to solve this problem.

 # use java synchronization with assumptions stated above
 # use zookeeper primitives for dealing with concurrency
 # use java synchronization and zookeeper  primitives for dealing with concurrency

I am in favor of #2.   And its also very simple in this case, just ignore NoNodeException because it indicates the node was deleted after the call to getChildren() was made.   
 
bq.  I've made post() also synchronized so that getList() doesn't miss any dead servers that get added after zoo.getChildren() is called.

It will still miss those servers.  When synchronized, If one thread is in getList() then another thread calling post() will block.   Detecting changes after getChildren is called is not needed, just need a consistent snapshot at a point in time.  It could be achieved by checking getChildren in a loop and waiting for it stabilize.   But the data could still  be outdated by other operations immediately after getList() returns, so the code still has to treat it as a snapshot.   Anything more would require some sort of transaction semantics across method calls, which is not needed.  ",22/Jan/14 18:44;vickyuec;Thanks for the explanation [~kturner]. I was under the impression that only master accesses the dead TServers znode. But if that's not the case what you said makes sense. I'll submit another patch that ignores the NoNodeException.,"22/Jan/14 19:05;kturner;bq.  I was under the impression that only master accesses the dead TServers znode.

I think that assumption may be correct (not 100% on this) for now.  I was just thinking that using zookeeper methods for dealing with concurrency will make the code more resilient to change in the future.  Its difficult to test the assumption that only the master modifies the znode and prevent future regressions.",23/Jan/14 10:45;vickyuec;Attached patch where this exception is ignored.,"23/Jan/14 17:13;jira-bot;Commit ecdd8528ddf0108919ec48dc545e765c2c3aa364 in branch refs/heads/1.6.0-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ecdd852 ]

ACCUMULO-2154 Ignore NoNodeException while getting DeadServerList

Signed-off-by: Keith Turner <kturner@apache.org>
","23/Jan/14 17:15;jira-bot;Commit ecdd8528ddf0108919ec48dc545e765c2c3aa364 in branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ecdd852 ]

ACCUMULO-2154 Ignore NoNodeException while getting DeadServerList

Signed-off-by: Keith Turner <kturner@apache.org>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Do not use absolute paths when comparing files,ACCUMULO-2173,12688319,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,10/Jan/14 20:10,27/Jan/14 23:33,13/Mar/19 22:01,27/Jan/14 23:33,,,,,,,,1.6.0,,,,,,,,,0,,,,,I noticed while looking into ACCUMULO-2172 that log recovery compares minc start events to tablets files using absolute paths.  This could cause problems for upgrade (walogs will have relative paths) and in the case where configuration is changed.   Also saw this being done in ACCUMULO-2110.  Need to look for this problem throughout code.   ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-18 01:06:05.156,,,no_permission,,,,,,,,,,,,367338,,,Mon Jan 20 17:31:07 UTC 2014,,,,,,0|i1rbgn:,367647,,,,,,,,"18/Jan/14 01:06;jira-bot;Commit 71b2baec7dd3df7fc8d3b2e1a6e57c0bb9c7a258 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=71b2bae ]

ACCUMULO-2173 use suffixes when comparing paths
","20/Jan/14 17:31;jira-bot;Commit 71b2baec7dd3df7fc8d3b2e1a6e57c0bb9c7a258 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=71b2bae ]

ACCUMULO-2173 use suffixes when comparing paths
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[RW] Error in Security.Validate,ACCUMULO-2183,12688415,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,11/Jan/14 23:08,24/Jan/14 17:10,13/Mar/19 22:01,23/Jan/14 18:08,,,,,,,,1.5.1,1.6.0,,test,,,,,,0,,,,,"{noformat}
11 12:02:58,543 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Security.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.start.Main$1.run(Main.java:103)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.Exception: Error running node security.Validate
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloException: Unexpected exception!
        at org.apache.accumulo.test.randomwalk.security.Validate.validate(Validate.java:117)
        at org.apache.accumulo.test.randomwalk.security.Validate.visit(Validate.java:37)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 9 more
Caused by: ThriftSecurityException(user:table_hostname_domain, code:USER_DOESNT_EXIST)
        at org.apache.accumulo.server.security.SecurityOperation.targetUserExists(SecurityOperation.java:277)
        at org.apache.accumulo.server.security.SecurityOperation.getUserAuthorizations(SecurityOperation.java:197)
        at org.apache.accumulo.server.security.SecurityOperation.getUserAuthorizations(SecurityOperation.java:214)
        at org.apache.accumulo.test.randomwalk.security.Validate.validate(Validate.java:108)
        ... 11 more
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-23 18:05:42.737,,,no_permission,,,,,,,,,,,,367434,,,Fri Jan 24 17:10:36 UTC 2014,,,,,,0|i1rc1r:,367743,,,,,,,,"23/Jan/14 18:05;jira-bot;Commit 956c32f8fa258ea0b87f267675cdcec91e16dce1 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=956c32f ]

ACCUMULO-2183 Look for the thrift SecurityErrorCode since this is coming from the ThriftSecurityException.
","23/Jan/14 18:05;jira-bot;Commit 956c32f8fa258ea0b87f267675cdcec91e16dce1 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=956c32f ]

ACCUMULO-2183 Look for the thrift SecurityErrorCode since this is coming from the ThriftSecurityException.
","23/Jan/14 18:41;ctubbsii;So, I think there's been a few cases in the past where the wrong enum is checked in the equals method. Because equals takes an Object as a parameter and there are two different SecurityErrorCode classes, it's very prone to happening a lot. I've tried to replace these if statements with switch statements, to avoid compile errors. I recommend checking these enums this way.","23/Jan/14 18:46;elserj;This is what I had mentioned I wanted to ask you about in IRC, btw.

It appears that there's a clean break of the client.impl.thrift.SecurityErrorCode and the client.SecurityErrorCode in ThriftSecurityException and AccumuloSecurityException respectively. Are you saying that this isn't the case or, maybe, is just happenstance?","23/Jan/14 21:57;ctubbsii;I must've missed the IRC conversation.

I think some effort was made to stop returning the thrift object in the getter method for the code, as that is public API. Is that what you mean by ""clean break""? There's still somewhat of a link... because we need to translate between the two when we construct the public API exception from the RPC/thrift exception.

I'm not saying that there's a bug or anything here... I'm just saying that the code is very confusing and has been prone to errors in the past due to the history of the RPC/public API translation and the similarity in class names. Since there's no compiler-check to ensure correctness with equals(Object), but there is with switch statements, I'm just saying it might be a good idea to use switch statements over equals for enum comparisons to avoid errors and ensure the compiler checks for correctness.","23/Jan/14 22:20;elserj;bq. I think some effort was made to stop returning the thrift object in the getter method for the code, as that is public API. Is that what you mean by ""clean break""?

No, just that client.impl.thrift.SecurityErrorCode is only used by ThriftSecurityException and client.SecurityErrorCode is only used by AccumuloSecurityException. 

One of the security randomwalk classes extends some of the internal security/authentication classes which is where that ThriftSecurityException comes from. A follow on ticket to rework that class (WalkingSecurity) would be best IMO. Let me know, and I can make one if you don't.","23/Jan/14 23:11;ctubbsii;Another suggestion was to use == for enum equality checks instead of .equals, because that also gives a compile-time type check.","24/Jan/14 17:10;jira-bot;Commit 1f96266cb249380a9a378ec1fdac84171d2c7465 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1f96266 ]

ACCUMULO-2183 Remove the .equals in favor of an equality check that enforces compile-time type checking.
","24/Jan/14 17:10;jira-bot;Commit 1f96266cb249380a9a378ec1fdac84171d2c7465 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1f96266 ]

ACCUMULO-2183 Remove the .equals in favor of an equality check that enforces compile-time type checking.
","24/Jan/14 17:10;jira-bot;Commit 1f96266cb249380a9a378ec1fdac84171d2c7465 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1f96266 ]

ACCUMULO-2183 Remove the .equals in favor of an equality check that enforces compile-time type checking.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bump maven plugin versions due to failures building maven site,ACCUMULO-2245,12690846,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,23/Jan/14 18:51,24/Jan/14 16:12,13/Mar/19 22:01,24/Jan/14 16:12,,,,,,,,1.5.1,1.6.0,,build,,,,,,0,,,,,"Went to run findbugs and generate the maven site, and got a few errors in the process. Looks like the general solution is to increase the version of a few plugins to make things happy again:

maven-site-plugin:3.2->3.3 (version defined in apache-13)
maven-project-info-reports-plugin:2.6->2.7",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-24 16:11:48.201,,,no_permission,,,,,,,,,,,,369585,,,Fri Jan 24 16:11:50 UTC 2014,,,,,,0|i1rp8f:,369890,,,,,,,,"24/Jan/14 16:11;jira-bot;Commit da2b79bc47eae993413aca9e2f23611948d79d1d in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=da2b79b ]

ACCUMULO-2245 Bump some plugin versions to get the maven site building again with Maven 3.1.1.
","24/Jan/14 16:11;jira-bot;Commit da2b79bc47eae993413aca9e2f23611948d79d1d in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=da2b79b ]

ACCUMULO-2245 Bump some plugin versions to get the maven site building again with Maven 3.1.1.
","24/Jan/14 16:11;jira-bot;Commit da2b79bc47eae993413aca9e2f23611948d79d1d in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=da2b79b ]

ACCUMULO-2245 Bump some plugin versions to get the maven site building again with Maven 3.1.1.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Warning message in Fate.transitionToFailed should be logged in the beginning of the method,ACCUMULO-2250,12690995,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vickyuec,vickyuec,vickyuec,24/Jan/14 09:30,24/Jan/14 15:41,13/Mar/19 22:01,24/Jan/14 15:35,1.5.0,,,,,,,1.5.1,,,fate,,,,,,0,,,,,See ACCUMULO-1850. The method got stuck at store.setProperty and we couldn't get any more information from logs.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,24/Jan/14 09:40;vickyuec;ACCUMULO-2250.v1.patch.txt;https://issues.apache.org/jira/secure/attachment/12625021/ACCUMULO-2250.v1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-01-24 15:34:03.155,,,no_permission,,,,,,,,,,,,369738,,,Fri Jan 24 15:40:30 UTC 2014,,,,,,0|i1rq4v:,370039,,,,,,,,24/Jan/14 09:40;vickyuec;Attached patch.,"24/Jan/14 15:34;jira-bot;Commit 930a6b84f84c87809bd6af0748358393b75b681f in branch refs/heads/1.6.0-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=930a6b8 ]

ACCUMULO-2250 Move error logging in Fate.transitionToFailed to beginning of method

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","24/Jan/14 15:34;jira-bot;Commit 930a6b84f84c87809bd6af0748358393b75b681f in branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=930a6b8 ]

ACCUMULO-2250 Move error logging in Fate.transitionToFailed to beginning of method

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","24/Jan/14 15:38;jira-bot;Commit b85c8b5c1fcd05c79ac777fc9f2e4085dcbb1b71 in branch refs/heads/1.5.1-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b85c8b5 ]

ACCUMULO-2250 Move error logging in Fate.transitionToFailed to beginning of method

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","24/Jan/14 15:40;jira-bot;Commit b85c8b5c1fcd05c79ac777fc9f2e4085dcbb1b71 in branch refs/heads/1.6.0-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b85c8b5 ]

ACCUMULO-2250 Move error logging in Fate.transitionToFailed to beginning of method

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","24/Jan/14 15:40;jira-bot;Commit b85c8b5c1fcd05c79ac777fc9f2e4085dcbb1b71 in branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b85c8b5 ]

ACCUMULO-2250 Move error logging in Fate.transitionToFailed to beginning of method

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConfigurableMacIT tests should each use their own dirs,ACCUMULO-2196,12688929,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vickyuec,kturner,kturner,15/Jan/14 03:36,24/Jan/14 02:15,13/Mar/19 22:01,23/Jan/14 23:47,,,,,,,,1.6.0,,,,,,,,,0,PatchAvailable,,,,"GarbageCollectorIT has multiple test methods.  MAC is started and stopped for each test method.  All of the test methods use the same dir for MAC and clear the dir.  So if one methods fails, then output is lost.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20/Jan/14 08:45;vickyuec;ACCUMULO-2196.v1.patch.txt;https://issues.apache.org/jira/secure/attachment/12623923/ACCUMULO-2196.v1.patch.txt,23/Jan/14 23:35;vickyuec;ACCUMULO-2196.v2.patch.txt;https://issues.apache.org/jira/secure/attachment/12624951/ACCUMULO-2196.v2.patch.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2014-01-20 08:45:53.222,,,no_permission,,,,,,,,,,,,367896,,,Fri Jan 24 02:15:42 UTC 2014,,,,,,0|i1revb:,368203,,,,,,,,20/Jan/14 08:45;vickyuec;Attached patch. Verified that all tests in GCIT used their own dirs.,"23/Jan/14 21:13;ctubbsii;I'd rather not have a special case just for the GCIT. It'd be better if the per-test directory was done in the base class, so we don't have the same issue in the future, if we create additional methods in other ConfigurableMacITs.",23/Jan/14 22:31;vickyuec;[~ctubbsii] Using it for all tests definitely makes sense. I wasn't aware of its impact since the jira mentioned only GCIT. I'll repurpose this jira for the base class and submit another patch.,23/Jan/14 23:20;ctubbsii;[~vickyuec]: Much appreciated. Thank you.,23/Jan/14 23:35;vickyuec;Attached patch where all tests use their own dir.,23/Jan/14 23:36;kturner;I am  adding test to VolumeIT and ran into this same issue.,"23/Jan/14 23:45;jira-bot;Commit e36ac378d13535b869336c0e6737274d255c72df in branch refs/heads/1.6.0-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e36ac37 ]

ACCUMULO-2196 ConfigurableMacIT tests should each use their own dirs

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
",23/Jan/14 23:47;ctubbsii;Tested and applied.,"24/Jan/14 02:15;jira-bot;Commit e36ac378d13535b869336c0e6737274d255c72df in branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e36ac37 ]

ACCUMULO-2196 ConfigurableMacIT tests should each use their own dirs

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
close consistency check failure,ACCUMULO-2206,12689276,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,16/Jan/14 15:59,22/Jan/14 19:47,13/Mar/19 22:01,22/Jan/14 17:06,,,,,,,,1.6.0,,,tserver,,,,,,0,16_qa_bug,,,,"while running the continuous ingest, with agitation, there are multiple close-consistency check failures in the logs:

{noformat}
Failed to do close consistency check for tablet 3;2de232;2dc237
	java.lang.RuntimeException: Closed tablet 3;2de232;2dc237 has walog entries in accumulo.metadata [3;2de232; hdfs://namenode:9000/home/user/accumulo/wal/host5+46372/c0260a2a-487c-47a6-991d-50007e357a63 (36)]
		at org.apache.accumulo.tserver.Tablet.closeConsistencyCheck(Tablet.java:2779)
		at org.apache.accumulo.tserver.Tablet.completeClose(Tablet.java:2726)
		at org.apache.accumulo.tserver.Tablet.close(Tablet.java:2604)
		at org.apache.accumulo.tserver.TabletServer$UnloadTabletHandler.run(TabletServer.java:2750)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
{noformat}

Running verification to see if there was any data loss.",10-node test cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-17 18:03:20.011,,,no_permission,,,,,,,,,,,,368243,,,Wed Jan 22 17:05:40 UTC 2014,,,,,,0|i1rgyn:,368548,,,,,,,,16/Jan/14 17:09;ecn;Verification ran cleanly.,"16/Jan/14 18:20;ecn;The first occurrence was was on node3 (found by scanning the monitor log):

{noformat}
2014-01-16 13:10:33,451 [tserver.Tablet] ERROR: tserver:node3 Closed tablet 3;2de232;2dc237 has walog entries in accumulo.metadata [3;2de232; hdfs://node2:9000/home/user/accumulo/wal/node5+46372/c0260a2a-487c-47a6-991d-50007e357a63 (36)]
{noformat}

This tablet was loaded at 13:10:18:
{noformat}
2014-01-16 13:10:18,795 [master.EventCoordinator] INFO : tablet 3;2de232;2dc237 was loaded on node3:34029
{noformat}

When the tablet was loaded, the WAL was used for recovery, with no mutations applied.

The !METADATA table WAL had been deleted, so I could not verify the mutations.  The metadata tablet !0;~< and the root table +r were online and did not have any recovery run on them.

Re-running the test with the trash on.
","16/Jan/14 19:01;ecn;bq. used for recovery, with no mutations applied

I think I know what's going on:

 # load tablet, recover but there are no mutations
 # no mutations means the tablet does not minor compact
 # the walog reference stays in memory
 # if there are no updates made, and the tablet is unloaded, it will unexpectedly have a WAL","17/Jan/14 18:03;jira-bot;Commit 8ead5c64d21e03d1a674c151ce624807791c3d13 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8ead5c6 ]

ACCUMULO-2206 add a test for a theory about recovering a tablet that has no mutations
","17/Jan/14 18:06;jira-bot;Commit 8ead5c64d21e03d1a674c151ce624807791c3d13 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8ead5c6 ]

ACCUMULO-2206 add a test for a theory about recovering a tablet that has no mutations
",17/Jan/14 18:55;vines;Is it possible that this exists in 1.5 as well?,22/Jan/14 16:31;ecn;This happened 5x last night.  In each case a recovery was run and no mutations were applied.  ,"22/Jan/14 17:05;jira-bot;Commit e57795cc2cfe37e14ec8f29f02e35642feeeb888 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e57795c ]

ACCUMULO-2206 remove the LogEntry properly when no mutations are applied to a tablet
","22/Jan/14 17:05;jira-bot;Commit e57795cc2cfe37e14ec8f29f02e35642feeeb888 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e57795c ]

ACCUMULO-2206 remove the LogEntry properly when no mutations are applied to a tablet
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AccumuloInputFormat cannot fetch empty column family,ACCUMULO-1661,12664926,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vickyuec,billie.rinaldi,billie.rinaldi,21/Aug/13 22:25,22/Jan/14 19:04,13/Mar/19 22:01,22/Jan/14 19:04,1.4.3,1.5.0,,,,,,1.5.1,1.6.0,,client,,,,,,0,,,,,"The following fails:
{code:java}
Job job = new Job();
HashSet<Pair<Text,Text>> cols = new HashSet<Pair<Text,Text>>();
cols.add(new Pair<Text,Text>(new Text(""""), null));
AccumuloInputFormat.fetchColumns(job, cols);
Set<Pair<Text,Text>> setCols = AccumuloInputFormat.getFetchedColumns(job);
assertEquals(cols.size(), setCols.size());
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,22/Jan/14 18:39;vickyuec;ACCUMULO-1661.1.5.1-SNAPSHOT.patch.txt;https://issues.apache.org/jira/secure/attachment/12624391/ACCUMULO-1661.1.5.1-SNAPSHOT.patch.txt,21/Jan/14 10:28;vickyuec;ACCUMULO-1661.v1.patch.txt;https://issues.apache.org/jira/secure/attachment/12624102/ACCUMULO-1661.v1.patch.txt,21/Jan/14 18:44;vickyuec;ACCUMULO-1661.v2.patch.txt;https://issues.apache.org/jira/secure/attachment/12624174/ACCUMULO-1661.v2.patch.txt,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2013-09-05 22:26:30.015,,,no_permission,,,,,,,,,,,,344869,,,Wed Jan 22 19:03:29 UTC 2014,,,,,,0|i1ngzz:,345170,,,,,,,,05/Sep/13 22:26;medined;Can you include the import statements? I am trying to run this test but the Job is not the right object for the fetchColumns call.,"30/Oct/13 22:15;vines;The issue is in Configuration.getStringCollection. That utilizes a tokenizer to split on commas. Unfortunately, when there's an empty COLF, that gets base 64ed to an empty string, which causes the tokenizer to interpret it not as a value but as cruft. Configuration.getStrings has the same behavior, so the only way around it is to not rely on the Configuration helpers, do the String transformations ourselves. Or, we can go a slightly hacky route and just manually check if that property is an empty String (vs. null) to know it's there. However, cases where the empty string is among other options would still probably get lost.","20/Jan/14 07:46;vickyuec;Newbie question: Do ""cols"" and ""setCols"" have to be identical? Javadoc for fetchColumns says ""An empty set is the default and is equivalent to scanning the all columns."" So can we put a condition that if ColumnFamily == new Text(""""), it implies that all CFs are selected? Also, in that case we should add an argument checker that ""cols"" has a size of 1 only.","20/Jan/14 15:18;billie.rinaldi;No, fetching """" would mean fetching all key/value pairs that have an empty column family -- there is one family in the set of families that is being fetched.",21/Jan/14 10:28;vickyuec;Attached patch. Splitting the string inside InputConfigurator.getFetchedColumns explicitly to include empty strings.,"21/Jan/14 16:24;kturner;Would be nice to add a few more test cases.  Does the following cover all the cases of empty fam and qual?

{noformat}
    cols.add(new Pair<Text,Text>(new Text(""""), null));
    cols.add(new Pair<Text,Text>(new Text(""foo""), new Text(""bar"")));
    cols.add(new Pair<Text,Text>(new Text(""""), new Text(""bar"")));
    cols.add(new Pair<Text,Text>(new Text(""""), new Text("""")));
    cols.add(new Pair<Text,Text>(new Text(""foo""), new Text("""")));
{noformat}",21/Jan/14 18:44;vickyuec;Added more cf:cq combinations and verified empty strings are handled correctly.,"22/Jan/14 15:59;ecn;Thanks Vikram.  Can you provide the patch against 1.5.1-SNAPSHOT so I can patch forward from there?
",22/Jan/14 18:39;vickyuec;Attached patch against 1.5.1-SNAPSHOT branch.,"22/Jan/14 19:03;jira-bot;Commit 13eb19c2b92180bc4752d75dd74b76d036eb38e2 in branch refs/heads/1.5.1-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=13eb19c ]

ACCUMULO-1661 Handle empty column family correctly for AccumuloInputFormat

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","22/Jan/14 19:03;jira-bot;Commit 13eb19c2b92180bc4752d75dd74b76d036eb38e2 in branch refs/heads/1.6.0-SNAPSHOT from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=13eb19c ]

ACCUMULO-1661 Handle empty column family correctly for AccumuloInputFormat

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","22/Jan/14 19:03;jira-bot;Commit 13eb19c2b92180bc4752d75dd74b76d036eb38e2 in branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=13eb19c ]

ACCUMULO-1661 Handle empty column family correctly for AccumuloInputFormat

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Can't run offline CI verification,ACCUMULO-2230,12689947,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,busbey,elserj,elserj,21/Jan/14 04:58,21/Jan/14 18:35,13/Mar/19 22:01,21/Jan/14 18:34,1.5.0,,,,,,,1.5.1,1.6.0,,test,,,,,,0,,,,,"If I try to run offline mapreduce verification, I'm told that my ci table is online and I can't scan it in offline mode.

{noformat}
Exception in thread ""main"" java.io.IOException: org.apache.accumulo.core.client.AccumuloException: Table is online ci(6f) cannot scan table in offline mode
	at org.apache.accumulo.core.client.mapreduce.InputFormatBase.getSplits(InputFormatBase.java:868)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:491)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:508)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:392)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1268)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1265)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1265)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1286)
	at org.apache.accumulo.test.continuous.ContinuousVerify.run(ContinuousVerify.java:223)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.accumulo.test.continuous.ContinuousVerify.main(ContinuousVerify.java:239)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
Caused by: org.apache.accumulo.core.client.AccumuloException: Table is online ci(6f) cannot scan table in offline mode
	at org.apache.accumulo.core.client.mapreduce.InputFormatBase.binOfflineTable(InputFormatBase.java:712)
	at org.apache.accumulo.core.client.mapreduce.InputFormatBase.getSplits(InputFormatBase.java:841)
	... 18 more
{noformat}

If I take the table offline, I get an error that the table is offline

{noformat}
Exception in thread ""main"" java.io.IOException: org.apache.accumulo.core.client.TableOfflineException: Table ci (6f) is offline
	at org.apache.accumulo.test.continuous.ContinuousVerify.run(ContinuousVerify.java:207)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.accumulo.test.continuous.ContinuousVerify.main(ContinuousVerify.java:239)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
Caused by: org.apache.accumulo.core.client.TableOfflineException: Table ci (6f) is offline
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.splitRangeByTablets(TableOperationsImpl.java:1050)
	at org.apache.accumulo.test.continuous.ContinuousVerify.run(ContinuousVerify.java:203)
	... 7 more
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,21/Jan/14 06:20;busbey;ACCUMULO-2230.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12624083/ACCUMULO-2230.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-01-21 06:20:52.174,,,no_permission,,,,,,,,,,,,368913,,,Tue Jan 21 18:34:50 UTC 2014,,,,,,0|i1rl3b:,369217,,,,,,,,"21/Jan/14 06:20;busbey;I don't have a 1.5.1-SNAP cluster handy to test this patch on yet.

Looks like the conversion of commandline parsing missed setting the verification job to run on the created clone.","21/Jan/14 06:21;busbey;Once someone (possibly future me) can verify this update on a 1.5.1-SNAP install, I'll commit. Or whomever tests can feel free to push.","21/Jan/14 17:16;elserj;At a glance, this looks like it should also not work with 1.4.5. TableOperations.splitRangeByTablets will throw an exception if the table is offline.

I think pulling ranges from the online variant of the table but then reading from the offline table was intentional.","21/Jan/14 17:30;busbey;1.4.5-SNAPSHOT works as expected currently (I've only been doing offline verification, and I've done several over the last two weeks)

I'll take another crack at fixing 1.5.1. Maybe we don't need to set ranges at all in offline mode?","21/Jan/14 17:35;elserj;I got it to work by just using the original table name instead of the clone for splitRangeByTablets. I think that's fine now.

Sadly, I ran into another issue. Currently trying to figure out why Accumulo didn't read my instance.dfs.dir from my accumulo-site.xml. Tracing through how that's getting pulled out. My hunch is that ACCUMULO_CONF_DIR isn't added to the classpath (or the Configuration).","21/Jan/14 17:43;busbey;Ah, you're right. that's what [1.4.5-SNAP does as well|https://github.com/apache/accumulo/blob/1.4.5-SNAPSHOT/src/server/src/main/java/org/apache/accumulo/server/test/continuous/ContinuousVerify.java#L193]. (though probably we should just take the cloned table offline after getting split points.)","21/Jan/14 17:46;elserj;bq. (though probably we should just take the cloned table offline after getting split points.)

Agreed. It's certainly a bit more straightforward to look at if we do everything on that cloned table.","21/Jan/14 18:25;jira-bot;Commit a43848849e78aa9bc6edb5d6d87e2a285d8fccf2 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a438488 ]

ACCUMULO-2230 Make sure offline scan uses the cloned table.
","21/Jan/14 18:25;jira-bot;Commit a43848849e78aa9bc6edb5d6d87e2a285d8fccf2 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a438488 ]

ACCUMULO-2230 Make sure offline scan uses the cloned table.
","21/Jan/14 18:25;jira-bot;Commit a43848849e78aa9bc6edb5d6d87e2a285d8fccf2 in branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a438488 ]

ACCUMULO-2230 Make sure offline scan uses the cloned table.
",21/Jan/14 18:34;busbey;Filed ACCUMULO-2233 to fix the range generation in all impacted versions,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
missing init.d scripts,ACCUMULO-1983,12683259,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,mberman,mberman,07/Dec/13 06:21,21/Jan/14 03:23,13/Mar/19 22:01,11/Jan/14 03:32,,,,,,,,1.6.0,,,,,,,,,0,,,,,"The assembly tarball includes scripts to install init.d scripts, like stand-alone-init.sh and tserver-only-init.sh.  They expect to find the scripts to copy over in files like scripts/init.d/accumulo-tserver.  It appears the scripts/init.d directory and its contents are no longer in the assembly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-11 00:54:12.943,,,no_permission,,,,,,,,,,,,362511,,,Tue Jan 21 03:23:51 UTC 2014,,,,,,0|i1qhkn:,362805,,,,,,,,11/Jan/14 00:54;elserj;So it looks like the init.d scripts got moved completely out of assemble/scripts and are now a part of each module (see ACCUMULO-210). I could probably do a relative-path copy -- I'm not sure of any better way to do this because they're not a part of any other artifact. Perhaps a relative-path copy in the assemble module is sufficient for 1.6.0.,"11/Jan/14 02:17;jira-bot;Commit 3ab5c3ee2fa0d60480d27e027ce864dfcfbed10e in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3ab5c3e ]

ACCUMULO-1983 Lift init.d scripts out of modules into tarball

With the init.d scripts being moved from the assemble module to the
server corresponding server module which the init.d script starts,
the other assemble/scripts/*.sh scripts reference non-existent files
in the tarball assembly.
","11/Jan/14 02:17;jira-bot;Commit 3ab5c3ee2fa0d60480d27e027ce864dfcfbed10e in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3ab5c3e ]

ACCUMULO-1983 Lift init.d scripts out of modules into tarball

With the init.d scripts being moved from the assemble module to the
server corresponding server module which the init.d script starts,
the other assemble/scripts/*.sh scripts reference non-existent files
in the tarball assembly.
","11/Jan/14 03:32;elserj;Best as I can tell right now, I didn't inadvertently break anything else :)","21/Jan/14 01:03;mberman;I think if we want to keep the init.d scripts with their corresponding modules, the maveny way to do it would be to declare the init.d script as an artifact of each module (of type ""init.d"" or something), and then declare them as dependencies of the packager, which could then use the copy-dependencies goal to get them into the assembly.  It's definitely more lines of pom, but it would be more portable and less sensitive to module rearrangements in the future.  Is there any reason _not_ to do this?  If people think it's a good idea, I'm happy to take care of it in 1.7.","21/Jan/14 03:10;elserj;Feel free to make a ticket for it! We should have any discussion on that ticket, anyways.",21/Jan/14 03:23;mberman;Opened ACCUMULO-2229,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rename DefaultKeyEncryptionStrategy to something more descriptive,ACCUMULO-2209,12689294,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,16/Jan/14 17:19,17/Jan/14 15:39,13/Mar/19 22:01,16/Jan/14 22:44,,,,,,,,1.6.0,,,client,,,,,,0,,,,,"DefaultKeyEncryptionStrategy is used in several places, but for most needs is probably inferior to CachedHdfsSecretKeyEncryptionStrategy (or whatever it is). We shouldn't be naming the strategies default as they're not descriptive. We should let the example files define what is default.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-16 22:44:10.761,,,no_permission,,,,,,,,,,,,368261,,,Fri Jan 17 15:39:42 UTC 2014,,,,,,0|i1rh2n:,368566,,,,,,,,"16/Jan/14 22:44;jira-bot;Commit f4409d9d8f6b843893cf6b6f5ba39306f0c6975f in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f4409d9 ]

ACCUMULO-2209 Removing DefaultKeyEncryptionStrategy and having explicitly named strategies
","17/Jan/14 04:00;jira-bot;Commit f4409d9d8f6b843893cf6b6f5ba39306f0c6975f in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f4409d9 ]

ACCUMULO-2209 Removing DefaultKeyEncryptionStrategy and having explicitly named strategies
","17/Jan/14 15:24;jira-bot;Commit 99c4361aea0878fbbce1b855492fa67f630f0c60 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=99c4361 ]

ACCUMULO-2209 reset the batch writer on any exception
","17/Jan/14 15:24;jira-bot;Commit 99c4361aea0878fbbce1b855492fa67f630f0c60 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=99c4361 ]

ACCUMULO-2209 reset the batch writer on any exception
","17/Jan/14 15:24;jira-bot;Commit 75f27e5d17b2b667438b3ca4ecd59e76d0ec206f in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=75f27e5 ]

ACCUMULO-2209 reset the batch writer on any exception
","17/Jan/14 15:24;jira-bot;Commit 99c4361aea0878fbbce1b855492fa67f630f0c60 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=99c4361 ]

ACCUMULO-2209 reset the batch writer on any exception
","17/Jan/14 15:24;jira-bot;Commit 75f27e5d17b2b667438b3ca4ecd59e76d0ec206f in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=75f27e5 ]

ACCUMULO-2209 reset the batch writer on any exception
","17/Jan/14 15:24;jira-bot;Commit 99c4361aea0878fbbce1b855492fa67f630f0c60 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=99c4361 ]

ACCUMULO-2209 reset the batch writer on any exception
","17/Jan/14 15:24;jira-bot;Commit 75f27e5d17b2b667438b3ca4ecd59e76d0ec206f in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=75f27e5 ]

ACCUMULO-2209 reset the batch writer on any exception
",17/Jan/14 15:39;mdrob;[~ecn] - Did you mean ACCUMULO-2213 for your commit message?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Security test failing with BAD_CREDENTIALS,ACCUMULO-1123,12634443,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,ecn,ecn,27/Feb/13 16:50,17/Jan/14 04:00,13/Mar/19 22:01,01/Mar/13 23:19,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"Security RW test fails with BAD_CREDENTIALS:

{noformat}
27 16:03:31,041 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Security.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:264)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:97)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node security.TableOp
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:264)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:251)
        ... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloException: Unexpected exception!
        at org.apache.accumulo.test.randomwalk.security.TableOp.visit(TableOp.java:115)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:251)
        ... 9 more
Caused by: java.lang.RuntimeException: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_CREDENTIALS for user table_some_host - Username or Password is Invalid
        at org.apache.accumulo.core.client.impl.ScannerIterator.hasNext(ScannerIterator.java:174)
        at org.apache.accumulo.test.randomwalk.security.TableOp.visit(TableOp.java:80)
        ... 10 more
Caused by: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_CREDENTIALS for user table_some_host - Username or Password is Invalid
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:701)
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:605)
        at org.apache.accumulo.core.client.impl.MetadataLocationObtainer.lookupTablets(MetadataLocationObtainer.java:152)
        at org.apache.accumulo.core.client.impl.TabletLocatorImpl.processInvalidated(TabletLocatorImpl.java:590)
        at org.apache.accumulo.core.client.impl.TabletLocatorImpl._locateTablet(TabletLocatorImpl.java:534)
        at org.apache.accumulo.core.client.impl.TabletLocator$1._locateTablet(TabletLocator.java:115)
        at org.apache.accumulo.core.client.impl.TabletLocatorImpl.locateTablet(TabletLocatorImpl.java:372)
        at org.apache.accumulo.core.client.impl.TabletLocatorImpl.lookupTabletLocation(TabletLocatorImpl.java:392)
        at org.apache.accumulo.core.client.impl.TabletLocatorImpl._locateTablet(TabletLocatorImpl.java:546)
        at org.apache.accumulo.core.client.impl.TabletLocatorImpl.locateTablet(TabletLocatorImpl.java:372)
        at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:248)
        at org.apache.accumulo.core.client.impl.ScannerIterator$Reader.run(ScannerIterator.java:82)
        at org.apache.accumulo.core.client.impl.ScannerIterator.hasNext(ScannerIterator.java:164)
        ... 11 more
Caused by: ThriftSecurityException(user:table_some_host, code:BAD_CREDENTIALS)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$startMultiScan_result$startMultiScan_resultStandardScheme.read(TabletClientService.java:8165)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$startMultiScan_result$startMultiScan_resultStandardScheme.read(TabletClientService.java:8142)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$startMultiScan_result.read(TabletClientService.java:8081)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_startMultiScan(TabletClientService.java:294)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.startMultiScan(TabletClientService.java:274)
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:644)

{noformat}
",10 node test cluster running randomwalk test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2211,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-01 00:01:53.912,,,no_permission,,,,,,,,,,,,314936,,,Fri Jan 17 04:00:02 UTC 2014,,,,,,0|i1ich3:,315280,,,,,,,,"01/Mar/13 00:01;vines;If you hit this again, can you check the logs and see if that user's password was recently changed?","01/Mar/13 23:19;vines;I could not recreate locally, but I believe it's due to having no real handling for passwords being in a transitive state. I added that for authorizations and a pause after changing password. Reasons are in the commit message, I'm not repeating myself.

Please reopen if it rears it's ugly head again, it may be a matter of modifying the pause. But I think 1s is enough, I hope.","02/Mar/13 04:16;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #114 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/114/])
    ACCUMULO-1123 - pay no mind to the man behind the curtain (Revision 1451773)
ACCUMULO-1123 - Had compensation for propogation times for uncached permissions. Authorizations and passwords didn't have the luxury. Added in transient state for authorizations and a pause for ChangePass to help compensate. Ideally, there would be compensation throughout the code for the password, but the code has already become a bit of a rats nest. WalkingSecurity helped clean it up tremendously, I should rewrite a lot of the states now that that exists to make it simpler. (Revision 1451770)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java

vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/ChangePass.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","02/Mar/13 04:20;hudson;Integrated in Accumulo-Trunk #755 (See [https://builds.apache.org/job/Accumulo-Trunk/755/])
    ACCUMULO-1123 - pay no mind to the man behind the curtain (Revision 1451773)
ACCUMULO-1123 - Had compensation for propogation times for uncached permissions. Authorizations and passwords didn't have the luxury. Added in transient state for authorizations and a pause for ChangePass to help compensate. Ideally, there would be compensation throughout the code for the password, but the code has already become a bit of a rats nest. WalkingSecurity helped clean it up tremendously, I should rewrite a lot of the states now that that exists to make it simpler. (Revision 1451770)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java

vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/ChangePass.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","02/Mar/13 09:20;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #9 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/9/])
    ACCUMULO-1123 - pay no mind to the man behind the curtain (Revision 1451771)
ACCUMULO-1123 - minor oversight (Revision 1451768)
ACCUMULO-1123 - Had compensation for propogation times for uncached permissions. Authorizations and passwords didn't have the luxury. Added in transient state for authorizations and a pause for ChangePass to help compensate. Ideally, there would be compensation throughout the code for the password, but the code has already become a bit of a rats nest. WalkingSecurity helped clean it up tremendously, I should rewrite a lot of the states now that that exists to make it simpler. (Revision 1451763)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java

vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java

vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/ChangePass.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","02/Mar/13 09:24;hudson;Integrated in Accumulo-1.5 #10 (See [https://builds.apache.org/job/Accumulo-1.5/10/])
    ACCUMULO-1123 - pay no mind to the man behind the curtain (Revision 1451771)
ACCUMULO-1123 - minor oversight (Revision 1451768)
ACCUMULO-1123 - Had compensation for propogation times for uncached permissions. Authorizations and passwords didn't have the luxury. Added in transient state for authorizations and a pause for ChangePass to help compensate. Ideally, there would be compensation throughout the code for the password, but the code has already become a bit of a rats nest. WalkingSecurity helped clean it up tremendously, I should rewrite a lot of the states now that that exists to make it simpler. (Revision 1451763)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java

vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java

vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/ChangePass.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","06/Mar/13 00:50;hudson;Integrated in Accumulo-1.5 #16 (See [https://builds.apache.org/job/Accumulo-1.5/16/])
    ACCUMULO-1123 - the same pause after changing password is needed at create user time (Revision 1453085)

     Result = FAILURE
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/CreateUser.java
","06/Mar/13 00:51;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #119 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/119/])
    ACCUMULO-1123 - the same pause after changing password is needed at create user time (Revision 1453086)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/CreateUser.java
","06/Mar/13 00:54;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #16 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/16/])
    ACCUMULO-1123 - the same pause after changing password is needed at create user time (Revision 1453085)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/CreateUser.java
","06/Mar/13 00:59;hudson;Integrated in Accumulo-Trunk #760 (See [https://builds.apache.org/job/Accumulo-Trunk/760/])
    ACCUMULO-1123 - the same pause after changing password is needed at create user time (Revision 1453086)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/CreateUser.java
","14/Jan/14 20:48;jira-bot;Commit ed4c2273f7fd34e27fbda1616321117b0561badf in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ed4c227 ]

ACCUMULO-2182 Backport of ACCUMULO-1123 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit ed4c2273f7fd34e27fbda1616321117b0561badf in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ed4c227 ]

ACCUMULO-2182 Backport of ACCUMULO-1123 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit ed4c2273f7fd34e27fbda1616321117b0561badf in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ed4c227 ]

ACCUMULO-2182 Backport of ACCUMULO-1123 to 1.4.x
","17/Jan/14 03:59;jira-bot;Commit 0ffb01a5600c4133f502a4b2a5befa2d0c70d8f4 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0ffb01a ]

ACCUMULO-2211 Add missing delay in Security randomwalk CreateUser

This commit adds a one second delay after creating the ""table"" user in the Security
randomwalk test, in the case where the creation fails with a permission denied error,
but the user needs to be created anyway to continue the test. The delay accompanies
those added in ACCUMULO-1123.
","17/Jan/14 03:59;jira-bot;Commit 0ffb01a5600c4133f502a4b2a5befa2d0c70d8f4 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0ffb01a ]

ACCUMULO-2211 Add missing delay in Security randomwalk CreateUser

This commit adds a one second delay after creating the ""table"" user in the Security
randomwalk test, in the case where the creation fails with a permission denied error,
but the user needs to be created anyway to continue the test. The delay accompanies
those added in ACCUMULO-1123.
","17/Jan/14 04:00;jira-bot;Commit 0ffb01a5600c4133f502a4b2a5befa2d0c70d8f4 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0ffb01a ]

ACCUMULO-2211 Add missing delay in Security randomwalk CreateUser

This commit adds a one second delay after creating the ""table"" user in the Security
randomwalk test, in the case where the creation fails with a permission denied error,
but the user needs to be created anyway to continue the test. The delay accompanies
those added in ACCUMULO-1123.
","17/Jan/14 04:00;jira-bot;Commit 0ffb01a5600c4133f502a4b2a5befa2d0c70d8f4 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0ffb01a ]

ACCUMULO-2211 Add missing delay in Security randomwalk CreateUser

This commit adds a one second delay after creating the ""table"" user in the Security
randomwalk test, in the case where the creation fails with a permission denied error,
but the user needs to be created anyway to continue the test. The delay accompanies
those added in ACCUMULO-1123.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SimpleProxyIT fails on TableNotFoundException,ACCUMULO-2134,12687336,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,04/Jan/14 22:23,15/Jan/14 01:49,13/Mar/19 22:01,09/Jan/14 16:31,,,,,,,,1.6.0,,,proxy,test,,,,,0,,,,,"{noformat}
Running org.apache.accumulo.proxy.SimpleProxyIT
2014-01-04 17:22:37.202 java[59396:1903] Unable to load realm info from SCDynamicStore
Tests run: 12, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 29.547 sec <<< FAILURE!
tableNotFound(org.apache.accumulo.proxy.SimpleProxyIT)  Time elapsed: 0.438 sec  <<< ERROR!
AccumuloException(msg:org.apache.accumulo.core.client.AccumuloException: org.apache.accumulo.core.client.TableNotFoundException: Table doesNotExists does not exist)
	at org.apache.accumulo.proxy.thrift.AccumuloProxy$removeConstraint_result$removeConstraint_resultStandardScheme.read(AccumuloProxy.java:42869)
	at org.apache.accumulo.proxy.thrift.AccumuloProxy$removeConstraint_result$removeConstraint_resultStandardScheme.read(AccumuloProxy.java:42855)
	at org.apache.accumulo.proxy.thrift.AccumuloProxy$removeConstraint_result.read(AccumuloProxy.java:42789)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
	at org.apache.accumulo.proxy.thrift.AccumuloProxy$Client.recv_removeConstraint(AccumuloProxy.java:1298)
	at org.apache.accumulo.proxy.thrift.AccumuloProxy$Client.removeConstraint(AccumuloProxy.java:1283)
	at org.apache.accumulo.proxy.SimpleProxyIT.tableNotFound(SimpleProxyIT.java:583)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-09 00:54:06.781,,,no_permission,,,,,,,,,,,,366335,,,Wed Jan 15 01:49:47 UTC 2014,,,,,,0|i1r5af:,366646,,,,,,,,"09/Jan/14 00:54;ecn;I saw this, too.  It was inconsistent, though.","09/Jan/14 01:01;elserj;Oh, good to know. I think I saw it pretty consistently. Either way, hopefully I'll figure out why :P","09/Jan/14 02:45;elserj;Well, I'm not sure how it fails intermittently for you, [~ecn]. It looks like either ACCUMULO-2079 or ACCUMULO-1965. I can fix this with a change to ProxyServer, but I'm currently trying to unravel whether or not this is an expected or unexpected API change. Given how I understand the changes that were made, I *believe* it was intentional.

Instead of throwing an TNFException, the code now throws an AccumuloException which wraps the TNFE, and thus the test case fails. I believe the intent was for the client API to unwrap the AccumuloException and throw the TNFE back to the client.","09/Jan/14 03:05;elserj;If one of [~ecn] or [~ctubbsii] can take a glance at this to make sure it's kosher, I'd appreciate it. I'll leave it open until then.",09/Jan/14 14:17;ecn;It is surprising that a method that throws TNFE doesn't throw TNFE when the table isn't found.  I would call this a regression.,"09/Jan/14 16:05;elserj;bq. It is surprising that a method that throws TNFE doesn't throw TNFE when the table isn't found. I would call this a regression.

I guess that's the not-straightforward part of this. Best as I can tell, I *think* this is what [~ctubbsii] did to not have to slap a NamespaceNotFoundException and TNFE on every TableOperations method? At the same time, it doesn't look like TableOperationsImpl hasn't ever thrown TableNotFoundException on removeProperty (at least in 1.5.0).

At the same time, there are a few methods on TableOperations that don't have TNFE thrown... which is awkward.","09/Jan/14 16:31;elserj;Given that this is what TableOperations(Impl) is doing, I believe ProxyServer just needed to be updated to handle this case, otherwise the semantics of ProxyServer would also vary from the previous release.","15/Jan/14 01:49;ctubbsii;The exception happens because the removeConstraint() method uses setProperty(), and somebody forgot to add TNFE to the setProperty() method. So, these methods never threw TNFE. So, as a hack, we've had to wrap the exception in Accumulo's client code. I don't know that there's any intent for the consumer of the API to unwrap the exception. Some people indicated they'd like to do that... but I don't know that we should be making guarantees in the API about a hierarchy of exception causes. Sadly, this means that TNFE for setProperty() related methods will result in an AccumuloException instead of TNFE. This was always the case, though. At least now, it should have some reasonable cause for the AccumuloException, with an informative message, instead of some TApplicationException or some other obscure and difficult-to-debug cause.

The intermittency of this issue might be related to ACCUMULO-2092, but I haven't done the investigation necessary to confirm that.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[RW] Image failed on writing to a non-existent table,ACCUMULO-2104,12686568,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,27/Dec/13 20:50,14/Jan/14 20:49,13/Mar/19 22:01,02/Jan/14 20:10,,,,,,,,1.6.0,,,test,,,,,,0,randomwalk,,,,"On the client:

{noformat}
27 01:15:32,206 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Sequential.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.start.Main$1.run(Main.java:137)
        at java.lang.Thread.run(Thread.java:744)
Caused by: org.apache.accumulo.core.client.MutationsRejectedException: # constraint violations : 0  security codes: {}  # server errors 3 # exceptions 3
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.checkForFailures(TabletServerBatchWriter.java:537)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.addMutation(TabletServerBatchWriter.java:249)
        at org.apache.accumulo.core.client.impl.MultiTableBatchWriterImpl$TableBatchWriter.addMutation(MultiTableBatchWriterImpl.java:64)
        at org.apache.accumulo.test.randomwalk.sequential.Write.visit(Write.java:45)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:203)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
Caused by: org.apache.accumulo.core.client.impl.AccumuloServerException: Error on server tserver2:9997
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.sendMutationsToTabletServer(TabletServerBatchWriter.java:937)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.access$1600(TabletServerBatchWriter.java:616)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter$SendTask.send(TabletServerBatchWriter.java:801)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter$SendTask.run(TabletServerBatchWriter.java:765)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        ... 1 more
Caused by: org.apache.thrift.TApplicationException: Internal error processing applyUpdates
        at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:71)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_closeUpdate(TabletClientService.java:431)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.closeUpdate(TabletClientService.java:417)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.sendMutationsToTabletServer(TabletServerBatchWriter.java:899)
        ... 10 more
{noformat}

On the tserver:

{noformat}
2013-12-27 01:15:30,334 [thrift.ProcessFunction] ERROR: Internal error processing applyUpdates
java.lang.IllegalArgumentException: Table with id i9 does not exist
        at org.apache.accumulo.core.client.impl.Tables.getNamespace(Tables.java:218)
        at org.apache.accumulo.server.security.SecurityOperation.hasNamespacePermissionForTableId(SecurityOperation.java:330)
        at org.apache.accumulo.server.security.SecurityOperation.canWrite(SecurityOperation.java:410)
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.setUpdateTablet(TabletServer.java:1477)
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.applyUpdates(TabletServer.java:1521)
        at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at com.sun.proxy.$Proxy17.applyUpdates(Unknown Source)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$applyUpdates.getResult(TabletClientService.java:2347)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$applyUpdates.getResult(TabletClientService.java:2333)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:744)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2106,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-28 04:20:45.743,,,no_permission,,,,,,,,,,,,365559,,,Tue Jan 14 20:49:02 UTC 2014,,,,,,0|i1r0hr:,365867,,,,,,,,"28/Dec/13 00:58;elserj;Looks like the only way this is possible (given the table name used and the structure of the Sequential randomwalk graph) would be that the table wasn't fully created when we tried to create the BatchWriter. At least that what I've come up with so far.

Edit: Looking at the code, this *should not* happen. Need to figure out if there's something more I missed.","28/Dec/13 02:03;elserj;Ok, I think I was looking at different logs for part of this.

This was actually an initial failure in Image (not Sequential). The BatchWriter has the timer thread to retry sending mutations. The ImageFixture (and it looks like all of the fixtures) don't actually close the (MultiTable)BatchWriter(s). The tables get deleted, the failures are retried, and then fail because the table is gone (but without an exact method call in the RW code because it was invoked from a timer).","28/Dec/13 04:20;jira-bot;Commit cbbcaac8889e4053f10d215b2fdfb09a085bffe3 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cbbcaac ]

ACCUMULO-2104 ACCUMULO-2106 Close the MTBW before deleting the tables in RW

If we don't close the MTBW, we have the potential to have failures be retried after we delete the tables (in the
teardown of the Fixture). This is, of course, besides the fact that a long-running RW client will just leak resources
like mad.
","28/Dec/13 04:21;jira-bot;Commit cbbcaac8889e4053f10d215b2fdfb09a085bffe3 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cbbcaac ]

ACCUMULO-2104 ACCUMULO-2106 Close the MTBW before deleting the tables in RW

If we don't close the MTBW, we have the potential to have failures be retried after we delete the tables (in the
teardown of the Fixture). This is, of course, besides the fact that a long-running RW client will just leak resources
like mad.
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit a3eae058d8fff13c768aa7ae1828cee617426878 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3eae05 ]

ACCUMULO-2182 Backport ACCUMULO-2104 and ACCUMULO-2106 to 1.5.x

This commit is an adaption of the backport to 1.4.x, adapted due to files moving
between the releases.
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit a3eae058d8fff13c768aa7ae1828cee617426878 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3eae05 ]

ACCUMULO-2182 Backport ACCUMULO-2104 and ACCUMULO-2106 to 1.5.x

This commit is an adaption of the backport to 1.4.x, adapted due to files moving
between the releases.
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:49;jira-bot;Commit a3eae058d8fff13c768aa7ae1828cee617426878 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3eae05 ]

ACCUMULO-2182 Backport ACCUMULO-2104 and ACCUMULO-2106 to 1.5.x

This commit is an adaption of the backport to 1.4.x, adapted due to files moving
between the releases.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[RW] Multitable.Write failed writing to non-existent table,ACCUMULO-2106,12686572,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,elserj,elserj,27/Dec/13 21:02,14/Jan/14 20:49,13/Mar/19 22:01,02/Jan/14 20:10,,,,,,,,1.6.0,,,test,,,,,,0,randomwalk,,,,"On the client:

{noformat}
27 06:22:31,086 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node MultiTable.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.start.Main$1.run(Main.java:137)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.Exception: Error running node mt.Write
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
Caused by: org.apache.accumulo.core.client.MutationsRejectedException: # constraint violations : 0  security codes: {}  # server errors 3 # exceptions 3
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.checkForFailures(TabletServerBatchWriter.java:537)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.addMutation(TabletServerBatchWriter.java:249)
        at org.apache.accumulo.core.client.impl.MultiTableBatchWriterImpl$TableBatchWriter.addMutation(MultiTableBatchWriterImpl.java:64)
        at org.apache.accumulo.test.randomwalk.multitable.Write.visit(Write.java:81)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 9 more
Caused by: org.apache.accumulo.core.client.impl.AccumuloServerException: Error on server tserver1:9997
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.sendMutationsToTabletServer(TabletServerBatchWriter.java:937)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.access$1600(TabletServerBatchWriter.java:616)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter$SendTask.send(TabletServerBatchWriter.java:801)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter$SendTask.run(TabletServerBatchWriter.java:765)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        ... 1 more
Caused by: org.apache.thrift.TApplicationException: Internal error processing applyUpdates
        at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:71)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_closeUpdate(TabletClientService.java:431)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.closeUpdate(TabletClientService.java:417)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.sendMutationsToTabletServer(TabletServerBatchWriter.java:899)
        ... 10 more
{noformat}

On the server:

{noformat}
2013-12-27 06:22:30,475 [thrift.ProcessFunction] ERROR: Internal error processing applyUpdates
java.lang.IllegalArgumentException: Table with id kq does not exist
        at org.apache.accumulo.core.client.impl.Tables.getNamespace(Tables.java:218)
        at org.apache.accumulo.server.security.SecurityOperation.hasNamespacePermissionForTableId(SecurityOperation.java:330)
        at org.apache.accumulo.server.security.SecurityOperation.canWrite(SecurityOperation.java:410)
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.setUpdateTablet(TabletServer.java:1477)
        at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.applyUpdates(TabletServer.java:1521)
        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at com.sun.proxy.$Proxy17.applyUpdates(Unknown Source)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$applyUpdates.getResult(TabletClientService.java:2347)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$applyUpdates.getResult(TabletClientService.java:2333)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:744)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-28 04:21:04.06,,,no_permission,,,,,,,,,,,,365563,,,Tue Jan 14 20:49:02 UTC 2014,,,,,,0|i1r0in:,365871,,,,,,,,28/Dec/13 03:32;elserj;I think the fix from ACCUMULO-2104 will also solve the issue here (at least it's plausible for the bug on the other ticket to cause this error).,"28/Dec/13 04:21;jira-bot;Commit cbbcaac8889e4053f10d215b2fdfb09a085bffe3 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cbbcaac ]

ACCUMULO-2104 ACCUMULO-2106 Close the MTBW before deleting the tables in RW

If we don't close the MTBW, we have the potential to have failures be retried after we delete the tables (in the
teardown of the Fixture). This is, of course, besides the fact that a long-running RW client will just leak resources
like mad.
","28/Dec/13 04:21;jira-bot;Commit cbbcaac8889e4053f10d215b2fdfb09a085bffe3 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cbbcaac ]

ACCUMULO-2104 ACCUMULO-2106 Close the MTBW before deleting the tables in RW

If we don't close the MTBW, we have the potential to have failures be retried after we delete the tables (in the
teardown of the Fixture). This is, of course, besides the fact that a long-running RW client will just leak resources
like mad.
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit a3eae058d8fff13c768aa7ae1828cee617426878 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3eae05 ]

ACCUMULO-2182 Backport ACCUMULO-2104 and ACCUMULO-2106 to 1.5.x

This commit is an adaption of the backport to 1.4.x, adapted due to files moving
between the releases.
","14/Jan/14 20:48;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:48;jira-bot;Commit a3eae058d8fff13c768aa7ae1828cee617426878 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3eae05 ]

ACCUMULO-2182 Backport ACCUMULO-2104 and ACCUMULO-2106 to 1.5.x

This commit is an adaption of the backport to 1.4.x, adapted due to files moving
between the releases.
","14/Jan/14 20:49;jira-bot;Commit 5c50e42be24bf58d3aa44e29baf491e26dfd8994 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5c50e42 ]

ACCUMULO-2182 Backport of ACCUMULO-2104 and ACCUMULO-2106 to 1.4.x
","14/Jan/14 20:49;jira-bot;Commit a3eae058d8fff13c768aa7ae1828cee617426878 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a3eae05 ]

ACCUMULO-2182 Backport ACCUMULO-2104 and ACCUMULO-2106 to 1.5.x

This commit is an adaption of the backport to 1.4.x, adapted due to files moving
between the releases.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"remove deprecation from ZooKeeperInstance(String, String) constructor",ACCUMULO-2167,12688165,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,09/Jan/14 23:51,13/Jan/14 20:23,13/Mar/19 22:01,13/Jan/14 20:19,,,,,,,,1.6.0,,,,,,,,,0,,,,,"In 1.6.0-SNAPSHOT the ZooKeeperInstance(String, String) constructor was deprecated.  It does not seem there is a compelling reason to do this.  Below are some reasons I can think of not to do it.
 
 * In 1.6.0 you still need to know an instance name and zookeepers to create a ZookeeperInstance programmatically.  So its not like its reason for being is no longer valid.
 * Its a nice conveince method for new code written against accumulo (its shorter than {{new ClientConfiguration()..withInstance(instanceName).withZkHosts(zooKeepers)}}
 * Most existing code using the API probably uses it.  Why annoy users unnecessarily?
 * There is no maintenance burden for keeping the method

I think all of the other constructors that were deprecated should stay deprecated.  Its likely those constructors are not used, and if their functionality is needed then ClientConfiguration can be used.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-13 20:18:16.763,,,no_permission,,,,,,,,,,,,367185,,,Mon Jan 13 20:23:12 UTC 2014,,,,,,0|i1raiv:,367494,,,,,,,,"13/Jan/14 20:18;jira-bot;Commit e99275f9241c6297072d09d40eb6b2fbe3cc8ffa in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e99275f ]

ACCUMULO-2167 removed deprecation from ZooKeeperInstance(String, String) constructor
","13/Jan/14 20:23;jira-bot;Commit e99275f9241c6297072d09d40eb6b2fbe3cc8ffa in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e99275f ]

ACCUMULO-2167 removed deprecation from ZooKeeperInstance(String, String) constructor
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
VFS Classloader has potential to collide localized resources,ACCUMULO-2174,12688328,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,10/Jan/14 20:54,11/Jan/14 00:16,13/Mar/19 22:01,11/Jan/14 00:16,1.5.0,,,,,,,1.5.1,1.6.0,,start,,,,,,0,,,,,"Looking through the VFS implementation, a single directory is used for *all* Accumulo processes on a single host for a given user.

Commons-vfs makes some attempt (adds a number to the localized resource, created from a random number between 0 and 2**16, and incremented for each updated resource) to give a ""unique"" resource. Rather than let this bite us later on, it's rather simple for us to just query the runtime and get the pid of the process to add into the temp directory that a process uses.

This could increase the copies of resources per host (by the number of processes), but I think the performance penalty is much better than suddenly getting someone else's jars in the middle of my process execution.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-10 23:42:02.102,,,no_permission,,,,,,,,,,,,367347,,,Sat Jan 11 00:16:13 UTC 2014,,,,,,0|i1rbin:,367656,,,,,,,,"10/Jan/14 23:42;jira-bot;Commit db56d8d21dc636e6d271ae4c710ed27196a24506 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=db56d8d ]

ACCUMULO-2174 Provide a better VFS tmpdir default that won't collide across processes
","11/Jan/14 00:15;jira-bot;Commit db56d8d21dc636e6d271ae4c710ed27196a24506 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=db56d8d ]

ACCUMULO-2174 Provide a better VFS tmpdir default that won't collide across processes
","11/Jan/14 00:16;jira-bot;Commit db56d8d21dc636e6d271ae4c710ed27196a24506 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=db56d8d ]

ACCUMULO-2174 Provide a better VFS tmpdir default that won't collide across processes
",11/Jan/14 00:16;elserj;Include process name in the temporary direction used.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Concurrent compactions before machine failure may cause uneeded recovery,ACCUMULO-2172,12688313,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,10/Jan/14 19:37,10/Jan/14 21:39,13/Mar/19 22:01,10/Jan/14 21:39,1.5.0,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,"[~vines] noticed that minc finish events are not synced to the walog.  I was looking into this issue to see if it was a problem and I noticed a possible issue w/ this.   If the following sequence of events occurs, its possible that duplicate recovery may occur.

 # Tablet T1 writes File F1 to metadata table after minor compaction
 # T1 write minc finish event to walog (no sync is done and info not in walog)
 # T1 adds F1 to set of files in tablets memory
 # T1 major compacts F1 into F2
 # Tablet server serving T1 fails (and nothing synced walog)
 # T1 recovers data in F1 because there is no finish event or file in metadata table

Step 2 must sync before step 3, because step 3 makes the file eligible for major compaction.  Its seems like the sync could be done using group commit for efficiency.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-10 21:37:49.091,,,no_permission,,,,,,,,,,,,367332,,,Fri Jan 10 21:39:01 UTC 2014,,,,,,0|i1rbfb:,367641,,,,,,,,10/Jan/14 19:49;kturner;seems this is an issue in 1.5.0 also.  Looked at 1.4.5-SNAP and its syncs these events.,"10/Jan/14 21:37;jira-bot;Commit 3b41d37ed27b5dc8724b427ed6970b083464bd94 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3b41d37 ]

ACCUMULO-2172 wait for minor compaction flags to be flushed to the WAL
","10/Jan/14 21:38;jira-bot;Commit 3b41d37ed27b5dc8724b427ed6970b083464bd94 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3b41d37 ]

ACCUMULO-2172 wait for minor compaction flags to be flushed to the WAL
","10/Jan/14 21:38;jira-bot;Commit 3b41d37ed27b5dc8724b427ed6970b083464bd94 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3b41d37 ]

ACCUMULO-2172 wait for minor compaction flags to be flushed to the WAL
",10/Jan/14 21:39;ecn;Good catch [~kturner] and [~vines]! ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HadoopLogCloser gives wrong class name in exception,ACCUMULO-2063,12685495,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,19/Dec/13 01:57,10/Jan/14 16:46,13/Mar/19 22:01,10/Jan/14 16:46,,,,,,,,1.6.0,,,,,,,,,0,,,,,When HadoopLogCloser does not know how to handle a file system it throws an exception with an error message.  The error message gives the classname of VolumeMangerImpl instead of the unknown filesystem type.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-10 16:46:14.95,,,no_permission,,,,,,,,,,,,364572,,,Fri Jan 10 16:46:14 UTC 2014,,,,,,0|i1qu8v:,364872,,,,,,,,10/Jan/14 16:46;elserj;Fixed in b671fdaa7d8afcff202abe471a203230ba17d176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cloning tables results in errors from the master,ACCUMULO-2013,12684561,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,13/Dec/13 22:14,09/Jan/14 21:59,13/Mar/19 22:01,09/Jan/14 21:59,,,,,,,,1.6.0,,,master,,,,,,0,,,,,"Cloning any normal table, the new table reports an error corresponding to it's table ID

{code}
Table (o) contains reference to namespace () that doesn't exist
{code}

being reported by the master in the monitor.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-16 18:18:59.711,,,no_permission,,,,,,,,,,,,363633,,,Tue Dec 31 01:39:00 UTC 2013,,,,,,0|i1qohz:,363939,,,,,,,,"16/Dec/13 18:18;jira-bot;Commit 1291713b89b9bd41326d0b4b0cf741fcb29b896a in branch refs/heads/1.6.0-SNAPSHOT from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1291713 ]

ACCUMULO-2013 - fixing errors when cloning table
","16/Dec/13 18:19;jira-bot;Commit 1291713b89b9bd41326d0b4b0cf741fcb29b896a in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1291713 ]

ACCUMULO-2013 - fixing errors when cloning table
","21/Dec/13 01:34;elserj;I just redeployed 1.6.0-SNAPSHOT (66c7848a) and saw this reported by one tserver shortly after starting a randomwalk over Image.xml. The table it complained about was one of the ""img_ndx..."" tables.","21/Dec/13 01:55;elserj;Just saw it via the Concurrent module too on the ctt_001 table

{noformat}
20 17:48:48,029 [concurrent.CreateTable] DEBUG: Created table ctt_001
20 17:48:48,270 [concurrent.CreateTable] DEBUG: Could not create table: org.apache.accumulo.core.client.AccumuloSecurityException: Error NAMESPACE_DOESNT_EXIST for user root on table nspc_001.ctt_002(?) - Unknown security exception
20 17:48:48,572 [concurrent.CreateTable] DEBUG: Could not create table: org.apache.accumulo.core.client.AccumuloSecurityException: Error NAMESPACE_DOESNT_EXIST for user root on table nspc_000.ctt_001(?) - Unknown security exception
{noformat}","21/Dec/13 04:18;vines;This looks like a different error. This is a randomwalk failing with
insufficient permissions. This ticket was a transient error on cloning
tables.

Sent from my phone, please pardon the typos and brevity.

",31/Dec/13 01:39;ctubbsii;Is this fixed now? I made a lot of improvements to the exception handling for namespaces and table operations in the master in ACCUMULO-1965.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
listiter lacks --all flag,ACCUMULO-2022,12684995,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,vines,vines,16/Dec/13 16:58,08/Jan/14 21:07,13/Mar/19 22:01,08/Jan/14 21:06,,,,,,,,1.6.0,,,shell,,,,,,0,,,,,"deleteiter has a nice useful --all flag for all iterator scopes. Unfortunately, listiter is lacking this. We should have consistency in these operations.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-08 21:07:15.448,,,no_permission,,,,,,,,,,,,364072,,,Wed Jan 08 21:07:31 UTC 2014,,,,,,0|i1qr5z:,364372,,,,,,,,"08/Jan/14 21:07;jira-bot;Commit 43b3533f4e85781184f95a1d84929308a69327ce in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=43b3533 ]

ACCUMULO-2022 Add a -all flag to listiter.
","08/Jan/14 21:07;jira-bot;Commit 43b3533f4e85781184f95a1d84929308a69327ce in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=43b3533 ]

ACCUMULO-2022 Add a -all flag to listiter.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GC doesn't respect instance SSL configuration,ACCUMULO-2032,12685045,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mberman,mberman,mberman,16/Dec/13 21:25,08/Jan/14 20:57,13/Mar/19 22:01,08/Jan/14 19:45,,,,,,,,1.6.0,,,gc,,,,,,0,,,,,"looks like the GC is starting up an unencrypted THsHaServer regardless of the instance.rpc.ssl.enabled config property.  then it traces a constant stream of {{ERROR: Read an invalid frame size of -2140274429. Are you using TFramedTransport on the client side?}} because the monitor is trying to connect over SSL as configured.

this used to work, but maybe got lost in some GC refactor?  i'm also looking into getting this case covered by automated tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16/Dec/13 22:46;mberman;0001-ACCUMULO-2032-make-GC-serve-SSL-when-SSL-is-turned-o.patch;https://issues.apache.org/jira/secure/attachment/12618989/0001-ACCUMULO-2032-make-GC-serve-SSL-when-SSL-is-turned-o.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-12-17 01:40:27.773,,,no_permission,,,,,,,,,,,,364122,,,Wed Jan 08 20:57:36 UTC 2014,,,,,,0|i1qrh3:,364422,,,,,,,,"17/Dec/13 01:40;ecn;bq. i'm also looking into getting this case covered by automated tests.

You took the words right out of my mouth.  Thanks!
",08/Jan/14 18:15;elserj;[~mberman] did you ever get some tests worked up for this? Is the patch you attached here still good for fixing the deficiency in this ticket?,"08/Jan/14 18:31;mberman;The patch should be good, although I haven't checked to see if the code has drifted at all in any way that might make applying it hard.  I forgot about writing tests over the holidays...I'll try to get to that later this week.","08/Jan/14 19:45;jira-bot;Commit 133e90a3c61aace351be7ab447446c9c6ea6b4f0 in branch refs/heads/1.6.0-SNAPSHOT from [~mberman]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=133e90a ]

ACCUMULO-2032: make GC serve SSL when SSL is turned on. also remove the entrypoint that allowed you to create a thrift server without thinking about SSL.
","08/Jan/14 20:57;jira-bot;Commit 133e90a3c61aace351be7ab447446c9c6ea6b4f0 in branch refs/heads/master from [~mberman]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=133e90a ]

ACCUMULO-2032: make GC serve SSL when SSL is turned on. also remove the entrypoint that allowed you to create a thrift server without thinking about SSL.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
simple.table.TabletShouldSplitTest incosistently fails,ACCUMULO-679,12598070,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,09/Jul/12 19:05,07/Jan/14 22:41,13/Mar/19 22:01,09/Jul/12 22:09,,,,,,,,1.5.0,,,test,,,,,,0,,,,,Having inconsistent failures on the TabletShouldSplit test due to 'split points not being shortened'. This should be resolved so we get consistent results if possible.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-07 19:04:22.518,,,no_permission,,,,,,,,,,,,246388,,,Tue Jan 07 22:41:21 UTC 2014,,,,,,0|i07lpr:,42284,,,,,,,,"07/Jan/14 19:04;jira-bot;Commit 8f4516eac94e093d42de0a3b3c4ac3d2c1d1838b in branch refs/heads/1.4.5-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8f4516e ]

ACCUMULO-2138 Backport ACCUMULO-679 to 1.4.x

Original commit message: Fixed the [TabletShouldSplit] test to do a more coherent
check and to produce results more consistently that are accurate. WOrks on my machine,
but may need more love later

git-svn-id: https://svn.apache.org/repos/asf/accumulo/trunk@1359426 13f79535-47bb-0310-9956-ffa450edef68
(cherry picked from commit 06db9a008e1fafb821d57f8bd5c35a7065932030)
","07/Jan/14 22:38;jira-bot;Commit 8f4516eac94e093d42de0a3b3c4ac3d2c1d1838b in branch refs/heads/1.5.1-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8f4516e ]

ACCUMULO-2138 Backport ACCUMULO-679 to 1.4.x

Original commit message: Fixed the [TabletShouldSplit] test to do a more coherent
check and to produce results more consistently that are accurate. WOrks on my machine,
but may need more love later

git-svn-id: https://svn.apache.org/repos/asf/accumulo/trunk@1359426 13f79535-47bb-0310-9956-ffa450edef68
(cherry picked from commit 06db9a008e1fafb821d57f8bd5c35a7065932030)
","07/Jan/14 22:39;jira-bot;Commit 8f4516eac94e093d42de0a3b3c4ac3d2c1d1838b in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8f4516e ]

ACCUMULO-2138 Backport ACCUMULO-679 to 1.4.x

Original commit message: Fixed the [TabletShouldSplit] test to do a more coherent
check and to produce results more consistently that are accurate. WOrks on my machine,
but may need more love later

git-svn-id: https://svn.apache.org/repos/asf/accumulo/trunk@1359426 13f79535-47bb-0310-9956-ffa450edef68
(cherry picked from commit 06db9a008e1fafb821d57f8bd5c35a7065932030)
","07/Jan/14 22:41;jira-bot;Commit 8f4516eac94e093d42de0a3b3c4ac3d2c1d1838b in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8f4516e ]

ACCUMULO-2138 Backport ACCUMULO-679 to 1.4.x

Original commit message: Fixed the [TabletShouldSplit] test to do a more coherent
check and to produce results more consistently that are accurate. WOrks on my machine,
but may need more love later

git-svn-id: https://svn.apache.org/repos/asf/accumulo/trunk@1359426 13f79535-47bb-0310-9956-ffa450edef68
(cherry picked from commit 06db9a008e1fafb821d57f8bd5c35a7065932030)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mappers are not running locally,ACCUMULO-2036,12685065,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,kturner,kturner,17/Dec/13 00:00,07/Jan/14 17:17,13/Mar/19 22:01,03/Jan/14 05:46,,,,,,,,1.6.0,,,,,,,,,0,16_qa_bug,,,,"I ran listscans in the Accumulo shell while running continuous verify on small cluster and almost not map task were running locally.

I think ACCUMULO-1585 has broken mapper locality in 1.6.0-SNAPSHOT.  Before that change Accumulo would always store IP addrs.  Code like the following in o.a.a.c.client.mapreduce.AbstractInputFormat.getSplits() would translate IPs to hostnames.  

{code:java}
       if (location == null) {
          InetAddress inetAddress = InetAddress.getByName(ip);
          location = inetAddress.getHostName();
          hostNameCache.put(ip, location);
        }
{code}

In my case I configured Accumulo to use hostnames, but not fully qualified ones.  So I think the above code was just passing the non-quallified hostname through.   I suspected hadoop wanted FQDN and changed the code to the following and mappers ran locally.  I need to confirm what hadoop is expecting.  I think the above code will result in a FQDN if given an IP,  so this is not an issue for 1.4 or 1.5.

{code:java}
       if (location == null) {
          InetAddress inetAddress = InetAddress.getByName(ip);
          location = inetAddress.getCanonicalHostName();
          hostNameCache.put(ip, location);
        }
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-03 03:42:17.405,,,no_permission,,,,,,,,,,,,364142,,,Mon Jan 06 20:32:05 UTC 2014,,,,,,0|i1qrlj:,364442,,,,,,,,"03/Jan/14 03:42;elserj;Looks like you were correct about fqdn, Keith. From hadoop-2.2.0, this gets called when the string looks like an IP, and the string is added otherwise.

{noformat}
  protected String resolveHost(String src) {
    String result = src; // Fallback in case of failure.
    try {
      InetAddress addr = InetAddress.getByName(src);
      result = addr.getHostName();
    } catch (UnknownHostException e) {
      LOG.warn(""Failed to resolve address: "" + src
          + "". Continuing to use the same."");
    }
    return result;
  }
{noformat}

Ok, dug down into the Java source and ultimately some man pages, but I found the information I want:

{noformat}
The domain name queries carried out by gethostbyname() and gethostbyaddr() use a combination of any or all of the name server named(8),  a  broken  out in /etc/host.conf.  The default action is to query named(8), followed by /etc/hosts.
{noformat}

I think that explains when/how Java will be returning the FQDN from the alias.

Just need to find again where Hadoop is assigning the mappers to TaskTrackers (or rather Map task to Container on NodeManager) to get the locality.","03/Jan/14 04:54;elserj;Found enough code through the TaskAttemptImpl and MapTaskAttemptImpl, the StateMachineFactory (and its transitions) and the RMContainerAllocator that make me confident that things are still happening how we thought they are.

This was probably a huge waste of time for something we could have been relatively certain about through testing, but oh well :P","03/Jan/14 05:41;jira-bot;Commit a89d97a003caa6a5a735098b6092f36ff86592b9 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a89d97a ]

ACCUMULO-2036 Try to get FQDN's for RangeInputSplit

We want to make sure that we get FQDNs (when possible) as this
will be what gets data-local mappers (map task running on the same
host as the tabletserver feeding it data)
","03/Jan/14 05:44;jira-bot;Commit a89d97a003caa6a5a735098b6092f36ff86592b9 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a89d97a ]

ACCUMULO-2036 Try to get FQDN's for RangeInputSplit

We want to make sure that we get FQDNs (when possible) as this
will be what gets data-local mappers (map task running on the same
host as the tabletserver feeding it data)
","03/Jan/14 05:45;elserj;Verified no (or, at least, very little) data locality before the fix, and nearly 100% data locality after the fix.","06/Jan/14 20:25;kturner;[~elserj] thanks for looking into this.  Nice that you made the change for mapred and mapreduce.  The duplicated code drives me a bit nuts.

It does not seems there is a way to test this automatically.  I am thinking we should create a list of things that need to be manually verified before release and add this to it.  I will open a ticket for that.",06/Jan/14 20:29;busbey;the job counters will tell you how many tasks were local. we could make an integration test (that required a Hadoop instance) that checked that the number was > 0 (or some other threshold).,"06/Jan/14 20:32;elserj;bq. thanks for looking into this. Nice that you made the change for mapred and mapreduce. The duplicated code drives me a bit nuts.

No problemo -- I agree on the duplicity. It's not ideal right now, but incremental improvements, and whatnot.

bq. It does not seems there is a way to test this automatically. I am thinking we should create a list of things that need to be manually verified before release and add this to it. I will open a ticket for that.

Agreed. I sat and spun my wheels for a while trying to come up with some way to test this, but couldn't come up with anything good (so I settled for manual verification). MapReduce/Yarn might have some testing cluster/utility (ala minidfscluster) that might give us hints at a nice, clean way to test this. That might be a good place to start looking.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Table listing puts creating/deleting tables in default namespace,ACCUMULO-2093,12686326,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,24/Dec/13 21:13,07/Jan/14 02:28,13/Mar/19 22:01,25/Dec/13 00:00,,,,,,,,1.6.0,,,,,,,,,0,,,,,"This manifests when a table is in being created or being deleted. The namespace node doesn't yet exist, so, we fall back to the default namespace. It should just exclude the table from the listing, or update the cache and try again, if the state is inconsistent.",[db74696|https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=db746960fbcafb1651c15ec2e5493d56acb5065c],,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-24 21:51:10.227,,,no_permission,,,,,,,,,,,,365306,,,Tue Jan 07 02:28:02 UTC 2014,,,,,,0|i1qys7:,365609,,,,,,,,"24/Dec/13 21:51;jira-bot;Commit 3cddee9ef10049219b551d578bbfa9f779697993 in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3cddee9 ]

ACCUMULO-2093 Exclude incomplete tables from listing.

  Specifically, tables who can't resolve with a fully-qualified table
  name are excluded from a table listing. This ensures that tables being
  created and/or deleted aren't shown in an inconsistent state.
","07/Jan/14 02:24;jira-bot;Commit ea8fe54145b306310a93e9df65ea5277dff2853e in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ea8fe54 ]

ACCUMULO-1976 Fix upgrade broken by ACCUMULO-2093
","07/Jan/14 02:28;jira-bot;Commit ea8fe54145b306310a93e9df65ea5277dff2853e in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ea8fe54 ]

ACCUMULO-1976 Fix upgrade broken by ACCUMULO-2093
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cobertura not working for functional tests in 1.5.x and earlier,ACCUMULO-1944,12682139,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,bhavanki,bhavanki,02/Dec/13 14:16,06/Jan/14 20:08,13/Mar/19 22:01,06/Jan/14 19:16,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,,test,,,,,,1,cobertura,testing,,,"The -C argument to test/system/auto/run.py should enable running instrumented functional tests to analyze coverage using Cobertura. The capability is not functional; code is not instrumented even when Cobertura is available, and tests are not run with the instrumented code.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,02/Jan/14 15:20;bhavanki;ACCUMULO-1944-1.4.patch;https://issues.apache.org/jira/secure/attachment/12621082/ACCUMULO-1944-1.4.patch,06/Jan/14 18:16;bhavanki;ACCUMULO-1944-1.4.v2.patch;https://issues.apache.org/jira/secure/attachment/12621635/ACCUMULO-1944-1.4.v2.patch,02/Jan/14 15:20;bhavanki;ACCUMULO-1944-1.5.patch;https://issues.apache.org/jira/secure/attachment/12621083/ACCUMULO-1944-1.5.patch,06/Jan/14 18:24;bhavanki;ACCUMULO-1944-1.5.v2.patch;https://issues.apache.org/jira/secure/attachment/12621636/ACCUMULO-1944-1.5.v2.patch,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,2013-12-02 16:38:26.612,,,no_permission,,,,,,,,,,,,361396,,,Mon Jan 06 20:08:23 UTC 2014,,,,,,0|i1qaqf:,361695,,,,,,,,"02/Dec/13 16:38;ecn;I have not tried to run coverage for a long time.  The last time I did, it was painfully slow, with many false failures due to timing issues.  I discourage you from putting any time into fixing this in the python test driver since it no longer exists.  Instead, I would put the effort into getting coverage to work for the integration tests.
","02/Dec/13 20:32;bhavanki;I had success with it last week, so I don't mind submitting changes. I bet the overall technique will be similar for any tests that use the Cobertura scripts instead of the Maven plugin. Those scripts were also broken (in Cobertura 2.0.x), so I have hopefully repaired those as well (submitted a pull request for it, will link to this ticket).",30/Dec/13 11:45;bhavanki;Current patch only applies to 1.4.5-SNAPSHOT. Working on testing patch for 1.5.1-SNAPSHOT.,"02/Jan/14 15:21;bhavanki;Patches available for 1.4.x and 1.5.x. Testing for the 1.5.x patch revealed that the original patch broke running functional tests when Cobertura is not installed, so I've submitted a new patch for 1.4.x with the required updates.","06/Jan/14 18:16;bhavanki;Updated patch for 1.4.x, as prior patch no longer applies.","06/Jan/14 18:24;bhavanki;Updated patch for 1.5.x, as prior patch no longer applies.","06/Jan/14 19:10;jira-bot;Commit 198b1abd9e81d1af55220bf22a0b4e6ec1d18048 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=198b1ab ]

ACCUMULO-1944 Fix coverage for functional tests

The -C flag for test/system/auto/run.py did not work. This changeset
allows it to work again if a functional Cobertura installation is
placed under $ACCUMULO_HOME/lib/test/cobertura.

The code for producing instrumented Accumulo code was inactive and
out of date. It was reworked so that, if -C is passed, the Accumulo
JARs are instrumented and placed into a location ahead of their
standard location in the test classpath. (If -C is not passed, any
instrumented JARs are removed.) The classpath is also dynamically
adjusted to include whatever Cobertura JAR is available; its name
includes a version number (as of 2.0.x).

The command-line scripts shipped with Cobertura 2.0.x are out of
date and do not work out of the box. Pull request #102 was submitted
to cobertura/cobertura on Github to fix the problem; in lieu of that,
the scripts must be manually updated to use a correct classpath.

Tested with Cobertura 2.0.3 / 2.0.4-SNAPSHOT with needed script
updates.
","06/Jan/14 19:11;jira-bot;Commit 8669b80f98da34da1b709d1ed4f14647cc1f952c in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8669b80 ]

ACCUMULO-1944 Restore test runs when Cobertura not installed

The changes in the prior commit to re-enable test coverage assume that Cobertura
is available. When it isn't, functional test runs fail. This commit allows runs
to proceed when Cobertura is not installed.
","06/Jan/14 19:12;jira-bot;Commit 198b1abd9e81d1af55220bf22a0b4e6ec1d18048 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=198b1ab ]

ACCUMULO-1944 Fix coverage for functional tests

The -C flag for test/system/auto/run.py did not work. This changeset
allows it to work again if a functional Cobertura installation is
placed under $ACCUMULO_HOME/lib/test/cobertura.

The code for producing instrumented Accumulo code was inactive and
out of date. It was reworked so that, if -C is passed, the Accumulo
JARs are instrumented and placed into a location ahead of their
standard location in the test classpath. (If -C is not passed, any
instrumented JARs are removed.) The classpath is also dynamically
adjusted to include whatever Cobertura JAR is available; its name
includes a version number (as of 2.0.x).

The command-line scripts shipped with Cobertura 2.0.x are out of
date and do not work out of the box. Pull request #102 was submitted
to cobertura/cobertura on Github to fix the problem; in lieu of that,
the scripts must be manually updated to use a correct classpath.

Tested with Cobertura 2.0.3 / 2.0.4-SNAPSHOT with needed script
updates.
","06/Jan/14 19:12;jira-bot;Commit 8669b80f98da34da1b709d1ed4f14647cc1f952c in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8669b80 ]

ACCUMULO-1944 Restore test runs when Cobertura not installed

The changes in the prior commit to re-enable test coverage assume that Cobertura
is available. When it isn't, functional test runs fail. This commit allows runs
to proceed when Cobertura is not installed.
","06/Jan/14 19:13;jira-bot;Commit 950f144c8e3517053af704189f0fdfd769487dfd in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=950f144 ]

ACCUMULO-1944 Fix coverage for functional tests

The -C flag for test/system/auto/run.py did not work. This changeset
allows it to work again if a functional Cobertura installation is
placed under $ACCUMULO_HOME/lib/test/cobertura.

The code for producing instrumented Accumulo code was inactive and
out of date. It was reworked so that, if -C is passed, the Accumulo
JARs are instrumented and placed into a location ahead of their
standard location in the test classpath. (If -C is not passed, any
instrumented JARs are removed.) The classpath is also dynamically
adjusted to include whatever Cobertura JAR is available; its name
includes a version number (as of 2.0.x).

The command-line scripts shipped with Cobertura 2.0.x are out of
date and do not work out of the box. Pull request #102 was submitted
to cobertura/cobertura on Github to fix the problem; in lieu of that,
the scripts must be manually updated to use a correct classpath.

Tested with Cobertura 2.0.3 / 2.0.4-SNAPSHOT with needed script
updates.
","06/Jan/14 19:14;jira-bot;Commit c23126a86d23566b154747d153bf489a09684c97 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c23126a ]

ACCUMULO-1944 Restore test runs when Cobertura not installed

The changes in the prior commit to re-enable test coverage assume that Cobertura
is available. When it isn't, functional test runs fail. This commit allows runs
to proceed when Cobertura is not installed.
","06/Jan/14 19:14;jira-bot;Commit 8669b80f98da34da1b709d1ed4f14647cc1f952c in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8669b80 ]

ACCUMULO-1944 Restore test runs when Cobertura not installed

The changes in the prior commit to re-enable test coverage assume that Cobertura
is available. When it isn't, functional test runs fail. This commit allows runs
to proceed when Cobertura is not installed.
","06/Jan/14 19:15;jira-bot;Commit 950f144c8e3517053af704189f0fdfd769487dfd in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=950f144 ]

ACCUMULO-1944 Fix coverage for functional tests

The -C flag for test/system/auto/run.py did not work. This changeset
allows it to work again if a functional Cobertura installation is
placed under $ACCUMULO_HOME/lib/test/cobertura.

The code for producing instrumented Accumulo code was inactive and
out of date. It was reworked so that, if -C is passed, the Accumulo
JARs are instrumented and placed into a location ahead of their
standard location in the test classpath. (If -C is not passed, any
instrumented JARs are removed.) The classpath is also dynamically
adjusted to include whatever Cobertura JAR is available; its name
includes a version number (as of 2.0.x).

The command-line scripts shipped with Cobertura 2.0.x are out of
date and do not work out of the box. Pull request #102 was submitted
to cobertura/cobertura on Github to fix the problem; in lieu of that,
the scripts must be manually updated to use a correct classpath.

Tested with Cobertura 2.0.3 / 2.0.4-SNAPSHOT with needed script
updates.
","06/Jan/14 19:16;jira-bot;Commit c23126a86d23566b154747d153bf489a09684c97 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c23126a ]

ACCUMULO-1944 Restore test runs when Cobertura not installed

The changes in the prior commit to re-enable test coverage assume that Cobertura
is available. When it isn't, functional test runs fail. This commit allows runs
to proceed when Cobertura is not installed.
","06/Jan/14 19:16;bhavanki;I applied the patches. I didn't apply any changes to 1.6.x or master, as the updates don't make sense for them - the test framework changed.

Since this is my first commit, I'd be perfectly fine if anyone feels the need to double-check what I did. [~mdrob] gave me a good tutorial on the process, so hopefully I got it all correct. Thanks.","06/Jan/14 19:17;jira-bot;Commit 950f144c8e3517053af704189f0fdfd769487dfd in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=950f144 ]

ACCUMULO-1944 Fix coverage for functional tests

The -C flag for test/system/auto/run.py did not work. This changeset
allows it to work again if a functional Cobertura installation is
placed under $ACCUMULO_HOME/lib/test/cobertura.

The code for producing instrumented Accumulo code was inactive and
out of date. It was reworked so that, if -C is passed, the Accumulo
JARs are instrumented and placed into a location ahead of their
standard location in the test classpath. (If -C is not passed, any
instrumented JARs are removed.) The classpath is also dynamically
adjusted to include whatever Cobertura JAR is available; its name
includes a version number (as of 2.0.x).

The command-line scripts shipped with Cobertura 2.0.x are out of
date and do not work out of the box. Pull request #102 was submitted
to cobertura/cobertura on Github to fix the problem; in lieu of that,
the scripts must be manually updated to use a correct classpath.

Tested with Cobertura 2.0.3 / 2.0.4-SNAPSHOT with needed script
updates.
","06/Jan/14 19:17;jira-bot;Commit c23126a86d23566b154747d153bf489a09684c97 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c23126a ]

ACCUMULO-1944 Restore test runs when Cobertura not installed

The changes in the prior commit to re-enable test coverage assume that Cobertura
is available. When it isn't, functional test runs fail. This commit allows runs
to proceed when Cobertura is not installed.
","06/Jan/14 19:41;elserj;I'm a little confused -- I'm looking at the 1.5.1-SNAPSHOT branch: 198b1abd9e81d1af55220bf22a0b4e6ec1d18048 and 8669b80f98da34da1b709d1ed4f14647cc1f952c seem to be duplicated by 950f144c8e3517053af704189f0fdfd769487dfd and c23126a86d23566b154747d153bf489a09684c97, respectively. They seem to be the (about) the same changes. I'm guessing that you applied both the 1.4 and the 1.5 patches?

In the future, you should just be applying the patch to the lowest-version branch which the issue will be fixed in, and then merge it through. This will be a change for you in process as you can now correctly resolve merge conflicts during the merge itself. I think [~busbey] and [~mdrob] came up with an alternative plan that we might want to look into adopting that would allow contributors to give that first patch, and then subsequent fixes for the merge conflicts while avoiding the duplicate commits.

Having these duplicated commits is what we want to try to avoid as much as possible as tools like git-bisect break down really quickly. Not a big deal that we need to do anything about now, but I just wanted to make sure you're aware :)","06/Jan/14 20:02;bhavanki;Thanks for the feedback, Josh! I had made two separate patches, one for 1.4 and another for 1.5. So, you are correct, I applied both. I can understand that they come out as duplicates since 1.4 gets merged into 1.5 during the process. That merge piece was something I didn't really get until [~mdrob] explained it today.

Next time, I'll try to resolve it during the merge. That makes a lot of sense now. Thanks again! :)",06/Jan/14 20:08;elserj;Cool! HTH.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ShellSetInstanceTest failures on clean system,ACCUMULO-2102,12686541,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,elserj,elserj,27/Dec/13 17:26,03/Jan/14 22:19,13/Mar/19 22:01,03/Jan/14 17:46,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"Installed a new system, and am seeing test failures on ShellSetInstanceTest.

{noformat}
java.lang.AssertionError: 
  Unexpected method call ClientConfiguration.containsKey(""instance.dfs.dir""):
	at org.easymock.internal.MockInvocationHandler.invoke(MockInvocationHandler.java:44)
	at org.easymock.internal.ObjectMethodsFilter.invoke(ObjectMethodsFilter.java:85)
	at org.easymock.internal.ClassProxyFactory$MockMethodInterceptor.intercept(ClassProxyFactory.java:94)
	at org.apache.accumulo.core.client.ClientConfiguration$$EnhancerByCGLIB$$470faeab.containsKey(<generated>)
	at org.apache.accumulo.core.client.impl.ServerConfigurationUtil$1.get(ServerConfigurationUtil.java:41)
	at org.apache.accumulo.core.conf.SiteConfiguration.get(SiteConfiguration.java:67)
	at org.apache.accumulo.core.util.shell.Shell.getZooInstance(Shell.java:433)
	at org.apache.accumulo.core.util.shell.Shell.setInstance(Shell.java:414)
	at org.apache.accumulo.core.util.shell.ShellSetInstanceTest.testSetInstance_HdfsZooInstance(ShellSetInstanceTest.java:188)
	at org.apache.accumulo.core.util.shell.ShellSetInstanceTest.testSetInstance_HdfsZooInstance_HostsGiven(ShellSetInstanceTest.java:121)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.internal.runners.TestMethod.invoke(TestMethod.java:68)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.runTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:312)
	at org.junit.internal.runners.MethodRoadie$2.run(MethodRoadie.java:88)
	at org.junit.internal.runners.MethodRoadie.runBeforesThenTestThenAfters(MethodRoadie.java:96)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.executeTest(PowerMockJUnit44RunnerDelegateImpl.java:296)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit49RunnerDelegateImpl$PowerMockJUnit49MethodRunner.executeTestInSuper(PowerMockJUnit49RunnerDelegateImpl.java:116)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit49RunnerDelegateImpl$PowerMockJUnit49MethodRunner.executeTest(PowerMockJUnit49RunnerDelegateImpl.java:77)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.runBeforesThenTestThenAfters(PowerMockJUnit44RunnerDelegateImpl.java:284)
	at org.junit.internal.runners.MethodRoadie.runTest(MethodRoadie.java:86)
	at org.junit.internal.runners.MethodRoadie.run(MethodRoadie.java:49)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.invokeTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:209)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.runMethods(PowerMockJUnit44RunnerDelegateImpl.java:148)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$1.run(PowerMockJUnit44RunnerDelegateImpl.java:122)
	at org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:33)
	at org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:45)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.run(PowerMockJUnit44RunnerDelegateImpl.java:120)
	at org.powermock.modules.junit4.common.internal.impl.JUnit4TestSuiteChunkerImpl.run(JUnit4TestSuiteChunkerImpl.java:101)
	at org.powermock.modules.junit4.common.internal.impl.AbstractCommonPowerMockRunner.run(AbstractCommonPowerMockRunner.java:53)
	at org.powermock.modules.junit4.PowerMockRunner.run(PowerMockRunner.java:53)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{noformat}

I also noticed the following exception printed to stdout, not sure if it's the root cause

{noformat}
[main} WARN  org.apache.accumulo.core.conf.SiteConfiguration  - accumulo-site.xml not found on classpath
java.lang.Throwable
	at org.apache.accumulo.core.conf.SiteConfiguration.getXmlConfig(SiteConfiguration.java:51)
	at org.apache.accumulo.core.conf.SiteConfiguration.get(SiteConfiguration.java:62)
	at org.apache.accumulo.core.util.shell.Shell.getZooInstance(Shell.java:437)
	at org.apache.accumulo.core.util.shell.Shell.setInstance(Shell.java:414)
	at org.apache.accumulo.core.util.shell.ShellSetInstanceTest.testSetInstance_HdfsZooInstance(ShellSetInstanceTest.java:188)
	at org.apache.accumulo.core.util.shell.ShellSetInstanceTest.testSetInstance_HdfsZooInstance_InstanceGiven(ShellSetInstanceTest.java:117)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.internal.runners.TestMethod.invoke(TestMethod.java:68)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.runTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:312)
	at org.junit.internal.runners.MethodRoadie$2.run(MethodRoadie.java:88)
	at org.junit.internal.runners.MethodRoadie.runBeforesThenTestThenAfters(MethodRoadie.java:96)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.executeTest(PowerMockJUnit44RunnerDelegateImpl.java:296)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit49RunnerDelegateImpl$PowerMockJUnit49MethodRunner.executeTestInSuper(PowerMockJUnit49RunnerDelegateImpl.java:116)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit49RunnerDelegateImpl$PowerMockJUnit49MethodRunner.executeTest(PowerMockJUnit49RunnerDelegateImpl.java:77)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.runBeforesThenTestThenAfters(PowerMockJUnit44RunnerDelegateImpl.java:284)
	at org.junit.internal.runners.MethodRoadie.runTest(MethodRoadie.java:86)
	at org.junit.internal.runners.MethodRoadie.run(MethodRoadie.java:49)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.invokeTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:209)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.runMethods(PowerMockJUnit44RunnerDelegateImpl.java:148)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$1.run(PowerMockJUnit44RunnerDelegateImpl.java:122)
	at org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:33)
	at org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:45)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.run(PowerMockJUnit44RunnerDelegateImpl.java:120)
	at org.powermock.modules.junit4.common.internal.impl.JUnit4TestSuiteChunkerImpl.run(JUnit4TestSuiteChunkerImpl.java:101)
	at org.powermock.modules.junit4.common.internal.impl.AbstractCommonPowerMockRunner.run(AbstractCommonPowerMockRunner.java:53)
	at org.powermock.modules.junit4.PowerMockRunner.run(PowerMockRunner.java:53)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{noformat}

The above errors are from the method testSetInstance_HdfsZooInstance_HostsGiven, but I also get similar failures on testSetInstance_HdfsZooInstance_Implicit and testSetInstance_HdfsZooInstance_Explicit","OpenJDK 1.7.0_45 or Oracle JDK 1.7.0_45 or OpenJDK 1.6.0_27, Git: 7838d403, Maven 3.0.4 or 3.1.1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,03/Jan/14 15:51;bhavanki;ACCUMULO-2102.try.diff;https://issues.apache.org/jira/secure/attachment/12621339/ACCUMULO-2102.try.diff,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-01-02 20:24:52.061,,,no_permission,,,,,,,,,,,,365532,,,Fri Jan 03 22:19:16 UTC 2014,,,,,,0|i1r05r:,365833,,,,,,,,27/Dec/13 17:33;elserj;The exception on STDOUT appears to be unrelated as I get that locally when I run the test passes yet it passes.,"27/Dec/13 18:27;elserj;Uhh, ok. Running one of the test methods that fails when running the entire class causes that method pass.",27/Dec/13 20:19;elserj;I can't figure out what's going on. Everything I've tested makes it appear that the test is working exactly as it should (yet still failing). Switching to Oracle JDK 1.7 on the system magically makes the test pass so I'm going to stop trying to figure this out.,"28/Dec/13 01:28;elserj;Oh, epic. This just re-appeared for me. It must be some sort of timing issue.","02/Jan/14 20:06;elserj;[~bhavanki] Do you have any cycles to look at this? I've only used EasyMock/PowerMock a few times, yet every time I have I recall running into absurd edge cases that caused funky breakages. My gut is telling me this is one of them :)","02/Jan/14 20:24;bhavanki;Sure, I'll take a gander at it.","02/Jan/14 20:30;elserj;Thanks, I really appreciate it. I can also give you access to the box I was seeing it on, if that would help.","02/Jan/14 22:07;bhavanki;I can't reproduce the error yet. It boils down to line 168 in ShellSetInstanceTest not running to record that call in the mock:

{noformat}
expect(clientConf.containsKey(Property.INSTANCE_DFS_DIR.getKey())).andReturn(true).atLeastOnce();
{noformat}

For the three tests you're getting similar errors for, that line should be run. For the other one in the set, ..._InstanceGiven, it isn't needed, and I gather that one is passing.

You could try making sure that that line is reached for the problematic tests. I'm also wondering if maybe work being done to deprecate instance.dfs.dir (like ACCUMULO-2061) is perhaps interfering. That's a long shot, though.

I think the other exception warning on stdout is OK. The code is trying to look in the default config before the mock, and the default isn't set up. It should just then go on to look at the mock, which is what should be servicing the call.

I'll mess around a bit more with it tomorrow - and if I get nowhere I'd be happy to see it failing on that box.","02/Jan/14 22:12;elserj;I attached a remote debugger to it when I was looking at this last, and I believe that line was always being reached (which is what confused me so).

I'll verify that now, and, if you get stuck, let me know. I can easily pop an account for you on my box if you can send me a pubkey.","03/Jan/14 14:48;bhavanki;OK, I'm sending my pub key to your gmail account. :)

One interesting detail is that, when I force it to fail by setting up the mock incorrectly, I see extra information like:

    ClientConfiguration.containsKey(""instance.dfs.dir""): expected: 1, actual: 2

That could be another clue.","03/Jan/14 15:27;bhavanki;I think the problem may lie in the use of {{SiteConfiguration}} (line 431 in Shell.java). It only creates a single static instance object during the run, so after the first time it is used in a unit test, subsequent unit tests should receive the same object with an old mock inside, instead of a new one with a new mock. This would explain why a test passes when you run it by itself, but they fail when all tests in the file are run (your second comment).

What it doesn't explain is why it always passes for me! But perhaps a way to get it to work consistently is to add another test support method to {{SiteConfiguration}} to clear its singleton {{instance}} field, so that it can be reset between tests.","03/Jan/14 15:51;bhavanki;I think that was it. I was able to reproduce the problem by removing all but two of the tests, and it ran in a fashion where the {{SiteConfiguration}} generated from the first test would not work for the second.

Try applying the diff I've attached to see if it fixes the problem for you.","03/Jan/14 17:08;elserj;I'm still testing it out, but it seems like that did the trick!

Thanks for your help, [~bhavanki]. Much appreciated.","03/Jan/14 17:46;elserj;Working for me presently. Thanks again for your help, Bill.","03/Jan/14 17:47;jira-bot;Commit 2654ba56f4e1a040839493096005a25f0c4925fd in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2654ba5 ]

ACCUMULO-2102 Fix for intermittent failures of ShellSetInstanceTest by Bill Havanki

I think the problem may lie in the use of SiteConfiguration by the Shell. It only creates a single static
instance object during the run, so after the first time it is used in a unit test, subsequent unit tests
should receive the same object with an old mock inside, instead of a new one with a new mock.
","03/Jan/14 17:48;jira-bot;Commit 2654ba56f4e1a040839493096005a25f0c4925fd in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2654ba5 ]

ACCUMULO-2102 Fix for intermittent failures of ShellSetInstanceTest by Bill Havanki

I think the problem may lie in the use of SiteConfiguration by the Shell. It only creates a single static
instance object during the run, so after the first time it is used in a unit test, subsequent unit tests
should receive the same object with an old mock inside, instead of a new one with a new mock.
",03/Jan/14 22:19;bhavanki;Awesome! Glad I could help.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Seeing unexpected trace output,ACCUMULO-1743,12671385,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,kturner,kturner,30/Sep/13 16:03,03/Jan/14 17:26,13/Mar/19 22:01,03/Jan/14 15:34,,,,,,,,1.6.0,,,trace,,,,,,0,,,,,"While testing ACCUMULO-1608 I was seeing unexpected trace output on the monitor page.  For example I would see two prep or two wal events when I only expected to see one.  I added debug stmts on the tserver to verify that wal was only being written to once.   

Once we figure out what is going on, need to write a trace test for conditional writer.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-03 15:13:48.109,,,no_permission,,,,,,,,,,,,351091,,,Fri Jan 03 17:26:39 UTC 2014,,,,,,0|i1oj9j:,351383,,,,,,,,"03/Jan/14 15:13;jira-bot;Commit 51f84de0ec2435e70c37846c7f363bfce3ebca00 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=51f84de ]

ACCUMULO-1743 added trace check of conditional writes
","03/Jan/14 15:13;jira-bot;Commit 51f84de0ec2435e70c37846c7f363bfce3ebca00 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=51f84de ]

ACCUMULO-1743 added trace check of conditional writes
","03/Jan/14 15:34;ecn;Could not find unexplained traces, wrote a test for traces of conditional writes.","03/Jan/14 17:19;elserj;Just saw this failure after your changes, [~ecn]. I'm thinking that the trace table wasn't yet created, got created, but the table cache wasn't updated before we tried to use it and got the error.

{noformat}
Running org.apache.accumulo.test.ConditionalWriterIT
Tests run: 17, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 21.262 sec <<< FAILURE!
testTrace(org.apache.accumulo.test.ConditionalWriterIT)  Time elapsed: 0.205 sec  <<< ERROR!
org.apache.accumulo.core.client.TableNotFoundException: Table trace does not exist
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.doFateOperation(TableOperationsImpl.java:329)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.doFateOperation(TableOperationsImpl.java:296)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableFateOperation(TableOperationsImpl.java:1572)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.deleteRows(TableOperationsImpl.java:550)
	at org.apache.accumulo.test.ConditionalWriterIT.testTrace(ConditionalWriterIT.java:1203)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: ThriftTableOperationException(tableId:null, tableName:trace, op:DELETE_RANGE, type:NOTFOUND, description:null)
	at org.apache.accumulo.core.master.thrift.FateService$executeFateOperation_result$executeFateOperation_resultStandardScheme.read(FateService.java:2895)
	at org.apache.accumulo.core.master.thrift.FateService$executeFateOperation_result$executeFateOperation_resultStandardScheme.read(FateService.java:2872)
	at org.apache.accumulo.core.master.thrift.FateService$executeFateOperation_result.read(FateService.java:2814)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
	at org.apache.accumulo.core.master.thrift.FateService$Client.recv_executeFateOperation(FateService.java:144)
	at org.apache.accumulo.core.master.thrift.FateService$Client.executeFateOperation(FateService.java:125)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.executeFateOperation(TableOperationsImpl.java:252)
	at org.apache.accumulo.core.client.admin.TableOperationsImpl.doFateOperation(TableOperationsImpl.java:305)
	... 13 more
{noformat}","03/Jan/14 17:25;jira-bot;Commit a573f96d434fb5ef3016b8f7d3d9904e4fd88d65 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a573f96 ]

ACCUMULO-1743 wait for the trace table to exist
","03/Jan/14 17:26;jira-bot;Commit a573f96d434fb5ef3016b8f7d3d9904e4fd88d65 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a573f96 ]

ACCUMULO-1743 wait for the trace table to exist
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
proxy does not handle Key timestamps correctly,ACCUMULO-1994,12683651,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,bfloss,bfloss,09/Dec/13 18:21,02/Jan/14 17:44,13/Mar/19 22:01,02/Jan/14 17:43,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,proxy,,,,,,0,,,,,"The proxy thrift IDL does not declare any default values for the Key struct.  This means that timestamp will default to 0.  However, in Java it defaults to Long.MAX_VALUE.  This means that ranges created through the proxy may behave differently than ranges created in Java.  For example, say in Ruby I create a range as follows
{code}
range = Range.new(:start => Key.new(:row => ""row1""), :startInclusive => true, :stop => Key.new(:row => ""row2""), :stopInclusive => true)
{code}
This range will not include any keys in row1 that don't have a column family, qualifier, or visibility since timestamp of 0 sorts last.  If I created the same range in Java, those keys would be included.

Change the thrift IDL to declare 0x7FFFFFFFFFFFFFFF (Long.MAX_VALUE) as the default value for timstamp so that the thrift-generated Key class behaves the same way as the Java version.

[~kturner] pointed me to the getRowRange helper method on the AccumuloProxy service.  This method helps in some cases, but not the case I mentioned above since I have two arbitrary rows.  Also, in looking through the code in ProxyServer, Keith noticed that the code does not seem to handle timestamps correctly.  For example, the getRowRange method does not pass a timestamp at all (not even the EMPTY value).  Also, the internal helper method getProxyKey ignores the timestamp on the incoming key.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-02 17:42:54.416,,,no_permission,,,,,,,,,,,,362723,,,Thu Jan 02 17:44:25 UTC 2014,,,,,,0|i1qivj:,363017,,,,,,,,"09/Dec/13 19:45;bfloss;Actually, I investigated this further, and it appears that getRowRange doesn't work at all.  The start and end of the range are the same Key (one with the supplied row as the row and Long.MAX_VALUE as the timestamp).","02/Jan/14 17:42;jira-bot;Commit 27ee2367056e5ad0cb6175f91154cd13d49e2c95 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27ee236 ]

ACCUMULO-1993 ACCUMULO-1994 make proxy useful for ruby, fix getRowRange (and test it)
","02/Jan/14 17:43;jira-bot;Commit 27ee2367056e5ad0cb6175f91154cd13d49e2c95 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27ee236 ]

ACCUMULO-1993 ACCUMULO-1994 make proxy useful for ruby, fix getRowRange (and test it)
","02/Jan/14 17:43;jira-bot;Commit 27ee2367056e5ad0cb6175f91154cd13d49e2c95 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27ee236 ]

ACCUMULO-1993 ACCUMULO-1994 make proxy useful for ruby, fix getRowRange (and test it)
","02/Jan/14 17:44;jira-bot;Commit 27ee2367056e5ad0cb6175f91154cd13d49e2c95 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27ee236 ]

ACCUMULO-1993 ACCUMULO-1994 make proxy useful for ruby, fix getRowRange (and test it)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
proxy classes conflict with Ruby system classes,ACCUMULO-1993,12683642,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,bfloss,bfloss,09/Dec/13 17:48,02/Jan/14 17:44,13/Mar/19 22:01,02/Jan/14 17:42,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,proxy,,,,,,0,,,,,"The proxy declares the Range class, however this class also exists as a Ruby system class, which causes problems when attempting to construct ranges.  Really, all the generated classes for Ruby should be placed in an Accumulo namespace.  Add the appropriate declaration, such as
{code}
namespace rb Accumulo
{code}
to the proxy thrift IDL.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-09 18:37:38.835,,,no_permission,,,,,,,,,,,,362714,,,Thu Jan 02 17:44:10 UTC 2014,,,,,,0|i1qitj:,363008,,,,,,,,"09/Dec/13 18:37;elserj;This is literally a one-line fix, right? This is easily something we should get done before 1.6.0 is cut.","09/Dec/13 18:57;bfloss;Yup, I've been testing with exactly the line I listed above in my local copy and everything seems to be working ok.  The readme needs to be updated to reflect the namespace change, so it's not quite a one liner, but still pretty easy. :)",09/Dec/13 19:12;busbey;Does that change cause any kind of breakage for the API?,"09/Dec/13 19:21;elserj;For the Ruby proxy api? Absolutely -- like Brian said, the names are no longer the same :P

Another reason for getting this into 1.6. Although, I don't really care about changing this mid-stream for 1.4 and 1.5 because conflicting with Ruby system classes is pretty bad. You might be able to get around it with some bonkers monkeypatching or similar, but that's just silly IMO.","09/Dec/13 19:23;bfloss;It depends... At the thrift communication level, it doesn't cause any problems.  Anyone who uses the new IDL to generate Ruby proxies would have to modify their Ruby code to reflect the namespace change.  But, they'd be able to use the Range class.  It seems much less fragile than renaming the Range class, but that's just my $0.02.

While I'm thinking about it, does Python have a range class too?  Will we run into the same problem there?","02/Jan/14 15:37;elserj;bq. While I'm thinking about it, does Python have a range class too? Will we run into the same problem there?

It's been a while since I've python'ed, but, giving their API docs a glance over, I don't see one (they do have a {{range()}} function, though). I'll test out a quick example while I do this.

Although, it may just be more straightforward to provide a namespace for it (before we find ourselves back in this situation again).","02/Jan/14 17:42;jira-bot;Commit 27ee2367056e5ad0cb6175f91154cd13d49e2c95 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27ee236 ]

ACCUMULO-1993 ACCUMULO-1994 make proxy useful for ruby, fix getRowRange (and test it)
","02/Jan/14 17:43;jira-bot;Commit 27ee2367056e5ad0cb6175f91154cd13d49e2c95 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27ee236 ]

ACCUMULO-1993 ACCUMULO-1994 make proxy useful for ruby, fix getRowRange (and test it)
","02/Jan/14 17:43;jira-bot;Commit 27ee2367056e5ad0cb6175f91154cd13d49e2c95 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27ee236 ]

ACCUMULO-1993 ACCUMULO-1994 make proxy useful for ruby, fix getRowRange (and test it)
","02/Jan/14 17:44;jira-bot;Commit 27ee2367056e5ad0cb6175f91154cd13d49e2c95 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27ee236 ]

ACCUMULO-1993 ACCUMULO-1994 make proxy useful for ruby, fix getRowRange (and test it)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cannot clear root table problem reports,ACCUMULO-2029,12685033,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,16/Dec/13 19:50,02/Jan/14 14:17,13/Mar/19 22:01,17/Dec/13 00:16,,,,,,,,1.6.0,,,monitor,,,,,,0,16_qa_bug,,,,Root table problems do not clear when I select the link to clear them in the monitor.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2031,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-17 00:12:14.519,,,no_permission,,,,,,,,,,,,364110,,,Tue Dec 17 21:22:50 UTC 2013,,,,,,0|i1qref:,364410,,,,,,,,"17/Dec/13 00:12;jira-bot;Commit f37342bab253d939f70e9616a222379ea2843334 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f37342b ]

ACCUMULO-2029 root table errors go in zookeeper (for now), don\'t need to decode url-encoded parameters on the recv side, the server does that for you
","17/Dec/13 00:12;jira-bot;Commit f37342bab253d939f70e9616a222379ea2843334 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f37342b ]

ACCUMULO-2029 root table errors go in zookeeper (for now), don\'t need to decode url-encoded parameters on the recv side, the server does that for you
","17/Dec/13 21:22;jira-bot;Commit 5bb28edba7ff587191e8c33cd909e3677465af48 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5bb28ed ]

ACCUMULO-2029 remove unnecessary import
","17/Dec/13 21:22;jira-bot;Commit 5bb28edba7ff587191e8c33cd909e3677465af48 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5bb28ed ]

ACCUMULO-2029 remove unnecessary import
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Concurrent Randomwalk fails on namespace,ACCUMULO-2085,12686231,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,23/Dec/13 23:27,02/Jan/14 14:12,13/Mar/19 22:01,24/Dec/13 04:09,,,,,,,,1.6.0,,,test,,,,,,0,16_qa_bug,,,,"{noformat}
20 17:51:47,137 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Concurrent.xml
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
	at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
	at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.accumulo.start.Main$1.run(Main.java:137)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.Exception: Error running node ct.DeleteNamespace
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
	... 8 more
Caused by: org.apache.accumulo.core.client.NamespaceNotEmptyException: Namespace nspc_000 (Id=s) it not empty, contains at least one table
	at org.apache.accumulo.core.client.admin.NamespaceOperationsImpl.delete(NamespaceOperationsImpl.java:228)
	at org.apache.accumulo.test.randomwalk.concurrent.DeleteNamespace.visit(DeleteNamespace.java:42)
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-24 04:09:14.954,,,no_permission,,,,,,,,,,,,365204,,,Tue Dec 24 06:19:46 UTC 2013,,,,,,0|i1qy5z:,365509,,,,,,,,"24/Dec/13 04:09;jira-bot;Commit 31f4fbf791935270d1e8094cc539f5eb1932ef92 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=31f4fbf ]

ACCUMULO-2085 Also catch NamespaceNotEmptyException when deleting a namespace.
","24/Dec/13 06:19;jira-bot;Commit 31f4fbf791935270d1e8094cc539f5eb1932ef92 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=31f4fbf ]

ACCUMULO-2085 Also catch NamespaceNotEmptyException when deleting a namespace.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Invalid table names (& namespaces) should have dedicated error codes,ACCUMULO-1965,12682775,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,vines,vines,04/Dec/13 22:33,31/Dec/13 23:29,13/Mar/19 22:01,28/Dec/13 01:10,,,,,,,,1.6.0,,,client,,,,,,0,,,,,"To improve the client API, we should minimize the number of exceptions that require String parsing to determine the exception type. Table naming errors is one of them.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-05 16:29:28.843,,,no_permission,,,,,,,,,,,,362032,,,Sat Dec 28 01:07:47 UTC 2013,,,,,,0|i1qemf:,362327,,,,,,,,"05/Dec/13 16:29;ctubbsii;Following the guidelines in ""Effective Java"", this type of error seems to be of the ""programmer error"" type, and as such, I think a RuntimeException with an informative error message is perfectly acceptable (so long as the message gets propagated to the client).","05/Dec/13 16:38;vines;While that is great for user facing applications, I do not interpret Accumulo as that. Accumulo is a backend, and it is more likely for apps to be written around  the accumulo client API. Unless you want to force the checking onto programmer writing a client, at which point you need to make the method for validating table names part of the public API. Either method is acceptable to me, but the former seemed the more straight forward and useful.","05/Dec/13 16:46;elserj;bq. Either method is acceptable to me, but the former seemed the more straight forward and useful.

Agreed","05/Dec/13 17:12;ctubbsii;I think API design principles tend to apply regardless of the argument of whether or not the API is ""user facing"". I can't see how we could even make that distinction, anyway... because all APIs are subject to being wrapped.

I just don't see a problem with the basic IllegalArgumentException with an informative message. If the API is wrapped and gets arguments from users, it should do its own argument validation before passing to Accumulo's API. We could make it easier to do this argument validation, though... and I think I'd prefer that option if there's a sensible way to do that. However, we already throw IllegalArgumentException for a lot of our API if the argument is unexpectedly null... and from an API perspective, I'm not sure this kind of error is functionally any different than that kind of error... they're both illegal arguments.

In essence, I think: if we document what are valid arguments, and you're a consumer of that API, then you need to ensure that the arguments you provide are valid arguments. This is true for anything using the API... whether you are an end user, or a wrapper.","05/Dec/13 17:36;busbey;bq. In essence, I think: if we document what are valid arguments, and you're a consumer of that API, then you need to ensure that the arguments you provide are valid arguments. This is true for anything using the API... whether you are an end user, or a wrapper.

+1 I agree with Christopher. Consider some example uses of our API.

with additional exception types:
{code}
public void userProvidedTable(String table) {
  try {
    connection.tableOperations().create(table);
    // ... 
  } catch (InvalidTableNameException exception) {
    // Provide user feedback about problem
  }
}
{code}

with an validity helper method
{code}
public void userProvidedTable(String table) {
  if (!(TableOperationsHelper.isValidTableName(table))) {
    // Provide user feedback about problem
  }
  connection.tableOperations().create(table);
  // ...
}
{code}

The validity of the table name isn't an unexpected situation that you can't know before you make the call (like e.g. if the table will exist when Accumulo goes to actually make the table).","05/Dec/13 17:48;vines;Valid table names aren't quite the same as null arguments. We should provide a utility for checking because users shouldn't depend on constants.valid table regex. 


Then, if they still fail, it could be an illegal argument exception or a typed exception (but never just a runtime exception) . And an illegal argument exception should be fine because that's the only real argument to create table. 

So either solution should work, but it seems like we should have a table name check utility available to users in the client api. ","05/Dec/13 18:05;busbey;bq. Then, if they still fail, it could be an illegal argument exception or a typed exception (but never just a runtime exception) . And an illegal argument exception should be fine because that's the only real argument to create table.

I agree that it should be an IllegalArgumentException.

bq. but it seems like we should have a table name check utility available to users in the client api.

AFAICT, we all agree on this point. How about going with a static method on TableOperationsHelper?

As an aside, do we have table name restrictions documented somewhere?  Other than Constants.VALID_TABLE_REGEX, I don't see anything and that's not in the public API. Namespaces have a note in the javadocs for the create method on NamespaceOperations.","05/Dec/13 18:20;kturner;bq. As an aside, do we have table name restrictions documented somewhere?

This would be nice to have in the javadoc","05/Dec/13 19:07;vines;Actually, looked at the code. Invalid table name presents as an AccumuloException, where as a null table name or null TimeType present as IllegalArgumentException. This is a good start, because having ambiguity between not providing a required field vs. having an invalid field type is an issue. My main gripe currently is that non-existence of a namespace presents as the exact same error as an invalid table name (as well as conflict with meta table names), which results in needing to parse error messages in order to disambiguate. There is a similar issue, though less critical, with namespace creation.","05/Dec/13 19:22;busbey;bq. My main gripe currently is that non-existence of a namespace presents as the exact same error as an invalid table name 

Shouldn't this use NamespaceNotFoundException ?","05/Dec/13 19:47;vines;It should, but then it's an API change. Currently that exception is only used by clone and importTable, in which they are inconsistently wrapped in IllegalArgumentExceptions and RuntimeExceptions, respectively.","05/Dec/13 19:49;vines;That was why I suggested that NamespaceNotFound/Exists/NotEmpty should all extend AccumuloException to get around those issues (and ultimately I think the various Table* exceptions should as well), but that idea was rejected without consensus here https://reviews.apache.org/r/15166/#comment54506 ","05/Dec/13 20:03;busbey;bq. It should, but then it's an API change.

This is all going in 1.6.0, right? I thought we made API changes across major versions?

bq. That was why I suggested that NamespaceNotFound/Exists/NotEmpty should all extend AccumuloException to get around those issues 

Code written against the create table API in 1.5 couldn't have known about namespaces. If we're making API change decisions with an eye towards making said code work in a mixed environment, extending AccumuloException would be a reasonable way to do that.

The reviewboard feedback you mention looks mostly ambivalent. Maybe this particular set of implications is worth its own ticket+patch or a mailing list thread?","05/Dec/13 20:12;vines;Done, ACCUMULO-1970

As for API changes, we can add APIs no problem, but changing existing ones require a deprecation cycle. This includes adding new exception types to the signature.","05/Dec/13 21:29;ctubbsii;Okay, I'm getting a grasp on what the bug actually is and what needs to be fixed.

Table operations like clone table and create table currently throw a TableNotFoundException, wrapped in a RuntimeException (because they're not technically supposed to happen (we should be throwing an AssertionError here, not a RuntimeException, anyway), but do, because we're re-using the ThriftTableOperationException to return a NOTFOUND code, which is interpreted as a TableNotFoundException).

I will fix this.

I could not find the importTable problem [~vines] was referring to.

I don't think this problem extends beyond clone and create, because in all other cases, we're only looking for an existing fully-qualified table, and it doesn't really matter why the table doesn't exist. In fact, it shouldn't even have to reveal more information than necessary (like the fact that a namespace exists or doesn't exist) when the fully-qualified table doesn't exist.","05/Dec/13 21:31;ctubbsii;Oops, didn't mean to add previous comment... it's old, before further discussions with [~vines]. What we've settled on is sending back an opcode for the namespace not found over the wire, and on the client side turning the opcode into an AccumuloException containing a NamespaceNotFoundException.

The intent is to revisit this in the future and see what we can do to clean this up.","28/Dec/13 01:03;jira-bot;Commit f35e3f47265868c560b3d49edebf1a8c24196512 in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f35e3f4 ]

ACCUMULO-1965 Fix exception handling for namespaces

  Make the exception handling propagate correctly to the client.
  Vastly expanded on existing namespace tests to include checks for
  throwing the correct exceptions. Consolidated a lot of the fate
  operations code and refactored the master (slightly; moved inner
  classes to separate files) to be easier to modify the relevant RPC
  handling code.

  Fixed many API bugs related to throwing correct exceptions, found from
  the new tests added to NamespacesIT.
","28/Dec/13 01:07;jira-bot;Commit f35e3f47265868c560b3d49edebf1a8c24196512 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f35e3f4 ]

ACCUMULO-1965 Fix exception handling for namespaces

  Make the exception handling propagate correctly to the client.
  Vastly expanded on existing namespace tests to include checks for
  throwing the correct exceptions. Consolidated a lot of the fate
  operations code and refactored the master (slightly; moved inner
  classes to separate files) to be easier to modify the relevant RPC
  handling code.

  Fixed many API bugs related to throwing correct exceptions, found from
  the new tests added to NamespacesIT.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ClassLoaderIT fails,ACCUMULO-2117,12686878,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,busbey,vines,vines,31/Dec/13 21:52,31/Dec/13 23:03,13/Mar/19 22:01,31/Dec/13 22:54,,,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"Seeing this failure of the ClassloaderIT from maven-

{code}Running org.apache.accumulo.test.functional.ClassLoaderIT
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 18.683 sec <<< FAILURE!
test(org.apache.accumulo.test.functional.ClassLoaderIT)  Time elapsed: 13.588 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<Test[Y]> but was:<Test[X]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.accumulo.test.functional.ClassLoaderIT.scanCheck(ClassLoaderIT.java:80)
	at org.apache.accumulo.test.functional.ClassLoaderIT.test(ClassLoaderIT.java:70)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{code}","mvn --version
Apache Maven 3.0.4
Maven home: /usr/share/maven
Java version: 1.6.0_27, vendor: Sun Microsystems Inc.
Java home: /usr/lib/jvm/java-6-openjdk-amd64/jre
Default locale: en_US, platform encoding: UTF-8
OS name: ""linux"", version: ""3.11.0-14-generic"", arch: ""amd64"", family: ""unix""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31/Dec/13 22:38;busbey;ACCUMULO-2117.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12620991/ACCUMULO-2117.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-12-31 21:57:21.918,,,no_permission,,,,,,,,,,,,365873,,,Tue Dec 31 22:54:45 UTC 2013,,,,,,0|i1r2f3:,366179,,,,,,,,"31/Dec/13 21:57;elserj;Fails for me too (mvn 3.1.1, oracle jdk 1.7.0_40, OSX)","31/Dec/13 22:00;busbey;I'm getting the analogous test failing on 1.4 functional tests. I have a couple of additional local repo patches, but I didn't expect them to impact this.

java 1.6.0_31-b04",31/Dec/13 22:06;busbey;missed the centos 6.4 bit.,"31/Dec/13 22:14;busbey;the patch from ACCUMULO-1910 appears to have set both the X and Y combiners to be X combiners

{noformat}
busbey2-MBA:accumulo busbey$ mkdir combinerx combinery
busbey2-MBA:accumulo busbey$ cd combinerx
busbey2-MBA:combinerx busbey$ ls
busbey2-MBA:combinerx busbey$ jar -xf ../test/system/auto/TestCombinerX.jar 
busbey2-MBA:combinerx busbey$ cd ../combinery
busbey2-MBA:combinery busbey$ jar -xf ../test/system/auto/TestCombinerY.jar 
busbey2-MBA:combinery busbey$ cd ..
busbey2-MBA:accumulo busbey$ diff -r combinerx combinery
busbey2-MBA:accumulo busbey$ 
{noformat}

editing the combiner in TestCombinerY.jar shows that it is writing TestX values.","31/Dec/13 22:38;busbey;manually unpacked, updated Y combiner to write ""TestY"" values, manually packaged, tested with 1.4.5-SNAPSHOT functional test.","31/Dec/13 22:54;jira-bot;Commit 0b6749a4f75bc3fa3ea256c75e5e2ad86103fdb3 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0b6749a ]

ACCUMULO-2117 ClassLoader test fails to tell the difference on Combiner change.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
","31/Dec/13 22:54;jira-bot;Commit 0b6749a4f75bc3fa3ea256c75e5e2ad86103fdb3 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0b6749a ]

ACCUMULO-2117 ClassLoader test fails to tell the difference on Combiner change.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
","31/Dec/13 22:54;jira-bot;Commit 0b6749a4f75bc3fa3ea256c75e5e2ad86103fdb3 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0b6749a ]

ACCUMULO-2117 ClassLoader test fails to tell the difference on Combiner change.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MasterClient.execute() eats table exceptions,ACCUMULO-2088,12686245,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,24/Dec/13 01:40,30/Dec/13 23:55,13/Mar/19 22:01,30/Dec/13 23:55,,,,,,,,1.6.0,,,,,,,,,0,,,,,"MasterClient.execute() tries to handle all the exceptions, and just wraps ThriftTableOperationExceptions in an AccumuloException instead of throwing the correct corresponding TableNotFoundException, etc...

At the very least, this has an impact on setProperty() and removeProperty() in TableOperations.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,365218,,,Mon Dec 30 23:55:37 UTC 2013,,,,,,0|i1qy93:,365523,,,,,,,,30/Dec/13 23:55;ctubbsii;Inadvertently fixed in ACCUMULO-1965,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master not balancing because balance information is out-of-date,ACCUMULO-1088,12633914,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,25/Feb/13 14:46,30/Dec/13 23:41,13/Mar/19 22:01,15/Mar/13 17:28,1.4.2,,,,,,,1.5.0,,,master,,,,,,0,,,,,"During tests with agitation, the test cluster would become unbalanced because the master did not realize a dead server was restarted.  All servers would be up, but the master would think that a dead server was still out there.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-25 17:08:30.633,,,no_permission,,,,,,,,,,,,314408,,,Mon Dec 30 23:41:15 UTC 2013,,,,,,0|i1i97z:,314753,,,,,,,,"25/Feb/13 17:08;hudson;Integrated in Accumulo-Trunk #743 (See [https://builds.apache.org/job/Accumulo-Trunk/743/])
    ACCUMULO-1088 when new tservers are noticed, remove any matching bad server information (Revision 1449757)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
","25/Feb/13 17:22;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #101 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/101/])
    ACCUMULO-1088 when new tservers are noticed, remove any matching bad server information (Revision 1449757)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
",27/Dec/13 23:05;ctubbsii;[~ecn] Had somebody ask me: is there a good workaround for this bug for 1.4.x?,"27/Dec/13 23:25;elserj;bq. is there a good workaround for this bug for 1.4.x?

Besides:

{noformat}
pkill -f maste[r] && $ACCUMULO_HOME/bin/start-here.sh
{noformat}

on the host running the master? I'm not aware of one.","28/Dec/13 18:27;ecn;I have a vague recollection of a change that [~kturner] made for 1.5 that made this problem go away.  I've not chased it down to a particular commit, but it had something to do with re-establishing connections to tservers in the master whenever there was an IOException.","28/Dec/13 18:36;mdrob;Are you thinking of ACCUMULO-1477 (fixVersion 1.4.4), which was a back port of ACCUMULO-513 (fixVersion 1.5.0)?",30/Dec/13 23:41;ctubbsii;The issue was fixed in ACCUMULO-2112.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master does not balance after intermittent communication failure,ACCUMULO-2112,12686777,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,30/Dec/13 18:06,30/Dec/13 22:23,13/Mar/19 22:01,30/Dec/13 19:11,1.4.0,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,1.5.1,1.4.5,1.5.1,1.6.0,master,,,,,,0,,,,,"The master had a momentary connection timeout error collecting stats from a single tablet server.  Because the connection was re-established on the next attempt, the master did not remove it from the bad servers list.  Because the bad server list was not cleared, it did not re-balance.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1088,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-30 19:10:02.963,,,no_permission,,,,,,,,,,,,365770,,,Mon Dec 30 22:23:58 UTC 2013,,,,,,0|i1r1sf:,366077,,,,,,,,"30/Dec/13 19:10;jira-bot;Commit f56ae10b3e72e6d03fa6324afcd23619ea94b7b9 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f56ae10 ]

ACCUMULO-2112 clear the bad server list of any server that is communicating
","30/Dec/13 19:10;jira-bot;Commit f56ae10b3e72e6d03fa6324afcd23619ea94b7b9 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f56ae10 ]

ACCUMULO-2112 clear the bad server list of any server that is communicating
","30/Dec/13 19:10;jira-bot;Commit f56ae10b3e72e6d03fa6324afcd23619ea94b7b9 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f56ae10 ]

ACCUMULO-2112 clear the bad server list of any server that is communicating
","30/Dec/13 19:10;jira-bot;Commit f56ae10b3e72e6d03fa6324afcd23619ea94b7b9 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f56ae10 ]

ACCUMULO-2112 clear the bad server list of any server that is communicating
","30/Dec/13 22:23;mjwall;This issue showed up in the master logs as ""ERROR: unable to get tablet server status"".  The tservers appeared to lose connection for a brief time, less than 30 seconds, but then start communicating again.  The server would then show up by IP in the list of Unresponsive servers and by hostname in the Tablet Servers when looking at the Tablet Server page of the monitor.  

I can verify applying this one line fix to the 1.4.4 tag removes the server from the list of unresponsive servers and balancing begins again when there are no unresponsive servers.

The ""unable to get server status""  should still show up in the master logs.  Maybe it is actually meaningful.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[RW] Multitable.CopyTable failed from using a closed ZooKeeperInstance,ACCUMULO-2105,12686571,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,elserj,elserj,27/Dec/13 20:58,30/Dec/13 22:17,13/Mar/19 22:01,30/Dec/13 21:24,,,,,,,,1.6.0,,,test,,,,,,0,randomwalk,,,,"{noformat}
27 02:03:25,324 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node MultiTable.xml
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
	at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
	at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.accumulo.start.Main$1.run(Main.java:137)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.Exception: Error running node mt.CopyTable
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
	... 8 more
Caused by: java.io.IOException: java.lang.RuntimeException: ZooKeeperInstance has been closed.
	at org.apache.accumulo.core.client.mapreduce.AbstractInputFormat.getSplits(AbstractInputFormat.java:596)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:491)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:508)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:392)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1268)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1265)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1265)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1286)
	at org.apache.accumulo.test.randomwalk.multitable.CopyTool.run(CopyTool.java:79)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.accumulo.test.randomwalk.multitable.CopyTable.visit(CopyTable.java:59)
	at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
	... 9 more
Caused by: java.lang.RuntimeException: ZooKeeperInstance has been closed.
	at org.apache.accumulo.core.client.ZooKeeperInstance.getInstanceID(ZooKeeperInstance.java:162)
	at org.apache.accumulo.core.security.Credentials.toThrift(Credentials.java:62)
	at org.apache.accumulo.core.client.impl.ThriftScanner.getBatchFromServer(ThriftScanner.java:99)
	at org.apache.accumulo.core.metadata.MetadataLocationObtainer.lookupTablet(MetadataLocationObtainer.java:100)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl.lookupTabletLocation(TabletLocatorImpl.java:462)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl._locateTablet(TabletLocatorImpl.java:619)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl.binRanges(TabletLocatorImpl.java:278)
	at org.apache.accumulo.core.client.impl.TabletLocatorImpl.binRanges(TabletLocatorImpl.java:353)
	at org.apache.accumulo.core.client.mapreduce.AbstractInputFormat.getSplits(AbstractInputFormat.java:582)
	... 23 more
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-30 21:24:58.738,,,no_permission,,,,,,,,,,,,365562,,,Mon Dec 30 22:17:38 UTC 2013,,,,,,0|i1r0if:,365870,,,,,,,,"30/Dec/13 21:24;jira-bot;Commit 379881e69bd7e93f11cfa13b415afe14be8634f6 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=379881e ]

ACCUMULO-2105 cannot close instance
","30/Dec/13 21:25;jira-bot;Commit 379881e69bd7e93f11cfa13b415afe14be8634f6 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=379881e ]

ACCUMULO-2105 cannot close instance
","30/Dec/13 21:33;elserj;[~ecn], do these changes also satisfy the comments on ACCUMULO-1923, notably MapReduceIT?","30/Dec/13 21:43;ecn;ACCUMULO-1923 is still open, and will probably not get closed.  This experience is making me lean away from making {{Instance}} a {{Closable}} or even having the {{close}} method.  ","30/Dec/13 21:46;elserj;Final implementation aside, I was only concerned about tests that were left broken due to the changes that were applied. I suppose I can run the MapReduceIT myself with your changes.

Thanks for looking at this, too.",30/Dec/13 22:17;busbey;[~ecn] please bring up your issues in the mailing list thread on resource cleanup.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Makefile overwrites JAVA_HOME from env,ACCUMULO-2101,12686534,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,27/Dec/13 16:28,27/Dec/13 17:45,13/Mar/19 22:01,27/Dec/13 17:45,,,,,,,,1.6.0,,,build,,,,,,0,,,,,"The Makefile attempts to calculate {{JAVA_HOME}} based on some assumptions about how it thinks the installation looks like.

For systems that already have JAVA_HOME defined, we don't need to make these assumptions and can fall back to what is already defined.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-27 17:01:00.773,,,no_permission,,,,,,,,,,,,365525,,,Fri Dec 27 17:29:53 UTC 2013,,,,,,0|i1r047:,365826,,,,,,,,"27/Dec/13 17:01;jira-bot;Commit 7838d4035f78376cbbd7452f7f8b013d4b398857 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7838d40 ]

ACCUMULO-2101 Check the environment for JAVA_HOME for native-maps Makefile

Pull the value for JAVA_HOME out of the environment instead of blindly setting
it relative to the location of a javah executable. If we have an empty value,
then fall back on the old calculation.
","27/Dec/13 17:29;jira-bot;Commit 7838d4035f78376cbbd7452f7f8b013d4b398857 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7838d40 ]

ACCUMULO-2101 Check the environment for JAVA_HOME for native-maps Makefile

Pull the value for JAVA_HOME out of the environment instead of blindly setting
it relative to the location of a javah executable. If we have an empty value,
then fall back on the old calculation.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Cannot click through 'accumulo.root' table link in ""Table List"" view.",ACCUMULO-2067,12685652,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,brassard,brassard,19/Dec/13 18:45,20/Dec/13 18:07,13/Mar/19 22:01,20/Dec/13 06:50,,,,,,,,1.6.0,,,monitor,,,,,,0,,,,,"The link should bring the user to ""Participating Tablet Servers"" view, but does not.

The table names used to create the anchors need to be URL encoded",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-20 06:50:08.957,,,no_permission,,,,,,,,,,,,364727,,,Fri Dec 20 18:07:39 UTC 2013,,,,,,0|i1qv73:,365027,,,,,,,,"20/Dec/13 06:50;jira-bot;Commit e7f68b586f8317b1e1e94aa56e6adbeacc10670f in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e7f68b5 ]

ACCUMULO-2067 urlencode the table id used in the link.
","20/Dec/13 16:10;jira-bot;Commit e7f68b586f8317b1e1e94aa56e6adbeacc10670f in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e7f68b5 ]

ACCUMULO-2067 urlencode the table id used in the link.
","20/Dec/13 18:07;jira-bot;Commit 4cf60b651fa86c6ac2a6e9501dbdd2ae5467ff8f in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cf60b6 ]

ACCUMULO-2067 Use urlencoding method already present in BasicServlet (thanks, [~ecn]).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IndexOutOfBoundsException,ACCUMULO-2074,12685817,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,20/Dec/13 13:59,20/Dec/13 16:13,13/Mar/19 22:01,20/Dec/13 16:13,,,,,,,,1.6.0,,,master,,,,,,0,,,,,"Running randomwalk test.  Saw this in the master logs:

{noformat}
2013-12-19 21:52:52,800 [thrift.ProcessFunction] ERROR: Internal error processing reportSplitExtent
java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
        at java.util.ArrayList.rangeCheck(ArrayList.java:635)
        at java.util.ArrayList.get(ArrayList.java:411)
        at org.apache.accumulo.master.Master$MasterClientServiceHandler.reportSplitExtent(Master.java:873)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at com.sun.proxy.$Proxy16.reportSplitExtent(Unknown Source)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Processor$reportSplitExtent.getResult(MasterClientService.java:2028)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Processor$reportSplitExtent.getResult(MasterClientService.java:2014)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:744)
{noformat}

Did not seem to affect anything, but I'm looking into other problems that occurred during the test.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-20 16:10:38.505,,,no_permission,,,,,,,,,,,,364935,,,Fri Dec 20 16:10:46 UTC 2013,,,,,,0|i1qwh3:,365235,,,,,,,,"20/Dec/13 16:10;jira-bot;Commit 6bf68ed0d6e725b8866e304fef693c9f6c6f71fe in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6bf68ed ]

ACCUMULO-2057 caused ACCUMULO-2074 ACCUMULO-2075; copy-paste-error
","20/Dec/13 16:10;jira-bot;Commit 551c6507d5f558fe45aad30b2de42dbf5c3005e0 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=551c650 ]

ACCUMULO-2057 caused ACCUMULO-2074 ACCUMULO-2075; copy-paste-error, re-adding the patch from ACCUMULO-2057 back into master
","20/Dec/13 16:10;jira-bot;Commit 6bf68ed0d6e725b8866e304fef693c9f6c6f71fe in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6bf68ed ]

ACCUMULO-2057 caused ACCUMULO-2074 ACCUMULO-2075; copy-paste-error
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConditionalWriterIT missing timeouts,ACCUMULO-2073,12685745,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,20/Dec/13 04:36,20/Dec/13 06:52,13/Mar/19 22:01,20/Dec/13 06:52,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"The ConditionalWriterIT doesn't have any timeouts and sits indefinitely for me (on a Mac, but that's not the point here).

Add the timeouts to the Test annotation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-20 05:04:47.968,,,no_permission,,,,,,,,,,,,364820,,,Fri Dec 20 05:04:47 UTC 2013,,,,,,0|i1qvrj:,365120,,,,,,,,"20/Dec/13 05:04;jira-bot;Commit 82d0555c7fef2668588d0f8fcb02b8ca71c325e0 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=82d0555 ]

ACCUMULO-2073 Add in some basic timeouts on the conditional writer ITs
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Perform validation on ACCUMULO_HOME,ACCUMULO-1997,12683707,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,09/Dec/13 23:01,20/Dec/13 05:58,13/Mar/19 22:01,20/Dec/13 05:58,,,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"ACCUMULO-1785 changed how config.sh works in such a way that ACCUMULO_HOME is not set by the Accumulo scripts as all.

A side-effect of this is that invalid/incorrect ACCUMULO_HOME settings silently pass through to the Java process which will fail miserably (classpaths, notably)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-20 05:55:12.865,,,no_permission,,,,,,,,,,,,362779,,,Fri Dec 20 05:58:58 UTC 2013,,,,,,0|i1qj7z:,363073,,,,,,,,"10/Dec/13 21:13;elserj;Just ran into another way that this could manifest itself -- start-all.sh will happily start extra processes on your box. I was testing some changes in a local directory (instead of where I normally run Accumulo), opened a new shell, and did a start-all.sh. Took a while to realize that I didn't reset my ACCUMULO_HOME and it started an extra set of processes.","20/Dec/13 05:55;jira-bot;Commit 36f503c653b2edbd29b37f79852602660e564db2 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=36f503c ]

ACCUMULO-1997 Verify that the ACCUMULO_HOME (computed or provided) is actually a directory
","20/Dec/13 05:57;jira-bot;Commit 36f503c653b2edbd29b37f79852602660e564db2 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=36f503c ]

ACCUMULO-1997 Verify that the ACCUMULO_HOME (computed or provided) is actually a directory
","20/Dec/13 05:57;jira-bot;Commit 36f503c653b2edbd29b37f79852602660e564db2 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=36f503c ]

ACCUMULO-1997 Verify that the ACCUMULO_HOME (computed or provided) is actually a directory
",20/Dec/13 05:58;elserj;Accumulo scripts will now exit with an error when ACCUMULO_HOME is set to a directory that does not exist.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Looking up instanceName in ZK doesn't use consistent encoding,ACCUMULO-1593,12659135,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,yuzhihong@gmail.com,ctubbsii,ctubbsii,22/Jul/13 16:53,20/Dec/13 05:12,13/Mar/19 22:01,20/Dec/13 05:12,,,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,newbie,,,,"We need to be more careful about encoding and decoding instance names and IDs in zookeeper. They should use UTF-8 explicitly, right now, they use the JVM default, which can differ between JVM runs (even between Initialize and start-all).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,01/Sep/13 16:06;yuzhihong@gmail.com;accumulo-1593-v1.txt;https://issues.apache.org/jira/secure/attachment/12600988/accumulo-1593-v1.txt,01/Sep/13 20:55;yuzhihong@gmail.com;accumulo-1593-v2.txt;https://issues.apache.org/jira/secure/attachment/12601008/accumulo-1593-v2.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-09-01 16:06:39.888,,,no_permission,,,,,,,,,,,,339328,,,Fri Dec 20 05:12:12 UTC 2013,,,,,,0|i1miz3:,339648,,,,,,,,01/Sep/13 16:06;yuzhihong@gmail.com;How about this patch ?,"01/Sep/13 17:23;mdrob;{noformat}
+        instanceId = new String(iidb, ""UTF-8"");
{noformat}
I'd prefer a UTF-8 constant (preferably a {{CharSet}}, but I wouldn't complain about a {{String}}).

{noformat}
+        Log.warn(""UTF-8 not supported"");
{noformat}
Should use the existing {{log}} field instead of a static call to {{jline.internal.Log}}. Actually, I'm not sure a warning is sufficient, since UTF-8 is one of the mandatory ones - see http://docs.oracle.com/javase/6/docs/api/java/nio/charset/Charset.html under Standard Charsets.


Orthogonal comment - why do we store the bytes of a string of a UUID (40 bytes) instead of the bytes of the longs of a UUID (16 bytes)?","01/Sep/13 20:55;yuzhihong@gmail.com;Using Constants.UTF8, UnsupportedEncodingException doesn't need to be referenced.

w.r.t. the last comment, can I handle that in a separate JIRA ?

Thanks for the quick review.","02/Sep/13 17:19;mdrob;Yea, the string v long decision should be a separate discussion. The patch looks good, but there is one other scenario that I thought of.

Could this break compatibility when upgrading from 1.5? I'm reasonably confident that a UUID serializes the same between ASCII, UTF-8, and CP1252. However, I have no idea what people use for their instance names and maybe that deserves an extra check. Probably could be a separate JIRA. [~ctubbsii], what do you think?","05/Sep/13 18:52;ctubbsii;I think it makes sense to ensure the name and the id are both UTF-8 encoded when put in ZK. Forcing this may break some fringe systems, but at the benefit of actually defining previously undefined behavior. I think it's a reasonable risk.

As for the UUID being stored as bytes from the numbers... I don't think it's a big deal. More importantly, though, there's a reason not to change it: Mike is right that it would affect upgrades... but it might be worse than that... because we don't store version information in the ZK mapping from name to instanceID. So, newer versions and older versions installed simultaneously may conflict when trying to read this mapping.","20/Dec/13 03:30;jira-bot;Commit 041b482f672bf6a147ac8c9d1646c5aee705d270 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=041b482 ]

ACCUMULO-1593 Applying Ted's patch to ensure UTF-8 String encoding applied to instance id pulled from ZK.
","20/Dec/13 04:06;jira-bot;Commit 041b482f672bf6a147ac8c9d1646c5aee705d270 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=041b482 ]

ACCUMULO-1593 Applying Ted's patch to ensure UTF-8 String encoding applied to instance id pulled from ZK.
","20/Dec/13 04:37;jira-bot;Commit 041b482f672bf6a147ac8c9d1646c5aee705d270 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=041b482 ]

ACCUMULO-1593 Applying Ted's patch to ensure UTF-8 String encoding applied to instance id pulled from ZK.
","20/Dec/13 05:12;elserj;Thanks, [~yuzhihong@gmail.com]! I had to mess with your patch a little bit due to the time delay. Sorry it took so long to get it applied -- looks like it just got lost in the breeze.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove deprecration warning on specifying a password with shell,ACCUMULO-2068,12685654,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,19/Dec/13 18:54,19/Dec/13 20:33,13/Mar/19 22:01,19/Dec/13 20:06,,,,,,,,1.6.0,,,shell,,,,,,0,,,,,"Warning the user about deprecation for the default authentication mechanism is rather rude. The shell should just default back to password authentication when I don't provide a ""scheme"" (pass:my-password)

{noformat}
2013-12-19 10:42:41,277 [shell.Shell] WARN : Specifying a raw password is deprecated.
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-19 20:06:25.744,,,no_permission,,,,,,,,,,,,364729,,,Thu Dec 19 20:33:31 UTC 2013,,,,,,0|i1qv7j:,365029,,,,,,,,"19/Dec/13 20:06;jira-bot;Commit ba0d7d34395140f147484198652a0c25bbf0f165 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ba0d7d3 ]

ACCUMULO-2068 Remove deprecation warning as we're preserving backwards compatibility for functionality that has existed
for a very long time.
","19/Dec/13 20:33;jira-bot;Commit ba0d7d34395140f147484198652a0c25bbf0f165 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ba0d7d3 ]

ACCUMULO-2068 Remove deprecation warning as we're preserving backwards compatibility for functionality that has existed
for a very long time.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shell Env interpolation lacking for kerberos configuration,ACCUMULO-2058,12685460,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,18/Dec/13 21:07,18/Dec/13 22:07,13/Mar/19 22:01,18/Dec/13 22:07,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,,client,,,,,,0,,,,,"The README recommended I used something like $ACCUMULO_CONF_DIR/accumulo.keytab for general.kerberos.keytab when configuring Accumulo to work with Kerberized HDFS, but the configuration values are not getting interpolated (only ACCUMULO_HOME is being expanded).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-18 21:58:50.173,,,no_permission,,,,,,,,,,,,364537,,,Wed Dec 18 22:07:50 UTC 2013,,,,,,0|i1qu13:,364837,,,,,,,,"18/Dec/13 21:58;jira-bot;Commit 559b18bc73225ea2cc779ec727c8f49b29ab2924 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=559b18b ]

ACCUMULO-2058 Add shell env interpolation for ACCUMULO_CONF_DIR when extracting kerberos keytab value.
","18/Dec/13 21:59;jira-bot;Commit 559b18bc73225ea2cc779ec727c8f49b29ab2924 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=559b18b ]

ACCUMULO-2058 Add shell env interpolation for ACCUMULO_CONF_DIR when extracting kerberos keytab value.
","18/Dec/13 22:06;jira-bot;Commit 559b18bc73225ea2cc779ec727c8f49b29ab2924 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=559b18b ]

ACCUMULO-2058 Add shell env interpolation for ACCUMULO_CONF_DIR when extracting kerberos keytab value.
","18/Dec/13 22:07;elserj;Fixed in 1.4 and 1.5, irrelevant in 1.6 as AccumuloConfiguration and PropertyType.PATH handle this already.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stop-here not accepting localhost,ACCUMULO-1980,12683233,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,07/Dec/13 00:28,18/Dec/13 20:50,13/Mar/19 22:01,18/Dec/13 20:50,,,,,,,,1.6.0,,,scripts,,,,,,0,,,,,"{code} bin/stop-here.sh
2013-12-06 19:26:13,798 [util.Admin] ERROR: java.lang.IllegalArgumentException: Address was expected to contain port. address=localhost
java.lang.IllegalArgumentException: Address was expected to contain port. address=localhost
	at org.apache.accumulo.core.util.AddressUtil.parseAddress(AddressUtil.java:28)
	at org.apache.accumulo.server.util.Admin.stopTabletServer(Admin.java:302)
	at org.apache.accumulo.server.util.Admin.main(Admin.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.accumulo.start.Main$1.run(Main.java:137)
	at java.lang.Thread.run(Thread.java:701)
{code}

This is running on a single node install where all processes are defined in their respective files as 'localhost'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-16 22:10:55.721,,,no_permission,,,,,,,,,,,,362485,,,Wed Dec 18 20:49:49 UTC 2013,,,,,,0|i1qhev:,362779,,,,,,,,"16/Dec/13 22:10;jira-bot;Commit 39b22d3eb5fb478376ebbf80a7d388baf5fd0338 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=39b22d3 ]

ACCUMULO-1980 admin stop HOST now defaults to port.

AddressUtil now supports a default port in general.
","16/Dec/13 22:11;jira-bot;Commit 39b22d3eb5fb478376ebbf80a7d388baf5fd0338 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=39b22d3 ]

ACCUMULO-1980 admin stop HOST now defaults to port.

AddressUtil now supports a default port in general.
",17/Dec/13 19:11;vines;Now it just hangs if there's no tserver to connect to,"18/Dec/13 20:49;jira-bot;Commit f228caff46816939b95f101942082a9da0277dce in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f228caf ]

ACCUMULO-1980 No longer tries to use master to stop tserver if no masters
","18/Dec/13 20:49;jira-bot;Commit f228caff46816939b95f101942082a9da0277dce in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f228caf ]

ACCUMULO-1980 No longer tries to use master to stop tserver if no masters
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validity checks missing for readFields and Thrift deserialization,ACCUMULO-1986,12683620,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,bhavanki,bhavanki,09/Dec/13 15:51,18/Dec/13 14:54,13/Mar/19 22:01,18/Dec/13 14:54,,,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,serialization,thrift,validation,,Classes in o.a.a.core.data (and potentially elsewhere) that support construction from a Thrift object and/or population from a {{DataInput}} (via a {{readFields()}} method) often lack data validity checks that the classes' constructors enforce. The missing checks make it possible for an attacker to create invalid objects by manipulating the bytes being read. The situation is analogous to the need to check objects deserialized from their Java serialized form within the {{readObject()}} method.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16/Dec/13 17:29;bhavanki;ACCUMULO-1986.patch;https://issues.apache.org/jira/secure/attachment/12618938/ACCUMULO-1986.patch,12/Dec/13 20:09;bhavanki;examined-classes.txt;https://issues.apache.org/jira/secure/attachment/12618462/examined-classes.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-12-18 14:53:33.239,,,no_permission,,,,,,,,,,,,362692,,,Wed Dec 18 14:53:39 UTC 2013,,,,,,0|i1qion:,362986,,,,,,,,"12/Dec/13 20:09;bhavanki;Attaching notes on 1.4.x classes that I examined for safe readFields and Thrift deserialization. This is to help others find out, for example, if I checked a particular class.","12/Dec/13 21:34;bhavanki;Review available. As suggested by [~ecn], the diff uploaded to RB is a Git patch rather than the result of the post-review tool.",16/Dec/13 17:29;bhavanki;Patch is also available as the diff used in RB.,"18/Dec/13 14:53;jira-bot;Commit adee0f129f66c346e026b1803793caa233d29930 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=adee0f1 ]

ACCUMULO-1986 Add data integrity checks to Key and Mutation

This change adds checks to the constructors for Key and Mutations which
take in Thrift data structures to ensure that required fields are not
null. These checks prevent creation of invalid objects from modified
Thrift structures.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","18/Dec/13 14:53;jira-bot;Commit adee0f129f66c346e026b1803793caa233d29930 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=adee0f1 ]

ACCUMULO-1986 Add data integrity checks to Key and Mutation

This change adds checks to the constructors for Key and Mutations which
take in Thrift data structures to ensure that required fields are not
null. These checks prevent creation of invalid objects from modified
Thrift structures.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","18/Dec/13 14:53;jira-bot;Commit a5e3ed3bb249d287d67f9079297ee5936ac2c914 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a5e3ed3 ]

ACCUMULO-1986 merge to 1.5.1-SNAPSHOT
","18/Dec/13 14:53;jira-bot;Commit 2d97b875a90a63060bbda7c9e6d7e79e68de1ae2 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2d97b87 ]

ACCUMULO-1986 merge failed to pull null pointer checks from 1.4
","18/Dec/13 14:53;jira-bot;Commit adee0f129f66c346e026b1803793caa233d29930 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=adee0f1 ]

ACCUMULO-1986 Add data integrity checks to Key and Mutation

This change adds checks to the constructors for Key and Mutations which
take in Thrift data structures to ensure that required fields are not
null. These checks prevent creation of invalid objects from modified
Thrift structures.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","18/Dec/13 14:53;jira-bot;Commit a5e3ed3bb249d287d67f9079297ee5936ac2c914 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a5e3ed3 ]

ACCUMULO-1986 merge to 1.5.1-SNAPSHOT
","18/Dec/13 14:53;jira-bot;Commit 2d97b875a90a63060bbda7c9e6d7e79e68de1ae2 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2d97b87 ]

ACCUMULO-1986 merge failed to pull null pointer checks from 1.4
","18/Dec/13 14:53;jira-bot;Commit adee0f129f66c346e026b1803793caa233d29930 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=adee0f1 ]

ACCUMULO-1986 Add data integrity checks to Key and Mutation

This change adds checks to the constructors for Key and Mutations which
take in Thrift data structures to ensure that required fields are not
null. These checks prevent creation of invalid objects from modified
Thrift structures.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","18/Dec/13 14:53;jira-bot;Commit a5e3ed3bb249d287d67f9079297ee5936ac2c914 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a5e3ed3 ]

ACCUMULO-1986 merge to 1.5.1-SNAPSHOT
","18/Dec/13 14:53;jira-bot;Commit 2d97b875a90a63060bbda7c9e6d7e79e68de1ae2 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2d97b87 ]

ACCUMULO-1986 merge failed to pull null pointer checks from 1.4
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NamespaceITs failing,ACCUMULO-2035,12685058,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,16/Dec/13 22:48,16/Dec/13 23:58,13/Mar/19 22:01,16/Dec/13 23:58,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"testNamespaceIteratorsAndConstraints(org.apache.accumulo.test.NamespacesIT)  Time elapsed: 1.357 sec  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.fail(Assert.java:95)
	at org.apache.accumulo.test.NamespacesIT.testNamespaceIteratorsAndConstraints(NamespacesIT.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)


Results :

Failed tests:   testNamespaceIteratorsAndConstraints(org.apache.accumulo.test.NamespacesIT)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-16 23:58:08.157,,,no_permission,,,,,,,,,,,,364135,,,Mon Dec 16 23:58:20 UTC 2013,,,,,,0|i1qrjz:,364435,,,,,,,,"16/Dec/13 23:58;jira-bot;Commit ae20660d8202cf511c5dbd07b164634fa6f32126 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ae20660 ]

ACCUMULO-2035 ACCUMULO-2025 I accidently made limitVersion always true instead of never true. Now proper.

Also split apart the Iterator and Constraints tests in NamespacesIT
","16/Dec/13 23:58;jira-bot;Commit ae20660d8202cf511c5dbd07b164634fa6f32126 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ae20660 ]

ACCUMULO-2035 ACCUMULO-2025 I accidently made limitVersion always true instead of never true. Now proper.

Also split apart the Iterator and Constraints tests in NamespacesIT
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
environment variables not being substituted in conf paths properly,ACCUMULO-2024,12684999,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mberman,mberman,mberman,16/Dec/13 17:06,16/Dec/13 18:00,13/Mar/19 22:01,16/Dec/13 17:17,,,,,,,,1.6.0,,,,,,,,,0,,,,,"config properties of type PATH are supposed to support substitutions of $ACCUMULO_HOME and $ACCUMULO_CONF_DIR, but at the moment that's not happening.  this makes the default SSL truststore/keystore paths invalid.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16/Dec/13 17:08;mberman;0001-ACCUMULO-2024-fix-config-path-property-env-variable-.patch;https://issues.apache.org/jira/secure/attachment/12618935/0001-ACCUMULO-2024-fix-config-path-property-env-variable-.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-12-16 17:16:09.718,,,no_permission,,,,,,,,,,,,364076,,,Mon Dec 16 18:00:52 UTC 2013,,,,,,0|i1qr6v:,364376,,,,,,,,"16/Dec/13 17:16;jira-bot;Commit 7a6fd95c8c1ad95f5001e84f00953fb9d2b620bd in branch refs/heads/1.6.0-SNAPSHOT from [~mberman]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7a6fd95 ]

ACCUMULO-2024: fix config path property env variable substitution
","16/Dec/13 17:17;vines;Oops, that's a goof. Applied your patch, thanks Michael","16/Dec/13 18:00;jira-bot;Commit 7a6fd95c8c1ad95f5001e84f00953fb9d2b620bd in branch refs/heads/master from [~mberman]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7a6fd95 ]

ACCUMULO-2024: fix config path property env variable substitution
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(default) namespace should not have iterators defined on it by default,ACCUMULO-1990,12683636,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,cmccubbin,cmccubbin,09/Dec/13 17:15,16/Dec/13 18:00,13/Mar/19 22:01,16/Dec/13 17:04,,,,,,,,1.6.0,,,,,,,,,0,,,,,"For example, the versioning iterator.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-16 17:04:14.637,,,no_permission,,,,,,,,,,,,362708,,,Mon Dec 16 18:00:51 UTC 2013,,,,,,0|i1qis7:,363002,,,,,,,,"16/Dec/13 17:04;jira-bot;Commit 82e2f57abd69e9b78eb10dc6f79d7f1a0e46576f in branch refs/heads/1.6.0-SNAPSHOT from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=82e2f57 ]

ACCUMULO-1990 - """" no longer has versioning set up by default
",16/Dec/13 17:04;vines;Removed special casing in init to set up versioning iterators,"16/Dec/13 18:00;jira-bot;Commit 82e2f57abd69e9b78eb10dc6f79d7f1a0e46576f in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=82e2f57 ]

ACCUMULO-1990 - """" no longer has versioning set up by default
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Build on clean checkout fails,ACCUMULO-1896,12679328,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mdrob,elserj,elserj,15/Nov/13 02:19,13/Dec/13 01:52,13/Mar/19 22:01,13/Dec/13 01:52,1.4.4,,,,,,,1.4.5,,,build,,,,,,0,,,,,"Likely still around since SVN->Git switch (can't keep empty dirs in Git repo).

Ran `mvn install -DskipTests`

{noformat}
[INFO] Creating debian package: /home/elserj/accumulo.git/target/accumulo_1.4.5-SNAPSHOT.deb
[INFO] Building data
[ERROR] Failed to create debian package /home/elserj/accumulo.git/target/accumulo_1.4.5-SNAPSHOT.deb
org.vafer.jdeb.PackagingException: Failed to create debian package /home/elserj/accumulo.git/target/accumulo_1.4.5-SNAPSHOT.deb
	at org.vafer.jdeb.maven.DebMaker.makeDeb(DebMaker.java:228)
	at org.vafer.jdeb.maven.DebMojo.execute(DebMojo.java:382)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:101)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:209)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:320)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:156)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:537)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:196)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:141)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:290)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:230)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:409)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:352)
Caused by: org.vafer.jdeb.PackagingException: Could not create deb package
	at org.vafer.jdeb.Processor.createDeb(Processor.java:162)
	at org.vafer.jdeb.maven.DebMaker.makeDeb(DebMaker.java:225)
	... 22 more
Caused by: java.io.FileNotFoundException: Data source not found : /home/elserj/accumulo.git/lib
	at org.vafer.jdeb.maven.Data.produce(Data.java:99)
	at org.vafer.jdeb.Processor.buildData(Processor.java:566)
	at org.vafer.jdeb.Processor.createDeb(Processor.java:127)
	... 23 more
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,12/Dec/13 17:23;mdrob;0001-ACCUMULO-1896-fix-deb-generation-on-clean-checkout.patch;https://issues.apache.org/jira/secure/attachment/12618439/0001-ACCUMULO-1896-fix-deb-generation-on-clean-checkout.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-11-15 18:15:28.666,,,no_permission,,,,,,,,,,,,358690,,,Fri Dec 13 01:51:59 UTC 2013,,,,,,0|i1pu07:,358980,,,,,,,,15/Nov/13 18:15;busbey;looks like it might be a dup of ACCUMULO-1868?,15/Nov/13 20:17;elserj;Similar but different I believe. The other you can actually build. This issue can't even create a tarball (or deb as is the source of the actual problem),"11/Dec/13 18:34;mdrob;I think this is an issue with the order that plugins are defined in the multi-module build. While {{mvn install}} fails, a {{mvn compile}} followed by {{mvn install}} works just fine.","11/Dec/13 19:29;mdrob;More specifically, the lib directory is created after the first execution of the maven-dependency-plugin. I can think of a few solutions, in increasing order of effort:

# Add an empty lib directory to the project. This will have the issue of causing bad {{deb}} builds if somebody does not run {{mvn process-dependencies}} first.
# Move the debian generation to a profile, like it is in 1.5+.
# Detect when the jdeb plugin is run and explicitly invoke process-dependencies. This will add to the build time, and make it way more complicated. I feel like [~ctubbsii] would kill me over this.

",11/Dec/13 23:25;mdrob;Patch available at https://reviews.apache.org/r/16196/,12/Dec/13 17:23;mdrob;Attaching patch here for review because review board improperly detects which sections moved in the pom.,"12/Dec/13 19:08;jira-bot;Commit 3b08c717ed69a0734b1f0230fad39c3fc123f9aa in branch refs/heads/1.4.5-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3b08c71 ]

ACCUMULO-1896 add lib/ext, logs, walogs to tgz
","12/Dec/13 19:08;jira-bot;Commit 3b08c717ed69a0734b1f0230fad39c3fc123f9aa in branch refs/heads/1.5.1-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3b08c71 ]

ACCUMULO-1896 add lib/ext, logs, walogs to tgz
","12/Dec/13 19:08;jira-bot;Commit 3b08c717ed69a0734b1f0230fad39c3fc123f9aa in branch refs/heads/1.6.0-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3b08c71 ]

ACCUMULO-1896 add lib/ext, logs, walogs to tgz
","12/Dec/13 19:08;jira-bot;Commit 3b08c717ed69a0734b1f0230fad39c3fc123f9aa in branch refs/heads/master from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3b08c71 ]

ACCUMULO-1896 add lib/ext, logs, walogs to tgz
","12/Dec/13 19:13;mdrob;Ugh, commit {{3b08c717ed69a0734b1f0230fad39c3fc123f9aa}} actually fixes ACCUMULO-1868, but I accidentally put the wrong JIRA in the commit message. Is this worth reverting or will angry people in the future be able to figure it out from this comment?",12/Dec/13 19:15;elserj;Your comment here is sufficient for me.,"13/Dec/13 01:51;jira-bot;Commit 72106a626ed27b2a849aa80639f8514b97710707 in branch refs/heads/1.4.5-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=72106a6 ]

ACCUMULO-1896 fix deb generation on clean checkout

Move .deb generation into a profile and update README
","13/Dec/13 01:51;jira-bot;Commit 72106a626ed27b2a849aa80639f8514b97710707 in branch refs/heads/1.5.1-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=72106a6 ]

ACCUMULO-1896 fix deb generation on clean checkout

Move .deb generation into a profile and update README
","13/Dec/13 01:51;jira-bot;Commit 72106a626ed27b2a849aa80639f8514b97710707 in branch refs/heads/1.6.0-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=72106a6 ]

ACCUMULO-1896 fix deb generation on clean checkout

Move .deb generation into a profile and update README
","13/Dec/13 01:51;jira-bot;Commit 72106a626ed27b2a849aa80639f8514b97710707 in branch refs/heads/master from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=72106a6 ]

ACCUMULO-1896 fix deb generation on clean checkout

Move .deb generation into a profile and update README
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Random port for Master doesn't make sense,ACCUMULO-1999,12683872,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,10/Dec/13 17:07,13/Dec/13 01:09,13/Mar/19 22:01,13/Dec/13 01:09,1.5.0,,,,,,,1.5.1,,,master,,,,,,0,,,,,"I was looking at ACCUMULO-1664. In 1.5.0, it appears that you can configure a port of 0 for the master. The master will bind itself to a random port, but none of the other procs know what that port was, so you just shot yourself in the foot.

I'd like to bring those changes back to 1.5.1 so a port of 0 actually works with the master and doesn't leave you with a broken system.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11/Dec/13 01:41;elserj;0001-ACCUMULO-1999-Backport-changes-from-1664-which-adver-3.patch;https://issues.apache.org/jira/secure/attachment/12618155/0001-ACCUMULO-1999-Backport-changes-from-1664-which-adver-3.patch,10/Dec/13 21:47;elserj;0001-ACCUMULO-1999-Backport-changes-from-1664-which-adver.patch;https://issues.apache.org/jira/secure/attachment/12618105/0001-ACCUMULO-1999-Backport-changes-from-1664-which-adver.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-12-12 21:41:37.687,,,no_permission,,,,,,,,,,,,362944,,,Thu Dec 12 23:31:08 UTC 2013,,,,,,0|i1qk9z:,363250,,,,,,,,"10/Dec/13 21:47;elserj;Backport of ACCUMULO-1664 if anyone wants to review. I tested the following:

# Random monitor, log4j, master, tserver procs and updates to other procs when those are restarted
# Log4j forwarding works after restart
# ZooKeeper lock advertisement for master is updated after new master is start
# `accumulo info` is updated after new master is started.","10/Dec/13 22:47;elserj;Attaching a 2nd verison of the patch with some suggestions from [~billie.rinaldi]:

# Cleaned up unnecessary Opts in SimpleGarbageCollector
# Used mergePropWithRandomPort in MiniAccumuloCluster
# Replace logging of portHint from configuration in MasterClient",11/Dec/13 01:41;elserj;Screwed up patch2. Patch 3 with the changes that 2 claimed to have.,"12/Dec/13 21:41;jira-bot;Commit 622fc7d20744ae8a7e75ba0dc945777f94254b48 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=622fc7d ]

ACCUMULO-1999 Backport changes from 1664 which advertise the Master's random port
","12/Dec/13 23:31;jira-bot;Commit 622fc7d20744ae8a7e75ba0dc945777f94254b48 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=622fc7d ]

ACCUMULO-1999 Backport changes from 1664 which advertise the Master's random port
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Range constructor lacks key checks, should be non-public",ACCUMULO-1958,12682441,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bhavanki,bhavanki,bhavanki,03/Dec/13 17:46,12/Dec/13 16:25,13/Mar/19 22:01,12/Dec/13 16:21,1.4.0,,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"This ticket pertains to the Range class constructor with the following signature:

{noformat}
public Range(Key, Key, boolean, boolean, boolean, boolean)
{noformat}

The constructor does not check that the start key is before the end key, like every other constructor in the class. Since the constructor is public, this makes it possible for a caller to create invalid ranges.

The constructor is used by other constructors that take in existing range objects, where the key check has implicitly been done, and so it would make sense to skip the check in this one, but then the constructor visibility should be at least protected.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,12/Dec/13 15:38;bhavanki;ACCUMULO-1958.patch;https://issues.apache.org/jira/secure/attachment/12618423/ACCUMULO-1958.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-12-05 18:36:55.342,,,no_permission,,,,,,,,,,,,361698,,,Thu Dec 12 16:25:28 UTC 2013,,,,,,0|i1qcl3:,361996,,,,,,,,"05/Dec/13 18:18;bhavanki;My preferred solution for this is to make the constructor protected, but that would alter the API. Is it too late to do that for 1.6.0?",05/Dec/13 18:36;kturner;Since its public it would first need to be deprecated in 1.6.0 and then the visibility could be changed in a later release.,"05/Dec/13 18:39;kturner;Just checked 1.4 and 1.5, The method exist and is public in those releases.  So could only deprecate in 1.6","05/Dec/13 18:45;bhavanki;OK. That implies then, that while the constructor is public, we'd have to add the range check to it. That would make its use by other constructors less efficient, but that's an appropriate trade-off IMO.",05/Dec/13 18:49;kturner;Another way to look at it is that its being deprecated because it does not have a range check AND other method exist that do and serve the same purpose.,"05/Dec/13 18:58;bhavanki;I'd be OK with leaving out the range check in 1.6.0 as long as the method is deprecated, since that's a flag to users that it's dangerous, and users will likely need to make code changes for 1.6.0 and can take the opportunity to move away from it.

For 1.4.x and 1.5.x, though, I think we'd need to add the range check. Even if we deprecate it there too, users won't be expected to rebuild moving from 1.x.y to 1.x.(y+1), so they'll continue using the constructor. In that case, it's tantamount to a bug fix.

I'm unsure, since I don't know fully the compatibility promises and standards for Accumulo across versions.","05/Dec/13 19:05;busbey;I presume the non-range-checking version is for some performance reason?

Can we just

* add a non-public method that does what this current implementation does
* make the method with this signature do the range check then call the above new method
* update internal, performance-sensitive, already-checked-the-range code to call the new method

This maintains API compatibility for all versions that exist, prevents invalid ranges, and allows the existing internal use.","05/Dec/13 19:11;bhavanki;Works for me. The only users of the non-range-checking version are other Range constructors that take in data that's already been checked, so I think for performance reasons the check was left out.","05/Dec/13 19:11;kturner;bq. For 1.4.x and 1.5.x, though, I think we'd need to add the range check.

Agreed.  Also agree that there should not be a difference in behavior between 1.4, 1.5, and 1.6 after the bug fix.

[~busbey] your suggestions addresses all concerns",06/Dec/13 16:03;bhavanki;Review available.,09/Dec/13 16:19;bhavanki;Review updated: the Thrift constructor and readFields now also include key checks.,12/Dec/13 15:38;bhavanki;Patch based on 1.4.5-SNAPSHOT.,"12/Dec/13 16:20;jira-bot;Commit cc68925ec08cb0ff14f30118526fb486449baf84 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cc68925 ]

ACCUMULO-1958 Make Range constructor safe

The public six-argument Range constructor lacked a check for the stop
key being before the start key. This change adds the check, plus a
similar, new protected constructor without the check for use by
constructors which do not need it. Checks are also included for
construction from Thrift and population via readFields.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","12/Dec/13 16:22;jira-bot;Commit cc68925ec08cb0ff14f30118526fb486449baf84 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cc68925 ]

ACCUMULO-1958 Make Range constructor safe

The public six-argument Range constructor lacked a check for the stop
key being before the start key. This change adds the check, plus a
similar, new protected constructor without the check for use by
constructors which do not need it. Checks are also included for
construction from Thrift and population via readFields.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","12/Dec/13 16:22;jira-bot;Commit cc68925ec08cb0ff14f30118526fb486449baf84 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cc68925 ]

ACCUMULO-1958 Make Range constructor safe

The public six-argument Range constructor lacked a check for the stop
key being before the start key. This change adds the check, plus a
similar, new protected constructor without the check for use by
constructors which do not need it. Checks are also included for
construction from Thrift and population via readFields.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","12/Dec/13 16:22;jira-bot;Commit e945c8d69e9d081a0387866a0889b5da3726735b in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e945c8d ]

ACCUMULO-1958 Make Range constructor safe

The public six-argument Range constructor lacked a check for the stop
key being before the start key. This change adds the check, plus a
similar, new protected constructor without the check for use by
constructors which do not need it. Checks are also included for
construction from Thrift and population via readFields.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","12/Dec/13 16:25;jira-bot;Commit cc68925ec08cb0ff14f30118526fb486449baf84 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cc68925 ]

ACCUMULO-1958 Make Range constructor safe

The public six-argument Range constructor lacked a check for the stop
key being before the start key. This change adds the check, plus a
similar, new protected constructor without the check for use by
constructors which do not need it. Checks are also included for
construction from Thrift and population via readFields.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","12/Dec/13 16:25;jira-bot;Commit e945c8d69e9d081a0387866a0889b5da3726735b in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e945c8d ]

ACCUMULO-1958 Make Range constructor safe

The public six-argument Range constructor lacked a check for the stop
key being before the start key. This change adds the check, plus a
similar, new protected constructor without the check for use by
constructors which do not need it. Checks are also included for
construction from Thrift and population via readFields.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
System/site constraints and iterators should NOT affect the METADATA table,ACCUMULO-324,12538856,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,vines,jvines,18/Jan/12 18:22,05/Dec/13 16:34,13/Mar/19 22:01,05/Dec/13 16:34,1.4.0,,,,,,,1.6.0,,,,,,,,,0,,,,,"Currently any system and site wide constraints and iterators set will affect the !METADATA table. While we want to provide this level of configuration to make things easier for users, we also don't want to have this feature which is essentially useless due to ill effects on this critical table. We should make specific exceptions that any site/system-wide iterators, constraints, and other scan/write-time affecting configurations do not affect the !METADATA site. If we need an iterator/constraint running against the !METADATA table, it will have to be configured for it specifically.

Do not fix until after ACCUMULO-323 has been resolved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-802,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-18 19:11:39.493,,,no_permission,,,,,,,,,,,,224359,,,Thu Nov 14 20:23:28 UTC 2013,,,,,,0|i07nvb:,42633,,,,,,,,"18/Dec/12 19:11;ctubbsii;In the future, it would be nice if we didn't support system level per-table properties, and instead only supported them at a namespace/table-group level.","13/Jun/13 16:04;ctubbsii;System-wide configuration should be added/merged with the default namespace configuration, which won't apply to the system tables.",01/Nov/13 22:24;vines;It does NOT look like this was addressed in the 802 patch. Can anyone confirm?,"01/Nov/13 22:41;ctubbsii;I think you are correct, but it should be an easy bugfix if ACCUMULO-802 is accepted.",14/Nov/13 20:23;ctubbsii;This is addressed in the latest version of the 802 patch.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BulkSplitOptimization and Compaction functional tests still writing to root of HDFS in 1.4.x,ACCUMULO-1893,12679285,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,busbey,busbey,busbey,14/Nov/13 20:07,29/Nov/13 23:10,13/Mar/19 22:01,29/Nov/13 23:10,1.4.4,,,,,,,1.4.5,,,test,,,,,,0,,,,,"In the current 1.4.x dev series, we still have failing functional tests because the java files for dealing with test data try to write to the root of HDFS.

It looks like the changes to the java files CreateMapFiles and BulkSplitOptimizationTest never made it to the repo.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1782,,,,,,,,,,,,,,14/Nov/13 20:56;busbey;ACCUMULO-1893.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12613930/ACCUMULO-1893.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-11-15 00:10:40.676,,,no_permission,,,,,,,,,,,,358647,,,Mon Nov 25 14:07:33 UTC 2013,,,,,,0|i1ptqn:,358937,,,,,,,,14/Nov/13 20:54;busbey;review board with fix on current 1.4 branch.,"14/Nov/13 20:56;busbey;initial patch against 1.4.5-SNAPSHOT, in case review board is misbehaving.

passes unit tests. passes function test simple.compaction.CompactionTest (which fails without this patch)","15/Nov/13 00:10;ctubbsii;This still should be done for 1.4 and 1.5, but it should be addressed in 1.6.0 by ACCUMULO-1599","15/Nov/13 00:29;busbey;Chris, this only exists in 1.4, the patches applied for the other branches in ACCUMULO-1563 correctly accounted for everything. I think that means it doesn't relate to ACCUMULO-1599?",15/Nov/13 01:26;ctubbsii;Ah! I didn't realize this was fixed in 1.5 already and is being backported to 1.4. My mistake.,22/Nov/13 20:59;busbey;Bump. Can a committer please take a look at this patch and provide feedback?,"25/Nov/13 13:44;jira-bot;Commit d0ceebbf0ae8198ec68f3d581c259013c73f4664 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d0ceebb ]

ACCUMULO-1893 keep tests from attempting to write to the root of HDFS.

Reapplication of part of ACCUMULO-1563 to current branch.

Author: Jon Hsieh <jmhsieh@apache.org>

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 13:58;jira-bot;Commit d0ceebbf0ae8198ec68f3d581c259013c73f4664 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d0ceebb ]

ACCUMULO-1893 keep tests from attempting to write to the root of HDFS.

Reapplication of part of ACCUMULO-1563 to current branch.

Author: Jon Hsieh <jmhsieh@apache.org>

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 14:00;jira-bot;Commit d0ceebbf0ae8198ec68f3d581c259013c73f4664 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d0ceebb ]

ACCUMULO-1893 keep tests from attempting to write to the root of HDFS.

Reapplication of part of ACCUMULO-1563 to current branch.

Author: Jon Hsieh <jmhsieh@apache.org>

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 14:04;jira-bot;Commit d0ceebbf0ae8198ec68f3d581c259013c73f4664 in branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d0ceebb ]

ACCUMULO-1893 keep tests from attempting to write to the root of HDFS.

Reapplication of part of ACCUMULO-1563 to current branch.

Author: Jon Hsieh <jmhsieh@apache.org>

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 14:07;kturner;The patch looked good, I applied it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooKeeperInstance constructor should avoid throwing RuntimeExceptions,ACCUMULO-1694,12667364,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,vines,06/Sep/13 17:49,29/Nov/13 18:24,13/Mar/19 22:01,29/Nov/13 18:24,,,,,,,,1.6.0,,,client,,,,,,0,,,,,"Currently all ZooKeeper related exceptions that occur in ZooKeeperInstance's constructor get propagated out as RuntimeExceptions. We should change this behavior to allow for better client handling of configuration issues.

I think the best options are to either have the constructor throw an exception for this (which I'm a bit meh on) or having methods which actually need to talk to ZooKeeper propagate a non-runtime exception. We can easily wrap this under AccumuloException for getConnector, I think, but getMasterLocations() and getRootTabletLocation() would also have to propagate an error which would mean an interface change.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,347301,,,Fri Nov 29 18:24:52 UTC 2013,,,,,,0|i1nvyn:,347600,,,,,,,,"29/Nov/13 18:24;vines;Resolved with ACCUMULO-1009 patch, I think",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE on randomwalk test,ACCUMULO-1943,12681685,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,27/Nov/13 23:29,28/Nov/13 00:42,13/Mar/19 22:01,28/Nov/13 00:42,,,,,,,,1.5.1,1.6.0,,test,,,,,,0,,,,,Looks like I moved module.xsd to test-resources in ACCUMULO-1222 that is needed by the randomwalk test.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-27 23:38:00.311,,,no_permission,,,,,,,,,,,,360949,,,Wed Nov 27 23:57:02 UTC 2013,,,,,,0|i1q7zb:,361248,,,,,,,,"27/Nov/13 23:38;jira-bot;Commit 7d886974d066a65830e4203cddc91f973da75725 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7d88697 ]

ACCUMULO-1943 Replace module.xsd in the test jar so randomwalk has access to it.
","27/Nov/13 23:38;jira-bot;Commit 7d886974d066a65830e4203cddc91f973da75725 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7d88697 ]

ACCUMULO-1943 Replace module.xsd in the test jar so randomwalk has access to it.
","27/Nov/13 23:57;jira-bot;Commit 7d886974d066a65830e4203cddc91f973da75725 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7d88697 ]

ACCUMULO-1943 Replace module.xsd in the test jar so randomwalk has access to it.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TabletIT test fails,ACCUMULO-1941,12681629,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,27/Nov/13 18:30,27/Nov/13 23:57,13/Mar/19 22:01,27/Nov/13 18:33,,,,,,,,1.6.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-27 18:32:51.408,,,no_permission,,,,,,,,,,,,360893,,,Wed Nov 27 23:57:01 UTC 2013,,,,,,0|i1q7mv:,361192,,,,,,,,"27/Nov/13 18:32;jira-bot;Commit 40a007a2d57f53f4430164eda95f513444ac2897 in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=40a007a ]

ACCUMULO-1941 Fix TabletIT test
","27/Nov/13 23:57;jira-bot;Commit 40a007a2d57f53f4430164eda95f513444ac2897 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=40a007a ]

ACCUMULO-1941 Fix TabletIT test
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Saw ConcurrentModificationException on Mini shutdown,ACCUMULO-1939,12681463,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,27/Nov/13 00:52,27/Nov/13 02:13,13/Mar/19 22:01,27/Nov/13 00:59,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Saw this on mini shutdown in 1.6.0-SNAPSHOT branch. It seems that the tabletServerProcesses.toArray() is called outside of a synchronized block. It looks like it only applies to 1.6, because in 1.4 and 1.5, the tablet server processes are in an array, not a list.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-27 00:53:11.352,,,no_permission,,,,,,,,,,,,360728,,,Wed Nov 27 02:13:30 UTC 2013,,,,,,0|i1q6mf:,361027,,,,,,,,"27/Nov/13 00:53;jira-bot;Commit 80fd647976db5baff8c1a372beee11e25d0428d9 in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=80fd647 ]

ACCUMULO-1939 Fix ConcurrentModificationException in MAC
","27/Nov/13 02:13;jira-bot;Commit 80fd647976db5baff8c1a372beee11e25d0428d9 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=80fd647 ]

ACCUMULO-1939 Fix ConcurrentModificationException in MAC
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
commons-io version conflict with CDH4,ACCUMULO-1244,12640918,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,afuchs,afuchs,05/Apr/13 03:08,26/Nov/13 15:47,13/Mar/19 22:01,18/Apr/13 16:17,,,,,,,,1.5.0,,,,,,,,,0,,,,,"CDH4 appears to rely on commons-io version 2.0 or greater. Accumulo currently packages in version 1.4. We should bump this up to achieve compatibility.

Workaround: put the hadoop dependency libraries before the accumulo dependency libraries in the general.classpaths variable in accumulo-site.xml.

{code}
2013-04-04 22:27:13,868 [tabletserver.Tablet] ERROR: Unknown error during minor compaction for extent: !0;~;!0<
java.lang.RuntimeException: java.lang.NoSuchMethodError: org.apache.commons.io.IOUtils.closeQuietly(Ljava/io/Closeable;)V
  at org.apache.accumulo.server.tabletserver.Tablet.minorCompact(Tablet.java:2152)
  at org.apache.accumulo.server.tabletserver.Tablet.access$4400(Tablet.java:152)
  at org.apache.accumulo.server.tabletserver.Tablet$MinorCompactionTask.run(Tablet.java:2219)
  at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
  at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
  at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
  at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
  at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
  at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NoSuchMethodError: org.apache.commons.io.IOUtils.closeQuietly(Ljava/io/Closeable;)V
  at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:941)
  at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
  at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
  at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
  at java.io.DataInputStream.read(DataInputStream.java:132)
  at java.io.DataInputStream.readFully(DataInputStream.java:178)
  at java.io.DataInputStream.readLong(DataInputStream.java:399)
  at org.apache.accumulo.core.file.rfile.bcfile.BCFile$Reader.<init>(BCFile.java:608)
  at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.init(CachableBlockFile.java:246)
  at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getBCFile(CachableBlockFile.java:257)
  at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.access$000(CachableBlockFile.java:143)
  at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader$MetaBlockLoader.get(CachableBlockFile.java:212)
  at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getBlock(CachableBlockFile.java:313)
  at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getMetaBlock(CachableBlockFile.java:367)
  at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getMetaBlock(CachableBlockFile.java:143)
  at org.apache.accumulo.core.file.rfile.RFile$Reader.<init>(RFile.java:834)
  at org.apache.accumulo.core.file.rfile.RFileOperations.openReader(RFileOperations.java:79)
  at org.apache.accumulo.core.file.DispatchingFileFactory.openReader(FileOperations.java:72)
  at org.apache.accumulo.server.tabletserver.Compactor.call(Compactor.java:317)
  at org.apache.accumulo.server.tabletserver.MinorCompactor.call(MinorCompactor.java:96)
  at org.apache.accumulo.server.tabletserver.Tablet.minorCompact(Tablet.java:2138)
  ... 9 more
{code}",Hadoop version 2.0.0-CDH4.2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1063,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-05 13:47:47.461,,,no_permission,,,,,,,,,,,,321377,,,Tue Nov 26 15:47:53 UTC 2013,,,,,,0|i1jg87:,321722,,,,,,,,05/Apr/13 13:47;billie.rinaldi;Would commons-io 2.1 be sufficient?  That appears to be the version used by Apache Hadoop 1 and 2.  Maybe we should review all our common dependencies with Hadoop.,"05/Apr/13 14:00;vines;I believe they all come from the apache pom parent, so we should double
check that we're still in line with them.

Sent from my phone, please pardon the typos and brevity.

","05/Apr/13 14:07;billie.rinaldi;These are the ones I've found with lower versions (1.5 branch dependency -> hadoop 1.0.3 dependency -> hadoop-common 2.0.2-alpha dependency).  The only one with a major version difference is commons-io.

{noformat}
commons-codec          1.2    -> 1.3    -> 1.4
commons-collections    3.2    -> 3.2.1  -> 3.2.1
commons-configuration  1.5    -> 1.6    -> 1.6
commons-io             1.4    -> 2.1    -> 2.1
commons-lang           2.4    -> 2.4    -> 2.5
commons-logging        1.0.4  -> 1.1.1  -> 1.1.1
log4j                  1.2.16 -> 1.2.15 -> 1.2.17
{noformat}","05/Apr/13 14:08;billie.rinaldi;No, these are specified explicitly in our pom.","09/Apr/13 17:20;ctubbsii;Should these just be listed as ""provided"" then, if we're assuming they will come in with the hadoop installation? Then, we can just specify a range of acceptable versions for our code, and let maven do the dependency resolution, based on the hadoop dependencies.",10/Apr/13 18:25;vines;Sounds good to me.,"10/Apr/13 18:39;kturner;bq. Should these just be listed as ""provided"" then, if we're assuming they will come in with the hadoop installation?

that follows the pattern of other dependencies Accumulo shares with Hadoop.  Why should these be different?  I do not know of a reason, making the change is ok w/ me.","10/Apr/13 23:34;hudson;Integrated in Accumulo-1.5 #72 (See [https://builds.apache.org/job/Accumulo-1.5/72/])
    ACCUMULO-1244 Make more libraries provided, because they must be. So, we'll depend on the version given by Hadoop. Remove all provided jars and source jars from lib directory. (Revision 1466685)

     Result = UNSTABLE
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/bin/accumulo
* /accumulo/branches/1.5/bin/bootstrap_hdfs.sh
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/examples/simple/pom.xml
* /accumulo/branches/1.5/fate/pom.xml
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/proxy/pom.xml
* /accumulo/branches/1.5/server/pom.xml
* /accumulo/branches/1.5/start/pom.xml
* /accumulo/branches/1.5/test/pom.xml
* /accumulo/branches/1.5/trace/pom.xml
","11/Apr/13 00:42;medined;+!, although I seem to be late to the voting booth.","11/Apr/13 21:04;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #184 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/184/])
    ACCUMULO-1244 fix log4 lookup for hadoop2 (Revision 1467052)
ACCUMULO-1265, ACCUMULO-1250, ACCUMULO-1244, ACCUMULO-1063 merged to trunk from 1.5 branch (Revision 1467036)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src

ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/scripts/generate-thrift.sh
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
","11/Apr/13 21:08;hudson;Integrated in Accumulo-1.5 #73 (See [https://builds.apache.org/job/Accumulo-1.5/73/])
    ACCUMULO-1244 fix log4 lookup for hadoop2 (Revision 1467051)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/bin/accumulo
","11/Apr/13 21:12;hudson;Integrated in Accumulo-Trunk #826 (See [https://builds.apache.org/job/Accumulo-Trunk/826/])
    ACCUMULO-1244 fix log4 lookup for hadoop2 (Revision 1467052)
ACCUMULO-1265, ACCUMULO-1250, ACCUMULO-1244, ACCUMULO-1063 merged to trunk from 1.5 branch (Revision 1467036)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src

ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/scripts/generate-thrift.sh
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
","15/Apr/13 22:18;vines;For the record, this breaks compatibility for releases at least at and before hadoop-1.0.1.","17/Apr/13 23:29;ctubbsii;So, of the 1.0.x line, can we just say we support >= 1.0.3?",17/Apr/13 23:47;elserj;No complaints here. Is there something with 1.0.0 through 1.0.2 that we don't support?,"17/Apr/13 23:57;vines;Like 0.20, 1.0.1 does not contain commons-io at all. I didn't take the time
to peg it's introduction.

Sent from my phone, please pardon the typos and brevity.

","18/Apr/13 00:24;ctubbsii;Okay, so I'd hate to package it by default.

The real issue here is whether it should be included in our distribution, and I think it should not be. If one is using an older version of hadoop, they can simply download this dependency and include it themselves. Either way, we mark it as ""provided""... whether it is provided by Hadoop, or provided alongside Hadoop, I think should be a user-consideration. As ""provided"", though, we should not include it at all.",18/Apr/13 00:25;ctubbsii;Re-opening until we decide whether to include commons-io in our distribution or not.,"18/Apr/13 00:55;kturner;bq. , I think should be a user-consideration. As ""provided"", though, we should not include it at all.

If we go down this path, then it should be documented in the README what the user should do if using hadoop 0.20","18/Apr/13 01:52;elserj;bq. Either way, we mark it as ""provided""... whether it is provided by Hadoop, or provided alongside Hadoop, I think should be a user-consideration. As ""provided"", though, we should not include it at all.

I think that's the best thing to do. That, and what Keith noted about updating documentation on the subject of running against 0.20","18/Apr/13 16:17;ctubbsii;Closed, and opened a documentation ticket to address this (ACCUMULO-1320).","20/Apr/13 15:11;billie.rinaldi;Is it a necessity for the dependencies to be marked provided in the module poms, or could we move the provided markings to the top-level pom?  It would useful for me to be able to see which ones are provided at the top level.  Also, I don't know how to run Accumulo now.  When I try to init, it throws an exception because it can't find log4j.  I even dropped a log4j jar in the lib directory, but it still doesn't work.","21/Apr/13 16:24;ecn;If you are running hadoop-2.0, you need to extend the classpath using the instructions in the example accumulo-site.xml files.  Hadoop moved the locations of its many jar files around.","22/Apr/13 15:16;ctubbsii;[~billie.rinaldi]
{quote}Is it a necessity for the dependencies to be marked provided in the module poms, or could we move the provided markings to the top-level pom?{quote}

I would argue that scopes are best put in module poms, because the same artifact may have two different scopes in two different modules in a multi-module project, and it gets confusing when the default ""compile"" scope is explicit in some cases (to override the parent) and implicit in other cases.

Specifying scopes this way, also helps simplify the copy-dependencies plugin configuration a lot, and makes the behavior of plugins that use the scopes more predictable (vs. the extra configuration in our assembly to get around the messiness of picking and choosing what to include). It also makes our integration testing environment much more realistic. The biggest downside I'm aware of is that provided scope is not resolved transitively in the unit testing phase of the build lifecycle.

{quote}When I try to init, it throws an exception because it can't find log4j.{quote}
I don't get that. Have you figured this out yet?","22/Apr/13 15:18;ctubbsii;[~billie.rinaldi] Also, your comment seems to relate to ACCUMULO-935.","22/Apr/13 20:03;billie.rinaldi;bq. If you are running hadoop-2.0, you need to extend the classpath using the instructions in the example accumulo-site.xml files.

It's not 2.0, but it's a later 1.x version that has moved the jar files too.  I added the actual jar directory to accumulo-site.xml and it didn't help.  I dropped the log4j jar in the accumulo/lib directory and it also didn't help.  I copied the jar to the hadoop/lib directory and then it could find it.

Is it possible that the classloader needs log4j before it is able to find out about the modification to general.classpaths?  I don't know why it would be able to find the jar in hadoop/lib and not accumulo/lib, though.  This is the error:

{noformat}
java.lang.NoClassDefFoundError: org/apache/log4j/Logger
	at org.apache.accumulo.start.classloader.AccumuloClassLoader.<clinit>(AccumuloClassLoader.java:65)
	at org.apache.accumulo.start.Main.main(Main.java:37)
{noformat}","22/Apr/13 21:32;vines;Line 84 of the accumulo script:
{code}LOG4J_JAR=$(find $HADOOP_PREFIX/lib $HADOOP_PREFIX/share/hadoop/common/lib -    name 'log4j*.jar' -print 2>/dev/null | head -1) {code}

Here's the culprit, I think. We need to make this a bit more tolerant for the various releases. But it should probably be a new ticket and/or under the hadoop2 ticket.","24/Apr/13 19:40;billie.rinaldi;Good find, John.  I'll open a ticket.","26/Nov/13 15:18;jira-bot;Commit 5e3967fa08a36b386cdd0b40a04b5cd7c1e331de in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5e3967f ]

ACCUMULO-1792 Update commons-io dependency for Hadoop2.

Based on the discussion around ACCUMULO-1244, we can update to 2.1 while not marking commons-io as provided to eliminated classpath issues on hadoop 2 and bring a copy in lib/ for hadoop 0.20.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","26/Nov/13 15:47;jira-bot;Commit 5e3967fa08a36b386cdd0b40a04b5cd7c1e331de in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5e3967f ]

ACCUMULO-1792 Update commons-io dependency for Hadoop2.

Based on the discussion around ACCUMULO-1244, we can update to 2.1 while not marking commons-io as provided to eliminated classpath issues on hadoop 2 and bring a copy in lib/ for hadoop 0.20.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","26/Nov/13 15:47;jira-bot;Commit 5e3967fa08a36b386cdd0b40a04b5cd7c1e331de in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5e3967f ]

ACCUMULO-1792 Update commons-io dependency for Hadoop2.

Based on the discussion around ACCUMULO-1244, we can update to 2.1 while not marking commons-io as provided to eliminated classpath issues on hadoop 2 and bring a copy in lib/ for hadoop 0.20.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",,,,,,,,,,,,,,,,,,,,,,,
Failed to build Accumulo Maven Plugin with error: package org.apache.http.annotation does not exist,ACCUMULO-1848,12677337,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,pkande,pkande,pkande,04/Nov/13 10:41,26/Nov/13 06:47,13/Mar/19 22:01,21/Nov/13 21:01,,,,,,,,1.6.0,,,build,,,,,,0,patch,,,,"When building Accumulo 1.6-SNAPSHOT with Hadoop 2.2 profile acitvated (enable), artifact Accumulo Maven Plugin fail to compile with below error.

Its resolution necessitates to use 
<groupId>org.apache.httpcomponents</groupId>
<artifactId>httpclient</artifactId> with<httpclient.version>4.2.1</httpclient.version>


[INFO] Apache Accumulo ................................... SUCCESS [1.771s]
[INFO] Trace ............................................. SUCCESS [0.698s]
[INFO] Fate .............................................. SUCCESS [0.160s]
[INFO] Start ............................................. SUCCESS [1.549s]
[INFO] Core .............................................. SUCCESS [2.658s]
[INFO] Simple Examples ................................... SUCCESS [2.045s]
[INFO] Server Base ....................................... SUCCESS [3.472s]
[INFO] GC Server ......................................... SUCCESS [0.591s]
[INFO] Master Server ..................................... SUCCESS [0.894s]
[INFO] Tablet Server ..................................... SUCCESS [1.459s]
[INFO] MiniCluster ....................................... SUCCESS [1.228s]
[INFO] Monitor Server .................................... SUCCESS [0.910s]
[INFO] Native Libraries .................................. SUCCESS [6.263s]
[INFO] Tracer Server ..................................... SUCCESS [0.399s]
[INFO] Accumulo Maven Plugin ............................. FAILURE [7.735s]
[INFO] Testing ........................................... SKIPPED
[INFO] Proxy ............................................. SKIPPED
[INFO] Extra Server Utilities ............................ SKIPPED
[INFO] Assemblies ........................................ SKIPPED
[INFO] Documentation ..................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 32.734s
[INFO] Finished at: Mon Nov 04 11:35:16 EET 2013
[INFO] Final Memory: 69M/689M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project accumulo-maven-plugin: Compilation failure: Compilation failure:
[ERROR] /home/opensource/github/accumulo/maven-plugin/src/main/java/org/apache/accumulo/maven/plugin/StartMojo.java:[26,33] error: package org.apache.http.annotation does not exist
[ERROR] /home/opensource/github/accumulo/maven-plugin/src/main/java/org/apache/accumulo/maven/plugin/StartMojo.java:[37,1] error: cannot find symbol
[ERROR] symbol: class ThreadSafe
[ERROR] /home/opensource/github/accumulo/maven-plugin/src/main/java/org/apache/accumulo/maven/plugin/StopMojo.java:[21,33] error: package org.apache.http.annotation does not exist
[ERROR] /home/opensource/github/accumulo/maven-plugin/src/main/java/org/apache/accumulo/maven/plugin/StopMojo.java:[30,1] error: cannot find symbol
[ERROR] symbol: class ThreadSafe
[ERROR] /home/opensource/github/accumulo/maven-plugin/src/main/java/org/apache/accumulo/maven/plugin/StartMojo.java:[26,33] error: package org.apache.http.annotation does not exist
[ERROR] /home/opensource/github/accumulo/maven-plugin/src/main/java/org/apache/accumulo/maven/plugin/StartMojo.java:[37,1] error: cannot find symbol
[ERROR] symbol: class ThreadSafe
[ERROR] /home/opensource/github/accumulo/maven-plugin/src/main/java/org/apache/accumulo/maven/plugin/StopMojo.java:[21,33] error: package org.apache.http.annotation does not exist
[ERROR] /home/opensource/github/accumulo/maven-plugin/src/main/java/org/apache/accumulo/maven/plugin/StopMojo.java:[30,1] error: cannot find symbol
[ERROR] -> [Help 1] ",CentOS 6.3 x64,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-04 14:24:14.835,,,no_permission,,,,,,,,,,,,356712,,,Tue Nov 26 06:47:37 UTC 2013,,,,,,0|i1phtj:,357002,,,,,,,,"04/Nov/13 11:59;pkande;{code}
diff --git a/core/pom.xml b/core/pom.xml
index 8b4706b..0c0f909 100644
--- a/core/pom.xml
+++ b/core/pom.xml
@@ -74,11 +74,6 @@
       <scope>provided</scope>
     </dependency>
     <dependency>
-      <groupId>commons-httpclient</groupId>
-      <artifactId>commons-httpclient</artifactId>
-      <scope>provided</scope>
-    </dependency>
-    <dependency>
       <groupId>commons-io</groupId>
       <artifactId>commons-io</artifactId>
       <scope>provided</scope>
@@ -104,6 +99,11 @@
       <scope>provided</scope>
     </dependency>
     <dependency>
+      <groupId>org.apache.httpcomponents</groupId>
+      <artifactId>httpclient</artifactId>
+      <scope>provided</scope>
+    </dependency>
+    <dependency>
       <groupId>org.apache.zookeeper</groupId>
       <artifactId>zookeeper</artifactId>
       <scope>provided</scope>
@@ -348,7 +348,7 @@
                   </mappings>
                 </configuration>
               </execution>
-              <!-- 
+              <!--
               <execution>
                 <id>build-tests-rpm</id>
                 <goals>
diff --git a/examples/simple/pom.xml b/examples/simple/pom.xml
index de60f8d..eb53902 100644
--- a/examples/simple/pom.xml
+++ b/examples/simple/pom.xml
@@ -50,11 +50,6 @@
       <scope>provided</scope>
     </dependency>
     <dependency>
-      <groupId>commons-httpclient</groupId>
-      <artifactId>commons-httpclient</artifactId>
-      <scope>provided</scope>
-    </dependency>
-    <dependency>
       <groupId>commons-io</groupId>
       <artifactId>commons-io</artifactId>
       <scope>provided</scope>
@@ -70,6 +65,11 @@
       <scope>provided</scope>
     </dependency>
     <dependency>
+      <groupId>org.apache.httpcomponents</groupId>
+      <artifactId>httpclient</artifactId>
+      <scope>provided</scope>
+    </dependency>
+    <dependency>
       <groupId>junit</groupId>
       <artifactId>junit</artifactId>
       <scope>test</scope>
diff --git a/maven-plugin/pom.xml b/maven-plugin/pom.xml
index f334795..3b66c3a 100644
--- a/maven-plugin/pom.xml
+++ b/maven-plugin/pom.xml
@@ -44,10 +44,6 @@
       <artifactId>commons-configuration</artifactId>
     </dependency>
     <dependency>
-      <groupId>commons-httpclient</groupId>
-      <artifactId>commons-httpclient</artifactId>
-    </dependency>
-    <dependency>
       <groupId>commons-io</groupId>
       <artifactId>commons-io</artifactId>
     </dependency>
@@ -99,6 +95,11 @@
       <groupId>org.slf4j</groupId>
       <artifactId>slf4j-log4j12</artifactId>
     </dependency>
+    <dependency>
+      <groupId>org.apache.httpcomponents</groupId>
+      <artifactId>httpclient</artifactId>
+      <scope>provided</scope>
+    </dependency>
   </dependencies>
   <build>
     <plugins>
diff --git a/pom.xml b/pom.xml
index 784f219..41bc78a 100644
--- a/pom.xml
+++ b/pom.xml
@@ -164,11 +164,6 @@
         <version>1.6</version>
       </dependency>
       <dependency>
-        <groupId>commons-httpclient</groupId>
-        <artifactId>commons-httpclient</artifactId>
-        <version>${httpclient.version}</version>
-      </dependency>
-      <dependency>
         <groupId>commons-io</groupId>
         <artifactId>commons-io</artifactId>
         <version>2.1</version>
@@ -447,6 +442,11 @@
         <version>${hadoop.version}</version>
       </dependency>
       <dependency>
+        <groupId>org.apache.httpcomponents</groupId>
+        <artifactId>httpclient</artifactId>
+        <version>${httpclient.version}</version>
+      </dependency>
+      <dependency>
         <groupId>org.apache.maven</groupId>
         <artifactId>maven-core</artifactId>
         <version>${maven.min-version}</version>
@@ -1158,7 +1158,7 @@
       </activation>
       <properties>
         <hadoop.version>2.2.0</hadoop.version>
-        <httpclient.version>3.1</httpclient.version>
+        <httpclient.version>4.2.1</httpclient.version>
         <slf4j.version>1.7.5</slf4j.version>
       </properties>
     </profile>
diff --git a/test/pom.xml b/test/pom.xml
index 8e4c152..e3b2b07 100644
--- a/test/pom.xml
+++ b/test/pom.xml
@@ -101,6 +101,11 @@
       <scope>provided</scope>
     </dependency>
     <dependency>
+      <groupId>org.apache.httpcomponents</groupId>
+      <artifactId>httpclient</artifactId>
+      <scope>provided</scope>
+    </dependency>
+    <dependency>
       <groupId>org.apache.zookeeper</groupId>
       <artifactId>zookeeper</artifactId>
       <scope>provided</scope>
@@ -116,11 +121,6 @@
       <scope>provided</scope>
     </dependency>
     <dependency>
-      <groupId>commons-httpclient</groupId>
-      <artifactId>commons-httpclient</artifactId>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
       <groupId>junit</groupId>
       <artifactId>junit</artifactId>
       <scope>test</scope>
{code}",04/Nov/13 14:24;elserj;Hi Pierre -- Could you provide what command you actually ran to see this error and the output of `git show HEAD`. Thanks.,"05/Nov/13 06:41;pkande;Hi Josh,

I have run the command [#mvn package -P assemble -DskipTests], and the
artificat Accumulo Maven Plugin complains about error: package
org.apache.http.annotation does not exist.
commons-httpclient does not include that class, instead it is in org.apache.
httpcomponents.

The command out of [#git show HEAD] is :

commit 8f87c720df9cf1838ccbdcfecb73ec1f0d7e4716
Merge: 4365784 109c179
Author: John Vines <jvines@gmail.com>
Date:   Mon Nov 4 13:35:26 2013 -0500

    Merge branch '1.6.0-SNAPSHOT'


Regards,
Pierre.







-- 
Regards,
Pierre
","05/Nov/13 07:33;pkande;Hey Josh,

Running command such #nvn install -DskipTests or #mvn compile -DskipTests
does not help neither, still produce package org.apache.http.annotation
does not exist on branch 1.6.0-SNAPSHOT.

Regards,
Pierre






-- 
Regards,
Pierre
","05/Nov/13 16:43;billie.rinaldi;[~pkande], this is a good point.  When I build, it doesn't fail because it is pulling in the httpcomponents dependency transitively through libthrift, but that should be a direct dependency since we use {{org.apache.http.annotation.ThreadSafe}} explicitly.  I'm not sure yet if we should be removing commons-httpclient; sounds like it's time for a dependency analysis.","08/Nov/13 22:58;billie.rinaldi;This should be fixed by the commit for ACCUMULO-1853.  [~pkande], please test it out and close the ticket if the problem is resolved.",19/Nov/13 18:00;ecn;[~pkande] is this fixed now?,21/Nov/13 21:01;ctubbsii;Verified fixed on 1.6.0-SNAPSHOT branch (as of 5bd68ef9b751848a441cb56ca82a7e2aafdf1461).,"26/Nov/13 06:47;pkande;Hi Eric,

I have submit the patch as attachment to this case, but I did not manage to
push it due some other urgency matter this last month.
Please allow me few more day, to submit the patch, and test it out.

Regards,
Pierre






-- 
Regards,
Pierre
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test failures after switching to Hadoop2,ACCUMULO-1823,12676242,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,vines,vines,28/Oct/13 23:22,25/Nov/13 18:27,13/Mar/19 22:01,25/Nov/13 18:27,,,,,,,,1.6.0,,,,,,,,,0,,,,,"With the migration to 1.6, I'm seeing timeout related failures in  MiniAccumuloClusterGCTest#testFilesAreGarbageCollected which is not remedied by upping the timeout to 10 minutes. Additionally, I'm seeing repeated failures in CloneTestIT which I tracked specifically to commit cdc1dc9f08beccac7817365f2c08f9f4ceda6923 (  `mvn verify -Dit.test=CloneTestIT -Dtest=foobar  -DfailIfNoTests=false` started failing after that commit). It failed with the following:

{code}java.io.FileNotFoundException: File /tmp/accumulo/test/target/mini-tests/org.apache.accumulo.test.functional.SimpleMacIT/1383066437606_16779/accumulo/tables/1 does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:379)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1482)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1522)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:564)
	at org.apache.accumulo.test.functional.CloneTestIT.testDeleteClone(CloneTestIT.java:160)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-29 02:05:45.744,,,no_permission,,,,,,,,,,,,355739,,,Tue Oct 29 20:02:29 UTC 2013,,,,,,0|i1pbtj:,356027,,,,,,,,"29/Oct/13 02:05;elserj;I'm wondering if the MACGCTest is just poorly written (yes, I wrote it) because inspecting the GC's logs show that it did delete files.

If you could provide other tests which failed for you that would be helpful in actually getting them fixed for you.","29/Oct/13 02:50;ecn;Please re-open with additional details.

Please provide logs for failing tests, and at the very least, the names of the specific tests that are failing.  Transcripts of test runs would be awesome.
","29/Oct/13 03:10;jira-bot;Commit 7200e43a610694d2a9652d3d603bafc86e4395da in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7200e43 ]

ACCUMULO-1481 ACCUMULO-1823 fixed bug w/ major compaction
","29/Oct/13 17:31;jira-bot;Commit 71934fb42e9e79feec334bd0fc7317092a6606ec in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=71934fb ]

ACCUMULO-1823 deal with hadoop-2.2 throwing an exception
","29/Oct/13 18:22;jira-bot;Commit 135e67b68592f0d1c7ca69bac318a7ad3ed55831 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=135e67b ]

ACCUMULO-1823 more tweaks to help stabilize the ITs, get more debugging for post-test analysis
","29/Oct/13 20:02;jira-bot;Commit 5b8efba01a2c654a618d7fb0b46c2981f7b3b3bf in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5b8efba ]

ACCUMULO-1823 more tweaks to help stabilize the ITs
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Have BulkSplitOptimization and Compaction functional tests not write to hdfs root dir.,ACCUMULO-1563,12656937,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,jmhsieh,jmhsieh,jmhsieh,09/Jul/13 20:46,25/Nov/13 14:04,13/Mar/19 22:01,12/Jul/13 15:13,1.4.3,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,test,,,,,,0,,,,,"The BulkSplit optimization and Compaction functional tests write and remove dirs from hdfs's root directory '/'.  This patch updates the test so that they are written the current user's hdfs home directory instead.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1893,,,,,,,,,,,,ACCUMULO-1537,,11/Jul/13 23:17;jmhsieh;acc-1563.trunk.patch;https://issues.apache.org/jira/secure/attachment/12591929/acc-1563.trunk.patch,09/Jul/13 20:59;jmhsieh;accumulo-1563-1.4.patch;https://issues.apache.org/jira/secure/attachment/12591514/accumulo-1563-1.4.patch,09/Jul/13 20:59;jmhsieh;accumulo-1563-1.5.patch;https://issues.apache.org/jira/secure/attachment/12591515/accumulo-1563-1.5.patch,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2013-07-11 21:07:50.684,,,no_permission,,,,,,,,,,,,337160,,,Mon Nov 25 14:04:05 UTC 2013,,,,,,0|i1m5mf:,337483,,,,,,,,"09/Jul/13 20:59;jmhsieh;I have 1.4 and 1.5 versions that are nearly identical modulo some renames and path moves.  

ACCUMULO-1537 got committed so don't have a trunk update yet. (the equivalent now java code has changed slightly there is a base dir being prepended... )","09/Jul/13 22:00;jmhsieh;Looks like in trunk the base dir stuff is the same dir the minicluster is writing its accumulo data to so the permission issues wouldn't be a problem.  Some of the changes should still be done though (like the CreateRFiles change in the 1.5 patch)

Currently having build problems against the IT tests against   
https://svn.apache.org/repos/asf/accumulo/trunk@1501497 
","11/Jul/13 21:07;mdrob;[~jmhsieh] - Are you still working on a trunk version of this patch? This is the last remaining issue for 1.4.4, and I'd like to resolve it before we get to building and tagging, but don't want to apply fixes to only some of the branches where they belong.","11/Jul/13 21:28;jmhsieh;
The trunk build has been unstable for me -- due to compilation errors and changes are still trickling in for ACCUMULO-1537 (From other projects, I'm used RTC and to having one jira one commit).  Anyway, I have a patch that should cover it on trunk but need to spend some time or wait to get that build working so I can test it.

If this is blocking 1.4.4, feel free to bump this to 1.4.5 
","11/Jul/13 23:17;jmhsieh;equivalent patch for trunk.  It is not as large because the now java auto-functional append a ""base"" dir which is a relative to user home accumulo dir in hdfs. 

Tested this with 

mvn clean integration-tests -Dtest=BulkSplitOptimizationIT,CompactionIT -DfailIfNoTests=false -DskipITs

(it is strange that I need to skip the integration tests to only run these -- ACCUMULO-1537 should probably figure out how to keep them in the Integration Test category).","11/Jul/13 23:22;jmhsieh;I've been testing the 1.4.x version for a weeks or so now -- I'm using a cm deployed hadoop and zookeeper which default to having perms enforced and has hdfs/hadoop as the super user and accumulo running as the root user.

I haven't actually tested the 1.5.x version but since it is nearly identical I think it should be good.","12/Jul/13 15:07;jira-bot;Commit 1502582 from [~ecn]
[ https://svn.apache.org/r1502582 ]

ACCUMULO-1563 committing Jonathan Hsieh's patch to prevent the test from writing to /","12/Jul/13 15:11;jira-bot;Commit 1502583 from [~ecn]
[ https://svn.apache.org/r1502583 ]

ACCUMULO-1563 committing Jonathan Hsieh's patch to prevent the test from writing to /","12/Jul/13 15:12;jira-bot;Commit 1502584 from [~ecn]
[ https://svn.apache.org/r1502584 ]

ACCUMULO-1563 committing Jonathan Hsieh's patch to prevent the test from writing to /",12/Jul/13 15:13;ecn;Patched!  Thanks [~jmhsieh].,"12/Jul/13 21:59;jmhsieh;[~ecn]  I think there was a minor oversight -- the 1.4 version seems to be missing the edits to java files (CreateMapFiles and BulkSplitOptimizationTest) 

",15/Jul/13 12:50;ecn;[~jmhsieh] Oops.  Sorry about that.  I'll get those changes in as soon as we have a writable repo.,"17/Oct/13 17:33;jira-bot;Commit fc2ad858cdee9d1b790043fb6adfe26c6f51b66a in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fc2ad85 ]

ACCUMULO-1782 Point bulk load tests away from HDFS root

This is a follow-on patch to ACCUMULO-1563, which adjusted directories
in some tests to avoid writing into the root of HDFS.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","17/Oct/13 17:33;jira-bot;Commit fc2ad858cdee9d1b790043fb6adfe26c6f51b66a in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fc2ad85 ]

ACCUMULO-1782 Point bulk load tests away from HDFS root

This is a follow-on patch to ACCUMULO-1563, which adjusted directories
in some tests to avoid writing into the root of HDFS.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","25/Nov/13 13:44;jira-bot;Commit d0ceebbf0ae8198ec68f3d581c259013c73f4664 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d0ceebb ]

ACCUMULO-1893 keep tests from attempting to write to the root of HDFS.

Reapplication of part of ACCUMULO-1563 to current branch.

Author: Jon Hsieh <jmhsieh@apache.org>

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 13:58;jira-bot;Commit d0ceebbf0ae8198ec68f3d581c259013c73f4664 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d0ceebb ]

ACCUMULO-1893 keep tests from attempting to write to the root of HDFS.

Reapplication of part of ACCUMULO-1563 to current branch.

Author: Jon Hsieh <jmhsieh@apache.org>

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 14:00;jira-bot;Commit d0ceebbf0ae8198ec68f3d581c259013c73f4664 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d0ceebb ]

ACCUMULO-1893 keep tests from attempting to write to the root of HDFS.

Reapplication of part of ACCUMULO-1563 to current branch.

Author: Jon Hsieh <jmhsieh@apache.org>

Signed-off-by: Keith Turner <kturner@apache.org>
","25/Nov/13 14:04;jira-bot;Commit d0ceebbf0ae8198ec68f3d581c259013c73f4664 in branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d0ceebb ]

ACCUMULO-1893 keep tests from attempting to write to the root of HDFS.

Reapplication of part of ACCUMULO-1563 to current branch.

Author: Jon Hsieh <jmhsieh@apache.org>

Signed-off-by: Keith Turner <kturner@apache.org>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MetadataTableUtil.removeUnusedEntries() should use one mutation,ACCUMULO-1914,12680541,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,21/Nov/13 15:30,22/Nov/13 20:21,13/Mar/19 22:01,22/Nov/13 15:35,1.4.0,,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"MetadataTableUtil.removeUnusedEntries() uses multiple mutations to delete a set of walogs.  It should use one mutation.  In 1.6.0-SNAPSHOT the code is only called when recovery happens and nothing is recovered.   Its possible that this code could remove a subset of the logs in the case of a fault and cause old data to be recovered.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-21 17:54:50.24,,,no_permission,,,,,,,,,,,,359806,,,Fri Nov 22 20:21:16 UTC 2013,,,,,,0|i1q0yn:,360105,,,,,,,,"21/Nov/13 17:54;jira-bot;Commit 8bd6e0ebacb8fafeef8627807f610f10b036be6e in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8bd6e0e ]

ACCUMULO-1914 make WALog cleanup after recovery an atomic mutation
","21/Nov/13 17:54;jira-bot;Commit 041270b778db9345c5276ef91fb4f95f3e9e0bbe in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=041270b ]

ACCUMULO-1914 make WALog cleanup after recovery an atomic mutation
","21/Nov/13 17:54;jira-bot;Commit fe46a60c40677df0909e400eda29c79e04f0ead9 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fe46a60 ]

ACCUMULO-1914 make WALog cleanup after recovery an atomic mutation
","21/Nov/13 17:54;jira-bot;Commit 8bd6e0ebacb8fafeef8627807f610f10b036be6e in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8bd6e0e ]

ACCUMULO-1914 make WALog cleanup after recovery an atomic mutation
","21/Nov/13 17:54;jira-bot;Commit 041270b778db9345c5276ef91fb4f95f3e9e0bbe in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=041270b ]

ACCUMULO-1914 make WALog cleanup after recovery an atomic mutation
","21/Nov/13 17:54;jira-bot;Commit fe46a60c40677df0909e400eda29c79e04f0ead9 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fe46a60 ]

ACCUMULO-1914 make WALog cleanup after recovery an atomic mutation
","21/Nov/13 17:58;jira-bot;Commit 2640ea9d926f771274ed10efd23e7400a483f6c0 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2640ea9 ]

ACCUMULO-1914 make WALog cleanup after recovery an atomic mutation
","21/Nov/13 17:59;jira-bot;Commit 7eaedc45b0e59edbd583965cf9a602ce59bf3faf in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7eaedc4 ]

ACCUMULO-1914 make WALog cleanup after recovery an atomic mutation
","22/Nov/13 20:21;jira-bot;Commit 2640ea9d926f771274ed10efd23e7400a483f6c0 in branch refs/heads/ACCUMULO-1854-merge from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2640ea9 ]

ACCUMULO-1914 make WALog cleanup after recovery an atomic mutation
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Monitor creates a new ZK object to fetch gc status and doesn't wait for it to connect.,ACCUMULO-1903,12679506,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,vines,vines,15/Nov/13 22:11,19/Nov/13 15:32,13/Mar/19 22:01,19/Nov/13 15:21,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,monitor,,,,,,0,newbie,,,,"May affect older versions, didn't check them for the same code, but it does exist in 1.5.1-SNAPSHOT and 1.6.0-SNAPSHOT currently.

Seeing a warning in the monitor ""Unable to contact the garbage collector at null"", stemming from a KeeperException KeeperErrorCode ConnectionLoss in fetchGcStatus().

Initially I thought this was just a connection error, but I took a look at the code and a quick google search led me to http://zookeeper-user.578899.n2.nabble.com/zookeeper-connection-loss-exception-occurs-on-new-created-ZooKeeper-instance-too-much-why-td6766831.html

In the getchGcStatus() we create a new ZooKeeper object with every call (!) and then immediately try to use it (!!) without waiting for it to finish establishing a connection. Because of these, I think we should A. ensure it's connected before attempting to use and B. try to reuse the same ZK object instead of creating a new one for each call.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-16 16:58:46.799,,,no_permission,,,,,,,,,,,,358866,,,Tue Nov 19 15:32:37 UTC 2013,,,,,,0|i1pv3b:,359156,,,,,,,,16/Nov/13 16:58;ivan.bella;At least use the Watcher parameter....,"16/Nov/13 16:59;ivan.bella;http://zookeeper.apache.org/doc/r3.3.3/api/org/apache/zookeeper/ZooKeeper.html#ZooKeeper(java.lang.String, int, org.apache.zookeeper.Watcher)","19/Nov/13 15:13;jira-bot;Commit 32b6b65766a695b8da76bdee36df13baace6f904 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=32b6b65 ]

ACCUMULO-1903 prefer the cached, reusable ZooReaderWriter over raw Zookeeper API
","19/Nov/13 15:18;jira-bot;Commit 32b6b65766a695b8da76bdee36df13baace6f904 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=32b6b65 ]

ACCUMULO-1903 prefer the cached, reusable ZooReaderWriter over raw Zookeeper API
","19/Nov/13 15:18;jira-bot;Commit bf8c90a02b7bef0b53790bccfe3f3bd30434243f in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bf8c90a ]

ACCUMULO-1903 prefer the cached, reusable ZooReaderWriter over raw Zookeeper API
","19/Nov/13 15:19;jira-bot;Commit 32b6b65766a695b8da76bdee36df13baace6f904 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=32b6b65 ]

ACCUMULO-1903 prefer the cached, reusable ZooReaderWriter over raw Zookeeper API
","19/Nov/13 15:20;jira-bot;Commit bf8c90a02b7bef0b53790bccfe3f3bd30434243f in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bf8c90a ]

ACCUMULO-1903 prefer the cached, reusable ZooReaderWriter over raw Zookeeper API
","19/Nov/13 15:20;jira-bot;Commit e4fb07c2072dd6a57b5bdc0d3c14c5722c9806ef in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e4fb07c ]

ACCUMULO-1903 prefer the cached, reusable ZooReaderWriter over raw Zookeeper API
","19/Nov/13 15:31;jira-bot;Commit 32b6b65766a695b8da76bdee36df13baace6f904 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=32b6b65 ]

ACCUMULO-1903 prefer the cached, reusable ZooReaderWriter over raw Zookeeper API
","19/Nov/13 15:32;jira-bot;Commit bf8c90a02b7bef0b53790bccfe3f3bd30434243f in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bf8c90a ]

ACCUMULO-1903 prefer the cached, reusable ZooReaderWriter over raw Zookeeper API
","19/Nov/13 15:32;jira-bot;Commit 55016d7762a8f40386c8c567b666fa5e04dc57ab in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=55016d7 ]

ACCUMULO-1903 prefer the cached, reusable ZooReaderWriter over raw Zookeeper API
","19/Nov/13 15:32;jira-bot;Commit 55016d7762a8f40386c8c567b666fa5e04dc57ab in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=55016d7 ]

ACCUMULO-1903 prefer the cached, reusable ZooReaderWriter over raw Zookeeper API
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NativeMap Makefile doesn't work with newest OSX/Xcode,ACCUMULO-1819,12676045,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,28/Oct/13 00:06,13/Nov/13 18:05,13/Mar/19 22:01,28/Oct/13 04:10,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,tserver,,,,,,0,,,,,"Updated my machine from mountain lion to mavericks, which included an update to Xcode. After, activating the `native` maven profile caused a failure due to being unable to find the jni headers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-28 01:06:07.091,,,no_permission,,,,,,,,,,,,355542,,,Wed Nov 13 18:05:59 UTC 2013,,,,,,0|i1palz:,355830,,,,,,,,"28/Oct/13 00:59;elserj;OSX isn't a support deployment platform, so I'm not really worried about it holding up 1.6.0.","28/Oct/13 01:06;mdrob;It _is_ a supported development platform though, and it should be possible to make and test modifications to the code based on whatever 1.6 tag we create.","28/Oct/13 01:07;elserj;Because I'm at a loss at the moment:

{code}
g++ -v -dynamiclib -O3 -I/System/Library/Frameworks/JavaVM.framework/Headers -I/Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home/include/darwin -I/usr/include/c++/4.2.1 -m64 -o libNativeMap-Mac_OS_X-x86_64-64.jnilib org_apache_accumulo_server_tabletserver_NativeMap.cc util.cc
Apple LLVM version 5.0 (clang-500.2.79) (based on LLVM 3.3svn)
Target: x86_64-apple-darwin13.0.0
Thread model: posix
 ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple x86_64-apple-macosx10.9.0 -emit-obj -disable-free -disable-llvm-verifier -main-file-name org_apache_accumulo_server_tabletserver_NativeMap.cc -mrelocation-model pic -pic-level 2 -mdisable-fp-elim -masm-verbose -munwind-tables -target-cpu core2 -target-linker-version 224.1 -v -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/clang/5.0 -I /System/Library/Frameworks/JavaVM.framework/Headers -I /Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home/include -I /Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home/include/darwin -I /usr/include/c++/4.2.1 -stdlib=libc++ -O3 -fdeprecated-macro -fdebug-compilation-dir /Users/jelser/projects/accumulo.git/server/src/main/c++/nativeMap -ferror-limit 19 -fmessage-length 208 -stack-protector 1 -mstackrealign -fblocks -fobjc-runtime=macosx-10.9.0 -fobjc-dispatch-method=mixed -fobjc-default-synthesize-properties -fencode-extended-block-signature -fcxx-exceptions -fexceptions -fdiagnostics-show-option -fcolor-diagnostics -o /var/folders/cd/x6rcp8_x0md0kkh4lppmwj600000gp/T/org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o -x c++ org_apache_accumulo_server_tabletserver_NativeMap.cc
clang -cc1 version 5.0 based upon LLVM 3.3svn default target x86_64-apple-darwin13.0.0
ignoring nonexistent directory ""/usr/include/c++/v1""
#include ""..."" search starts here:
#include <...> search starts here:
 /System/Library/Frameworks/JavaVM.framework/Headers
 /Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home/include
 /Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home/include/darwin
 /usr/include/c++/4.2.1
 /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/c++/v1
 /usr/local/include
 /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/clang/5.0/include
 /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include
 /usr/include
 /System/Library/Frameworks (framework directory)
 /Library/Frameworks (framework directory)
End of search list.
In file included from org_apache_accumulo_server_tabletserver_NativeMap.cc:20:
./NativeMap.h:40:13: warning: assigning field to itself [-Wself-assign-field]
                this->lba = lba;
                          ^
1 warning generated.
 ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang"" -cc1 -triple x86_64-apple-macosx10.9.0 -emit-obj -disable-free -disable-llvm-verifier -main-file-name util.cc -mrelocation-model pic -pic-level 2 -mdisable-fp-elim -masm-verbose -munwind-tables -target-cpu core2 -target-linker-version 224.1 -v -resource-dir /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/clang/5.0 -I /System/Library/Frameworks/JavaVM.framework/Headers -I /Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home/include -I /Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home/include/darwin -I /usr/include/c++/4.2.1 -stdlib=libc++ -O3 -fdeprecated-macro -fdebug-compilation-dir /Users/jelser/projects/accumulo.git/server/src/main/c++/nativeMap -ferror-limit 19 -fmessage-length 208 -stack-protector 1 -mstackrealign -fblocks -fobjc-runtime=macosx-10.9.0 -fobjc-dispatch-method=mixed -fobjc-default-synthesize-properties -fencode-extended-block-signature -fcxx-exceptions -fexceptions -fdiagnostics-show-option -fcolor-diagnostics -o /var/folders/cd/x6rcp8_x0md0kkh4lppmwj600000gp/T/util-pTWn83.o -x c++ util.cc
clang -cc1 version 5.0 based upon LLVM 3.3svn default target x86_64-apple-darwin13.0.0
ignoring nonexistent directory ""/usr/include/c++/v1""
#include ""..."" search starts here:
#include <...> search starts here:
 /System/Library/Frameworks/JavaVM.framework/Headers
 /Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home/include
 /Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home/include/darwin
 /usr/include/c++/4.2.1
 /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/c++/v1
 /usr/local/include
 /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/clang/5.0/include
 /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include
 /usr/include
 /System/Library/Frameworks (framework directory)
 /Library/Frameworks (framework directory)
End of search list.
 ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ld"" -demangle -dynamic -dylib -arch x86_64 -macosx_version_min 10.9.0 -o libNativeMap-Mac_OS_X-x86_64-64.jnilib /var/folders/cd/x6rcp8_x0md0kkh4lppmwj600000gp/T/org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o /var/folders/cd/x6rcp8_x0md0kkh4lppmwj600000gp/T/util-pTWn83.o -lc++ -lSystem /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/clang/5.0/lib/darwin/libclang_rt.osx.a
Undefined symbols for architecture x86_64:
  ""std::basic_ios<char, std::char_traits<char> >::widen(char) const"", referenced from:
      Field::set(JNIEnv_*, _jbyteArray*, int) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      LinkedBlockAllocator::deleteLast(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      Block::rollback(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::ostream::put(char)"", referenced from:
      Field::set(JNIEnv_*, _jbyteArray*, int) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      LinkedBlockAllocator::deleteLast(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      Block::rollback(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::ostream::flush()"", referenced from:
      Field::set(JNIEnv_*, _jbyteArray*, int) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      LinkedBlockAllocator::deleteLast(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      Block::rollback(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::ostream& std::ostream::_M_insert<void const*>(void const*)"", referenced from:
      LinkedBlockAllocator::deleteLast(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      Block::rollback(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::ostream::operator<<(int)"", referenced from:
      Field::set(JNIEnv_*, _jbyteArray*, int) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::ios_base::Init::Init()"", referenced from:
      __GLOBAL__I_a in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::ios_base::Init::~Init()"", referenced from:
      __GLOBAL__I_a in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::basic_ios<char, std::char_traits<char> >::clear(std::_Ios_Iostate)"", referenced from:
      Block::rollback(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)"", referenced from:
      Field::set(JNIEnv_*, _jbyteArray*, int) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      LinkedBlockAllocator::deleteLast(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      Block::rollback(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::_Rb_tree_decrement(std::_Rb_tree_node_base*)"", referenced from:
      std::_Rb_tree<SubKey, std::pair<SubKey const, Field>, std::_Select1st<std::pair<SubKey const, Field> >, std::less<SubKey>, BlockAllocator<std::pair<SubKey const, Field> > >::_M_insert_unique(std::pair<SubKey const, Field> const&) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      std::_Rb_tree<Field, std::pair<Field const, std::map<SubKey, Field, std::less<SubKey>, BlockAllocator<std::pair<SubKey const, Field> > > >, std::_Select1st<std::pair<Field const, std::map<SubKey, Field, std::less<SubKey>, BlockAllocator<std::pair<SubKey const, Field> > > > >, std::less<Field>, BlockAllocator<std::pair<Field const, std::map<SubKey, Field, std::less<SubKey>, BlockAllocator<std::pair<SubKey const, Field> > > > > >::_M_insert_unique(std::pair<Field const, std::map<SubKey, Field, std::less<SubKey>, BlockAllocator<std::pair<SubKey const, Field> > > > const&) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::_Rb_tree_increment(std::_Rb_tree_node_base*)"", referenced from:
      _Java_org_apache_accumulo_server_tabletserver_NativeMap_createNMI__J_3I in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      _Java_org_apache_accumulo_server_tabletserver_NativeMap_nmiNext in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      Iterator::Iterator(NativeMapData&, Field&, SubKey&, int*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::__throw_length_error(char const*)"", referenced from:
      std::vector<Block, std::allocator<Block> >::_M_insert_aux(__gnu_cxx::__normal_iterator<Block*, std::vector<Block, std::allocator<Block> > >, Block const&) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      std::vector<BigBlock, std::allocator<BigBlock> >::_M_insert_aux(__gnu_cxx::__normal_iterator<BigBlock*, std::vector<BigBlock, std::allocator<BigBlock> > >, BigBlock const&) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)"", referenced from:
      std::_Rb_tree<SubKey, std::pair<SubKey const, Field>, std::_Select1st<std::pair<SubKey const, Field> >, std::less<SubKey>, BlockAllocator<std::pair<SubKey const, Field> > >::_M_insert_unique(std::pair<SubKey const, Field> const&) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      std::_Rb_tree<Field, std::pair<Field const, std::map<SubKey, Field, std::less<SubKey>, BlockAllocator<std::pair<SubKey const, Field> > > >, std::_Select1st<std::pair<Field const, std::map<SubKey, Field, std::less<SubKey>, BlockAllocator<std::pair<SubKey const, Field> > > > >, std::less<Field>, BlockAllocator<std::pair<Field const, std::map<SubKey, Field, std::less<SubKey>, BlockAllocator<std::pair<SubKey const, Field> > > > > >::_M_insert_unique(std::pair<Field const, std::map<SubKey, Field, std::less<SubKey>, BlockAllocator<std::pair<SubKey const, Field> > > > const&) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
  ""std::cerr"", referenced from:
      Field::set(JNIEnv_*, _jbyteArray*, int) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      LinkedBlockAllocator::deleteLast(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
      Block::rollback(void*) in org_apache_accumulo_server_tabletserver_NativeMap-tEV7us.o
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [libNativeMap-Mac_OS_X-x86_64-64.jnilib] Error 1
{code}",28/Oct/13 01:14;elserj;Adding {{-undefined dynamic_lookup}} appears to have made it link properly. That implies that I should also be able to make it work without having to perform the dynamic lookup,"28/Oct/13 03:58;jira-bot;Commit 0e882211f2bda4bfb544463e076eea0fdd7dd3e9 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0e88221 ]

ACCUMULO-1819 Update Makefile for native map to build on new OSX version
","28/Oct/13 04:00;jira-bot;Commit 0e882211f2bda4bfb544463e076eea0fdd7dd3e9 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0e88221 ]

ACCUMULO-1819 Update Makefile for native map to build on new OSX version
","28/Oct/13 04:08;jira-bot;Commit 090a8cf68464e414741edbf4eefe9f47c59a4daf in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=090a8cf ]

ACCUMULO-1819 Screwed up the merge conflict
","28/Oct/13 04:08;jira-bot;Commit 0e882211f2bda4bfb544463e076eea0fdd7dd3e9 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0e88221 ]

ACCUMULO-1819 Update Makefile for native map to build on new OSX version
","28/Oct/13 04:08;jira-bot;Commit 090a8cf68464e414741edbf4eefe9f47c59a4daf in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=090a8cf ]

ACCUMULO-1819 Screwed up the merge conflict
","28/Oct/13 04:10;elserj;Fixed by adding some more includes and changing the undefined symbol option from the default of error to dynamic_lookup.

There's probably a better way to fix this but I don't know what it is.","28/Oct/13 16:39;jira-bot;Commit 9e8370253e8471b66a6ed5b871f988481d930731 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e83702 ]

ACCUMULO-1819 fix warning about useless assignment
","13/Nov/13 18:05;jira-bot;Commit e5dfd06ce9f52b606984c1331f6ee2c155f44d1d in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e5dfd06 ]

ACCUMULO-1884 Fix NativeMap Makefile for OS X

The NativeMap Makefile was originally updated for recent OS X versions
under ACCUMULO-1819, but when the file moved for 1.6.x, the changes
were not included.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","13/Nov/13 18:05;jira-bot;Commit e5dfd06ce9f52b606984c1331f6ee2c155f44d1d in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e5dfd06 ]

ACCUMULO-1884 Fix NativeMap Makefile for OS X

The NativeMap Makefile was originally updated for recent OS X versions
under ACCUMULO-1819, but when the file moved for 1.6.x, the changes
were not included.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ShellConfigTest fails when run as root user,ACCUMULO-1881,12678641,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,11/Nov/13 19:24,13/Nov/13 16:47,13/Mar/19 22:01,13/Nov/13 16:47,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"I'm not getting the error on my Mac, but on my VM there is an assertion error on line 80, in testTokenAndOption.  In the output log for the test it says
{noformat}
AccumuloSecurityException: Error BAD_CREDENTIALS for user root - Username or Password is Invalid
{noformat}",CentOS 6.3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-11 19:59:45.822,,,no_permission,,,,,,,,,,,,358008,,,Wed Nov 13 16:47:12 UTC 2013,,,,,,0|i1ppsv:,358298,,,,,,,,"11/Nov/13 19:59;mdrob;Which log are you seeing that error?

The test passes when I run it on my Ubuntu 13.04 laptop.",11/Nov/13 20:05;billie.rinaldi;The bad credentials error shows up in core/target/surefire-reports/org.apache.accumulo.core.util.shell.ShellConfigTest-output.txt.,"11/Nov/13 20:41;mdrob;Hmm... This is all I get in the output file.
{noformat}
mike@lumiere:~/workspace/accumulo$ cat core/target/surefire-reports/org.apache.accumulo.core.util.shell.ShellConfigTest-output.txt
[main} INFO  org.apache.hadoop.conf.Configuration.deprecation  - fs.default.name is deprecated. Instead, use fs.defaultFS
[main} WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[main} ERROR org.apache.accumulo.core.util.shell.Shell  - com.beust.jcommander.ParameterException: Must supply either both or neither of '--tokenClass' and '--tokenProperty'
[main} INFO  org.apache.hadoop.conf.Configuration.deprecation  - fs.default.name is deprecated. Instead, use fs.defaultFS
[main} ERROR org.apache.accumulo.core.util.shell.Shell  - com.beust.jcommander.ParameterException: Can not supply '--pass' option with '--tokenClass' option
{noformat}
It would probably be a good idea to give better error messages than ""ParameterException"" but that does not look like your error...",13/Nov/13 00:43;billie.rinaldi;I've also been able to replicate the error on an Ubuntu Precise (12.04) VM.,"13/Nov/13 04:01;mdrob;Maybe it is a hardware issue? I will try to spin up a VM and see if I can
replicate that way.

","13/Nov/13 16:18;billie.rinaldi;This was difficult to track down.  MockAccumulo creates a root user with empty password.  The test tries to connect to MockAccumulo as the current user with password foo.  When a user doesn't exist, MockAccumulo just creates it, but when it does (as in the case of the root user) it compares the provided password with the existing one.","13/Nov/13 16:43;jira-bot;Commit ff9bfeb8810794b10ab69b18998a6fe183e45a29 in branch refs/heads/1.6.0-SNAPSHOT from [~billie.rinaldi@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ff9bfeb ]

ACCUMULO-1881 added fake username to ShellConfigTest
","13/Nov/13 16:47;jira-bot;Commit ff9bfeb8810794b10ab69b18998a6fe183e45a29 in branch refs/heads/master from [~billie.rinaldi@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ff9bfeb ]

ACCUMULO-1881 added fake username to ShellConfigTest
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NullPointerException thrown by ColumnVisibility#flatten() with empty visibility,ACCUMULO-1434,12648460,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mdrob,elserj,elserj,20/May/13 16:53,11/Nov/13 19:52,13/Mar/19 22:01,11/Nov/13 19:52,1.4.3,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,client,,,,,,0,,,,,"I called flatten() on an empty ColumnVisibility (e.g. """") and got an NPE. It would be nice if the class itself could handle the side-case for an empty colvis",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-11 19:50:01.864,,,no_permission,,,,,,,,,,,,328815,,,Mon Nov 11 19:50:45 UTC 2013,,,,,,0|i1kqcn:,329157,,,,,,,,"20/May/13 17:05;elserj;1.4 branch also NPEs, will verify on the 1.4.3 tag.","20/May/13 17:11;elserj;My brain must not be working -- this happens on branch 1.4, 1.4.3 and branch 1.5. It just must have been a new codepath I was executing.

Dropping priority and changing the type from bug to improvement as this was what has always been the case.","11/Nov/13 19:50;jira-bot;Commit d059d007766920b58946a52e2c051ab19b8e8bda in branch refs/heads/1.4.5-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d059d00 ]

ACCUMULO-1434 Added 'empty' node to CV parse tree
","11/Nov/13 19:50;jira-bot;Commit d059d007766920b58946a52e2c051ab19b8e8bda in branch refs/heads/1.5.1-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d059d00 ]

ACCUMULO-1434 Added 'empty' node to CV parse tree
","11/Nov/13 19:50;jira-bot;Commit d059d007766920b58946a52e2c051ab19b8e8bda in branch refs/heads/1.6.0-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d059d00 ]

ACCUMULO-1434 Added 'empty' node to CV parse tree
","11/Nov/13 19:50;jira-bot;Commit d059d007766920b58946a52e2c051ab19b8e8bda in branch refs/heads/master from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d059d00 ]

ACCUMULO-1434 Added 'empty' node to CV parse tree
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BloomFilterIT fails due to timeout,ACCUMULO-1862,12678041,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,billie.rinaldi,billie.rinaldi,07/Nov/13 19:11,08/Nov/13 15:15,13/Mar/19 22:01,08/Nov/13 15:15,,,,,,,,1.6.0,,,test,,,,,,0,,,,,Discussion started on ACCUMULO-1853 at [this comment|https://issues.apache.org/jira/browse/ACCUMULO-1853?focusedCommentId=13816054&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13816054].  The tserver log indicated it was running low on memory.  Neither increasing the timeout to 24 minutes nor raising the tserver's memory to 8GB resulted in different behavior.,"Mac OS X 10.8.5, 16GB RAM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,07/Nov/13 19:32;ecn;patch;https://issues.apache.org/jira/secure/attachment/12612678/patch,07/Nov/13 20:27;billie.rinaldi;use_truncated.patch;https://issues.apache.org/jira/secure/attachment/12612690/use_truncated.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-11-07 19:23:08.39,,,no_permission,,,,,,,,,,,,357416,,,Fri Nov 08 15:15:33 UTC 2013,,,,,,0|i1pm5j:,357706,,,,,,,,"07/Nov/13 19:23;ecn;I think it's the audit logging.  Your stack traces show the tserver blocked on log writing.

I'm looking in the logs for my run, and I'm seeing gigantic audit records in the log.",07/Nov/13 19:31;ecn;[~billie.rinaldi] can you try the attached patch?,"07/Nov/13 20:27;billie.rinaldi;The patch made BloomFilterIT pass (of course, then AuditMessageIT failed).  I removed the logging change, went into AuditedSecurityOperation and made it do a trivial amount of logging per scan (just the table name, as below).  It passed twice and failed twice with ""Queries had less than 10% improvement.""
{noformat}
2013-11-07 12:11:49,624 [Audit] INFO : operation: permitted; user: root; audit test batch bt3
{noformat}
Also, although this doesn't appear to fix the issue, I noticed AuditedSecurityOperation isn't using the truncated lists of ranges (see attached patch).","07/Nov/13 22:06;ecn;Ugh, the {{truncate()}} method is broken.
","07/Nov/13 22:28;jira-bot;Commit b005a24112affb011d15168963a76dac6434f491 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b005a24 ]

ACCUMULO-1862 implement the desired truncate
",08/Nov/13 15:15;billie.rinaldi;It passed!  (At least once.),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Spurious ClassNotFoundException,ACCUMULO-1846,12677195,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,elserj,elserj,02/Nov/13 03:11,02/Nov/13 06:29,13/Mar/19 22:01,02/Nov/13 06:29,,,,,,,,1.6.0,,,,,,,,,0,,,,,"From the monitor:

{noformat}
Failed to load class 
	java.lang.ClassNotFoundException: org.apache.accumulo.master.recovery.HadoopLogCloser
		at org.apache.commons.vfs2.impl.VFSClassLoader.findClass(VFSClassLoader.java:175)
		at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
		at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
		at org.apache.accumulo.start.classloader.vfs.AccumuloVFSClassLoader.loadClass(AccumuloVFSClassLoader.java:102)
		at org.apache.accumulo.core.conf.AccumuloConfiguration.instantiateClassProperty(AccumuloConfiguration.java:193)
		at org.apache.accumulo.master.recovery.RecoveryManager.recoverLogs(RecoveryManager.java:162)
		at org.apache.accumulo.master.TabletGroupWatcher.run(TabletGroupWatcher.java:195)
{noformat}

From the master.debug.log: 

{noformat}
2013-11-01 23:07:26,557 [master.EventCoordinator] INFO : tablet !!R<< was loaded on localhost:9997
2013-11-01 23:07:26,567 [master.Master] DEBUG: Finished gathering information from 1 servers in 0.01 seconds
2013-11-01 23:07:26,568 [master.Master] DEBUG: not balancing because there are unhosted tablets
2013-11-01 23:07:26,636 [recovery.RecoveryManager] DEBUG: Recovering hdfs://localhost:8020/accumulo1.6/wal/localhost+9997/224c63ac-a7db-4ba6-be87-a6d1fd7a0921 to hdfs://localhost:8020/accumulo1.6/recovery/224c63ac-a7db-4ba6-be87-a6d1fd7a0921d to load class
        at org.apache.commons.vfs2.impl.VFSClassLoader.findClass(VFSClassLoader.java:175)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        at org.apache.accumulo.start.classloader.vfs.AccumuloVFSClassLoader.loadClass(AccumuloVFSClassLoader.java:102)
        at org.apache.accumulo.core.conf.AccumuloConfiguration.instantiateClassProperty(AccumuloConfiguration.java:193)
        at org.apache.accumulo.master.recovery.RecoveryManager.recoverLogs(RecoveryManager.java:162)
        at org.apache.accumulo.master.TabletGroupWatcher.run(TabletGroupWatcher.java:195)
2013-11-01 23:07:26,645 [conf.AccumuloConfiguration] INFO : Using org.apache.accumulo.server.master.recovery.HadoopLogCloser
2013-11-01 23:07:26,645 [recovery.RecoveryManager] INFO : Starting recovery of hdfs://localhost:8020/accumulo1.6/wal/localhost+9997/224c63ac-a7db-4ba6-be87-a6d1fd7a0921 (in : 10s) created for hdfs:, tablet !0;~< holds a reference
2013-11-01 23:07:26,647 [master.Master] DEBUG: 1 assigned to dead servers: [!0<;~@(null,localhost:9997[142010edaa87210],null)]...
{noformat}

I think I was seeing this when I intentionally set the tserver's heap very small to force it to OOM during log recovery (to verify that WAL entries aren't prematurely deleted).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-02 06:23:59.238,,,no_permission,,,,,,,,,,,,356570,,,Sat Nov 02 06:28:42 UTC 2013,,,,,,0|i1pgxr:,356858,,,,,,,,"02/Nov/13 06:23;ctubbsii;Oh, I moved the class during a refactor. I moved it back to its original package, so we didn't break config compatibility between versions... but forget to change the String literal in the Property back to the original class name for the default value of said property.","02/Nov/13 06:28;jira-bot;Commit 61d00d47ddca609a3cff37bdca9140cc8457ba20 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=61d00d4 ]

ACCUMULO-1846 Fix ClassNotFoundException for default log closer
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make it easier to find and run admin commands,ACCUMULO-1650,12662886,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,09/Aug/13 16:40,30/Oct/13 13:23,13/Mar/19 22:01,30/Oct/13 13:23,,,,,,,,1.6.0,,,,,,,,,0,newbie,,,,"Accumulo has a lot of admin commands that are not easy to find or run.   It would be nice if we could do the following :

{noformat}
  $ accumulo admin instances --list
{noformat}

instead of :

{noformat}
  $ accumulo org.apache.accumulo.server.util.ListInstances
{noformat}

Also ""accumulo admin"" could list all possible admin commands

{noformat}
  $ accumulo admin
  Usage : accumulo admin <command> 
  Commands :
    instances   - <short description>
    findOffline - <short description>
    zookeeper   - <short description>
  
  For more information about a specific command run :
    accumulo admin <command> --help
  $
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1706,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-05 02:00:23.413,,,no_permission,,,,,,,,,,,,342888,,,Thu Sep 05 23:24:43 UTC 2013,,,,,,0|i1n4t3:,343192,,,,,,,,"05/Sep/13 02:00;jira-bot;Commit 53a29837df77d8cc57f7973770865ccf0354a4fc in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=53a2983 ]

ACCUMULO-1650 improved a few admin commands and also made them easier to find and run
","05/Sep/13 22:36;ctubbsii;I think it might be better if the ""admin"" features, like ""shutdown"" that relate to the operations of Accumulo, are separated from troubleshooting utilities like FindOfflineTablets.

Perhaps this feature should be called ""check"", with various flags to perform the various tests.
","05/Sep/13 23:24;jira-bot;Commit 61f007c06c3ac91768480733fe594e85b3bd7478 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=61f007c ]

ACCUMULO-1650 Remove warning
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AccumuloVFSClassloader incorrectly treats folders as folders of jar files,ACCUMULO-1514,12652769,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,ctubbsii,ctubbsii,14/Jun/13 00:11,29/Oct/13 20:54,13/Mar/19 22:01,29/Oct/13 20:54,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Specifying a directory of classes is incorrectly interpreted as a directory of jars in the general.dynamic.classpaths configuration property.

Example: adding a path such as *_$ACCUMULO_HOME/core/target/classes_* gets incorrectly interpreted as *_$ACCUMULO_HOME/core/target/classes/\*_* and evaluates to *_$ACCUMULO_HOME/core/target/classes/org_* and *_$ACCUMULO_HOME/core/target/classes/META-INF_*, but *NOT* to *_$ACCUMULO_HOME/core/target/classes_* as expected.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-28 23:36:23.268,,,no_permission,,,,,,,,,,,,333092,,,Tue Oct 29 20:54:07 UTC 2013,,,,,,0|i1lglr:,333420,,,,,,,,"28/Oct/13 23:36;vines;Had the following as the last item in my general classpath
{code}/home/john/workspace/accumulo/server/target/classes/org/apache/accumulo/server{code}

with the dirlist
{code}ls /home/john/workspace/accumulo/server/target/classes/org/apache/accumulo/server
Accumulo$1.class           cli     constraints  fs         logger       metrics   security               tabletserver  util
Accumulo.class             client  data         gc         master       monitor   ServerConstants.class  thrift        zookeeper
Accumulo$LogMonitor.class  conf    fate         iterators  metanalysis  problems  ServerOpts.class       trace
{code}

and got the following with bin/accumulo classpath

{code}
...
	file:/usr/lib/hadoop/lib/oro-2.0.8.jar
	file:/usr/lib/hadoop/lib/aspectjtools-1.6.11.jar
	file:/usr/lib/hadoop/lib/jetty-6.1.26.jar
	file:/home/john/workspace/accumulo/server/target/classes/org/apache/accumulo/server/

Level 4: Accumulo Dynamic Classloader (loads everything defined by general.dynamic.classpaths) VFS classpaths items are:
...
{code}


Tried with and without the trailing / on the path and never got it to pick up any of the subdirectories","28/Oct/13 23:36;vines;Wait, dynamic classpaths, missed that","28/Oct/13 23:49;vines;So it boils down to this switch {code}switch (fo.getType()) {
        case FILE:
          classpath.add(fo);
          pathsToMonitor.add(fo);
          break;
        case FOLDER:
          pathsToMonitor.add(fo);
          for (FileObject child : fo.getChildren()) {
            classpath.add(child);
          }
          break;
        case IMAGINARY:...{code}

So this code always adds all children, but not the folder to the classpath. I can see two solutions -
1. Treat files and folders exactly the same (folder will be on classpath instead of all children)
2. Explicitly add the folder to the classpath as well as it's children (folder and all children will be on classpath)","29/Oct/13 00:34;ctubbsii;For consistency, I really wish this code behaved like a [java classpath|http://docs.oracle.com/javase/6/docs/technotes/tools/windows/classpath.html]:

{code}
x match {
 case x/ -> classpath.add(x) // directory case
 case x/* -> x.getChildren() foreach classpath.add // java classpath wildcard case
 case x -> classpath.add(x) // file case
}
{code}
",29/Oct/13 15:20;vines;So option 1,"29/Oct/13 17:20;jira-bot;Commit 2f5974ca62ac58b07a53e021652f4b80756dc07d in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2f5974c ]

ACCUMULO-1514 Dynamic classloader now has same behavior as general classloader

don't matter
","29/Oct/13 17:27;jira-bot;Commit fb25913c5b9d1d9615dd32807b6583c558794e49 in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=fb25913 ]

I jumped the gun

Revert ""ACCUMULO-1514 Dynamic classloader now has same behavior as general classloader""

This reverts commit 2f5974ca62ac58b07a53e021652f4b80756dc07d.
","29/Oct/13 20:54;jira-bot;Commit 6140f926d545ca00bd572f4d58cb6a105eba04d5 in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6140f92 ]

ACCUMULO-1514 - dynamic classloader more like regular classloader
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Adjust Authorizor Interface to validate auths instead of retrieving a list,ACCUMULO-1681,12666769,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,03/Sep/13 22:02,28/Oct/13 23:16,13/Mar/19 22:01,28/Oct/13 23:16,,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"Currently the Authorizor interface is used to request a set of authorizations which then get checked against the authorizations a user is attempting to use. However, some security systems only support the ability to validate authorizations/permissions/roles and not provide a list. That makes these systems (entirely) incompatible with Accumulo when they don't have to be.

We should switch the behavior of Accumulo to ask the Authorizor (via SecurityOperations) if the auths are valid. The existing getAuths functionality will still use that call and would have potentially limited support, similar to the potentially limited support of any of the set operations.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Sep/13 18:12;vines;ACCUMULO-1681.patch;https://issues.apache.org/jira/secure/attachment/12601430/ACCUMULO-1681.patch,06/Sep/13 21:11;vines;ACCUMULO-1681.v2.patch;https://issues.apache.org/jira/secure/attachment/12601906/ACCUMULO-1681.v2.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-09-07 00:51:34.533,,,no_permission,,,,,,,,,,,,346707,,,Mon Oct 28 23:10:42 UTC 2013,,,,,,0|i1nsb3:,347008,,,,,,,,"04/Sep/13 18:12;vines;The attached patch converts the interface to the improved mechanism. Since I just made this ticket last night, I'm going to wait a few days before committing it in case discussion is warranted.","05/Sep/13 15:54;vines;One thing that isn't handled in that patch is exposing the interface to the Constraint system (which currently uses getAuths). There's no way to directly switch the VisibilityConstraint over because it uses the VisibilityEvaluator, and we don't want to replicate that code. Instead, I'm thinking that we should abstract out Authorizations just a smidge to have an AuthorizationContainer interface which can be used for validation. Then, both Authorizations and the Authorizor could both have contains() and then the VisibiltyEvaluator's logic could be used for both directly checking against a set of labels (normal in code) but also against a configured Authorizor (constraint).","06/Sep/13 21:11;vines;Modified patch which handles the previous mentioned AuthorizationContainer, to allow better integration of the VisibilityContraint and the new authorizor method.","07/Sep/13 00:51;ctubbsii;Since we've already established the standard that visibility labels should be human-readable, and previous discussions around Authorizations have concluded with the idea that java Strings contain the set of everything that is ""human-readable"" for this definition, I don't see a reason to make the interface accept ByteSequence instead of CharSequence (or really String, to offer the guarantee of no side-effects in the interface).

Additionally, I'd like to see a comprehensive user module, that manages a user's authorizations, authentication, and permissions, comprehensively, rather than as separate things. We sort of have this already internally on the back end, but it's not very separable from our internal code. I think that's prerequisite to all these little changes to improve the backend security, and would better isolate these changes in a way that other developers can actually write their own pluggable modules to handle these, without worrying about constant interface changes. We're gradually making improvements here, and that's good... but we're not really working towards a good end-goal, I think.

This feature also highlights the fact that authorizors, like authenticators, are really a separate service, and that our API that deals with management of that service, doesn't necessarily make sense. Like createUser/deleteUser wouldn't necessarily make sense for some backend implementations, setAuthorizations doesn't make sense on an Authorizor that is developed externally to the core project, and configured as a plugin. This problem exists now... but is highlighted by interface changes like this, where the goal is to function without those interface methods (getAuths) having a reasonable implementation.

One feature we'd lose here, is the ability for the shell to automatically retrieve authorizations and scan with all the user's authorizations, by default. We'd also need to consider the fact that many users call getAuths for a user, and intersect it with a set of auths, on the client side, before creating a scanner. We'd need to enable that case. This goes back to the comprehensive, public-facing user service interface. As is, I think the existing authenticator/authorizor/tablepermissionshandler are a bit unpolished to consider user-facing (though they're available for experimenting on the back end configuration). But, with a bit of polishing, such as the addition of an intersect method (maybe you can't view authorizations, but you should be able to prune a set), would help support these use cases.
","07/Sep/13 02:01;vines;{quote}
Since we've already established the standard that visibility labels should be human-readable, and previous discussions around Authorizations have concluded with the idea that java Strings contain the set of everything that is ""human-readable"" for this definition, I don't see a reason to make the interface accept ByteSequence instead of CharSequence (or really String, to offer the guarantee of no side-effects in the interface).
{quote}

Actually, I thought the rules for visibilities changed to allow quoted strings which could contain anything. Regardless, that contains() method is exactly the same as the existing Authorizations.contains() method. If you want to change that, that is an entirely separate issue.

{quote}
Additionally, I'd like to see a comprehensive user module, that manages a user's authorizations, authentication, and permissions, comprehensively, rather than as separate things. We sort of have this already internally on the back end, but it's not very separable from our internal code. I think that's prerequisite to all these little changes to improve the backend security, and would better isolate these changes in a way that other developers can actually write their own pluggable modules to handle these, without worrying about constant interface changes. We're gradually making improvements here, and that's good... but we're not really working towards a good end-goal, I think.
{quote}

I'm not sure how I feel exposing the SecurityOperations as a whole to users. But making that pluggable still wouldn't have caught this because it requires changes to how the TServer handled authorizations and constraints. The end goal is to make a pluggable system that has flexibility, but the question is what is the flexing point. Do we want people to drop in alternative tserver client handlers to deal with it?

{quote}
This feature also highlights the fact that authorizors, like authenticators, are really a separate service, and that our API that deals with management of that service, doesn't necessarily make sense. Like createUser/deleteUser wouldn't necessarily make sense for some backend implementations, setAuthorizations doesn't make sense on an Authorizor that is developed externally to the core project, and configured as a plugin. This problem exists now... but is highlighted by interface changes like this, where the goal is to function without those interface methods (getAuths) having a reasonable implementation.
{quote}

Agreed. But until we write a separate manager for the classic ZooKeeper based ones, we need to keep these around.

{quote}
One feature we'd lose here, is the ability for the shell to automatically retrieve authorizations and scan with all the user's authorizations, by default. We'd also need to consider the fact that many users call getAuths for a user, and intersect it with a set of auths, on the client side, before creating a scanner. We'd need to enable that case. This goes back to the comprehensive, public-facing user service interface. As is, I think the existing authenticator/authorizor/tablepermissionshandler are a bit unpolished to consider user-facing (though they're available for experimenting on the back end configuration). But, with a bit of polishing, such as the addition of an intersect method (maybe you can't view authorizations, but you should be able to prune a set), would help support these use cases.
{quote}

Correct, and I think that once we have the ZooKeeper security manager in place, getAuths will be the one method that has optional support. But adding in a getAuthsSubset or something like that to get that would be something worth exploring. However, that would require an iterative check as the basic model for some of these Authorization systems are ""Do I have this/these auths, Y/N?"", not ""Which of these auths do I have?"". But it should be doable.","09/Sep/13 21:11;ctubbsii;{quote}Actually, I thought the rules for visibilities changed to allow quoted strings which could contain anything. Regardless, that contains() method is exactly the same as the existing Authorizations.contains() method.{quote}

Technically, quoting was introduced to avoid the reserved character problem, not to allow for arbitrary bytes. There's still good reasons to treat this as human-readable. The fact that it uses bytes for its contains method is incidental to the history of treating everything as bytes. I don't know that ""contains"" was ever really considered part of the public API... it's just a getter to power internal use of the Authorizations object. Since it's there, we can treat it as public API... for historical reasons, but I'd really want any improvements to this API (like the addition of an AuthorizationsContainer) to reflect and enforce the human-readable assumptions, rather than to follow Authorizations.contains(). Since this is something new, and not simply a modification of something that we're stuck with, it seems like it's a good opportunity to improve this API all around.

{quote}I'm not sure how I feel exposing the SecurityOperations as a whole to users.{quote}

While the existing backend SecurityOperation (singular for the backend) does provide similar functionality to the type of centralized ""flexing point"" that I'd prefer, I'd want something that is logically more user-centric rather than generically ""security"" centric. In other words, something that takes Credentials on the backend and provides a User instance, with methods like ""canPerform(Action)"" and ""hasAuthorization(Authorization)"" and ""isAuthenticated()"". This would allow us to prepackage things like an LDAPUserModule or an ZooKeeperUserModule or a CustomUserModule (that maybe uses Kerberos for authentication, LDAP for authorizations, and a policy file for permissions).

What I'd really like is for us to come up with a comprehensive solution that implements all these improvements and push for it to be a major feature of an upcoming release (1.7? maybe call it 2.0?). Without that comprehensive solution, I'm reluctant to get on board for this in 1.6.","11/Sep/13 17:22;vines;{quote}
What I'd really like is for us to come up with a comprehensive solution that implements all these improvements and push for it to be a major feature of an upcoming release (1.7? maybe call it 2.0?). Without that comprehensive solution, I'm reluctant to get on board for this in 1.6.
{quote}

The problem is we really won't be able to come up with a comprehensive solution working in a bubble. We need to iteratively work on this, not push it down the road and say it will be super duper good by then. ",19/Sep/13 17:41;ctubbsii;Agreed. I only stated that as a desired end state to reach towards. :),"28/Oct/13 23:10;jira-bot;Commit 9a2041d56019e253b08732c9d931e99981f41660 in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9a2041d ]

ACCUMULO-1681 - Rolling in match (after merging)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Grep appears to ignore -o option to write to a file.,ACCUMULO-1587,12658991,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mdrob,elserj,elserj,22/Jul/13 00:24,28/Oct/13 14:21,13/Mar/19 22:01,28/Oct/13 14:21,,,,,,,,1.5.1,1.6.0,,shell,,,,,,0,,,,,{{scan -o}} works but {{grep -o}} appears to ignore the option.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-28 14:15:51.957,,,no_permission,,,,,,,,,,,,339184,,,Mon Oct 28 14:20:38 UTC 2013,,,,,,0|i1mi33:,339504,,,,,,,,"28/Oct/13 14:15;jira-bot;Commit d61afcc28901c3d1bf34a5940b76f2e140f3f340 in branch refs/heads/1.5.1-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d61afcc ]

ACCUMULO-1587 add 'print to file' for grep
","28/Oct/13 14:20;jira-bot;Commit d61afcc28901c3d1bf34a5940b76f2e140f3f340 in branch refs/heads/master from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d61afcc ]

ACCUMULO-1587 add 'print to file' for grep
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
remove test/system/auto,ACCUMULO-1803,12675136,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,22/Oct/13 21:47,25/Oct/13 22:38,13/Mar/19 22:01,25/Oct/13 20:01,,,,,,,,1.6.0,,,test,,,,,,1,,,,,"Now that there are no tests in test/system/auto, I think we should delete it.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-25 20:01:01.079,,,no_permission,,,,,,,,,,,,354756,,,Fri Oct 25 22:38:12 UTC 2013,,,,,,0|i1p5rj:,355045,,,,,,,,"25/Oct/13 20:01;jira-bot;Commit c3ca9872a1b272fc89b006cdc779f61bb7237759 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c3ca987 ]

ACCUMULO-1803 remove auto
","25/Oct/13 22:38;jira-bot;Commit 9e32d86ecb374bdcd5ec554488afda04e23f8958 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e32d86 ]

ACCUMULO-1803 remove classes unneeded for functional test, found SplitRecoverIT was not working as intended
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ACCUMULO_CONF_DIR not respected for accumulo-metrics.xml,ACCUMULO-1584,12658644,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,jmhsieh,jmhsieh,jmhsieh,18/Jul/13 21:29,23/Oct/13 20:41,13/Mar/19 22:01,22/Oct/13 19:43,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"the ""/conf"" part of the prefix is hard coded in MetricsConfiguration.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,18/Jul/13 21:36;jmhsieh;accumulo-1584-1.4.patch;https://issues.apache.org/jira/secure/attachment/12593067/accumulo-1584-1.4.patch,18/Jul/13 21:36;jmhsieh;accumulo-1584.patch;https://issues.apache.org/jira/secure/attachment/12593066/accumulo-1584.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-10-22 18:58:39.057,,,no_permission,,,,,,,,,,,,338838,,,Tue Oct 22 19:53:05 UTC 2013,,,,,,0|i1mfy7:,339158,,,,,,,,18/Jul/13 21:36;jmhsieh;Same patches but 1.4 has the different directory structure.  the unlabeled on applies to 1.5 and master.,"22/Oct/13 18:58;busbey;Still applies cleanly to 1.4.5-SNAPSHOT. [review board|https://reviews.apache.org/r/14849/]

only nit is that the patch is pre-git, so it's not in the [preferred contributor format|http://accumulo.apache.org/git.html#contributors].

If a committer would prefer that fixed, let me know and I'll reformat it.","22/Oct/13 19:43;jira-bot;Commit f9759261e12a5334af86ef9767750195692eded6 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f975926 ]

ACCUMULO-1584 applying Jonathan Hsieh's patch
","22/Oct/13 19:43;jira-bot;Commit f9759261e12a5334af86ef9767750195692eded6 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f975926 ]

ACCUMULO-1584 applying Jonathan Hsieh's patch
","22/Oct/13 19:43;jira-bot;Commit f9759261e12a5334af86ef9767750195692eded6 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f975926 ]

ACCUMULO-1584 applying Jonathan Hsieh's patch
",22/Oct/13 19:43;ecn;Thanks!,"22/Oct/13 19:53;busbey;Thanks Eric!

Fixed in: 1.4.5, 1.5.1, 1.6.0",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
intermittent integration test failure,ACCUMULO-1740,12670583,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,25/Sep/13 21:49,22/Oct/13 17:17,13/Mar/19 22:01,22/Oct/13 17:17,,,,,,,,,,,test,,,,,,0,,,,,"Some of the recovery integration tests fail with a very long timeout (10 minutes).

After a restart of the tablet servers, the WAL is sorted, and the root tablet is assigned.  After that, the master does not assign the !METADATA tablets.

I've managed to jstack the master, and it seems to be stuck scanning.  I turned on DEBUG log messages and I see this:
{noformat}
2013-09-25 17:27:46,340 [impl.TabletServerBatchReaderIterator] DEBUG: Server : rd6ul-14706v.tycho.ncsc.mil:37957 msg : java.net.SocketTimeoutException: 120000 millis timeout while waiting for channel to be ready for
 read. ch : java.nio.channels.SocketChannel[connected local=/10.0.0.1:33362 remote=rd6ul-14706v.tycho.ncsc.mil/10.0.0.1:37957]
2013-09-25 17:27:46,340 [impl.TabletServerBatchReaderIterator] DEBUG: org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: 120000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.0.0.1:33362 remote=rd6ul-14706v.tycho.ncsc.mil/10.0.0.1:37957]
java.io.IOException: org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: 120000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.0.0.1:33362 remote=rd6ul-14706v.tycho.ncsc.mil/10.0.0.1:37957]
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:705)
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator$QueryTask.run(TabletServerBatchReaderIterator.java:364)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: 120000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.0.0.1:33362 remote=rd6ul-14706v.tycho.ncsc.mil/10.0.0.1:37957]
        at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:129)
        at org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)
        at org.apache.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)
        at org.apache.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)
        at org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)
        at org.apache.accumulo.core.client.impl.ThriftTransportPool$CachedTTransport.readAll(ThriftTransportPool.java:254)
        at org.apache.thrift.protocol.TCompactProtocol.readByte(TCompactProtocol.java:601)
        at org.apache.thrift.protocol.TCompactProtocol.readMessageBegin(TCompactProtocol.java:470)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_startMultiScan(TabletClientService.java:310)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.startMultiScan(TabletClientService.java:290)
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:650)
        ... 7 more
Caused by: java.net.SocketTimeoutException: 120000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.0.0.1:33362 remote=rd6ul-14706v.tycho.ncsc.mil/10.0.0.1:37957]
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:258)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
        at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:127)
        ... 18 more
{noformat}

The tablet server does put the root tablet online.

There are 8 tests that restart tablet servers, this usually only happens to one of the tests per run, making it difficult to track down.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-27 17:41:08.897,,,no_permission,,,,,,,,,,,,350412,,,Tue Oct 22 17:17:25 UTC 2013,,,,,,0|i1of3b:,350705,,,,,,,,"26/Sep/13 16:57;ecn;Jstack of the tablet servers shows scans in progress:

{noformat}
""ClientPool 17"" daemon prio=10 tid=0x00007f9bb8002000 nid=0x37af in Object.wait() [0x00007f9b9fcfa000]
   java.lang.Thread.State: RUNNABLE
        at org.apache.accumulo.server.tabletserver.TabletServer$ThriftClientHandler.startMultiScan(TabletServer.java:1329)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at $Proxy10.startMultiScan(Unknown Source)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$startMultiScan.getResult(TabletClientService.java:2248)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$startMultiScan.getResult(TabletClientService.java:2232)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:161)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:213)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
{noformat}
... many threads ...
{noformat}
""ClientPool 74"" daemon prio=10 tid=0x00007f9bb8001000 nid=0x74cb in Object.wait() [0x00007f9c1c22c000]
   java.lang.Thread.State: RUNNABLE
        at org.apache.accumulo.server.security.AuditedSecurityOperation.canScan(AuditedSecurityOperation.java:147)
        at org.apache.accumulo.server.tabletserver.TabletServer$ThriftClientHandler.startScan(TabletServer.java:1161)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
        at $Proxy10.startScan(Unknown Source)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$startScan.getResult(TabletClientService.java:2173)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$startScan.getResult(TabletClientService.java:2157)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:161)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:213)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
{noformat}

Seems to happen only under heavy loads. I'm seeing it while experimenting with running 8+ tests simultaneously.
","27/Sep/13 17:41;jira-bot;Commit e5e5b2bc39be0c500e18880d7e1821f2903bfb2d in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e5e5b2b ]

ACCUMULO-1740 no idea why this fixes the hangs we've seen
","22/Oct/13 17:17;ecn;Calling this fixed, but please reopen if you see it again.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test ShutdownIT#stopDuringStart sometimes times out,ACCUMULO-1735,12670310,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,24/Sep/13 16:40,22/Oct/13 17:15,13/Mar/19 22:01,22/Oct/13 17:15,,,,,,,,1.6.0,,,master,,,,,,0,,,,,"Something about the shutdown state transition is failing:

{noformat}
2013-09-24 12:13:06,411 [master.EventCoordinator] INFO : [Root Tablet]: 1 tablets are UNASSIGNED
2013-09-24 12:13:06,416 [master.EventCoordinator] INFO : [Root Tablet]: 1 tablets are ASSIGNED
2013-09-24 12:13:06,702 [master.EventCoordinator] INFO : tablet !!R<< was loaded on host:45705
2013-09-24 12:13:06,706 [master.EventCoordinator] INFO : [Root Tablet]: 1 tablets are HOSTED
2013-09-24 12:13:06,830 [master.Master] INFO : Assigning 2 tablets
2013-09-24 12:13:06,974 [master.EventCoordinator] INFO : [Non-Root Metadata Tablets]: 2 tablets are UNASSIGNED
2013-09-24 12:13:06,975 [master.EventCoordinator] INFO : State changed from NORMAL to SAFE_MODE
2013-09-24 12:13:06,979 [master.EventCoordinator] INFO : State changed from SAFE_MODE to UNLOAD_METADATA_TABLETS
2013-09-24 12:13:06,989 [master.EventCoordinator] INFO : State changed from UNLOAD_METADATA_TABLETS to UNLOAD_ROOT_TABLET
2013-09-24 12:13:06,992 [master.EventCoordinator] INFO : [Non-Root Metadata Tablets]: 2 tablets are ASSIGNED
2013-09-24 12:13:06,995 [master.EventCoordinator] INFO : [Root Tablet]: 1 tablets unloaded
2013-09-24 12:13:07,285 [master.EventCoordinator] INFO : [Root Tablet]: 1 tablets are UNASSIGNED
2013-09-24 12:13:07,697 [master.EventCoordinator] INFO : tablet !0;~< was loaded on host:45705
{noformat}

The root tablet is taken offline, but there are !METADATA tablets online. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-24 18:38:11.715,,,no_permission,,,,,,,,,,,,350139,,,Tue Sep 24 18:38:11 UTC 2013,,,,,,0|i1odf3:,350433,,,,,,,,"24/Sep/13 18:38;jira-bot;Commit 49381c176cc3aef04d2b665c74d0f7f882323506 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=49381c1 ]

ACCUMULO-1735 update master state as soon as a meta tablet is assigned
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CleanTmpIT test is failing against hadoop 2.2.0,ACCUMULO-1788,12674554,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,18/Oct/13 17:04,18/Oct/13 20:53,13/Mar/19 22:01,18/Oct/13 20:53,,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"This is a restart test.  The tablet server fails to find the WAL recovery file after starting back up.

{noformat}
2013-10-18 12:57:22,729 [tabletserver.TabletServer] WARN : exception trying to assign tablet !!R<< /root_tablet
java.lang.RuntimeException: java.io.IOException: Unable to find recovery files for extent !!R<< logEntry: !!R<< hdfs://localhost:45558/accumulo/wal/hostname+34614/c1ce674c-b292-4e32-a035-21a97c2c2463 (1)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-18 20:53:46.748,,,no_permission,,,,,,,,,,,,354176,,,Fri Oct 18 20:53:46 UTC 2013,,,,,,0|i1p27r:,354468,,,,,,,,"18/Oct/13 17:11;ecn;The master initiates recovery, but the log doesn't seem to be recovered.  I see many entries of:

{noformat}
2013-10-18 12:58:15,682 [recovery.RecoveryManager] DEBUG: Recovering hdfs://localhost:45558/accumulo/wal/hostname+34614/c1ce674c-b292-4e32-a035-21a97c2c2463 to hdfs://localhost:45558/accumulo/recovery/c1ce674c-b292-4e32-a035-21a97c2c2463
{noformat}
","18/Oct/13 17:33;ecn;The tablet server is sorting the file... but it's looking for the sorted recovery file in the wrong place in DFS.

{noformat}
2013-10-18 13:28:21,379 [hdfs.DFSClient] DEBUG: /accumulo/recovery/e40da7fe-305c-49a7-8de5-d954d50a7fde/finished: masked=rwxr-xr-x
...
2013-10-18 13:28:21,899 [tabletserver.TabletServer] INFO : Looking for hdfs://localhost:44002/accumulo/wal/hostname+45153/e40da7fe-305c-49a7-8de5-d954d50a7fde/finished
{noformat}

Needs to look in /accumulo/recovery, not the original wal location.
","18/Oct/13 20:53;jira-bot;Commit b0c5e535af1e6fcc8d28ef580a1cbdc8e2aa55fc in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b0c5e53 ]

ACCUMULO-1788 fix test, use the right filesystem to create/delete a _tmp file
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MiniAccumuloClusterGCTest fails if GC is already running,ACCUMULO-1786,12674421,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,17/Oct/13 22:35,17/Oct/13 23:16,13/Mar/19 22:01,17/Oct/13 23:16,,,,,,,,1.4.5,1.5.1,1.6.0,mini,,,,,,0,,,,,Noticed that the MiniAccumuloClusterGCTest failed locally. Found that it couldn't start because I already have a GC running in a real instance locally.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-17 22:56:39.558,,,no_permission,,,,,,,,,,,,354043,,,Thu Oct 17 23:14:17 UTC 2013,,,,,,0|i1p1ev:,354335,,,,,,,,"17/Oct/13 22:56;jira-bot;Commit 19e24abffb7a919ea406ab5c2b08ef0e3b385b74 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=19e24ab ]

ACCUMULO-1786 Use the PortUtils to get a free port for the test
","17/Oct/13 23:05;jira-bot;Commit 19e24abffb7a919ea406ab5c2b08ef0e3b385b74 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=19e24ab ]

ACCUMULO-1786 Use the PortUtils to get a free port for the test
","17/Oct/13 23:14;jira-bot;Commit 19e24abffb7a919ea406ab5c2b08ef0e3b385b74 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=19e24ab ]

ACCUMULO-1786 Use the PortUtils to get a free port for the test
","17/Oct/13 23:14;jira-bot;Commit 5480ae0f1a040a39a7ac51336dd94fb3122c8863 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5480ae0 ]

Merge branch '1.5.1-SNAPSHOT'

Conflicts:
	minicluster/src/test/java/org/apache/accumulo/minicluster/MiniAccumuloClusterGCTest.java

Merging ACCUMULO-1786 is a no-op because of ACCUMULO-1664. Processes are
able to use random ports and MAC already does in 1.6.0-SNAPSHOT, so
there's no need to do anything special in the test.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
out of memory error creating native thread,ACCUMULO-847,12615498,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,ecn,ecn,09/Nov/12 15:47,17/Oct/13 21:07,13/Mar/19 22:01,15/Nov/12 21:03,,,,,,,,1.4.4,1.5.0,,tserver,,,,,,0,,,,,"Long running tablet servers had many gigabytes of memory allocated above what was expected (native + jvm).  Inspection of the heap did not show an unusual number of native objects allocated.  Servers would eventually fail to create new threads.

See HADOOP-7154 for the details.
",RHEL6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-09 16:08:41.772,,,no_permission,,,,,,,,,,,,256786,,,Thu Oct 17 21:07:16 UTC 2013,,,,,,0|i0ir2v:,107481,,,,,,,,"09/Nov/12 16:08;hudson;Integrated in Accumulo-Trunk #545 (See [https://builds.apache.org/job/Accumulo-Trunk/545/])
    ACCUMULO-847 the rhel6 glibc uses a memory allocation strategy that is inappropriate for java in most circumstances (Revision 1407500)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/bin/config.sh
","15/Nov/12 21:00;ecn;It's much worse than I thought.

Based on a user's ingest patterns, I created a new little test program to ingest random-length values with random rows in a single column.  I ran experiments, watching resident memory use of the tserver with top.  I experimented with the number of arenas and also setting M_MMAP_THRESHOLD_ to zero to force all memory allocations to mmap() and not sbrk().  At the end of the test, I flushed all tables to disk, and waited for compactions to finish.

Here's the results for ingesting 10M k-v with a value size of 1-4096, on a tserver with 1G jvm and 1G native map:

||Arenas||Thresh=0||Res Mem||Secs||
|unlimited|FALSE|3|556|
|unlimited|TRUE|4.2|626|
|4|TRUE|2.5|565|
|1|FALSE|1.9|569|
|1|TRUE|1.9|534|

Same data with the HotSpot 6.0.25 JVM:

||Arenas||Thresh=0||Res Mem||Secs||
|unlimited|FALSE|3.5|573|
|unlimited|TRUE|3.8|552|
|4|TRUE|2.7|569|
|1|FALSE|1.9|556|
|1|TRUE|1.9|572|

Pay no attention to the seconds column; I was doing other lightweight tasks on the computer while the test ran, so I expected that much noise.

I've started to recommend 

{noformat}
export MALLOC_ARENA_MAX=${MALLOC_ARENA_MAX:-1}
{noformat}

in {{bin/config.sh}} and I will make the change for the trunk.","15/Nov/12 21:17;elserj;""Res Mem"" is in GB, correct?","15/Nov/12 22:34;hudson;Integrated in Accumulo-Trunk #553 (See [https://builds.apache.org/job/Accumulo-Trunk/553/])
    ACCUMULO-847 turn off arena-based native memory allocation (Revision 1410010)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/bin/config.sh
","16/Nov/12 02:20;elserj;I reran Eric's test on my box at home (8core, 16G of ram, 3 spinning disks for data dirs) using the same Accumulo heap and native map sizes.

Relevant software versions:
* Sun JDK 1.6.0_37
* glibc-2.15-r3 (if it's important, I can resolve what Gentoo patched in the r3 version above 2.15 that the community tagged)
* Kernel 3.6.6

||Arenas||Thresh||Res Mem (GB)||
|0|0|2|
|0|1|1.9|
|1|0|1.3|
|1|1|1.3|
|4|0|1.6|

The big take-away I see from this is:

# Altering the number of arenas has the expected effect on resident memory
# On my system, I did *not* see resident memory rise out of reasonable bounds.","16/Nov/12 03:18;ecn;Thanks, Josh for running my test.  This is another great data point: RHEL6 glibc memory management is pretty awful!

If anyone wants my little test program, I can add it to the ticket.  It's nothing fancy, so I've not bothered.  I'll commit it once I figure out how to create an automated functional test that will ensure that memory stays ""reasonable.""
","16/Nov/12 04:34;vines;If you don't mind, I'd like to give it a go.","23/May/13 17:15;hudson;Integrated in Accumulo-1.4.x #309 (See [https://builds.apache.org/job/Accumulo-1.4.x/309/])
    ACCUMULO-847 merge back to 1.4 branch (Revision 1485724)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/bin/config.sh
* /accumulo/branches/1.4/docs/src/user_manual
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/test/functional
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/zookeeper/ZooLock.java
",17/Oct/13 21:03;busbey;Also fixed in 1.4.4,"17/Oct/13 21:07;elserj;Thanks, [~busbey].",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MiniAccumuloCluster has ConcurrentModificationException,ACCUMULO-1776,12673492,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,sonixbp,ctubbsii,ctubbsii,11/Oct/13 20:52,15/Oct/13 21:24,13/Mar/19 22:01,15/Oct/13 21:24,,,,,,,,1.6.0,,,mini,,,,,,0,,,,,"MiniAccumuloCluster throws concurrency exception in loop over tabletServerProcesses in stop().

The likely suspect is the shutdown hook that also calls stop.

stop, and other methods that modify this list (killProcess, start, exec) should be synchronized.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-13 00:48:30.444,,,no_permission,,,,,,,,,,,,353115,,,Tue Oct 15 21:07:20 UTC 2013,,,,,,0|i1ovon:,353402,,,,,,,,"13/Oct/13 00:48;sonixbp;This should probably be changed as well:

{noformat}
        for (Process tserver : tabletServerProcesses) {
          if (proc.equals(tserver)) {
            tabletServerProcesses.remove(tserver);
            tserver.destroy();
            found = true;
            break;
          }
        }
{noformat}","13/Oct/13 00:53;sonixbp;Woops scratch that, you already had that in the description. My bad :-)","15/Oct/13 21:07;jira-bot;Commit 5d1e7b8b59c7ae6140b13f2deaa675e5a44187a7 in branch refs/heads/master from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5d1e7b8 ]

ACCUMULO-1776 Synchronizing methods that manipulate the list of tablet server processes
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mutation equals() method does not always work,ACCUMULO-1626,12660927,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,31/Jul/13 15:44,14/Oct/13 11:45,13/Mar/19 22:01,31/Jul/13 17:01,1.4.0,1.5.0,,,,,,1.4.4,1.5.1,1.6.0,,,,,,,0,,,,,"Mutations has a equals() method, but it only works if hashcode() is called first on the two mutations.  So equals() will work ok in hash sets and maps, but not when equals() is called w/o calling hashcode().",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1734,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-31 15:48:36.763,,,no_permission,,,,,,,,,,,,341116,,,Wed Jul 31 16:52:05 UTC 2013,,,,,,0|i1mtz3:,341434,,,,,,,,"31/Jul/13 15:48;jira-bot;Commit acc4fd16f6390579c82e9635a3fa614f3822bfba in branch refs/heads/1.4.4-SNAPSHOT from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=acc4fd1 ]

ACCUMULO-1626 fixed equals method in mutation
","31/Jul/13 16:22;jira-bot;Commit acc4fd16f6390579c82e9635a3fa614f3822bfba in branch refs/heads/1.5.1-SNAPSHOT from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=acc4fd1 ]

ACCUMULO-1626 fixed equals method in mutation
","31/Jul/13 16:52;jira-bot;Commit acc4fd16f6390579c82e9635a3fa614f3822bfba in branch refs/heads/master from [~kturner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=acc4fd1 ]

ACCUMULO-1626 fixed equals method in mutation
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooSession.connect barely adheres to timeout,ACCUMULO-1410,12647067,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,10/May/13 18:13,01/Oct/13 16:20,13/Mar/19 22:01,01/Oct/13 16:20,,,,,,,,1.6.0,,,client,fate,,,,,0,,,,,"ZooSession.connect, which is used by ZooKeeperInstance, takes an argument for a timeout, and utilizes it to an extent-
{quote}
if (System.currentTimeMillis() - startTime > 2 * timeout)
{quote}

However, this is only used after a check which uses hardcoded values. Currently, this is set to 10*1000ms. More specifically, it uses this value and checks every 100ms to see if it's connected. So if you have a tiny timeout, there are 2 issues:

# Your timeout is only useful in 10 second increments, rounded up

# You get a nice helpful error message that hides that real lengths of attempt


I think the block of code should be changed to just try to connect for the user specified timeout length, working in the same 100ms increments. This allows more granularity in the handling of the user specified values (and I think it also simplifies the code). This will also make the timeout message more accurate.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Sep/13 20:37;vines;ACCUMULO-1410.patch;https://issues.apache.org/jira/secure/attachment/12601457/ACCUMULO-1410.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-09-09 18:55:16.916,,,no_permission,,,,,,,,,,,,327424,,,Mon Sep 09 18:55:16 UTC 2013,,,,,,0|i1khrz:,327768,,,,,,,,04/Sep/13 20:37;vines;A little more attention is paid to times to try to adhere more closely to the requested timeout values. Not sure if this is kosher to push because technically it will change behavior for some users...,"09/Sep/13 18:55;jira-bot;Commit 5d7a4a727247d7d19ea29b1031bedcefb690b4a1 in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5d7a4a7 ]

ACCUMULO-1410 - making the ZK connections a bit tolerant to user requests
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Document native maps,ACCUMULO-1428,12648228,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,sonixbp,kturner,kturner,17/May/13 18:49,21/Sep/13 04:22,13/Mar/19 22:01,21/Sep/13 04:22,,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,AFAIK there is no documentation that outlines why native maps exist and how to build them.  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-21 03:30:05.601,,,no_permission,,,,,,,,,,,,328584,,,Sat Sep 21 03:31:11 UTC 2013,,,,,,0|i1koxr:,328928,,,,,,,,"21/Sep/13 03:30;jira-bot;Commit 0bc311b1a6efe4e69c4685254604c0f078f12598 in branch refs/heads/1.5.1-SNAPSHOT from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0bc311b ]

ACCUMULO-1428 Documenting native maps
","21/Sep/13 03:31;jira-bot;Commit 0bc311b1a6efe4e69c4685254604c0f078f12598 in branch refs/heads/master from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0bc311b ]

ACCUMULO-1428 Documenting native maps
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Race condition between master and tserver when acquiring tserver lock,ACCUMULO-1277,12642619,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,dptruitt,dptruitt,15/Apr/13 21:51,17/Sep/13 20:08,13/Mar/19 22:01,16/Apr/13 20:13,1.4.3,,,,,,,1.4.4,1.5.0,,master,tserver,,,,,0,,,,,"When restarting a stopped tserver, the following happens:
The tserver (in TabletServer.announceExistence()) creates an entry in zookeeper at /accumulo/instance-id/tserver/host:port.

This in turn triggers master to execute the call chain:
LiveTServerSet.process(WatchedEvent)
LiveTServerSet.scanServers()
LiveTServerSet.checkServer(Set<TServerInstance>, Set<TServerInstance>, String, String)

The checkServer() method checks to see if the ZooLock data has been created yet (if tserver loses the race, it has not yet been created) causing master to then delete the tserver node.  

When the tserver attempts to create the ZooLock, the parent path no longer exists and creating the lock fails.  Eventually the tserver will time out waiting to create the lock, and fail to start.

This problem is easier to reproduce in a smallish cluster using a single zookeeper node, where there is more latency between the tserver and zookeeper than there is between the master and zookeeper.

This behavior was introduced in the fix for ACCUMULO-1049.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-16 14:04:53.31,,,no_permission,,,,,,,,,,,,323033,,,Tue Sep 17 19:31:02 UTC 2013,,,,,,0|i1jqfj:,323378,,,,,,,,"16/Apr/13 14:04;kturner;I had some code in place that delayed deleting empty tserver nodes, but it looks like I just dropped it.  Ooppss.  I'll take a look at this.  Nice write up.  ","16/Apr/13 14:40;dptruitt;It seems like a lot of the locking complexity in Accumulo might be alleviated by upgrading to the 3.4.x versions of zookeeper, which supports multi-operation transactions.","16/Apr/13 14:59;kturner;bq. It seems like a lot of the locking complexity in Accumulo might be alleviated by upgrading to the 3.4.x versions of zookeeper, which supports multi-operation transactions.

I have wanted to use that feature in the past.  Maybe we can bump the version for 1.6  I think the zookeeper team is now recommending 3.4.5.","17/Apr/13 00:20;hudson;Integrated in Accumulo-1.4.x #293 (See [https://builds.apache.org/job/Accumulo-1.4.x/293/])
    ACCUMULO-1277 made master delay deleting lockless tserver nodes in zookeeper (Revision 1468589)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/zookeeper/ZooLock.java
","17/Apr/13 00:30;hudson;Integrated in Accumulo-Trunk #833 (See [https://builds.apache.org/job/Accumulo-Trunk/833/])
    ACCUMULO-1277 made master delay deleting lockless tserver nodes in zookeeper (Revision 1468585)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/src
","17/Sep/13 19:31;charlescva;The following stack trace may indicate the occurrence of this bug in your Accumulo 1.4.3 cluster when attempting to start tablet servers:

{noformat}
Uncaught exception in TabletServer.main, exiting
         java.lang.RuntimeException: java.lang.RuntimeException: Too many retries, exiting.
                 at org.apache.accumulo.server.tabletserver.TabletServer.announceExistence(TabletServer.java:2684)
                 at org.apache.accumulo.server.tabletserver.TabletServer.run(TabletServer.java:2703)
                 at org.apache.accumulo.server.tabletserver.TabletServer.main(TabletServer.java:3168)
                 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
                 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
                 at java.lang.reflect.Method.invoke(Method.java:597)
                 at org.apache.accumulo.start.Main$1.run(Main.java:89)
                 at java.lang.Thread.run(Thread.java:662)
         Caused by: java.lang.RuntimeException: Too many retries, exiting.
                 at org.apache.accumulo.server.tabletserver.TabletServer.announceExistence(TabletServer.java:2681)
                 ... 8 more
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Borked the CSS link,ACCUMULO-1600,12659333,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,23/Jul/13 13:44,17/Sep/13 13:35,13/Mar/19 22:01,17/Sep/13 13:35,,,,,,,,,,,,,,,,,0,,,,,"I was trying to get the site working on domains not always deployed at the root of a domain, and inadvertently screwed up the CSS on subpages.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-23 13:44:37.313,,,no_permission,,,,,,,,,,,,339526,,,Tue Jul 23 17:09:34 UTC 2013,,,,,,0|i1mk73:,339846,,,,,,,,"23/Jul/13 13:44;jira-bot;Commit 1506042 from [~elserj] in branch 'site/trunk'
[ https://svn.apache.org/r1506042 ]

ACCUMULO-1600 Revert my change to the CSS to get the site correct again.",23/Jul/13 17:05;elserj;couple of other goofups too,"23/Jul/13 17:09;jira-bot;Commit 1506162 from [~elserj] in branch 'site/trunk'
[ https://svn.apache.org/r1506162 ]

ACCUMULO-1600 Grab the rest of the URLs I had made relative instead of absolute",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Provide feedback that a compaction is ""stuck""",ACCUMULO-1345,12644615,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,mdrob,mdrob,25/Apr/13 14:59,16/Sep/13 22:13,13/Mar/19 22:01,06/Sep/13 22:40,,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"The system should be able to detect when a compaction has not read or written data in a while, indicating that it may be stuck on something (e.g. an infinite loop in a user iterator).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1570,ACCUMULO-1188,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-25 15:12:54.875,,,no_permission,,,,,,,,,,,,324980,,,Mon Sep 16 22:13:06 UTC 2013,,,,,,0|i1k2fr:,325325,,,,,,,,"25/Apr/13 15:12;kturner;listing compactions was added in 1.5.  I looking at the command, it only supports filtering on tablet servers.  If that command could filter on tables and the compact command did not print warnings (ACCUMULO-1344) would this be an adequate solution?","25/Apr/13 17:01;mdrob;[~kturner] - Yea, that seems reasonable.","21/Jun/13 17:53;mdrob;Thinking about this some more, I'm not sure that {{listcompactions}} filtering on tables would be good enough. Compactions should report to the master that they have made progress (similar to MR tasks), either through entries read/written, or through an explicit progress call inside of an iterator. If progress hasn't been made for a configurable amount of time (10 minutes) then action should be taken.",21/Jun/13 18:01;mdrob;We saw compactions getting stuck and think it was caused by HDFS-88 with Accumulo 1.4.3,"21/Jun/13 18:11;kturner;If compactions were run in a separate process (ACCUMULO-1188), then that process could be killed.  Also the tserver monitor the child process for progress.","06/Sep/13 22:37;jira-bot;Commit dee8bbb98ba155bec1612d4a4919648159efeb1e in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=dee8bbb ]

ACCUMULO-1345 log warning and stack trace when compaction does not make progress
","06/Sep/13 22:50;kturner;Here is an example of what this the commit I just made does.  Below shows configuring accumulo to warn if a compaction does not make progress in 30 seconds AND then setting the slow iterator to sleep for 60 seconds.

{noformat}
root@test16> config -s tserver.compaction.warn.time=30s
root@test16> table foo
root@test16 foo> config -t foo -s table.iterator.minc.slow=100,org.apache.accumulo.test.functional.SlowIterator
root@test16 foo> config -t foo -s table.iterator.minc.slow.opt.sleepTime=60000
root@test16 foo> insert r1 cf1 cq1 v1
root@test16 foo> flush -t foo 
2013-09-06 18:43:38,299 [shell.Shell] INFO : Flush of table foo initiated...
{noformat}

Eventually, the following shows up in the tserver logs.   

{noformat}
2013-09-06 18:44:27,044 [tabletserver.CompactionWatcher] WARN : Compaction of 2<< has not made progress for at least 39999ms
java.lang.Exception: Possible stack trace of compaction stuck on 2<<
        at java.lang.Thread.sleep(Native Method)
        at org.apache.accumulo.core.util.UtilWaitThread.sleep(UtilWaitThread.java:26)
        at org.apache.accumulo.test.functional.SlowIterator.next(SlowIterator.java:56)
        at org.apache.accumulo.server.tabletserver.Compactor.compactLocalityGroup(Compactor.java:499)
        at org.apache.accumulo.server.tabletserver.Compactor.call(Compactor.java:357)
        at org.apache.accumulo.server.tabletserver.MinorCompactor.call(MinorCompactor.java:96)
        at org.apache.accumulo.server.tabletserver.Tablet.minorCompact(Tablet.java:2085)
        at org.apache.accumulo.server.tabletserver.Tablet.access$4300(Tablet.java:157)
        at org.apache.accumulo.server.tabletserver.Tablet$MinorCompactionTask.run(Tablet.java:2172)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
2013-09-06 18:44:38,384 [tabletserver.Compactor] DEBUG: Compaction 2<< 1 read | 1 written |      0 entries/sec | 60.006 secs
2013-09-06 18:44:47,043 [tabletserver.CompactionWatcher] INFO : Compaction of 2<< is no longer stuck
{noformat}

","16/Sep/13 22:13;jira-bot;Commit 2ab30557c434c52c75203603e713f9cd7aa4d454 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2ab3055 ]

ACCUMULO-1345 added filename to log message about stuck compactions
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix documentation for deleterows,ACCUMULO-1407,12647024,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,10/May/13 15:10,12/Sep/13 14:46,13/Mar/19 22:01,12/Sep/13 14:46,1.4.0,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,In the course of researching ACCUMULO-1346 it was observed that javadoc and shell docs related to delete rows are incorrect.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,327381,,,2013-05-10 15:10:31.0,,,,,,0|i1khif:,327725,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Importtable writes file column entries with a filename of ""null""",ACCUMULO-1558,12656695,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,elserj,elserj,08/Jul/13 21:17,11/Sep/13 22:56,13/Mar/19 22:01,11/Sep/13 22:56,1.5.0,,,,,,,1.5.1,1.6.0,,shell,,,,,,0,,,,,"Ran exporttable, updated my version of hadoop, and re-imported the table I cared about.

Got no errors, but noticed when I tried to scan the table that each filename was 'null'

{noformat}
3;2 file:/b-000004m/null []
3;3 file:/b-000004m/null []
3;4 file:/b-000004m/null []
3;5 file:/b-000004m/null []
3;6 file:/b-000004m/null []
3;7 file:/b-000004m/null []
3;8 file:/b-000004m/null []
3;9 file:/b-000004m/null []
3< file:/b-000004m/null []
{noformat}","Gentoo Linux, kernel 3.9.5. Pre-upgrade CDH3u5: hadoop 0.20-based, ZK-3.3.5. Post-upgrade CDH4.3.0: Hadoop 2.0-based, ZK-3.4.5.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-11 22:43:52.145,,,no_permission,,,,,,,,,,,,336918,,,Wed Sep 11 22:56:06 UTC 2013,,,,,,0|i1m44v:,337241,,,,,,,,"08/Jul/13 21:26;elserj;The table directory is also empty:

{noformat}
${instance.dfs.dir}/tables/3/b-000004m
{noformat}","11/Sep/13 22:43;jira-bot;Commit 052068601041f9d97a882ef3db0cc99f46cbf38a in branch refs/heads/1.5.1-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0520686 ]

ACCUMULO-1558 made import table fail when files do not exist
","11/Sep/13 22:51;jira-bot;Commit 052068601041f9d97a882ef3db0cc99f46cbf38a in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0520686 ]

ACCUMULO-1558 made import table fail when files do not exist
","11/Sep/13 22:56;kturner;The problem was that import table was ignoring missing files.  The problem is easy to reproduce, just import twice from the same dir.  The 1st import will move all of the files.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stop-here doesn't consider system hostname,ACCUMULO-1698,12667384,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,_alexm,_alexm,_alexm,06/Sep/13 19:53,11/Sep/13 01:30,13/Mar/19 22:01,11/Sep/13 01:30,1.4.3,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,scripts,,,,,,0,,,,,"On poorly configured systems where the hostname doesn't appear in /etc/hosts, a proper hostname isn't always obtained by stop-here.sh, as a result accumulo admin stop won't be issued before killing local services.

{code}
[alexm@r03n39 ~]$ hostname
r03n39.demo
[alexm@r03n39 ~]$ grep r03n39.demo /etc/hosts
[alexm@r03n39 ~]$ hostname -a

[alexm@r03n39 ~]$
{code}

start-here has slightly expanded search for valid hostname",CentOS release 6.4 (Final),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,06/Sep/13 19:57;_alexm;ACCUMULO-1698.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12601885/ACCUMULO-1698.1.patch.txt,06/Sep/13 20:59;_alexm;ACCUMULO-1698.2.patch.txt;https://issues.apache.org/jira/secure/attachment/12601904/ACCUMULO-1698.2.patch.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-09-06 21:15:21.508,,,no_permission,,,,,,,,,,,,347321,,,Wed Sep 11 01:30:16 UTC 2013,,,,,,0|i1nw2v:,347620,,,,,,,,06/Sep/13 19:57;_alexm;Simple patch based on logic in start-here script. Verified on original environment.,"06/Sep/13 20:59;_alexm;Patch for 1.4.5-SNAPSHOT, previous was for master.","06/Sep/13 21:15;busbey;Any reason not to include the ""localhost"" fall back from start-here.sh (1.4.5-SNAPSHOT, 1.5.1-SNAPSHOT, and master)? Or the fall back to ips (1.5.1-SNAPSHOT, master)?","06/Sep/13 21:21;_alexm;localhost fallback is covered by the first if case:

{code}
if grep -q localhost $ACCUMULO_HOME/conf/slaves
{code}","06/Sep/13 21:26;busbey;ah yes, fair enough. Worth folding that into the single loop as start-here does? It would simplify things longer term.","11/Sep/13 01:17;jira-bot;Commit ac4a027b42ebe66fd184f8b0792272e4bdb86f8e in branch refs/heads/1.4.5-SNAPSHOT from [~_alexm]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ac4a027 ]

ACCUMULO-1698, have stop-here use system+aliased hostname

Signed-off-by: Josh Elser <elserj@apache.org>
","11/Sep/13 01:25;jira-bot;Commit cd135831c5c4005129c652384cfdd3711c4b2f64 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cd13583 ]

ACCUMULO-1698 Merge branch '1.4.5-SNAPSHOT' into 1.5.1-SNAPSHOT

Conflicts:
	bin/stop-here.sh
","11/Sep/13 01:25;jira-bot;Commit ac4a027b42ebe66fd184f8b0792272e4bdb86f8e in branch refs/heads/1.5.1-SNAPSHOT from [~_alexm]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ac4a027 ]

ACCUMULO-1698, have stop-here use system+aliased hostname

Signed-off-by: Josh Elser <elserj@apache.org>
","11/Sep/13 01:29;jira-bot;Commit 63c5d64cbc8ae30d06da84bb36324eca38fc0e36 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=63c5d64 ]

ACCUMULO-1698 Merge branch '1.5.1-SNAPSHOT'
","11/Sep/13 01:29;jira-bot;Commit cd135831c5c4005129c652384cfdd3711c4b2f64 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cd13583 ]

ACCUMULO-1698 Merge branch '1.4.5-SNAPSHOT' into 1.5.1-SNAPSHOT

Conflicts:
	bin/stop-here.sh
","11/Sep/13 01:29;jira-bot;Commit ac4a027b42ebe66fd184f8b0792272e4bdb86f8e in branch refs/heads/master from [~_alexm]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ac4a027 ]

ACCUMULO-1698, have stop-here use system+aliased hostname

Signed-off-by: Josh Elser <elserj@apache.org>
","11/Sep/13 01:30;elserj;Applied! Thanks, Alex.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IndexedDocIterator incorrectly declares some variables as static,ACCUMULO-1700,12667622,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,09/Sep/13 17:16,10/Sep/13 17:07,13/Mar/19 22:01,10/Sep/13 17:07,1.4.4,1.5.0,,,,,,1.5.1,1.6.0,,client,,,,,,0,,,,,"Also, I noticed that the IndexedDocIterator is using a package private variable from the IntersectingIterator.  It would be better to make this variable protected in case people want to extend the IntersectingIterator in different ways.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,09/Sep/13 17:18;billie.rinaldi;ACCUMULO-1700.patch;https://issues.apache.org/jira/secure/attachment/12602167/ACCUMULO-1700.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-09-10 02:09:35.935,,,no_permission,,,,,,,,,,,,347559,,,Tue Sep 10 16:47:52 UTC 2013,,,,,,0|i1nxjr:,347858,,,,,,,,09/Sep/13 17:18;billie.rinaldi;Anyone have feelings about the earliest fix version for this patch?,10/Sep/13 02:09;mdrob;1.5.1 if it applies 'cleanly enough' seems like a reasonable line in the sand.,"10/Sep/13 15:37;jira-bot;Commit 9af0b9d60aa9cf7c50093bd7bc9b9875b86abb52 in branch refs/heads/1.5.1-SNAPSHOT from [~billie.rinaldi@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9af0b9d ]

ACCUMULO-1700 removed static modifier from variables
","10/Sep/13 16:47;jira-bot;Commit 9af0b9d60aa9cf7c50093bd7bc9b9875b86abb52 in branch refs/heads/master from [~billie.rinaldi@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9af0b9d ]

ACCUMULO-1700 removed static modifier from variables
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
No ability to disable trash for root tablet & WAL,ACCUMULO-1618,12660150,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,26/Jul/13 22:56,09/Sep/13 16:13,13/Mar/19 22:01,09/Sep/13 16:13,1.5.0,,,,,,,1.5.1,1.6.0,,tserver,,,,,,0,,,,,"In 1.5 we changed the check in the garbage collector from a flag that gets passed in into a system setting. However, there are a few other places in the code where we want to provide the ability to bypass the trash. At least one is in the Tablet.java#bringMajorCompactionOnline. There is another case in the WALs, but the errors don't have stack traces.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Sep/13 15:26;vines;ACCUMULO-1618.patch;https://issues.apache.org/jira/secure/attachment/12601395/ACCUMULO-1618.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-08-08 03:48:12.934,,,no_permission,,,,,,,,,,,,340342,,,Mon Sep 09 16:08:06 UTC 2013,,,,,,0|i1mp7j:,340660,,,,,,,,"08/Aug/13 03:48;rmutyala;I am making a change of putting fs.trash.interval to zero in the configuration that creates FS when gc.trash.ignore is set to true. 

I tested some scenarios and thing seem to be working. Please review this patch. ","13/Aug/13 20:47;vines;That isn't an adequate fix, IMO, due to HDFS-8689. With that, the server's configuration of fs.trash.interval takes precedent and can't be overridden by the client configuration. HDFS-4683 provides a tldr explanation in it by Doug Cutting as the top comment.

I believe the only satisfactory way to do it is to scope out all instances of fs.moveToTrash and put the appropriate config checks in place around them like we do in the SimpleGarbageCollector. Ideally we want the config's to be loaded more than once per server so it can be changed without a full system restart because the gc is light enough to get away with that but tservers aren't.","14/Aug/13 17:26;yuzhihong@gmail.com;@John:
HDFS-8689 doesn't seem to exist.
Could it be a typo ?","14/Aug/13 17:31;vines;Sorry, HADOOP-8689","14/Aug/13 17:45;rmutyala;True. I was watching that item, and didn't realize there was another jira that went in for serverside trash configuration on v2. So, this patch will fail on 2.0 branch. 

I will go ahead and make a change to fix fs.moveToTrash with the check. I believe loading the configs more than once to not require full system restart should have its own ticket and tracked separately. ","04/Sep/13 15:26;vines;I put this together to resolve this. I just found all calls for moveToTrash and added the appropriate config check, which I think is the only things necessary. It does slightly change the meaning of the setting (since it's more than GC that uses it), but I don't think it's worth renaming or anything like that since the semantics are the same. Unless there are objections, I'll commit it to 1.5.1 and 1.6.0 in a few days.","09/Sep/13 16:07;jira-bot;Commit 368fe1c447bf17e91baf7ced2049c9ac611f1b96 in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=368fe1c ]

ACCUMULO-1618 - adding trash variable checks to dispersed WAL cleanup code
","09/Sep/13 16:08;jira-bot;Commit 368fe1c447bf17e91baf7ced2049c9ac611f1b96 in branch refs/heads/1.5.1-SNAPSHOT from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=368fe1c ]

ACCUMULO-1618 - adding trash variable checks to dispersed WAL cleanup code
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MiniAccumuloCluster doesn't properly support multiple Hadoop versions,ACCUMULO-1668,12665590,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,26/Aug/13 20:46,06/Sep/13 17:41,13/Mar/19 22:01,06/Sep/13 17:41,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Static variables are inline'd by the java compiler, and since these keys could vary from one Hadoop version to another, they may require Accumulo to be re-compiled to support multiple versions.

Also, DFSConfigKeys.DFS_SUPPORT_APPEND_KEY doesn't exist in Hadoop 1.2.1
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-06 17:40:57.318,,,no_permission,,,,,,,,,,,,345530,,,Fri Sep 06 17:40:57 UTC 2013,,,,,,0|i1nl2f:,345831,,,,,,,,"06/Sep/13 17:40;jira-bot;Commit 90feb4ce1ba95da3da4d351d15496565388b3609 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=90feb4c ]

ACCUMULO-1668 test constants changes, ACCUMULO-1643 use hadoop 1.2.1
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Race condition in BulkImport causes ConcurrentModificationException,ACCUMULO-1252,12641402,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,bills,bills,08/Apr/13 17:03,05/Sep/13 13:03,13/Mar/19 22:01,05/Sep/13 13:03,1.4.2,,,,,,,1.4.4,,,,,,,,,0,,,,,"The LoadFiles class gets a synchronized list of files to import and, while iterating over that list, creates another list of Callable's. If the list of files to load is long enough, it's possible that a bulk import on a previous file in the list could finish and remove itself from the master list before all of the commands to import the rest of the files are created. This causes a ConcurrentModificationException when trying to fetch the next file to load.

I think the concurrent lists support an iterator that will not fail if the underlying list is modified, but if not, I think this can be solved by first creating a list of Callables and then adding them to the thread pool in a separate loop.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-08 17:27:23.474,,,no_permission,,,,,,,,,,,,321818,,,Mon Jun 03 22:56:35 UTC 2013,,,,,,0|i1jixr:,322163,,,,,,,,08/Apr/13 17:27;ecn;This happened when multiple import requests were being processed for over 700 files.,"08/Apr/13 18:13;hudson;Integrated in Accumulo-Trunk #823 (See [https://builds.apache.org/job/Accumulo-Trunk/823/])
    ACCUMULO-1252 remove loaded files outside the threadpool (Revision 1465690)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/trunk/src
","08/Apr/13 18:16;hudson;Integrated in Accumulo-1.4.x #288 (See [https://builds.apache.org/job/Accumulo-1.4.x/288/])
    ACCUMULO-1252 remove loaded files outside the threadpool (Revision 1465687)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
","08/Apr/13 18:53;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #181 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/181/])
    ACCUMULO-1252 remove loaded files outside the threadpool (Revision 1465690)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/trunk/src
","08/Apr/13 18:57;hudson;Integrated in Accumulo-1.5 #69 (See [https://builds.apache.org/job/Accumulo-1.5/69/])
    ACCUMULO-1252 remove loaded files outside the threadpool (Revision 1465688)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/branches/1.5/src
","08/Apr/13 19:00;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #68 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/68/])
    ACCUMULO-1252 remove loaded files outside the threadpool (Revision 1465688)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java
* /accumulo/branches/1.5/src
",03/Jun/13 22:56;mdrob;Is this resolved?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove username from initialization,ACCUMULO-1544,12655609,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,01/Jul/13 15:33,04/Sep/13 20:31,13/Mar/19 22:01,04/Sep/13 18:38,1.5.0,,,,,,,1.5.1,,,start,,,,,,0,,,,,"This is an artifact from a brief transition area during the 1.5 development. We have a flag for the user to set what the root username is, except it's never used. We should remove both the variable and the flag for it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-04 18:28:48.13,,,no_permission,,,,,,,,,,,,335884,,,Wed Sep 04 20:31:38 UTC 2013,,,,,,0|i1lxrj:,336208,,,,,,,,"04/Sep/13 18:28;jira-bot;Commit 9aebb2b110abe773523dc43a46b1804fc5d37797 in branch refs/heads/1.5.1-SNAPSHOT from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9aebb2b ]

ACCUMULO-1544 - removing username flag and use from init/MAC
","04/Sep/13 18:37;jira-bot;Commit 808a5e01e0091cc52685411aa497b282b45fb38d in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=808a5e0 ]

Merging ACCUMULO-1544 forward (even though no changes needed to be propogated)
","04/Sep/13 18:37;jira-bot;Commit 9aebb2b110abe773523dc43a46b1804fc5d37797 in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9aebb2b ]

ACCUMULO-1544 - removing username flag and use from init/MAC
","04/Sep/13 20:31;jira-bot;Commit 0cf2ff72d9c9f2e76165e3285991c9b546b5f7ec in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0cf2ff7 ]

ACCUMULO-1544 Thought this flag was gone in MAC, fixed now
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Input Format puts passwords in Configuration, which is world readable",ACCUMULO-829,12613013,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,shickey,kturner,kturner,22/Oct/12 18:32,28/Aug/13 16:15,13/Mar/19 22:01,28/Aug/13 16:15,1.4.0,1.4.2,1.5.0,,,,,1.6.0,,,,,,,,,0,,,,,"Using this ticket to reopen ACCUMULO-489 because of ACCUMULO-826.   

The reason I created a new ticket instead of opening 489 again is because work done against 489 was released in 1.4.1. I think leaving that ticket as-is makes it easier to understand whats in 1.4.1. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1041,,23/May/13 15:11;shickey;TokenFile-README.txt;https://issues.apache.org/jira/secure/attachment/12584509/TokenFile-README.txt,23/May/13 15:11;shickey;tokenfile.patch;https://issues.apache.org/jira/secure/attachment/12584508/tokenfile.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2012-12-18 16:25:51.392,,,no_permission,,,,,,,,,,,,250386,,,Wed Aug 28 16:15:02 UTC 2013,,,,,,0|i0ay1r:,61789,,,,,,,,18/Dec/12 16:25;ctubbsii;Examples should show any differences also.,"26/Jan/13 04:33;hudson;Integrated in Accumulo-Trunk #675 (See [https://builds.apache.org/job/Accumulo-Trunk/675/])
    ACCUMULO-829 Adds a new option to pass in the path to a file that gets added to the distributed cache, with the user's credentials. (Revision 1438827)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/ConfiguratorBase.java
","26/Jan/13 04:36;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #33 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/33/])
    ACCUMULO-829 Adds a new option to pass in the path to a file that gets added to the distributed cache, with the user's credentials. (Revision 1438827)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/ConfiguratorBase.java
","07/Feb/13 21:15;ctubbsii;Reopening this because changes made for ACCUMULO-259 (and related tickets, such as ACCUMULO-1041) affect the behavior, and need to be resolved before I can test this and mark it as fixed.","07/Feb/13 21:19;ctubbsii;Some reverting happened for ACCUMULO-1003 that broke this, but those changes should be fixed by ACCUMULO-1041, and this ticket can be revisited.","12/Apr/13 20:21;kturner;This feature was mostly done for 1.5.  Commit r1442284 inadvertently deleted half of the feature and it was never fixed.  In the interest of finalizing 1.5, I deleted the rest of the feature.  This issue will have to be fixed in a later release.","12/Apr/13 20:34;hudson;Integrated in Accumulo-1.5 #76 (See [https://builds.apache.org/job/Accumulo-1.5/76/])
    ACCUMULO-829 ACCUMULO-987 removed partially implemented feature to pass credentials to map reduce via file (Revision 1467444)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloInputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloOutputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloRowInputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/ConfiguratorBase.java
","12/Apr/13 23:56;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #76 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/76/])
    ACCUMULO-829 ACCUMULO-987 removed partially implemented feature to pass credentials to map reduce via file (Revision 1467444)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloInputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloOutputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloRowInputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormat.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/ConfiguratorBase.java
","12/Apr/13 23:57;hudson;Integrated in Accumulo-Trunk #830 (See [https://builds.apache.org/job/Accumulo-Trunk/830/])
    ACCUMULO-829 ACCUMULO-987 removed partially implemented feature to pass credentials to map reduce via file (Revision 1467453)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/ConfiguratorBase.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","13/Apr/13 00:05;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #188 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/188/])
    ACCUMULO-829 ACCUMULO-987 removed partially implemented feature to pass credentials to map reduce via file (Revision 1467453)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/ConfiguratorBase.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
",23/May/13 15:10;shickey;Patch to add the use of token files instead of passwords. Adds a utility to create token files that store the token rather than having map-reduce jobs put it in the configuration. ,"23/May/13 16:10;ctubbsii;Added Sean to contributors, so I could assign him the ticket.","23/May/13 20:33;hudson;Integrated in Accumulo-Trunk #887 (See [https://builds.apache.org/job/Accumulo-Trunk/887/])
    ACCUMULO-829 Apply patch from Sean Hickey, with modification of moving utility class for creating tokens to core instead of server (Revision 1485798)

     Result = UNSTABLE
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOnRequiredTable.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/ConfiguratorBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/CreateToken.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapred/TokenFileTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/TokenFileTest.java
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/Main.java
","23/May/13 20:41;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #246 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/246/])
    ACCUMULO-829 Apply patch from Sean Hickey, with modification of moving utility class for creating tokens to core instead of server (Revision 1485798)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOnRequiredTable.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/ConfiguratorBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/CreateToken.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapred/TokenFileTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/TokenFileTest.java
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/Main.java
","27/Aug/13 18:51;mdrob;Is this issue resolved? It looks like the patch has been applied. [~ctubbsii], is there any more to add?","28/Aug/13 16:11;ctubbsii;I want to clean up the internals of how the credentials are passed in the protected getters still. Right now, I think it's a bit convoluted, because of ACCUMULO-1312 (more precisely, the Credentials object created in ACCUMULO-1312 has serialization methods that can help clean up a lot of this).","28/Aug/13 16:15;ctubbsii;Sub-tickets still need completing to polish up, but the primary task is done.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE writing to the WAL,ACCUMULO-888,12618229,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,29/Nov/12 21:01,20/Aug/13 20:03,13/Mar/19 22:01,19/Dec/12 20:28,1.4.2,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"
I missconfigured the WAL max size to ""4"" and got this strange error:

{noformat}
2012-11-29 12:12:55,610 [log.TabletServerLogger] ERROR: Unexpected error writing to log, retrying attempt 5
java.lang.NullPointerException
        at org.apache.accumulo.server.tabletserver.log.RemoteLogger.logManyTablets(RemoteLogger.java:145)
        at org.apache.accumulo.server.tabletserver.log.TabletServerLogger$6.write(TabletServerLogger.java:393)
        at org.apache.accumulo.server.tabletserver.log.TabletServerLogger.write(TabletServerLogger.java:298)
        at org.apache.accumulo.server.tabletserver.log.TabletServerLogger.logManyTablets(TabletServerLogger.java:382)
        at org.apache.accumulo.server.tabletserver.TabletServer$ThriftClientHandler.flush(TabletServer.java:1539)
        at org.apache.accumulo.server.tabletserver.TabletServer$ThriftClientHandler.closeUpdate(TabletServer.java:1610)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-03 17:09:20.032,,,no_permission,,,,,,,,,,,,292858,,,Mon Dec 03 17:09:20 UTC 2012,,,,,,0|i0sg07:,164070,,,,,,,,"03/Dec/12 17:09;hudson;Integrated in Accumulo-1.4.x #249 (See [https://builds.apache.org/job/Accumulo-1.4.x/249/])
    ACCUMULO-888 concurrent use of a logger can result in an NPE; make the error explicitly a LoggerClosedException (Revision 1416580)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/tabletserver/log/RemoteLogger.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to connect to remote Accumulo instance via Java,ACCUMULO-687,12598622,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,yury.vashchla,yury.vashchla,12/Jul/12 20:43,15/Aug/13 02:36,13/Mar/19 22:01,12/Jul/12 21:04,1.4.1,,,,,,,,,,,,,,,,0,,,,,"I have an Accumulo instance setup (with everything running on onehost) and I'm able to connect locally through the Accumulo shell.

However from a remote machine:

new ZooKeeperInstance(""inst0"", ""192.168.1.4"").getConnector(""root"", ""password"".getBytes());

I get the following error:

12/07/12 16:02:57 WARN impl.ServerClient: Failed to find an available server in the list of servers: [127.0.0.1:9997:9997 (120000)]
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-07-12 20:51:19.113,,,no_permission,,,,,,,,,,,,246381,,,Thu Aug 15 02:36:53 UTC 2013,,,,,,0|i07lo7:,42277,,,,,,,,"12/Jul/12 20:51;ecn;Change your masters/slaves files to contain ""192.168.1.4"" instead of ""localhost"". You can use whatever hostname that host has so long as it is resolvable.
",12/Jul/12 21:04;yury.vashchla;It works. Thanks a lot!!,15/Aug/13 02:36;beedaan;Thank you!  Is this documented anywhere else?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GC removed WAL that master wasn't done with,ACCUMULO-1651,12662892,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,mberman,mberman,09/Aug/13 17:16,09/Aug/13 22:26,13/Mar/19 22:01,09/Aug/13 22:26,,,,,,,,1.6.0,,,gc,master,,,,,0,,,,,"I have a master that's spinning trying to recover a walog that doesn't exist in hdfs.  It looks like the GC cleaned it up.  I was stopping and starting my cluster throughout this period, and there was at least a few minutes in which every service was talking SSL except the GC, so the GC couldn't receive thrift messages from other services, but [~vines] says this shouldn't affect the GC's deletion behavior.


Here are some relevant logs.  Note that the master thinks its logSet includes that file straight through the time the GC removed it.

GC:
{code}
2013-08-09 11:58:14,835 [util.MetadataTableUtil] INFO : Returning logs [!!R<< hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7 (1)] for extent !!R<<
2013-08-09 11:58:14,852 [gc.GarbageCollectWriteAheadLogs] DEBUG: Removing WAL for offline server hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7
2013-08-09 12:03:15,467 [util.MetadataTableUtil] INFO : Returning logs [!!R<< hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7 (1)] for extent !!R<<
{code}

Master:
{code}
2013-08-09 11:57:45,235 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:45,238 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:45,286 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:45,324 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:45,939 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:45,942 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:45,975 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:55,612 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:55,679 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:55,739 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:55,764 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:55,784 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:56,031 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:57:56,046 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:58:56,051 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 11:59:56,057 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:00:56,062 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:01:56,066 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:02:56,071 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:08:56,103 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:09:56,108 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:10:56,113 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:11:56,118 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:13:19,883 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:14:19,887 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
<master was restarted here>
2013-08-09 12:15:44,459 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:15:44,467 [recovery.RecoveryManager] DEBUG: Recovering hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7 to hdfs://localhost:54310/otherAccumuloInstance/recovery/5a383792-c89b-41ed-bc22-0802e76638f7
2013-08-09 12:15:44,472 [recovery.RecoveryManager] INFO : Starting recovery of hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7 (in : 10s) created for localhost+9997, tablet !!R<< holds a reference
2013-08-09 12:15:54,479 [recovery.RecoveryManager] DEBUG: Unable to initate log sort for hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7: java.io.FileNotFoundException: java.io.FileNotFoundException: File not found /otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7
2013-08-09 12:16:44,487 [state.ZooTabletStateStore] DEBUG: root tablet logSet [localhost+9997/hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7]
2013-08-09 12:16:44,488 [recovery.RecoveryManager] DEBUG: Recovering hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7 to hdfs://localhost:54310/otherAccumuloInstance/recovery/5a383792-c89b-41ed-bc22-0802e76638f7
2013-08-09 12:16:44,490 [recovery.RecoveryManager] INFO : Starting recovery of hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7 (in : 20s) created for localhost+9997, tablet !!R<< holds a reference
2013-08-09 12:17:04,494 [recovery.RecoveryManager] DEBUG: Unable to initate log sort for hdfs://localhost:54310/otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7: java.io.FileNotFoundException: java.io.FileNotFoundException: File not found /otherAccumuloInstance/wal/localhost+9997/5a383792-c89b-41ed-bc22-0802e76638f7
<repeating ad infinitum>
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-08-09 18:19:40.171,,,no_permission,,,,,,,,,,,,342894,,,Fri Aug 09 22:23:27 UTC 2013,,,,,,0|i1n4uf:,343198,,,,,,,,"09/Aug/13 18:19;ecn;This is probably due to switching over to the Root Table.  I'll bet that confirmDeletes is not taking the root table log reference (in zookeeper) into account.
","09/Aug/13 22:23;jira-bot;Commit e0a37f808ad266740cec702279861ce28e991cc8 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e0a37f8 ]

ACCUMULO-1651 read log records from zookeeper, the root table and the metadata table, added a test
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MiniAccumuloCluster's MiniDFS data directory is created relative to the working directory,ACCUMULO-1631,12661202,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mberman,mberman,mberman,01/Aug/13 19:17,09/Aug/13 13:57,13/Mar/19 22:01,09/Aug/13 13:57,,,,,,,,1.6.0,,,mini,,,,,,1,,,,,"Seems like it should go in one of the directories passed in the MiniAccumuloConfig (where other namenode and datanode data already go).

This is causing integration tests to fail on my local machine, since every test tries to use the same dfs tree but they're not always cleaned up and unlocked nicely over the lifespan of the tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,01/Aug/13 20:19;mberman;ACCUMULO-1631.patch;https://issues.apache.org/jira/secure/attachment/12595474/ACCUMULO-1631.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,341391,,,Thu Aug 01 20:22:37 UTC 2013,,,,,,0|i1mvo7:,341709,,,,,,,,"01/Aug/13 20:22;mberman;Unfortunately it seems like the only way to fix this is to use System.setProperty() to override the MiniDFS defaults (it looks from the code initially like it can be overridden with a combination of constructor flags and config switches, but the same property is referenced deeper in the code without respect to those switches).

Also had to change the expected permissions from 775 to 755, since MiniDFS creates the directories under there with no particular permissions, making them 755, but then immediately tries to verify that they have the permissions you requested, which fails if you requested anything else.

This fixes many integration test failures of the form ""Cannot lock storage build/test/data/dfs/name1. The directory is already locked"" on my local build",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Services don't bind to specified --address parameter,ACCUMULO-1464,12649385,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ctubbsii,ctubbsii,24/May/13 20:00,07/Aug/13 14:19,13/Mar/19 22:01,07/Aug/13 14:19,,,,,,,,1.6.0,,,gc,master,monitor,trace,tserver,,0,,,,,"The --address parameter on services are evidently ignored. The only service I've found that actually respects it is the Monitor service, and even then, it's only respected for the HTTP port, and not the log4j port. Everything else binds to 0.0.0.0

`jps -m` shows that the process is correctly started with the --address parameter, so it's not an issue with the scripts.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,329712,,,2013-05-24 20:00:58.0,,,,,,0|i1kvtr:,330047,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Files in cloned table disappear when source deleted,ACCUMULO-1629,12661168,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,01/Aug/13 16:42,05/Aug/13 13:47,13/Mar/19 22:01,05/Aug/13 13:44,,,,,,,,1.6.0,,,,,,,,,0,,,,,"I was running randomwalk trying to reproduce ACCUMULO-1625 and ran into what may be a different issue.  Eventually concurrent random walk test failed because a file disappeared.  After looking in the logs for a while, I determined the following happened.

  # File I000005n.rf bulk imported into tableid q
  # tableid q cloned into tableid u
  # tableid q deleted
  # scan of tableid u fails because I000005n.rf does not exist

When a table is deleted it checks to see if any clones reference files in the table.  If so, then it lets the Accumulo GC delete the deleted tables files.  If not, then the files are deleted immediately.  Maybe something is going wrong with this check.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-08-02 15:05:24.983,,,no_permission,,,,,,,,,,,,341357,,,Mon Aug 05 13:47:09 UTC 2013,,,,,,0|i1mvgn:,341675,,,,,,,,"02/Aug/13 15:05;jira-bot;Commit 4bff142d3a017c220fc1a69adc962535735758f6 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4bff142 ]

ACCUMULO-1629 reproduced conetable bug seen in random walk in functional test
","05/Aug/13 12:56;jira-bot;Commit 4c51fb26d8b84e22a887317d3c0449ee5dedf51c in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4c51fb2 ]

ACCUMULO-1629 file references between tables no longer use the ""../"" indirection
","05/Aug/13 13:43;jira-bot;Commit a54dbe2e288918f167ffe527a4c61fbc7a38cdbf in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a54dbe2 ]

ACCUMULO-1629 skip the table itself when looking for other references
","05/Aug/13 13:47;jira-bot;Commit bf320f8493c4bcc88d98d746ba57c0984e52596b in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bf320f8 ]

ACCUMULO-1629 fix unused import warning
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Don't cache credentials in client-side Connector,ACCUMULO-1312,12643097,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,17/Apr/13 23:55,29/Jul/13 20:07,13/Mar/19 22:01,29/Jul/13 20:07,1.5.0,,,,,,,1.6.0,,,client,,,,,,0,,,,,"AuthenticationToken objects are Destroyable. However, this cannot be exercised properly in the client code, because the Connector immediately serializes the credentials and stores them as long as the Connector lives.

It should be possible to destroy a token after creating a Connector, and thereby forcing any further RPC calls initiated by that Connector to fail to authenticate. This means that serialization on the client side to a TCredentials object needs to occur just before the RPC call.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-295,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-26 23:58:50.245,,,no_permission,,,,,,,,,,,,323507,,,Mon Jul 29 19:58:29 UTC 2013,,,,,,0|i1jtcv:,323852,,,,,,,,"18/Apr/13 00:03;ctubbsii;Not as problematic as ACCUMULO-295, but similar behavior.","26/Jul/13 23:58;jira-bot;Commit 5e0d7e7bafa48a1151451714231a7158b1d9b74e in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5e0d7e7 ]

ACCUMULO-1312 Fix mapred and proxy serialization issues.
","26/Jul/13 23:58;jira-bot;Commit 99da5641c28784c7b717cce6749673863c2ec8cf in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=99da564 ]

ACCUMULO-1312 use Credentials object to avoid serializing as long as
possible
","29/Jul/13 19:58;jira-bot;Commit d9ab84498cad5ee70eee3d337224b3d5ca7ab0db in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d9ab844 ]

ACCUMULO-1312 Test Connectors and serialization with destroyed tokens
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incorrect use of getCanonicalName in BloomFilterLayer code (and others),ACCUMULO-1616,12659892,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,25/Jul/13 20:51,25/Jul/13 21:01,13/Mar/19 22:01,25/Jul/13 21:01,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Found places in our code where we serialize classnames with getCanonicalName() instead of the correct getName(), for dynamic loading.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-25 21:01:11.545,,,no_permission,,,,,,,,,,,,340084,,,Thu Jul 25 21:01:11 UTC 2013,,,,,,0|i1mnmf:,340402,,,,,,,,"25/Jul/13 21:01;jira-bot;Commit 98b2a0bc50c62700a38c88ce0354c31d2d642fbf in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=98b2a0b ]

ACCUMULO-1616 Replace occurances of Class.getCanonicalName() with
Class.getName() for correctness and for consistency in log messages.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"If initial port binding fails, ThriftMetrics MBean is never registered for subsequently bound TServer",ACCUMULO-1586,12658781,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mberman,mberman,mberman,19/Jul/13 16:36,22/Jul/13 18:25,13/Mar/19 22:01,22/Jul/13 18:25,1.5.0,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,"When trying a range of ports, the MBean for reporting metrics is registered before the connection has had an opportunity to fail.  If it fails and we try a new port, the same MBean objectName is used for registering the new ThriftMetrics object created for the new server.  This fails because there is already an MBean registered with that name.  A couple possible fixes: wait to register until we're sure the connection has succeeded; create the timed processor outside the port-binding loop; or deregister the bean after a failure.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,22/Jul/13 15:29;mberman;ACCUMULO-1586.patch;https://issues.apache.org/jira/secure/attachment/12593532/ACCUMULO-1586.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-07-22 18:25:05.223,,,no_permission,,,,,,,,,,,,338975,,,Mon Jul 22 18:25:43 UTC 2013,,,,,,0|i1mgsn:,339295,,,,,,,,"22/Jul/13 15:30;mberman;Chose the ""create the timed processor outside the port binding loop"" option.  Kept a TServerUtils.startTServer() delegate that still takes the unwrapped Processor so other consumers don't have to wrap it themselves if they're not doing anything fancy.","22/Jul/13 18:25;jira-bot;Commit 1a48f7c34da98f4ba1fe3fac133081ee5f35caca in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1a48f7c ]

ACCUMULO-1586 committing Michael Berman's patch
",22/Jul/13 18:25;ecn;Patched.  Thanks!,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
InputFormatBase always sets a regex filter at level 50 during initialize(),ACCUMULO-1267,12642090,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bills,bills,bills,11/Apr/13 18:26,03/Jul/13 04:19,13/Mar/19 22:01,03/Jul/13 04:19,1.4.2,,,,,,,1.4.4,,,,,,,,,0,,,,,"Even if a user doesn't supply a regex for the row, column family or column qualifier, a filter still gets set on the scanner at level 50. The code should be smart enough to not set the iterator if no regex is set.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-11 19:52:22.768,,,no_permission,,,,,,,,,,,,322504,,,Wed Jul 03 04:18:36 UTC 2013,,,,,,0|i1jn67:,322849,,,,,,,,"11/Apr/13 19:52;billie.rinaldi;Good catch, William!",04/Jun/13 12:43;billie.rinaldi;This bug only affects branch 1.4.,"03/Jul/13 04:04;jira-bot;Commit 1499198 from [~bills]
[ https://svn.apache.org/r1499198 ]

ACCUMULO-1267 Added check to see if a user actually sets a regex before applying the RegExFilter to the record reader's scanner.","03/Jul/13 04:14;jira-bot;Commit 1499201 from [~bills]
[ https://svn.apache.org/r1499201 ]

ACCUMULO-1267 record only merge from 1.4 onto 1.5","03/Jul/13 04:18;jira-bot;Commit 1499203 from [~bills]
[ https://svn.apache.org/r1499203 ]

ACCUMULO-1267 Record only merge from 1.4 onto trunk",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FileOperations expects RFile filenames to contain only 1 dot.,ACCUMULO-1518,12653223,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,dlyle,dlyle,dlyle,17/Jun/13 17:17,02/Jul/13 12:29,13/Mar/19 22:01,02/Jul/13 12:29,1.4.2,1.4.3,1.5.0,,,,,1.4.4,1.5.1,1.6.0,,,,,,,0,,,,,"If I attempt to create or read an RFile that contains more than 1 dot in the filename, FileOperations throws an IllegalArgumentException(""File name "" + name + "" has no extension"").
Please allow creation/import of RFiles that have more than 1 dot in the filename.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,17/Jun/13 18:15;dlyle;accumulo-1518-1.4.3.patch;https://issues.apache.org/jira/secure/attachment/12588174/accumulo-1518-1.4.3.patch,17/Jun/13 18:28;dlyle;accumulo-1518.patch;https://issues.apache.org/jira/secure/attachment/12588179/accumulo-1518.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-06-17 19:24:45.934,,,no_permission,,,,,,,,,,,,333546,,,Mon Jun 17 20:39:20 UTC 2013,,,,,,0|i1ljen:,333874,,,,,,,,17/Jun/13 17:19;dlyle;Patch to allow more than one dot and a test.,17/Jun/13 18:15;dlyle;1.4.3 version of patch.,"17/Jun/13 19:24;jira-bot;Commit 1493894 from [~kturner]
[ https://svn.apache.org/r1493894 ]

ACCUMULO-1518 Patch from David M. Lyle that allows opening rfiles w/ multiple dots in name.","17/Jun/13 19:28;jira-bot;Commit 1493896 from [~kturner]
[ https://svn.apache.org/r1493896 ]

ACCUMULO-1518 Patch from David M. Lyle that allows opening rfiles w/ multiple dots in name.","17/Jun/13 19:36;jira-bot;Commit 1493899 from [~kturner]
[ https://svn.apache.org/r1493899 ]

ACCUMULO-1518 Patch from David M. Lyle that allows opening rfiles w/ multiple dots in name.","17/Jun/13 19:48;kturner;[~dlyle] thanks for the patch.  Let me know if you would like to be added to the contributors page and if you would like your org set.  

The unit test was not properly formatted and did not have the Apache License header.  I fixed these issues before committing.  The Accumulo [source|http://accumulo.apache.org/source.html] page has some info on formatting source code.

","17/Jun/13 20:39;dlyle;Sure, I'd really enjoy having my name on the contributors page. No org.

Thanks!

-D...




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove hadoop boxes from monitor,ACCUMULO-873,12617649,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,vines,vines,26/Nov/12 16:45,01/Jul/13 22:27,13/Mar/19 22:01,01/Jul/13 20:48,1.4.1,1.4.2,,,,,,1.5.0,,,monitor,,,,,,0,,,,,"Accumulo includes some HDFS information on the Overview page of the monitor. Unfortunately, there is not cosistency in hadoop and hadoop compatible distributions with regard to their stats apis. When these failures do happen, it breaks everything on the overview page, which includes the graphs. We should just purge them. People can get their dfs/jt stats from the respective services if they want them.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-26 18:34:15.092,,,no_permission,,,,,,,,,,,,292154,,,Mon Jul 01 22:26:54 UTC 2013,,,,,,0|i0rs4n:,160201,,,,,,,,"26/Nov/12 18:34;ecn;My preference is to remove this from the monitor page.

# it doesn't work with a non-hdfs user
# it isn't part of the public API
# hdfs works well enough these days that we're not monitoring it so closely, which was the purpose for it in the first place
# it won't work with other file systems
# JobTracker box should go away, too: there's no API for it in foture versions of hadoop

","02/Jan/13 19:57;hudson;Integrated in Accumulo-Trunk #598 (See [https://builds.apache.org/job/Accumulo-Trunk/598/])
    ACCUMULO-873 removed hdfs info from accumulo monitor page (Revision 1427887)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
",07/Jun/13 12:36;billie.rinaldi;We should either remove the 1.4 fix version or merge this to 1.4.,10/Jun/13 16:33;billie.rinaldi;Does anyone want this for 1.4?,12/Jun/13 20:30;ctubbsii;+0 for removing it in 1.4.,"01/Jul/13 18:07;mdrob;Interpreting [~ctubbsii]'s +0 as a ""no preference,"" I think we should just drop the fix version in the interests of getting 1.4.4 out the door sooner rather than later.","01/Jul/13 22:00;ctubbsii;See http://www.apache.org/foundation/voting.html
+0 means 'I don't feel strongly about it, but I'm okay with this.'","01/Jul/13 22:26;elserj;+0

I think I'd fall on the side of not removing them in a (1.4.3, 1.5.0) release just to keep continuity in the 1.4 releases, but it's really just whatever.

And then I realized [~billie.rinaldi] did it already :P",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FormatterCommandTest fails in Eclipse,ACCUMULO-1529,12654187,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,21/Jun/13 15:52,21/Jun/13 15:53,13/Mar/19 22:01,21/Jun/13 15:53,,,,,,,,1.6.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-21 15:53:34.013,,,no_permission,,,,,,,,,,,,334464,,,Fri Jun 21 15:53:34 UTC 2013,,,,,,0|i1lp27:,334790,,,,,,,,"21/Jun/13 15:53;jira-bot;Commit 1495484 from [~ctubbsii]
[ https://svn.apache.org/r1495484 ]

ACCUMULO-1529 fix newline problems in FormatterCommandTest when running out of Eclipse",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DynamicClassloader test uses an insufficient classpath,ACCUMULO-523,12550509,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,11/Apr/12 12:28,20/Jun/13 20:42,13/Mar/19 22:01,11/Apr/12 17:23,,,,,,,,,,,test,,,,,,0,,,,,"reported by Keys Botzum:

 simple.dynamic.DynamicClassloader fails with class loader issues referencing both Accumulo and Hadoop classes. I examined simple/dynamic.py and determined that the class path references weren't sufficient where javac was invoked. I added the following to the class path command line options for javac and now it works:  /opt/accumulo-1.4.0/lib/\*:/opt/mapr/hadoop/hadoop-0.20.2/lib/\*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-20 20:42:14.626,,,no_permission,,,,,,,,,,,,235373,,,Thu Jun 20 20:42:14 UTC 2013,,,,,,0|i07mof:,42440,,,,,,,,20/Jun/13 20:42;jmhsieh;Committed in 1.4.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shell du command doesn't work unless in table context,ACCUMULO-1513,12652750,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,billie.rinaldi,billie.rinaldi,13/Jun/13 21:32,20/Jun/13 17:32,13/Mar/19 22:01,20/Jun/13 17:32,1.5.0,,,,,,,1.5.1,1.6.0,,shell,,,,,,0,,,,,"The du command is borrowing some of our standard TableOperation syntax but not all of it, and it's confusing.  For other table operations, you can either specify a table name as in ""command -t tableName"", or enter a table context with ""table tableName"" and then enter just ""command"".

Du takes a list of tables.  Currently it doesn't work unless you're in a table context.  When you're in a table context, it adds that table to the list of tables specified for the command.

My initial thought is that it should ignore the table context entirely, just take the list of tables and du them.  I'm not sure it makes a lot of sense to run ""table t1"", ""du t2"", and get back the results of ""du t1 t2"".  On the other hand, I could see it being useful to just run du with no options in a table context and get back the du for that table, so I'm neutral on implementing this.  However, we should definitely make du work outside of a table context.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-14 15:32:41.063,,,no_permission,,,,,,,,,,,,333074,,,Thu Jun 20 17:32:40 UTC 2013,,,,,,0|i1lghr:,333402,,,,,,,,"14/Jun/13 15:32;ecn;I'm in that code right now, changing it to run the du in the server, and not on the client, as part of ACCUMULO-118. I'll fix this, too.
","20/Jun/13 17:32;jira-bot;Commit 1495111 from [~ecn]
[ https://svn.apache.org/r1495111 ]

ACCUMULO-1513 add -t argument to make du more like other commands","20/Jun/13 17:32;ecn;{noformat}
root@test> du
2013-06-20 13:30:01,124 [shell.Shell] ERROR: java.lang.IllegalStateException: Not in a table context. Please use 'table <tableName>' to switch to a table, or use '-t' to specify a table if option is available.
root@test> du -t test_ingest
               4,342,325 [test_ingest]
root@test> table test_ingest
root@test test_ingest> du
               4,342,325 [test_ingest]
root@test test_ingest> du -t !METADATA
                   2,035 [!METADATA]
root@test test_ingest> du !METADATA
                   2,035 [!METADATA]
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockTable's addMutation does not check for empty mutation,ACCUMULO-1505,12652223,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ryanleary,ryanleary,ryanleary,11/Jun/13 16:27,11/Jun/13 19:19,13/Mar/19 22:01,11/Jun/13 19:19,1.4.3,,,,,,,1.4.4,1.5.1,1.6.0,client,,,,,,0,,,,,"When calling addMutation or addMutations on a MockBatchWriter, the updates stored in the mutation are iterated over then committed in the MockTable class. 

When this occurs in the TabletServerBatchWriter (eventually called from the BatchWriterImpl), however, the mutation size is first checked and if the mutation size is 0, an IllegalArgumentException is thrown.

In practice, if you have code that tries to submit an empty mutation to a BatchWriter, it will fail and throw an exception in the real world, but this will not be caught in tests against MockAccumulo.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11/Jun/13 18:45;ryanleary;accumulo1505.patch;https://issues.apache.org/jira/secure/attachment/12587269/accumulo1505.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-06-11 18:50:30.753,,,no_permission,,,,,,,,,,,,332547,,,Tue Jun 11 19:19:34 UTC 2013,,,,,,0|i1ld8v:,332876,,,,,,,,11/Jun/13 18:43;ryanleary;Added fixes to check for null mutation/mutation iterables as well as empty mutations. Adds unit test for these cases.,"11/Jun/13 18:50;jira-bot;Commit 1491900 from [~vines]
[ https://svn.apache.org/r1491900 ]

ACCUMULO-1505 - Applying Ryan Leary's patch","11/Jun/13 19:13;jira-bot;Commit 1491910 from [~vines]
[ https://svn.apache.org/r1491910 ]

ACCUMULO-1505 - fixing up some warnings in the patch","11/Jun/13 19:14;jira-bot;Commit 1491911 from [~vines]
[ https://svn.apache.org/r1491911 ]

ACCUMULO-1505 - merging Ryan Leary's patch, with modifications to update and remove warnings","11/Jun/13 19:17;jira-bot;Commit 1491912 from [~vines]
[ https://svn.apache.org/r1491912 ]

ACCUMULO-1505 - Ryan Leary's patch with updates/warning busting","11/Jun/13 19:19;vines;Looks good. I went ahead and applied it to 1.4.4, 1.5.1, and 1.6.0. There was a typing warning from the use of Collection.EMPTY_LIST that I fixed. Additionally, updated it to use the new APIs for 1.5.0+.

I also added you as a contributor, Ryan. Thanks again!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Leaks a BatchScanner thread pool for each BatchDeleter,ACCUMULO-728,12603315,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,jstoneham,jstoneham,13/Aug/12 19:28,07/Jun/13 17:21,13/Mar/19 22:01,14/Jan/13 22:31,1.3.5-incubating,1.3.6,,,,,,1.4.0,,,client,,,,,,0,,,,,"Each BatchDeleter (i.e., TabletServerBatchDeleter) causes a BatchScanner thread to leak. This is because TabletServerBatchDeleter extends TabletServerBatchReader which opens a thread pool on construction but no close() method is offered on the BatchDeleter interface.

Workaround: downcast BatchDeleter to either BatchScanner or TabletServerBatchDeleter, then call close().

It appears the close() method is available on BatchDeleter from 1.4 forward, but this still affects 1.3 series users (which is why I'm documenting it).

Since BatchDeleter is a one-off class - call delete() and forget - it might make sense for it to close itself instead when complete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246346,,,2012-08-13 19:28:10.0,,,,,,0|i07lgf:,42242,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master did not shutdown,ACCUMULO-1213,12639291,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,27/Mar/13 12:15,07/Jun/13 16:50,13/Mar/19 22:01,27/Mar/13 12:45,1.4.2,,,,,,,1.4.3,1.5.0,,master,,,,,,0,,,,,"Brought up a large cluster in SAFE_MODE.

It did not respond to ./bin/stop-all.sh.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-27 14:26:37.799,,,no_permission,,,,,,,,,,,,319761,,,Fri Jun 07 16:50:29 UTC 2013,,,,,,0|i1j687:,320102,,,,,,,,"27/Mar/13 14:26;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #162 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/162/])
    ACCUMULO-1213 master did not transition from HAVE_LOCK to SAFE_MODE (Revision 1461550)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
","27/Mar/13 14:30;hudson;Integrated in Accumulo-1.4.x #287 (See [https://builds.apache.org/job/Accumulo-1.4.x/287/])
    ACCUMULO-1213 master did not transition from HAVE_LOCK to SAFE_MODE (Revision 1461548)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/Master.java
","27/Mar/13 14:35;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #54 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/54/])
    ACCUMULO-1213 master did not transition from HAVE_LOCK to SAFE_MODE (Revision 1461549)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.5/src
","27/Mar/13 14:40;hudson;Integrated in Accumulo-1.5 #57 (See [https://builds.apache.org/job/Accumulo-1.5/57/])
    ACCUMULO-1213 master did not transition from HAVE_LOCK to SAFE_MODE (Revision 1461549)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.5/src
","27/Mar/13 14:44;hudson;Integrated in Accumulo-Trunk #803 (See [https://builds.apache.org/job/Accumulo-Trunk/803/])
    ACCUMULO-1213 master did not transition from HAVE_LOCK to SAFE_MODE (Revision 1461550)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
","07/Jun/13 16:50;ctubbsii;No change was performed for 1.3.7, so I removed the fixVersion for 1.3.7",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FindOfflineTablets is broken,ACCUMULO-1473,12650148,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,30/May/13 14:29,31/May/13 19:56,13/Mar/19 22:01,31/May/13 19:55,1.4.2,,,,,,,1.4.4,,,,,,,,,0,,,,,org.apache.accumulo.server.util.FindOfflineTablets does not work.  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-30 14:37:14.36,,,no_permission,,,,,,,,,,,,330475,,,Thu May 30 14:37:14 UTC 2013,,,,,,0|i1l0iv:,330809,,,,,,,,"30/May/13 14:37;jira-bot;Commit 1487877 from kturner
[ https://svn.apache.org/r1487877 ]

ACCUMULO-1473 Fixed multiple bugs in FindOfflineTablets",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make master use new connections for tserver info,ACCUMULO-1477,12650361,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,mdrob,mdrob,31/May/13 16:04,31/May/13 19:49,13/Mar/19 22:01,31/May/13 19:49,1.4.0,,,,,,,1.4.4,,,tserver,,,,,,0,,,,,Please backport the fix telling the master to create new connections to tservers from ACCUMULO-513 to the 1.4 line.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-513,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-31 19:45:39.596,,,no_permission,,,,,,,,,,,,330688,,,Fri May 31 19:45:39 UTC 2013,,,,,,0|i1l1u7:,331022,,,,,,,,"31/May/13 19:45;jira-bot;Commit 1488368 from kturner
[ https://svn.apache.org/r1488368 ]

ACCUMULO-1477 made master create new connection when getting tserver status",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix formatting of examples,ACCUMULO-1465,12649449,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,25/May/13 13:32,31/May/13 19:35,13/Mar/19 22:01,31/May/13 19:35,1.5.0,,,,,,,1.5.1,,,docs,,,,,,0,,,,,"See http://accumulo.apache.org/1.5/examples/, which is taken from docs/examples/README.  Some of the new examples have not been added to the index page.  I created links for them on the page to see which ones they are.  These links should be added to the README with descriptions.  Also, some of the titles of the new examples are incorrect or missing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-31 19:23:36.562,,,no_permission,,,,,,,,,,,,329776,,,Fri May 31 19:32:20 UTC 2013,,,,,,0|i1kw7z:,330111,,,,,,,,"31/May/13 19:23;jira-bot;Commit 1488358 from [~billie.rinaldi]
[ https://svn.apache.org/r1488358 ]

ACCUMULO-1465 fixed formatting and titles for examples","31/May/13 19:25;jira-bot;Commit 1488359 from [~billie.rinaldi]
[ https://svn.apache.org/r1488359 ]

ACCUMULO-1465 regenerated website examples","31/May/13 19:32;jira-bot;Commit 1488362 from [~billie.rinaldi]
[ https://svn.apache.org/r1488362 ]

ACCUMULO-1465 merged examples formatting to trunk",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to deal with half-dead tservers,ACCUMULO-513,12549548,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,04/Apr/12 18:22,31/May/13 16:21,13/Mar/19 22:01,21/Mar/13 16:00,1.4.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"Every once in a while a tablet server will go zombie.  The tablet server is alive and talking to the master and zookeeper, but not accepting new connections from clients.  To keep these types of tablet servers from causing problems a process could try to scan a tablet on each tablet server periodically.  If it can not scan a tablet within a certain number of tries, it could delete the tservers lock in zookeeper.  The monitor process could do this.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-18 23:50:46.68,,,no_permission,,,,,,,,,,,,234539,,,Thu Mar 21 16:40:13 UTC 2013,,,,,,0|i07mqn:,42450,,,,,,,,"18/Jan/13 23:50;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #7 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/7/])
    ACCUMULO-513 Added API and shell command for pinging tablet servers. (Revision 1435416)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockInstanceOperations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/PingCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/PingIterator.java
","18/Jan/13 23:56;hudson;Integrated in Accumulo-Trunk #649 (See [https://builds.apache.org/job/Accumulo-Trunk/649/])
    ACCUMULO-513 Added API and shell command for pinging tablet servers. (Revision 1435416)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockInstanceOperations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/PingCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/PingIterator.java
","21/Mar/13 16:15;hudson;Integrated in Accumulo-Trunk #792 (See [https://builds.apache.org/job/Accumulo-Trunk/792/])
    ACCUMULO-513 made master always form a new connection when getting tserver status info (Revision 1459375)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tserverOps/ShutdownTServer.java
* /accumulo/trunk/src
","21/Mar/13 16:19;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #151 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/151/])
    ACCUMULO-513 made master always form a new connection when getting tserver status info (Revision 1459375)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tserverOps/ShutdownTServer.java
* /accumulo/trunk/src
","21/Mar/13 16:29;hudson;Integrated in Accumulo-1.5 #46 (See [https://builds.apache.org/job/Accumulo-1.5/46/])
    ACCUMULO-513 made master always form a new connection when getting tserver status info (Revision 1459374)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/tserverOps/ShutdownTServer.java
","21/Mar/13 16:40;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #44 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/44/])
    ACCUMULO-513 made master always form a new connection when getting tserver status info (Revision 1459374)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/tserverOps/ShutdownTServer.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mock merge throws concurrent modification exception,ACCUMULO-1474,12650150,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,30/May/13 14:38,30/May/13 15:09,13/Mar/19 22:01,30/May/13 15:09,1.5.0,,,,,,,1.5.1,1.6.0,,client,,,,,,0,,,,,"{code}
java.util.TreeMap$NavigableSubMap$SubMapIterator.nextEntry(TreeMap.java:1595)
	at java.util.TreeMap$NavigableSubMap$SubMapKeyIterator.next(TreeMap.java:1656)
	at java.util.AbstractSet.removeAll(AbstractSet.java:171)
	at org.apache.accumulo.core.client.mock.MockTable.merge(MockTable.java:140)
	at org.apache.accumulo.core.client.mock.MockAccumulo.merge(MockAccumulo.java:93)
	at org.apache.accumulo.core.client.mock.MockTableOperations.merge(MockTableOperations.java:307)
{code}

This is in code that will end up doing a lot of merges.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-30 15:05:49.979,,,no_permission,,,,,,,,,,,,330477,,,Thu May 30 15:08:14 UTC 2013,,,,,,0|i1l0jb:,330811,,,,,,,,"30/May/13 15:05;jira-bot;Commit 1487883 from [~vines]
[ https://svn.apache.org/r1487883 ]

ACCUMULO-1474 - making splits use a concurrent set instead of a standard set","30/May/13 15:08;jira-bot;Commit 1487885 from [~vines]
[ https://svn.apache.org/r1487885 ]

ACCUMULO-1474 - merging to trunk",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
proxy TFramedTransport max size too small (should be configurable),ACCUMULO-1424,12648164,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,afuchs,afuchs,17/May/13 12:00,25/May/13 01:23,13/Mar/19 22:01,25/May/13 01:23,,,,,,,,1.4.4,1.5.0,,proxy,,,,,,0,,,,,The TFramedTransport used by the proxy is limited by default to a 16MB max frame size. Messages bigger than that will be rejected by the server. This size should be configurable.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1251,ACCUMULO-1141,ACCUMULO-482,,,,,,,,,,,,21/May/13 18:34;vines;ACCUMULO-1424.patch;https://issues.apache.org/jira/secure/attachment/12584050/ACCUMULO-1424.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-05-21 18:34:22.948,,,no_permission,,,,,,,,,,,,328520,,,Sat May 25 01:23:22 UTC 2013,,,,,,0|i1kojj:,328864,,,,,,,,"21/May/13 18:34;vines;If we're doing an RC5 release, would it be possible to squeeze this patch in as well? Adam and I have talked to some folks who have bitten this bug with Casandra and I think it's something that is really simple to make it avoidable.",21/May/13 18:51;afuchs;This fix seems low risk enough and there is a high enough probability that users will run into the bug that I think we should sneak the patch into 1.5.0.,21/May/13 19:03;elserj;I would've said this is more a candidate for a 1.5.1.,"21/May/13 22:31;hudson;Integrated in Accumulo-1.5 #131 (See [https://builds.apache.org/job/Accumulo-1.5/131/])
    ACCUMULO-1424 i hate reading big numbers (Revision 1484928)
ACCUMULO-1424 add a configuration parameter for max transfer size (Revision 1484916)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/proxy.properties
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java

ecn : 
Files : 
* /accumulo/branches/1.5/proxy/proxy.properties
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java
","21/May/13 22:42;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #243 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/243/])
    ACCUMULO-1424 i hate reading big numbers (Revision 1484929)
ACCUMULO-1424 add a configuration parameter for max transfer size (Revision 1484918)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/proxy.properties
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/proxy.properties
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","21/May/13 22:47;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #133 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/133/])
    ACCUMULO-1424 i hate reading big numbers (Revision 1484928)
ACCUMULO-1424 add a configuration parameter for max transfer size (Revision 1484916)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/proxy.properties
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java

ecn : 
Files : 
* /accumulo/branches/1.5/proxy/proxy.properties
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java
","21/May/13 22:51;hudson;Integrated in Accumulo-Trunk #884 (See [https://builds.apache.org/job/Accumulo-Trunk/884/])
    ACCUMULO-1424 i hate reading big numbers (Revision 1484929)
ACCUMULO-1424 add a configuration parameter for max transfer size (Revision 1484918)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/proxy.properties
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/proxy.properties
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java
* /accumulo/trunk/server
* /accumulo/trunk/src
",23/May/13 15:24;kturner;This should be ported to 1.4,"25/May/13 01:23;ctubbsii;Closing ticket that is marked as complete for 1.5.0. It also says fixed for 1.4.4. If that is not the case, or needs further work, please open a separate ticket, so this one can stay closed and searchable as a fixed ticket for 1.5.0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TableOperations.list() lacks javadoc,ACCUMULO-1443,12648704,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,kturner,kturner,21/May/13 20:27,21/May/13 22:51,13/Mar/19 22:01,21/May/13 21:32,1.4.0,,,,,,,1.5.0,,,docs,,,,,,0,,,,,The list() method in TableOperations lacks javadoc.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-21 22:31:57.256,,,no_permission,,,,,,,,,,,,329059,,,Tue May 21 22:51:09 UTC 2013,,,,,,0|i1krun:,329401,,,,,,,,"21/May/13 22:31;hudson;Integrated in Accumulo-1.5 #131 (See [https://builds.apache.org/job/Accumulo-1.5/131/])
    ACCUMULO-1443 copy javadoc from TableOperationsImpl to interface (Revision 1484970)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
","21/May/13 22:42;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #243 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/243/])
    ACCUMULO-1443 merge to trunk (Revision 1484971)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","21/May/13 22:47;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #133 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/133/])
    ACCUMULO-1443 copy javadoc from TableOperationsImpl to interface (Revision 1484970)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
","21/May/13 22:51;hudson;Integrated in Accumulo-Trunk #884 (See [https://builds.apache.org/job/Accumulo-Trunk/884/])
    ACCUMULO-1443 merge to trunk (Revision 1484971)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Dependencies on sibling modules in Accumulo shouldn't be in the ""provided"" scope",ACCUMULO-1436,12648464,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,20/May/13 17:29,21/May/13 17:12,13/Mar/19 22:01,21/May/13 01:57,,,,,,,,1.5.0,,,,,,,,,0,,,,,"Marking dependencies as ""provided"" for artifacts we're generating, is confusing, as it requires end-users to add additional dependencies that aren't necessarily intuitive (such as the accumulo-start jar, to get MiniAccumuloCluster to work when depending on accumulo-server).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-21 00:55:29.245,,,no_permission,,,,,,,,,,,,328819,,,Tue May 21 06:41:53 UTC 2013,,,,,,0|i1kqdj:,329161,,,,,,,,"21/May/13 00:55;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #130 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/130/])
    ACCUMULO-1436 dependency cleanup to make accumulo artifacts non-provided (Revision 1484616)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/examples/simple/pom.xml
* /accumulo/branches/1.5/proxy/pom.xml
* /accumulo/branches/1.5/server/pom.xml
* /accumulo/branches/1.5/start/pom.xml
* /accumulo/branches/1.5/test/pom.xml
","21/May/13 00:57;hudson;Integrated in Accumulo-1.5 #128 (See [https://builds.apache.org/job/Accumulo-1.5/128/])
    ACCUMULO-1436 dependency cleanup to make accumulo artifacts non-provided (Revision 1484616)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/examples/simple/pom.xml
* /accumulo/branches/1.5/proxy/pom.xml
* /accumulo/branches/1.5/server/pom.xml
* /accumulo/branches/1.5/start/pom.xml
* /accumulo/branches/1.5/test/pom.xml
","21/May/13 06:31;hudson;Integrated in Accumulo-Trunk #883 (See [https://builds.apache.org/job/Accumulo-Trunk/883/])
    ACCUMULO-1440, ACCUMULO-1436 merge to trunk (Revision 1484639)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/conf/PropertyTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
","21/May/13 06:41;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #242 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/242/])
    ACCUMULO-1440, ACCUMULO-1436 merge to trunk (Revision 1484639)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/conf/PropertyTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add sample RFiles to excludes for rat check,ACCUMULO-1441,12648496,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,20/May/13 20:15,21/May/13 17:11,13/Mar/19 22:01,21/May/13 17:11,1.5.0,,,,,,,1.5.0,,,build,,,,,,1,,,,,"This isn't a problem on CentOS, but Mac OS X apparently can't tell the .rf files are binary.  We could add them to the exclude list for convenience.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-21 00:50:46.025,,,no_permission,,,,,,,,,,,,328851,,,Tue May 21 01:00:58 UTC 2013,,,,,,0|i1kqkn:,329193,,,,,,,,"21/May/13 00:50;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #241 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/241/])
    ACCUMULO-1441 added rfiles to apache-rat-plugin excludes - merged to trunk (Revision 1484588)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","21/May/13 00:55;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #130 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/130/])
    ACCUMULO-1441 added rfiles to apache-rat-plugin excludes (Revision 1484580)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/branches/1.5/core/pom.xml
","21/May/13 00:57;hudson;Integrated in Accumulo-1.5 #128 (See [https://builds.apache.org/job/Accumulo-1.5/128/])
    ACCUMULO-1441 added rfiles to apache-rat-plugin excludes (Revision 1484580)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/branches/1.5/core/pom.xml
","21/May/13 01:00;hudson;Integrated in Accumulo-Trunk #882 (See [https://builds.apache.org/job/Accumulo-Trunk/882/])
    ACCUMULO-1441 added rfiles to apache-rat-plugin excludes - merged to trunk (Revision 1484588)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
setscaniter doesn't work from different table context,ACCUMULO-1429,12648229,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,mdrob,mdrob,17/May/13 19:05,21/May/13 16:20,13/Mar/19 22:01,17/May/13 19:41,1.4.3,,,,,,,1.4.4,1.5.0,,shell,,,,,,0,,,,,"setscaniter does not use the configured iterator when scanning from a different table context. Steps to reproduce:

1. setscaniter to add a filter to table a
2. change to table context b
3. scan -t a

You will see entries that should have been filtered out. If you scan from table context a, then it works properly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-17 20:24:09.902,,,no_permission,,,,,,,,,,,,328585,,,Fri May 17 22:28:00 UTC 2013,,,,,,0|i1koxz:,328929,,,,,,,,"17/May/13 20:24;hudson;Integrated in Accumulo-1.5 #121 (See [https://builds.apache.org/job/Accumulo-1.5/121/])
    ACCUMULO-1429 use the specified tablename (Revision 1483956)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/ScanCommand.java
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/proxy/README
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/src
","17/May/13 20:27;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #123 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/123/])
    ACCUMULO-1429 use the specified tablename (Revision 1483956)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/ScanCommand.java
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/proxy/README
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/src
","17/May/13 22:17;hudson;Integrated in Accumulo-Trunk #877 (See [https://builds.apache.org/job/Accumulo-Trunk/877/])
    ACCUMULO-1429 use the specified tablename (Revision 1483962)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/ScanCommand.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","17/May/13 22:22;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #235 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/235/])
    ACCUMULO-1429 use the specified tablename (Revision 1483962)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/ScanCommand.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","17/May/13 22:28;hudson;Integrated in Accumulo-1.4.x #306 (See [https://builds.apache.org/job/Accumulo-1.4.x/306/])
    ACCUMULO-1429 use the specified tablename (Revision 1483954)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/util/shell/commands/ScanCommand.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
release tarballs include wrong contents,ACCUMULO-1404,12646941,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,10/May/13 02:26,19/May/13 02:18,13/Mar/19 22:01,19/May/13 01:15,,,,,,,,1.5.0,,,build,docs,,,,,0,,,,,"Generated javadocs in docs/apidocs are missing from 1.5.0-RC2 tarball. These should be included in the assembly, but are missing for some reason.

The src/main/latex folders, on the other hand, are included, but shouldn't be. This isn't a source tarball.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-11 04:43:56.567,,,no_permission,,,,,,,,,,,,327298,,,Sun May 19 02:18:52 UTC 2013,,,,,,0|i1kgzz:,327642,,,,,,,,"11/May/13 04:43;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #108 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/108/])
    ACCUMULO-1404 make maven-release-plugin include the proper files for binary release artifacts, and rename binary-release tarball to more explicitly describe what it is and to adjust the baseDirectory to match user expectations from prior releases (Revision 1481249)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/assemble/src/main/assemblies/bin.xml
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
* /accumulo/branches/1.5/pom.xml
","11/May/13 04:49;hudson;Integrated in Accumulo-1.5 #106 (See [https://builds.apache.org/job/Accumulo-1.5/106/])
    ACCUMULO-1404 make maven-release-plugin include the proper files for binary release artifacts, and rename binary-release tarball to more explicitly describe what it is and to adjust the baseDirectory to match user expectations from prior releases (Revision 1481249)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/assemble/src/main/assemblies/bin.xml
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
* /accumulo/branches/1.5/pom.xml
","11/May/13 05:18;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #217 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/217/])
    ACCUMULO-1404, ACCUMULO-1384 merge to trunk (Revision 1481250)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src/main/assemblies/bin.xml
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/bin/tool.sh
* /accumulo/trunk/pom.xml
","11/May/13 05:23;hudson;Integrated in Accumulo-Trunk #859 (See [https://builds.apache.org/job/Accumulo-Trunk/859/])
    ACCUMULO-1404, ACCUMULO-1384 merge to trunk (Revision 1481250)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src/main/assemblies/bin.xml
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/bin/tool.sh
* /accumulo/trunk/pom.xml
",11/May/13 12:01;ctubbsii;Tarball still contains wrong thrift files for proxy. It contains temporary files from the gen-java folder that shouldn't be there.,"13/May/13 16:16;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #111 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/111/])
    ACCUMULO-1404 include proxy bindings, proxy thrift definition for additional bindings, and example source code in binary packages (Revision 1481935)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
","13/May/13 16:24;hudson;Integrated in Accumulo-1.5 #109 (See [https://builds.apache.org/job/Accumulo-1.5/109/])
    ACCUMULO-1404 include proxy bindings, proxy thrift definition for additional bindings, and example source code in binary packages (Revision 1481935)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
",17/May/13 17:13;ctubbsii;Reopened because the shared libraries are getting packaged into the source-release assembly.,17/May/13 17:21;kturner;the proxy properties file and proxy README are missing from the binary tarball.,"17/May/13 20:24;hudson;Integrated in Accumulo-1.5 #121 (See [https://builds.apache.org/job/Accumulo-1.5/121/])
    ACCUMULO-1404 if we're going to include c++ sources in the bin distribution, don't require a source dependency in the makefile (Revision 1483922)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/c++/nativeMap/Makefile
","17/May/13 20:27;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #123 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/123/])
    ACCUMULO-1404 if we're going to include c++ sources in the bin distribution, don't require a source dependency in the makefile (Revision 1483922)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/c++/nativeMap/Makefile
","18/May/13 01:08;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #124 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/124/])
    ACCUMULO-1404 add the missing proxy pieces (README, proxy.properties, examples) (Revision 1483994)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
","18/May/13 01:13;hudson;Integrated in Accumulo-1.5 #122 (See [https://builds.apache.org/job/Accumulo-1.5/122/])
    ACCUMULO-1404 add the missing proxy pieces (README, proxy.properties, examples) (Revision 1483994)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
","19/May/13 02:11;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #238 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/238/])
    ACCUMULO-1404,ACCUMULO-1423 merge to trunk (Revision 1484205)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","19/May/13 02:14;hudson;Integrated in Accumulo-Trunk #880 (See [https://builds.apache.org/job/Accumulo-Trunk/880/])
    ACCUMULO-1404,ACCUMULO-1423 merge to trunk (Revision 1484205)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","19/May/13 02:15;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #127 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/127/])
    ACCUMULO-1404,ACCUMULO-1423 include missing files in binary tarball; fix some permissions (Revision 1484204)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
","19/May/13 02:18;hudson;Integrated in Accumulo-1.5 #125 (See [https://builds.apache.org/job/Accumulo-1.5/125/])
    ACCUMULO-1404,ACCUMULO-1423 include missing files in binary tarball; fix some permissions (Revision 1484204)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
mvn release:prepare doesn't run tests,ACCUMULO-1430,12648261,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,17/May/13 22:20,18/May/13 20:20,13/Mar/19 22:01,18/May/13 19:59,,,,,,,,1.5.0,,,,,,,,,0,,,,,"This is really a matter of leaving the seal-jars profile activated *only* at release:perform (on the clean checkout of the tag that it does).

Jar sealing and running unit tests are mutually exclusive for the reason that we tend to mirror package names in unit tests to gain access to package-private fields and methods.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-18 20:12:37.886,,,no_permission,,,,,,,,,,,,328617,,,Sat May 18 20:20:09 UTC 2013,,,,,,0|i1kp53:,328961,,,,,,,,"18/May/13 20:12;hudson;Integrated in Accumulo-Trunk #879 (See [https://builds.apache.org/job/Accumulo-Trunk/879/])
    ACCUMULO-1430 merge to trunk (Revision 1484172)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/build.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","18/May/13 20:13;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #237 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/237/])
    ACCUMULO-1430 merge to trunk (Revision 1484172)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/build.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","18/May/13 20:15;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #126 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/126/])
    ACCUMULO-1430 run tests during release:prepare (Revision 1484170)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/build.sh
* /accumulo/branches/1.5/pom.xml
","18/May/13 20:20;hudson;Integrated in Accumulo-1.5 #124 (See [https://builds.apache.org/job/Accumulo-1.5/124/])
    ACCUMULO-1430 run tests during release:prepare (Revision 1484170)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/build.sh
* /accumulo/branches/1.5/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move SystemToken to server package,ACCUMULO-1415,12647396,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,13/May/13 22:28,14/May/13 23:15,13/Mar/19 22:01,14/May/13 20:49,,,,,,,,1.5.0,,,client,master,tserver,,,,0,,,,,"We created a special SystemToken for the internal authentication mechanisms used by Accumulo. However, this token should be under the server project to prevent confusion of the end user.

I think this should be done for 1.5, but I don't know how that fares with the release schedule going.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-14 01:04:39.472,,,no_permission,,,,,,,,,,,,327752,,,Tue May 14 23:15:12 UTC 2013,,,,,,0|i1kjsv:,328096,,,,,,,,"14/May/13 01:04;ctubbsii;I agree, it should be done for 1.5.0, if the impact is small. If the impact is too large, keeping it out of the ""client"" packages should be sufficient for 1.5.0.","14/May/13 20:46;vines;Nothing in the client should be using it. I tested it, worked fine, minimal code changes (i.e. just moving the source and creating the package in server)","14/May/13 21:33;hudson;Integrated in Accumulo-Trunk #869 (See [https://builds.apache.org/job/Accumulo-Trunk/869/])
    ACCUMULO-1415 - SystemToken moving to server (Revision 1482580)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/security/tokens/SystemToken.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/security
","14/May/13 21:35;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #227 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/227/])
    ACCUMULO-1415 - SystemToken moving to server (Revision 1482580)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/security/tokens/SystemToken.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/security
","14/May/13 23:07;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #117 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/117/])
    ACCUMULO-1415 - SystemToken moving to server (Revision 1482579)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/security/tokens/SystemToken.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security/token
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security/token/SystemToken.java
","14/May/13 23:15;hudson;Integrated in Accumulo-1.5 #115 (See [https://builds.apache.org/job/Accumulo-1.5/115/])
    ACCUMULO-1415 - SystemToken moving to server (Revision 1482579)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/security/tokens/SystemToken.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security/token
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security/token/SystemToken.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shell --fake requires HDFS to be running,ACCUMULO-974,12628126,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,treardon,billie.rinaldi,billie.rinaldi,17/Jan/13 23:37,14/May/13 18:56,13/Mar/19 22:01,14/May/13 16:47,1.4.2,,,,,,,1.5.0,,,shell,,,,,,0,,,,,"The ""accumulo shell --fake"" functionality appears to have been broken by ACCUMULO-752, ""Add support for importDirectory to the mock instance"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,01/May/13 00:44;treardon;ACCUMULO-974.patch;https://issues.apache.org/jira/secure/attachment/12581299/ACCUMULO-974.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-03-06 14:00:09.471,,,no_permission,,,,,,,,,,,,304977,,,Tue May 14 18:56:51 UTC 2013,,,,,,0|i17x8v:,254356,,,,,,,,06/Mar/13 14:00;kevin.faro;what features have been broken?  Can somebody submit a JUnit that pinpoints what isn't working anymore?,"07/Mar/13 15:33;ecn;ShellTest runs the shell against MockAccumulo, which is what the -fake flag does.  It doesn't test bulk import, though.

I just tried running the shell with -fake and performing a bulk import, and both appear to work just fine in the 1.5 branch.
","08/Mar/13 21:36;billie.rinaldi;Try running the fake shell without having HDFS running.  1.4.2 errors out immediately on MockInstance.getDefaultFileSystem, and 1.4 branch says ""Retrying connect to server: localhost/127.0.0.1:9000"" a few times before erroring out the same way.  It's the same in trunk/1.5.",12/Mar/13 23:03;dlmarion;just replicated this on 1.4.3 branch,"30/Apr/13 17:22;billie.rinaldi;I'm still seeing this on 1.4 branch, 1.5 branch and trunk.","30/Apr/13 19:40;ecn;I can't reproduce this:

{noformat}
# single node instance:
$ pkill -f hadoop
$ ./bin/accumulo shell --fake
Password: 

Shell - Apache Accumulo Interactive Shell
- 
- version: 1.5.0-SNAPSHOT
- instance name: fake
- instance id: mock-instance-id
- 
- type 'help' for a list of available commands
- 
ecn@fake> createtable t
ecn@fake t> insert a b c d
ecn@fake t> scan
a b:c []    d
ecn@fake t> 
{noformat}
","30/Apr/13 21:23;billie.rinaldi;Interesting.  I just checked out a fresh copy to my CentOS VM and it worked fine once I got all the jars in the right place.  But on my local machine I see this:
{noformat}
$ bin/accumulo shell --fake (here hadoop is running)
2013-04-30 14:18:15.609 java[96484:e303] Unable to load realm info from SCDynamicStore
Enter current password for 'billie'@'mock-instance': 

Shell - Apache Accumulo Interactive Shell
- 
- version: 1.4.4-SNAPSHOT
- instance name: mock-instance
- instance id: mock-instance-id
- 
- type 'help' for a list of available commands
- 
billie@mock-instance> 
$ killall java (here hadoop is killed)
$ bin/accumulo shell --fake
2013-04-30 14:18:31.509 java[96523:e303] Unable to load realm info from SCDynamicStore
2013-04-30 14:18:32,733 [ipc.Client] INFO : Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s).
{noformat}
I'll try to find out more.","30/Apr/13 22:04;treardon;I can reproduce on trunk consistently. Having not used the fake shell much, I mistakenly thought HDFS was a requirement (thereby limiting the usefulness of the fake shell :)","01/May/13 00:44;treardon;Patch attached that uses LocalFileSystem within MockInstance.getDefaultFileSystem().

Pretty sure that I did not break ACCUMULO-752, can someone verify?","07/May/13 16:29;kturner;[~treardon], should the configuration in the patch be cloned and then modified?  Configuration has a copy constructor.  Or was modifying the cached config intentional so that later mock operations would see that change?","07/May/13 17:10;treardon;Keith, correct. I needed to modify the cached config so that importDirectory did not immediately implode.

I was not able to fully validate that the importDirectory additions from ACCUMULO-752 still work, since I've never used that command and wasn't sure what input format is required. I did validate that importDirectory will read input files from the given dir and move them appropriately when using the fake shell; this only worked after modifying the cached config.","14/May/13 16:45;vines;This isn't platform specific, it's system configuration specific. If you have a hadoop-conf on your classpath, either via hadoop-env.sh being configured or system exports being set, then cached configuration will pick it up.

This patch is the only way to fix it, I tried changing getDefaultFileSystem to use getLocal(), but importdirectory doesn't pick it up. Importdirectory seems to work fine with the patch, so applying it","14/May/13 18:42;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #226 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/226/])
    ACCUMULO-974 - Applying Tim Reardon's patch for Mock (Revision 1482447)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockInstance.java
","14/May/13 18:46;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #116 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/116/])
    ACCUMULO-974 - Applying Tim Reardon's patch for Mock (Revision 1482445)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mock/MockInstance.java
","14/May/13 18:51;hudson;Integrated in Accumulo-1.5 #114 (See [https://builds.apache.org/job/Accumulo-1.5/114/])
    ACCUMULO-974 - Applying Tim Reardon's patch for Mock (Revision 1482445)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mock/MockInstance.java
","14/May/13 18:56;hudson;Integrated in Accumulo-Trunk #868 (See [https://builds.apache.org/job/Accumulo-Trunk/868/])
    ACCUMULO-974 - Applying Tim Reardon's patch for Mock (Revision 1482447)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockInstance.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shell's setiter is not informative when using a bad class name,ACCUMULO-1358,12645249,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mdrob,vines,vines,29/Apr/13 15:48,14/May/13 16:13,13/Mar/19 22:01,14/May/13 00:13,1.4.0,,,,,,,1.5.0,,,shell,,,,,,0,newbie,,,,"In the shell, I did setiter using a class that wasn't found. Rather then a message about it not being found, I just get told that I have an invalid argument. Even turning on debug, I had to use the stack trace to figure out why it was erroring.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,07/May/13 02:55;mdrob;ACCUMULO-1358.v1.patch;https://issues.apache.org/jira/secure/attachment/12582024/ACCUMULO-1358.v1.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-04-29 15:52:19.264,,,no_permission,,,,,,,,,,,,325611,,,Tue May 14 00:13:12 UTC 2013,,,,,,0|i1k6br:,325956,,,,,,,,"29/Apr/13 15:52;kturner;I have also seen the shell give very uninformative messages in the past when it can find the class, but the class does not implement OptionDescriber.  Not sure if it still does this.","29/Apr/13 16:11;vines;Saw that too-

bq. ERROR: org.apache.accumulo.core.util.shell.ShellCommandException: Command could not be initialized (Unable to load blah.TestingIterator as type org.apache.accumulo.core.iterators.OptionDescriber; configure with 'config' instead)

Not as bad, but still not good","07/May/13 02:55;mdrob;Apply to 1.5 branch with {{patch -p1}}

Added a significantly more informative message for class not found and a slightly more informative message for class not implementing OptionDesciber.

Added unit tests for illegal arguments in setiter. Did not add tests for valid classes because the command then expects user input and I wasn't sure how to wire that.","07/May/13 16:14;kturner;Thanks for the patch Mike.  I applied it to 1.5 and trunk..  Will need to leave the ticket open until we determine if this will be in 1.5.0 or 1.5.1.  I had to make the unit test delete the table it created, otherwise a later unit test would fail.  The unit test probably ran in a different order for you.

bq. Added unit tests for illegal arguments in setiter. Did not add tests for valid classes because the command then expects user input and I wasn't sure how to wire that.

org.apache.accumulo.test.ShellServerTest test setting a valid class, so this case is covered.  ","07/May/13 16:14;hudson;Integrated in Accumulo-Trunk #852 (See [https://builds.apache.org/job/Accumulo-Trunk/852/])
    ACCUMULO-1358 Appled patch from Mike Drob, with modification to delete table in unit test. (Revision 1479946)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetIterCommand.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","07/May/13 16:22;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #210 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/210/])
    ACCUMULO-1358 Appled patch from Mike Drob, with modification to delete table in unit test. (Revision 1479946)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetIterCommand.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","07/May/13 17:44;hudson;Integrated in Accumulo-1.5 #99 (See [https://builds.apache.org/job/Accumulo-1.5/99/])
    ACCUMULO-1358 Appled patch from Mike Drob, with modification to delete table in unit test. (Revision 1479932)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetIterCommand.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
","07/May/13 18:00;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #101 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/101/])
    ACCUMULO-1358 Appled patch from Mike Drob, with modification to delete table in unit test. (Revision 1479932)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetIterCommand.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
","14/May/13 00:13;vines;Considering we're still cutting RCs, this made it into 1.5.0",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
problems running generate_monitor_certificate.sh,ACCUMULO-1276,12642567,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,medined,medined,15/Apr/13 17:07,14/May/13 15:17,13/Mar/19 22:01,14/May/13 15:17,1.4.3,,,,,,,1.5.0,,,scripts,,,,,,0,,,,,"I tried to run the generate_monitor_certificate.sh script on an Ubuntu VM
and saw the following message:

root@li459-74:/usr/local/accumulo# bin/generate_monitor_certificate.sh
tail: cannot open `+2' for reading: No such file or directory

I briefly looked into the script but don't know enough about /dev/random to
debug much.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-15 17:08:20.513,,,no_permission,,,,,,,,,,,,322981,,,Wed Apr 17 20:50:18 UTC 2013,,,,,,0|i1jq3z:,323326,,,,,,,,"15/Apr/13 17:08;ecn;My redhat linux machine doesn't have uuencode, either.
","15/Apr/13 17:35;billie.rinaldi;This stuff ""cat /dev/random | head -c33 | uuencode -m foo | head -2 | tail +2"" is trying to generate a random ASCII password.  /dev/random generates random binary data, uuencode makes it ASCII, and the head/tail strip out the header and footer.

What if we used a UUID generated by uuidgen to make a password?  Any other ideas?","15/Apr/13 17:47;kturner;bq. Any other ideas?

seems md5sum is usually installed.  It will give ascii output.  It does not really matter that it hashes, it does not hurt or help.

cat /dev/random | head -c 16 | md5sum | cut -d ' ' -f 1","15/Apr/13 17:57;billie.rinaldi;Macs don't have md5sum.  I guess it's more important for it to work on Linux, though.","15/Apr/13 17:59;ecn;How about xxd?
","15/Apr/13 18:00;medined;http://www.howtogeek.com/howto/30184/10-ways-to-generate-a-random-password-from-the-command-line/



","15/Apr/13 18:00;medined;I did need to apt-get a package for the uuencode to work.



","15/Apr/13 18:01;ecn;Also, going to use dd instead of cat:

{noformat}
dd if=/dev/random count=32 bs=1 2>/dev/null |xxd -p -c 256
{noformat}

Since cat is probably doing buffered I/O and reading 512 bytes of precious entropy.
","15/Apr/13 18:15;kturner;xxd comes with vim... at least on my box it comes from the vim-common package

on macs I think md5sum is md5, or something like that... it is a different name.... anyway, should try to figure out something that works on a Mac because its not an uncommen dev environment

","15/Apr/13 18:17;billie.rinaldi;Looks fine to me.  Interestingly, this command generates 64 characters on my Mac and 32 characters on CentOS.","15/Apr/13 18:53;ctubbsii;I like the tr -dc method:
{code}
tr -dc '#-&A-Za-z0-9@~' < /dev/urandom | head -c 20
{code}

But, I  don't see why we should generate a password at all... we should prompt for one instead. The responsibility for securing the a certificate should be that of the user, not our script.","15/Apr/13 19:39;billie.rinaldi;Regardless of what the script does, the user still has the option of generating a certificate themselves and setting the configuration properties manually.  We should make sure to document both options.  The question is how easy we want this convenience script to be.  Right now it is very easy.  If you want to make the script prompt for the keystore password and the key password, that might be OK.  I would advocate for having the script take the passwords and pass them to keytool instead of using the interactive mode of keytool.  If the script can't print out the site properties, there's no point in having it.

Actually -- I might go as far as to say that the script is just for easy development / testing.  We could document it as such, or get rid of it.","15/Apr/13 19:44;medined;Once the process is documented, the need for the script would be reduced.



","15/Apr/13 19:57;ctubbsii;[~billie.rinaldi] said:
{quote}Actually – I might go as far as to say that the script is just for easy development / testing. We could document it as such, or get rid of it.{quote}

I agree. If we had an integration test for testing the monitor, that leveraged maven-keytool-plugin to generate the certificate in an automated way, I'd say we get rid of it.

Also, if it's just for development/testing/documentation purposes, there's really no reason to bother with the generating of the password... it could just be ""password"". (At the very least, there's no reason to lose system entropy for testing.)

[~medined] said:
{quote}Once the process is documented, the need for the script would be reduced.{quote}
We just need to document what kind of certificates we accept and how to configure them. Documenting the process to generate these certificates should be left to their respective tools/websites (openssl, keytool, etc.).","16/Apr/13 02:21;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #190 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/190/])
    ACCUMULO-1276 improved password generation (Revision 1468205)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/generate_monitor_certificate.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","16/Apr/13 02:26;hudson;Integrated in Accumulo-Trunk #832 (See [https://builds.apache.org/job/Accumulo-Trunk/832/])
    ACCUMULO-1276 improved password generation (Revision 1468205)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/generate_monitor_certificate.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","16/Apr/13 02:30;hudson;Integrated in Accumulo-1.5 #79 (See [https://builds.apache.org/job/Accumulo-1.5/79/])
    ACCUMULO-1276 improved password generation (Revision 1468201)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/bin/generate_monitor_certificate.sh
","16/Apr/13 02:35;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #78 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/78/])
    ACCUMULO-1276 improved password generation (Revision 1468201)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/bin/generate_monitor_certificate.sh
","17/Apr/13 19:37;hudson;Integrated in Accumulo-1.5 #82 (See [https://builds.apache.org/job/Accumulo-1.5/82/])
    ACCUMULO-1276 found another xml-unfriendly character (&) (Revision 1468983)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/bin/generate_monitor_certificate.sh
","17/Apr/13 19:51;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #81 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/81/])
    ACCUMULO-1276 found another xml-unfriendly character (&) (Revision 1468983)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/bin/generate_monitor_certificate.sh
","17/Apr/13 20:44;hudson;Integrated in Accumulo-Trunk #835 (See [https://builds.apache.org/job/Accumulo-Trunk/835/])
    ACCUMULO-1276 found another xml-unfriendly character (&) (Revision 1468988)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/generate_monitor_certificate.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","17/Apr/13 20:50;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #193 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/193/])
    ACCUMULO-1276 found another xml-unfriendly character (&) (Revision 1468988)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/generate_monitor_certificate.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
make delay between recoverLease calls configurable,ACCUMULO-1328,12644003,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,22/Apr/13 21:13,13/May/13 15:15,13/Mar/19 22:01,23/Apr/13 17:34,,,,,,,,1.5.0,,,,,,,,,0,,,,,"See HBASE-8389.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-23 19:54:25.377,,,no_permission,,,,,,,,,,,,324370,,,Mon May 13 15:15:22 UTC 2013,,,,,,0|i1jyof:,324715,,,,,,,,"23/Apr/13 19:54;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #87 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/87/])
    ACCUMULO-1328 add new config item to RW test (Revision 1471060)
ACCUMULO-1328 make the retry time for recoverLease() configurable (Revision 1470971)
ACCUMULO-1328 make the retry time for recoverLease() configurable (Revision 1470967)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java

ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java

ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/LogCloser.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRLogCloser.java
","23/Apr/13 19:56;hudson;Integrated in Accumulo-Trunk #841 (See [https://builds.apache.org/job/Accumulo-Trunk/841/])
    ACCUMULO-1328 add new config item to RW test (Revision 1471064)
ACCUMULO-1328 make the retry time for recoverLease() configurable (Revision 1470972)
ACCUMULO-1328 make the retry time for recoverLease() configurable (Revision 1470969)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/LogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRLogCloser.java
* /accumulo/trunk/src
","23/Apr/13 20:03;hudson;Integrated in Accumulo-1.5 #88 (See [https://builds.apache.org/job/Accumulo-1.5/88/])
    ACCUMULO-1328 add new config item to RW test (Revision 1471060)
ACCUMULO-1328 make the retry time for recoverLease() configurable (Revision 1470971)
ACCUMULO-1328 make the retry time for recoverLease() configurable (Revision 1470967)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java

ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java

ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/LogCloser.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRLogCloser.java
","23/Apr/13 20:12;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #199 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/199/])
    ACCUMULO-1328 add new config item to RW test (Revision 1471064)
ACCUMULO-1328 make the retry time for recoverLease() configurable (Revision 1470972)
ACCUMULO-1328 make the retry time for recoverLease() configurable (Revision 1470969)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/LogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRLogCloser.java
* /accumulo/trunk/src
","13/May/13 15:06;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #219 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/219/])
    ACCUMULO-1328 add SYNC_BLOCK to WAL create calls; warn about synconclose flag when appropriate (Revision 1481867)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/DfsLogger.java
* /accumulo/trunk/src
","13/May/13 15:06;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #110 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/110/])
    ACCUMULO-1328 add SYNC_BLOCK to WAL create calls; warn about synconclose flag when appropriate (Revision 1481854)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/log/DfsLogger.java
","13/May/13 15:09;hudson;Integrated in Accumulo-1.5 #108 (See [https://builds.apache.org/job/Accumulo-1.5/108/])
    ACCUMULO-1328 add SYNC_BLOCK to WAL create calls; warn about synconclose flag when appropriate (Revision 1481854)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/log/DfsLogger.java
","13/May/13 15:15;hudson;Integrated in Accumulo-Trunk #861 (See [https://builds.apache.org/job/Accumulo-Trunk/861/])
    ACCUMULO-1328 add SYNC_BLOCK to WAL create calls; warn about synconclose flag when appropriate (Revision 1481867)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/DfsLogger.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accumulo Shell does not respect 'exit' when executing file,ACCUMULO-1348,12644634,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,mdrob,mdrob,mdrob,25/Apr/13 17:27,09/May/13 01:19,13/Mar/19 22:01,09/May/13 01:19,1.4.2,,,,,,,1.5.0,,,shell,,,,,,0,,,,,"If there is an {{exit}} statement in the file given via {{accumulo shell -f file}}, the execution seems to skip it and go on to the next command instead of terminating.

To recreate:
{noformat}
[mike@home ~] cat bug.accumulo
exit
scan -np -t !METADATA
[mike@home ~] bin/accumulo shell -f /home/mike/bug.accumulo
{noformat}

Expected output: None
Actual output: A full scan of the !METADATA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,30/Apr/13 04:52;mdrob;ACCUMULO-1348.v1.patch;https://issues.apache.org/jira/secure/attachment/12581120/ACCUMULO-1348.v1.patch,04/May/13 16:43;mdrob;ACCUMULO-1348.v2.patch;https://issues.apache.org/jira/secure/attachment/12581796/ACCUMULO-1348.v2.patch,04/May/13 17:16;mdrob;ACCUMULO-1348.v3.patch;https://issues.apache.org/jira/secure/attachment/12581797/ACCUMULO-1348.v3.patch,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2013-04-30 05:58:20.571,,,no_permission,,,,,,,,,,,,324999,,,Thu May 09 01:19:06 UTC 2013,,,,,,0|i1k2jz:,325344,,,,,,,,"30/Apr/13 05:58;ctubbsii;Problems with patch:
# needs consistent (unix) newlines
# should be a patch for the top of the branch to patch
# the test resource file needs a license file exception for the rat plugin in the core/pom.xml
# patch doesn't specify the branch to which it should be applied

Also, if fix is intended prior to 1.6 (trunk), provide patch against earliest branch to fix, and I'll merge it forward to the newer branches.","30/Apr/13 06:04;ctubbsii;Added [~mdrob] to contributors, so I could assign him this ticket and work with him on accepting the patch.","04/May/13 16:43;mdrob;* Added exclusions to rat check in {{core/pom.xml}}
* Verified that all newlines are Unix newlines.
* Patch build on top of 1.5 branch. (Apply with {{-p1}})",04/May/13 17:16;mdrob;Added exit check to MockShell; no relevant integration changes.,"04/May/13 22:48;ctubbsii;The patch was applied to the 1.5 branch and the trunk (1.6). However, depending on whether 1.5.0-RC1 becomes 1.5.0 or not (it probably won't), the fixVersion on this ticket may be 1.5.0 or 1.5.1; So, I'm leaving this ticket open until we know for sure, so it can be marked accordingly.","07/May/13 02:35;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #100 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/100/])
    ACCUMULO-1348 Applied patch from Mike Drob to 1.5 branch (Revision 1479204)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mock/MockShell.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/branches/1.5/core/src/test/resources/shelltest.txt
","07/May/13 02:37;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #209 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/209/])
    ACCUMULO-1348 merged patch to trunk (Revision 1479211)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockShell.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/trunk/core/src/test/resources/shelltest.txt
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","07/May/13 02:42;hudson;Integrated in Accumulo-Trunk #851 (See [https://builds.apache.org/job/Accumulo-Trunk/851/])
    ACCUMULO-1348 merged patch to trunk (Revision 1479211)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockShell.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/trunk/core/src/test/resources/shelltest.txt
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","07/May/13 02:53;hudson;Integrated in Accumulo-1.5 #98 (See [https://builds.apache.org/job/Accumulo-1.5/98/])
    ACCUMULO-1348 Applied patch from Mike Drob to 1.5 branch (Revision 1479204)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mock/MockShell.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/branches/1.5/core/src/test/resources/shelltest.txt
",09/May/13 01:19;ctubbsii;Patched prior to 1.5.0-RC2.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kerberos directions in README,ACCUMULO-1392,12646626,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,ecn,ecn,08/May/13 14:23,08/May/13 22:56,13/Mar/19 22:01,08/May/13 21:23,,,,,,,,1.5.0,,,docs,,,,,,0,,,,,"In the README at the top of the accumulo distribution, there are instructions for running accumulo in a kerberos environment.

{noformat}
Place this file in $ACCUMULO_HOME/conf for every host. It should be owned by
the accumulo user and chmodded to 400. Add the following to the accumulo-env.sh

In the accumulo-site.xml file on each node, add settings for general.kerberos.keytab...
{noformat}

""Add the following"" ... what?


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-08 22:31:22.349,,,no_permission,,,,,,,,,,,,326984,,,Wed May 08 22:56:45 UTC 2013,,,,,,0|i1kes7:,327328,,,,,,,,"08/May/13 22:31;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #104 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/104/])
    ACCUMULO-1392 - I seemed to have kaiboshed this in the original merge (Revision 1480465)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/README
","08/May/13 22:34;hudson;Integrated in Accumulo-1.5 #102 (See [https://builds.apache.org/job/Accumulo-1.5/102/])
    ACCUMULO-1392 - I seemed to have kaiboshed this in the original merge (Revision 1480465)

     Result = FAILURE
vines : 
Files : 
* /accumulo/branches/1.5/README
","08/May/13 22:52;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #214 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/214/])
    ACCUMULO-1392 - I seemed to have kaiboshed this in the original merge (Revision 1480466)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
","08/May/13 22:56;hudson;Integrated in Accumulo-Trunk #856 (See [https://builds.apache.org/job/Accumulo-Trunk/856/])
    ACCUMULO-1392 - I seemed to have kaiboshed this in the original merge (Revision 1480466)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
simple.largeRow.LargeRowTest FAILED due to out of range exception,ACCUMULO-1227,12639697,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,cheng xu,cheng xu,28/Mar/13 22:32,08/May/13 00:20,13/Mar/19 22:01,07/May/13 23:20,1.4.2,1.4.3,,,,,,1.4.4,1.5.0,,test,,,,,,0,,,,," 4:18:26 runTest (simple.largeRow.LargeRowTest) ............................. DEBUG:test.auto:localhost: /usr/lib/accumulo/bin/accumulo org.apache.accumulo.server.test.functional.FunctionalTest -m localhost -u root -p secret -i ip-10-151-77-24-32355 org.apache.accumulo.server.test.functional.LargeRowTest getConfig
DEBUG:test.auto:
{ 'tserver.compaction.major.delay':'1', }
DEBUG:test.auto:
INFO:test.auto:killing accumulo processes everywhere
DEBUG:test.auto:localhost: /usr/lib/accumulo/test/system/auto/pkill.sh 9 2000 ip-10-151-77-24-32355.*org.apache.accumulo.start
DEBUG:test.auto:localhost: hadoop fs -rmr /user/root/accumulo-ip-10-151-77-24-32355
INFO:test.auto:Error output from command: rmr: cannot remove /user/root/accumulo-ip-10-151-77-24-32355: No such file or directory.
DEBUG:test.auto:Exit code: 255
DEBUG:test.auto:localhost: /usr/lib/accumulo/bin/accumulo init --clear-instance-name
DEBUG:test.auto:Output from command: 2013-03-26 14:18:29,914 util.Initialize INFO : Hadoop Filesystem is hdfs://ip-10-151-77-24.ec2.internal:8020
2013-03-26 14:18:29,916 util.Initialize INFO : Accumulo data dir is /user/root/accumulo-ip-10-151-77-24-32355
2013-03-26 14:18:29,916 util.Initialize INFO : Zookeeper server is localhost:2181
2013-03-26 14:18:29,916 util.Initialize INFO : Checking if Zookeeper is available. If this hangs, then you need to make sure zookeeper is running
Instance name : ip-10-151-77-24-32355
Enter initial password for root: ******
Confirm initial password for root: ******
2013-03-26 14:18:30,377 util.NativeCodeLoader INFO : Loaded the native-hadoop library
2013-03-26 14:18:30,525 security.ZKAuthenticator INFO : Initialized root user with username: root at the request of user !SYSTEM
DEBUG:test.auto:Exit code: 0
DEBUG:test.auto:localhost: /usr/lib/accumulo/bin/accumulo logger
DEBUG:test.auto:localhost: /usr/lib/accumulo/bin/accumulo tserver
DEBUG:test.auto:localhost: /usr/lib/accumulo/bin/accumulo monitor
DEBUG:test.auto:localhost: /usr/lib/accumulo/bin/accumulo org.apache.accumulo.server.master.state.SetGoalState NORMAL
DEBUG:test.auto:Output from command: 2013-03-26 14:18:32,095 server.Accumulo INFO : Attempting to talk to zookeeper
2013-03-26 14:18:32,471 server.Accumulo INFO : Zookeeper connected and initialized, attemping to talk to HDFS
2013-03-26 14:18:33,736 server.Accumulo INFO : Connected to HDFS
DEBUG:test.auto:Exit code: 0
DEBUG:test.auto:localhost: /usr/lib/accumulo/bin/accumulo master
DEBUG:test.auto:localhost: /usr/lib/accumulo/bin/accumulo org.apache.accumulo.server.test.functional.FunctionalTest -m localhost -u root -p secret -i ip-10-151-77-24-32355 org.apache.accumulo.server.test.functional.LargeRowTest setup
DEBUG:test.auto:
DEBUG:test.auto:
DEBUG:test.auto:localhost: /usr/lib/accumulo/bin/accumulo org.apache.accumulo.server.test.functional.FunctionalTest -m localhost -u root -p secret -i ip-10-151-77-24-32355 org.apache.accumulo.server.test.functional.LargeRowTest run
DEBUG:test.auto:Waiting for /usr/lib/accumulo/bin/accumulo org.apache.accumulo.server.test.functional.FunctionalTest -m localhost -u root -p secret -i ip-10-151-77-24-32355 org.apache.accumulo.server.test.functional.LargeRowTest run to stop in 120 secs
DEBUG:test.auto:err: Thread ""org.apache.accumulo.server.test.functional.FunctionalTest"" died null
java.lang.reflect.InvocationTargetException
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.accumulo.start.Main$1.run(Main.java:89)
at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.Exception: # of table splits points out of range, #splits=10 table=lr min=1 max=9
at org.apache.accumulo.server.test.functional.FunctionalTest.checkSplits(FunctionalTest.java:216)
at org.apache.accumulo.server.test.functional.LargeRowTest.test1(LargeRowTest.java:98)
at org.apache.accumulo.server.test.functional.LargeRowTest.run(LargeRowTest.java:86)
at org.apache.accumulo.server.test.functional.FunctionalTest.main(FunctionalTest.java:312)
... 6 more
ERROR:test.auto:This looks like a stack trace: Thread ""org.apache.accumulo.server.test.functional.FunctionalTest"" died null
java.lang.reflect.InvocationTargetException
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.accumulo.start.Main$1.run(Main.java:89)
at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.Exception: # of table splits points out of range, #splits=10 table=lr min=1 max=9
at org.apache.accumulo.server.test.functional.FunctionalTest.checkSplits(FunctionalTest.java:216)
at org.apache.accumulo.server.test.functional.LargeRowTest.test1(LargeRowTest.java:98)
at org.apache.accumulo.server.test.functional.LargeRowTest.run(LargeRowTest.java:86)
at org.apache.accumulo.server.test.functional.FunctionalTest.main(FunctionalTest.java:312)
... 6 more
FAIL
======================================================================
FAIL: runTest (simple.largeRow.LargeRowTest)
----------------------------------------------------------------------
Traceback (most recent call last):
File ""/usr/lib/accumulo/test/system/auto/JavaTest.py"", line 56, in runTest
self.waitForStop(handle, self.maxRuntime)
File ""/usr/lib/accumulo/test/system/auto/TestUtils.py"", line 383, in waitForStop
self.assert_(self.processResult(out, err, handle.returncode))
AssertionError
INFO:test.auto:killing accumulo processes everywhere
DEBUG:test.auto:localhost: /usr/lib/accumulo/test/system/auto/pkill.sh 1 2000 ip-10-151-77-24-32355.*org.apache.accumulo.start
DEBUG:test.auto:localhost: hadoop fs -rmr /user/root/accumulo-ip-10-151-77-24-32355
DEBUG:test.auto:Output from command: Moved to trash: hdfs://ip-10-151-77-24.ec2.internal:8020/user/root/accumulo-ip-10-151-77-24-32355
DEBUG:test.auto:Exit code: 0
DEBUG:test.auto:localhost: /usr/lib/accumulo/bin/accumulo org.apache.accumulo.server.util.DeleteZooInstance ip-10-151-77-24-32355
DEBUG:test.auto:Exit code: 0
DEBUG:test.auto:localhost: rm -rf /usr/lib/accumulo/walogs/ip-10-151-77-24-32355
DEBUG:test.auto:Exit code: 0
DEBUG:test.auto:localhost: rm -rf /usr/lib/accumulo/logs/ip-10-151-77-24-32355
DEBUG:test.auto:Exit code: 0
======================================================================
FAIL: runTest (simple.largeRow.LargeRowTest)
----------------------------------------------------------------------
Traceback (most recent call last):
File ""/usr/lib/accumulo/test/system/auto/JavaTest.py"", line 56, in runTest
self.waitForStop(handle, self.maxRuntime)
File ""/usr/lib/accumulo/test/system/auto/TestUtils.py"", line 383, in waitForStop
self.assert_(self.processResult(out, err, handle.returncode))
AssertionError
----------------------------------------------------------------------
Ran 1 test in 38.133s
FAILED (failures=1)",Hortonworks Data Platform 1.1.2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-28 23:21:23.166,,,no_permission,,,,,,,,,,,,320166,,,Wed May 08 00:20:25 UTC 2013,,,,,,0|i1j8q7:,320507,,,,,,,,"28/Mar/13 23:21;elserj;I believe you copied the wrong log.

Also, I assume you saw this running against Accumulo 1.4.2 like your other tickets?","28/Mar/13 23:49;cheng xu;Yes, this was ran on 1.4.2.  I've updated the bug with the correct log now.","29/Mar/13 00:22;elserj;Cool. Thanks for verifying. Looks like [~jvines@gmail.com] also ran into this.

http://mail-archives.apache.org/mod_mbox/accumulo-dev/201303.mbox/%3CCADczPYT-B1y7Z-QQZ2f0oVPg7PegQgWVO0ZuVsS0rBGZZwfcrg@mail.gmail.com%3E","29/Mar/13 15:20;vines;Yes, I was able to recreate it against 1.4.2 and 1.4.3. I talked to Eric a little bit on irc and he mentioned that it was possibly to the test being overly sensitive and he mentioned possibly backporting some changes from 1.5 to the way the tests behave to rectify this.","29/Mar/13 22:06;billie.rinaldi;I don't think this is a timing issue, it seems to be a logic issue with the test.  It creates a new table with no splits and writes 100 entries each with a row of size 131,072 (and one- or two-byte values).  So there are 13,107,390 bytes of data.  It changes the split threshold to 2,621,440, then waits 10 seconds, and then checks that there are between 1 and 9 splits on the table.  When I recreate this process, the table's single file has size 32,618,617 bytes before splitting, and changing the split threshold eventually results in 16 tablets.  16 tablets is what I would expect based on the file size.

I'm not sure what the test is trying to do.  It should pass if we make it check that there are between 1 and 16 tablets instead of 1 and 9, but I'm not sure why we're verifying that.  ","22/Apr/13 20:33;ecn;Actually, it starts with 9 splits.  It should have between 9 and 16.","23/Apr/13 00:59;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #86 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/86/])
    ACCUMULO-1227 fix LargeRowTest (Revision 1470705)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java
","23/Apr/13 01:08;hudson;Integrated in Accumulo-1.5 #87 (See [https://builds.apache.org/job/Accumulo-1.5/87/])
    ACCUMULO-1227 fix LargeRowTest (Revision 1470705)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java
","23/Apr/13 01:13;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #198 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/198/])
    ACCUMULO-1227 fix LargeRowTest (Revision 1470706)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java
","23/Apr/13 01:21;hudson;Integrated in Accumulo-Trunk #840 (See [https://builds.apache.org/job/Accumulo-Trunk/840/])
    ACCUMULO-1227 fix LargeRowTest (Revision 1470706)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java
","08/May/13 00:08;hudson;Integrated in Accumulo-Trunk #853 (See [https://builds.apache.org/job/Accumulo-Trunk/853/])
    ACCUMULO-1227 test was failing (Revision 1480120)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java
","08/May/13 00:11;hudson;Integrated in Accumulo-1.4.x #301 (See [https://builds.apache.org/job/Accumulo-1.4.x/301/])
    ACCUMULO-1227 test was failing (Revision 1480121)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/test/functional/LargeRowTest.java
","08/May/13 00:13;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #211 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/211/])
    ACCUMULO-1227 test was failing (Revision 1480120)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java
","08/May/13 00:14;hudson;Integrated in Accumulo-1.5 #100 (See [https://builds.apache.org/job/Accumulo-1.5/100/])
    ACCUMULO-1227 test was failing (Revision 1480118)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java
","08/May/13 00:20;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #102 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/102/])
    ACCUMULO-1227 test was failing (Revision 1480118)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/LargeRowTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Authorizations and ColumnVisibility API should not accept Charset param,ACCUMULO-1005,12629763,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,treardon,ctubbsii,ctubbsii,29/Jan/13 19:43,07/May/13 02:53,13/Mar/19 22:01,04/May/13 05:20,,,,,,,,1.5.0,,,,,,,,,0,,,,,"The Charset parameter was added to the public API for ACCUMULO-241. However, this intermingles internal serialization/comparison implementation, and the semantics of the public API.

The Charset parameter effectively instructs Accumulo how to serialize the object. This can break the comparison with what is stored in the table and is an unnecessary breakage.

In the public API, we should only accept Strings, and allow any valid java String. Internally, the serialization of these should consistently be UTF-8.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-743,,,,,,,,,,,,,,06/Apr/13 21:46;treardon;ACCUMULO-1005.patch;https://issues.apache.org/jira/secure/attachment/12577399/ACCUMULO-1005.patch,17/Apr/13 15:52;vines;ACCUMULO-1005_deprecate.patch;https://issues.apache.org/jira/secure/attachment/12579147/ACCUMULO-1005_deprecate.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-04-06 21:46:45.78,,,no_permission,,,,,,,,,,,,310259,,,Tue May 07 02:53:52 UTC 2013,,,,,,0|i1hjmf:,310604,,,,,,,,06/Apr/13 21:46;treardon;Patch is attached that removes Charset/encoding from Authorizations and ColumnVisibility. All serialization is done using UTF-8. I also added a new multi-byte unit test for each class to ensure nothing was broken.,08/Apr/13 12:40;ecn;We'll need to deprecate the API in 1.5 before we remove it.,"08/Apr/13 14:48;kturner;I do not think the initial assumption of this ticket is valid.  The String functions are provided for convenience.    Internally Accumulo treats this data as byte arrays.  Accumulo does not care about encoding, if the user wants to use something besides utf8 then that will not break anything internally.   For example, the following constructors take byte arrays.

{code:java}
   public Authorizations(Collection<byte[]> authorizations)
{code}

{code:java}
   public ColumnVisibility(byte[] expression)
{code}

More specifically, the language is defined by bytes that correspond to certain characters in ASCII.  Between quotes you can have any bytes you like, it does not matter what they are, all comparisons are done using byte arrays.  ","08/Apr/13 15:00;kturner;bq. We'll need to deprecate the API in 1.5 before we remove it.

Some of these may be new in 1.5, and not need deprecation.","10/Apr/13 17:08;ctubbsii;To add clarification to this issue, the intent of this ticket assumes the design goal that visibility labels should be human-readable, and therefore, should only accept human-readable strings (in whatever language).

Since that's been a design goal of visibility expressions and authorizations for a long time now, we don't need to support methods that control internal behavior of how Accumulo stores these strings as bytes. To reduce human errors when it comes to charsets and encodings and serialization, we should just be consistent in our internal serialization, instead of allowing users to instruct Accumulo to store it one way, and then another user write code that instructs Accumulo to read it a different way.

It may, however, make sense to allow convenience methods that accept bytes or ByteBuffer or Text or whatever, but we should treat these as bytes that have been pre-serialized to our internal serialization (probably UTF-8), and those convenience methods (if they exist) should document that the bytes they represent should be of this form. (Though, personally, I think those should go away also, as all human-readable characters that can be represented in Java can be represented in UTF-8, and I see no reason to accept anything other than String or CharSequence, deprecate the rest, and internally serialize/deserialize using UTF-8 bytes.)",17/Apr/13 15:52;vines;I went through Tim's patch and made sure deprecations were done for older calls. I'm not committing it as it appears that discussion needs to continue.,"17/Apr/13 15:55;vines;For the record, this does seem to be an extension of the UTF-8 ticket from a few months back. I do agree with Chris though- we strive for visibilities to be human readable, in whatever language that human uses, so lets make that the only option.",17/Apr/13 23:31;ctubbsii;Marking as patch available.,"07/May/13 02:35;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #100 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/100/])
    ACCUMULO-1005 Applying patch contributed by Tim Reardon to remove Charset options from Authorizations and ColumnVisibility, with minor edits from John Vines and minor documentation additions and cleanup from myself (Revision 1479039)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/security/Authorizations.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/security/ColumnVisibility.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/security/AuthorizationsTest.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/security/ColumnVisibilityTest.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/security/VisibilityEvaluatorTest.java
","07/May/13 02:37;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #209 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/209/])
    ACCUMULO-1005, ACCUMULO-1316 merge to trunk (Revision 1479040)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/Authorizations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/ColumnVisibility.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/AuthorizationsTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/ColumnVisibilityTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/VisibilityEvaluatorTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","07/May/13 02:42;hudson;Integrated in Accumulo-Trunk #851 (See [https://builds.apache.org/job/Accumulo-Trunk/851/])
    ACCUMULO-1005, ACCUMULO-1316 merge to trunk (Revision 1479040)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/Authorizations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/ColumnVisibility.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/AuthorizationsTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/ColumnVisibilityTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/VisibilityEvaluatorTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","07/May/13 02:53;hudson;Integrated in Accumulo-1.5 #98 (See [https://builds.apache.org/job/Accumulo-1.5/98/])
    ACCUMULO-1005 Applying patch contributed by Tim Reardon to remove Charset options from Authorizations and ColumnVisibility, with minor edits from John Vines and minor documentation additions and cleanup from myself (Revision 1479039)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/security/Authorizations.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/security/ColumnVisibility.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/security/AuthorizationsTest.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/security/ColumnVisibilityTest.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/security/VisibilityEvaluatorTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pair incorrectly assumes its components are Comparable,ACCUMULO-1382,12646142,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,05/May/13 22:56,07/May/13 02:42,13/Mar/19 22:01,06/May/13 01:51,,,,,,,,1.6.0,,,,,,,,,0,warning,,,,"In trunk (for 1.6.0), Pair<A,B> was made Comparable, but makes assumptions that A and B are Comparable. This should either be checked in its compareTo method explicitly, or should be enforced in the generic parameters. This assumption is a runtime bug-in-waiting.

It looks like this was added to support some of the new Lexicoders.

I did a rough check to see the implications of enforcing the parameters to be Comparable (changing it from Pair<A,B> to Pair<A extends Comparable<A>,B extends Comparable<B>>), and it looks like there's a problem because we use this class with generated thrift code, which are not Comparable objects.

It might be better to make a ComparablePair that extends Pair, for use in the Lexicoders, instead of making Pair itself Comparable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-05 23:32:47.506,,,no_permission,,,,,,,,,,,,326500,,,Tue May 07 02:42:12 UTC 2013,,,,,,0|i1kbt3:,326845,,,,,,,,"05/May/13 23:32;elserj;I did notice this when I was applying the patch, started down the path of Java-type-suck-iness, and just said screw it. I should've made a note then. Thanks for doing so.","06/May/13 00:25;sonixbp;Sorry guys, this was totally my fault and I should have caught it while I was merging the lexicoders from Keith's github repo. Do we need to supply a Pair lexicoder? Maybe we should leave that one up to the user?",06/May/13 01:51;ctubbsii;Made a ComparablePair for use by the PairLexicoder.,"07/May/13 02:37;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #209 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/209/])
    ACCUMULO-1382 Make PairLexicoder use a ComparablePair, so the Comparable-ness of its parameters can be enforced. Also fixed javadocs, header comments, formatting, and warnings introduced by ACCUMULO-1336. (Revision 1479448)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/BigIntegerLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/BytesLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/DateLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/DoubleLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/Encoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/IntegerLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/Lexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/ListLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/LongLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/PairLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/ReverseLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/StringLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/TextLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/UIntegerLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/ULongLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/UUIDLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/util/ByteUtils.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/util/FixedByteArrayOutputStream.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ComparablePair.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/Pair.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/BigIntegerLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/DoubleLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/IntegerLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/LexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/ListLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/LongLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/PairLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/ReverseLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/UIntegerLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/ULongLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/UUIDLexicoderTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/mini/MiniAccumuloConfig.java
","07/May/13 02:42;hudson;Integrated in Accumulo-Trunk #851 (See [https://builds.apache.org/job/Accumulo-Trunk/851/])
    ACCUMULO-1382 Make PairLexicoder use a ComparablePair, so the Comparable-ness of its parameters can be enforced. Also fixed javadocs, header comments, formatting, and warnings introduced by ACCUMULO-1336. (Revision 1479448)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/BigIntegerLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/BytesLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/DateLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/DoubleLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/Encoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/IntegerLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/Lexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/ListLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/LongLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/PairLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/ReverseLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/StringLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/TextLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/UIntegerLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/ULongLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/UUIDLexicoder.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/util/ByteUtils.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/lexicoder/util/FixedByteArrayOutputStream.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ComparablePair.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/Pair.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/BigIntegerLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/DoubleLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/IntegerLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/LexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/ListLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/LongLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/PairLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/ReverseLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/UIntegerLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/ULongLexicoderTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/lexicoder/UUIDLexicoderTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/mini/MiniAccumuloConfig.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unexpected insert error not displayed in shell,ACCUMULO-772,12608703,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,21/Sep/12 22:27,03/May/13 13:16,13/Mar/19 22:01,21/Sep/12 23:01,1.4.0,1.4.1,,,,,,1.4.2,1.5.0,,,,,,,,0,,,,,"When an unexpected error occurs when executing insert in the shell, nothing is displayed.   For example if an unexpected runtime exception occurs in the batch writer, then nothing will be displayed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246304,,,2012-09-21 22:27:03.0,,,,,,0|i07l7b:,42201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extraneous vfs output should be logged (and breaks functional tests),ACCUMULO-926,12625878,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,03/Jan/13 17:20,02/May/13 02:30,13/Mar/19 22:01,03/Jan/13 18:54,,,,,,,,1.5.0,,,start,,,,,,0,,,,,"We need to add some log configuration to point the vfs logging to log files instead of System out. This logging, aside from being a minor nuisance in operations, breaks a good chunk of the python functional tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-708,ACCUMULO-943,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-03 19:09:01.796,,,no_permission,,,,,,,,,,,,302459,,,Thu Jan 03 19:09:01 UTC 2013,,,,,,0|i173bj:,249505,,,,,,,,"03/Jan/13 18:40;vines;I didn't see you grabbed the ticket, I just committed a fix. If you have a better solution I can back mine out though. [~kturner]",03/Jan/13 18:54;vines;Squelching via log4j.properties,"03/Jan/13 19:09;hudson;Integrated in Accumulo-Trunk #602 (See [https://builds.apache.org/job/Accumulo-Trunk/602/])
    ACCUMULO-926 - I didn't need to mess with the script, it turns out (Revision 1428548)
ACCUMULO-926 - appropriate log4j squelching (Revision 1428539)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/bin/accumulo

vines : 
Files : 
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/conf/examples/1GB/native-standalone/log4j.properties
* /accumulo/trunk/conf/examples/1GB/standalone/log4j.properties
* /accumulo/trunk/conf/examples/2GB/native-standalone/log4j.properties
* /accumulo/trunk/conf/examples/2GB/standalone/log4j.properties
* /accumulo/trunk/conf/examples/3GB/native-standalone/log4j.properties
* /accumulo/trunk/conf/examples/3GB/standalone/log4j.properties
* /accumulo/trunk/conf/examples/512MB/native-standalone/log4j.properties
* /accumulo/trunk/conf/examples/512MB/standalone/log4j.properties
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Symlinks to bin/accumulo don't work,ACCUMULO-432,12544429,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,jvines,28/Feb/12 15:09,02/May/13 02:30,13/Mar/19 22:01,02/Jan/13 21:03,1.4.0,,,,,,,1.5.0,,,scripts,,,,,,0,,,,,"jdeb, which we use for creating our debian files, automatically creates a symlink for /usr/bin/accumulo. I was unable to find a way to configure this in jdeb. Granted, a symlink to $ACCUMULO_HOME/bin/accumulo should be made to work, regardless of the state of our debian packaging.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-429,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-09-25 16:48:03.281,,,no_permission,,,,,,,,,,,,229666,,,Wed Jan 02 21:19:39 UTC 2013,,,,,,0|i07n87:,42529,,,,,,,,"25/Sep/12 16:48;ekohlwey;Supporting symlinks to scripts is difficult, and doing it 100% correctly is physically impossible. There's some background discussion on this post if you're interested http://mywiki.wooledge.org/BashFAQ/028 . While symlinks work well for binaries, they are bad for shell, particularly bash scripts.

It would be better to have a script for /usr/bin/accumulo (that is part of the data tarball) that executes /usr/lib/accumulo/bin/accumulo. This is the current approach in Hadoop and it works well.","25/Sep/12 17:44;vines;I chalk up the majority of this ticket to my lack of understanding of jdeb. I plan on giving the packaging as a whole more loving in the coming months, so expect improvements.

As for this ticket specifically, I do have a tested Bourne method for resolving links that works on Darwin and ubuntu. I want to test it a bit more and then work on integrating it into our scripts.","26/Sep/12 11:38;ctubbsii;John- I'm also interested in improving packaging... especially for Fedora and CentOS. So, if you wouldn't mind keeping me abreast, or including me in any brainstorming, I'd be appreciative. Ideally, I'd like to do our packaging so well that we set the standard for packaging and delivering Maven projects on Linux.","02/Jan/13 21:19;hudson;Integrated in Accumulo-Trunk #599 (See [https://builds.apache.org/job/Accumulo-Trunk/599/])
    ACCUMULO-432 - Adding readlink (with work around for BSDs lack of -f support... stupid bsd) (Revision 1428040)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/trunk/bin/accumulo
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
shell tables command does not paginate,ACCUMULO-1356,12644962,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,treardon,treardon,treardon,26/Apr/13 23:10,02/May/13 02:30,13/Mar/19 22:01,29/Apr/13 18:45,,,,,,,,1.6.0,,,shell,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1193,,,,,,,,,,,,,,,,,,,29/Apr/13 01:30;treardon;ACCUMULO-1356.patch;https://issues.apache.org/jira/secure/attachment/12580918/ACCUMULO-1356.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-04-29 18:45:00.081,,,no_permission,,,,,,,,,,,,325324,,,Mon Apr 29 21:51:17 UTC 2013,,,,,,0|i1k4jz:,325669,,,,,,,,"29/Apr/13 01:33;treardon;I didn't notice that ACCUMULO-748 also calls for pagination, as well as sorting by id.",29/Apr/13 18:45;ecn;Patch applied. Thanks!,"29/Apr/13 21:29;hudson;Integrated in Accumulo-Trunk #845 (See [https://builds.apache.org/job/Accumulo-Trunk/845/])
    ACCUMULO-1356 applying patch from Tim Reardon to paginate tables output (Revision 1477263)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/TablesCommand.java
","29/Apr/13 21:51;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #203 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/203/])
    ACCUMULO-1356 applying patch from Tim Reardon to paginate tables output (Revision 1477263)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/TablesCommand.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Functional tests fail more than I'm comfortable with,ACCUMULO-235,12536290,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,jvines,23/Dec/11 15:00,02/May/13 02:29,13/Mar/19 22:01,17/Aug/12 15:10,,,,,,,,1.5.0,,,master,scripts,tserver,,,,0,test,,,,"A good chunk of the functional tests fail, typically a time out during shut down. This may be a symptom of a bigger problem, so we should investigate what's going on here so we can fix it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-608,,,,,,,,,,,,ACCUMULO-606,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-05-25 14:24:25.713,,,no_permission,,,,,,,,,,,,221973,,,Fri May 25 14:24:25 UTC 2012,,,,,,0|i07oen:,42720,,,,,,,,25/May/12 14:24;jvines;606 will fix one of the broken tests.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Docs profile doesn't fail when prerequisites aren't available,ACCUMULO-1343,12644454,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,24/Apr/13 21:44,30/Apr/13 03:43,13/Mar/19 22:01,29/Apr/13 21:33,,,,,,,,1.5.0,,,build,docs,,,,,0,,,,,"If the ""docs"" profile is activated in maven, scripts that expect pdflatex to be available are executed. If pdflatex is not available, these scripts exit silently. They should fail, since the docs profile was explicitly activated and is expected to succeed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-26 01:42:08.06,,,no_permission,,,,,,,,,,,,324821,,,Tue Apr 30 03:43:04 UTC 2013,,,,,,0|i1k1gn:,325167,,,,,,,,"26/Apr/13 01:42;hudson;Integrated in Accumulo-1.5 #92 (See [https://builds.apache.org/job/Accumulo-1.5/92/])
    ACCUMULO-1343 Make the build fail when docs fail to build (Revision 1475770)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/docs/src/developer_manual/build.sh
* /accumulo/branches/1.5/docs/src/user_manual/build.sh
","26/Apr/13 01:46;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #91 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/91/])
    ACCUMULO-1343 Make the build fail when docs fail to build (Revision 1475770)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/docs/src/developer_manual/build.sh
* /accumulo/branches/1.5/docs/src/user_manual/build.sh
","30/Apr/13 03:38;hudson;Integrated in Accumulo-Trunk #846 (See [https://builds.apache.org/job/Accumulo-Trunk/846/])
    ACCUMULO-1271, ACCUMULO-370, ACCUMULO-1343, ACCUMULO-1181 merge to trunk (Revision 1477350)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/build.sh
* /accumulo/trunk/assemble/dist.xml
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src
* /accumulo/trunk/assemble/src/main
* /accumulo/trunk/assemble/src/main/assemblies
* /accumulo/trunk/assemble/src/main/assemblies/bin.xml
* /accumulo/trunk/contrib/dotfile-rpmmacros
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java-filtered
* /accumulo/trunk/core/src/main/java-filtered/org
* /accumulo/trunk/core/src/main/java-filtered/org/apache
* /accumulo/trunk/core/src/main/java-filtered/org/apache/accumulo
* /accumulo/trunk/core/src/main/java-filtered/org/apache/accumulo/core
* /accumulo/trunk/core/src/main/java-filtered/org/apache/accumulo/core/FilteredConstants.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/Constants.java
* /accumulo/trunk/docs/src/developer_manual/build.sh
* /accumulo/trunk/docs/src/user_manual/build.sh
* /accumulo/trunk/docs/src/user_manual/chapters/administration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","30/Apr/13 03:43;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #204 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/204/])
    ACCUMULO-1271, ACCUMULO-370, ACCUMULO-1343, ACCUMULO-1181 merge to trunk (Revision 1477350)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/build.sh
* /accumulo/trunk/assemble/dist.xml
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src
* /accumulo/trunk/assemble/src/main
* /accumulo/trunk/assemble/src/main/assemblies
* /accumulo/trunk/assemble/src/main/assemblies/bin.xml
* /accumulo/trunk/contrib/dotfile-rpmmacros
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java-filtered
* /accumulo/trunk/core/src/main/java-filtered/org
* /accumulo/trunk/core/src/main/java-filtered/org/apache
* /accumulo/trunk/core/src/main/java-filtered/org/apache/accumulo
* /accumulo/trunk/core/src/main/java-filtered/org/apache/accumulo/core
* /accumulo/trunk/core/src/main/java-filtered/org/apache/accumulo/core/FilteredConstants.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/Constants.java
* /accumulo/trunk/docs/src/developer_manual/build.sh
* /accumulo/trunk/docs/src/user_manual/build.sh
* /accumulo/trunk/docs/src/user_manual/chapters/administration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
shell history command does not paginate,ACCUMULO-1193,12638323,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,treardon,ecn,ecn,21/Mar/13 17:38,29/Apr/13 21:51,13/Mar/19 22:01,29/Apr/13 17:47,,,,,,,,1.6.0,,,shell,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29/Apr/13 01:29;treardon;ACCUMULO-1193.patch;https://issues.apache.org/jira/secure/attachment/12580917/ACCUMULO-1193.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-04-29 21:29:29.113,,,no_permission,,,,,,,,,,,,318799,,,Mon Apr 29 21:51:17 UTC 2013,,,,,,0|i1j0af:,319140,,,,,,,,29/Apr/13 17:47;ecn;Patch applied.  Thanks!,"29/Apr/13 21:29;hudson;Integrated in Accumulo-Trunk #845 (See [https://builds.apache.org/job/Accumulo-Trunk/845/])
    ACCUMULO-1193 applying patch from Tim Reardon to paginate history (Revision 1477230)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/HistoryCommand.java
","29/Apr/13 21:51;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #203 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/203/])
    ACCUMULO-1193 applying patch from Tim Reardon to paginate history (Revision 1477230)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/HistoryCommand.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
du shell command help should specify units,ACCUMULO-1330,12644128,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,sonixbp,kturner,kturner,23/Apr/13 14:32,25/Apr/13 03:32,13/Mar/19 22:01,24/Apr/13 23:44,,,,,,,,1.5.0,,,,,,,,,0,newbie,,,,Help for the du shell command should specify units,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23/Apr/13 21:41;sonixbp;ACCUMULO-1330.patch;https://issues.apache.org/jira/secure/attachment/12580140/ACCUMULO-1330.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-04-23 14:40:13.8,,,no_permission,,,,,,,,,,,,324495,,,Thu Apr 25 03:32:54 UTC 2013,,,,,,0|i1jzfz:,324840,,,,,,,,"23/Apr/13 14:40;sonixbp;Mind if I take this on?
","23/Apr/13 15:27;kturner;bq. Mind if I take this on?

not at all",24/Apr/13 12:45;kturner;I applied the patch. Thanks again Corey.,"24/Apr/13 19:26;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #89 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/89/])
    ACCUMULO-1330 patch from Corey Nolet which specifies units in du help command (Revision 1471390)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/DUCommand.java
","24/Apr/13 19:34;hudson;Integrated in Accumulo-1.5 #90 (See [https://builds.apache.org/job/Accumulo-1.5/90/])
    ACCUMULO-1330 patch from Corey Nolet which specifies units in du help command (Revision 1471390)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/DUCommand.java
","25/Apr/13 03:24;hudson;Integrated in Accumulo-Trunk #843 (See [https://builds.apache.org/job/Accumulo-Trunk/843/])
    ACCUMULO-1330 patch from Corey Nolet which specifies units in du help command (Revision 1471569)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/DUCommand.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","25/Apr/13 03:32;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #201 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/201/])
    ACCUMULO-1330 patch from Corey Nolet which specifies units in du help command (Revision 1471569)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/DUCommand.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
improve documentation,ACCUMULO-1104,12633951,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,medined,ecn,ecn,25/Feb/13 17:09,22/Apr/13 16:31,13/Mar/19 22:01,22/Apr/13 16:31,,,,,,,,1.5.0,,,docs,,,,,,0,,,,,fix typos and missing information in documentation for the 1.5.  See sub-tickets.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-26 19:09:54.906,,,no_permission,,,,,,,,,,,,314445,,,Mon Mar 04 18:23:20 UTC 2013,,,,,,0|i1i9fz:,314789,,,,,,,,"26/Feb/13 19:09;ctubbsii;I'm wondering if maybe some of these things can be rolled into a list, rather than separate tickets/sub-tasks for every individual tweak. I realize there's a trade-off here... so I'm not sure it's easy to establish a rock solid rule to know when to do sub-tasks and when to put them in a single ticket... but I think these particular sub-tasks are approaching one extreme end of the spectrum.",27/Feb/13 00:05;medined;SVN# 1450543. This update has resolved many of this issues on the 1.5 branch. The SVN commit references all of the Jira tickets so hopefully they will link correctly. Some of these issues relate to the HTML version of the user manual.,"28/Feb/13 01:36;hudson;Integrated in Accumulo-Trunk #748 (See [https://builds.apache.org/job/Accumulo-Trunk/748/])
    merging changes from 1.5

ACCUMULO-1118 - updating cli's default password to be empty, and some of the tests appropriately
ACCUMULO-1104, ACCUMULO-1093, ACCUMULO-1094, ACCUMULO-1095, ACCUMULO-1099, ACCUMULO-1097, ACCUMULO-1102 - Improve documentation
ACCUMULO-858: Parse Exception During Run of Maven Changes Report Plugin
ACCUMULO-1120 - credentials now getting properly read (Revision 1451008)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_design.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/dirlist/CountTest.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","28/Feb/13 02:31;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #107 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/107/])
    merging changes from 1.5

ACCUMULO-1118 - updating cli's default password to be empty, and some of the tests appropriately
ACCUMULO-1104, ACCUMULO-1093, ACCUMULO-1094, ACCUMULO-1095, ACCUMULO-1099, ACCUMULO-1097, ACCUMULO-1102 - Improve documentation
ACCUMULO-858: Parse Exception During Run of Maven Changes Report Plugin
ACCUMULO-1120 - credentials now getting properly read (Revision 1451008)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_design.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/dirlist/CountTest.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","03/Mar/13 08:04;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #10 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/10/])
    ACCUMULO-1104 Another update to account for 1.5 changes in the user manual (Revision 1452010)
ACCUMULO-1104 ACCUMULO-1136 Applying additional wording for using config as opposed to setiter. Fix various other documentation which are now incorrect in 1.5. (Revision 1452005)
ACCUMULO-1104 Correcting documented option to show timestamps in shell in user manual. (Revision 1452000)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/branches/1.5/docs/src/user_manual/chapters/administration.tex

elserj : 
Files : 
* /accumulo/branches/1.5/docs/src/user_manual/accumulo_user_manual.tex
* /accumulo/branches/1.5/docs/src/user_manual/chapters/clients.tex
* /accumulo/branches/1.5/docs/src/user_manual/chapters/shell.tex
* /accumulo/branches/1.5/docs/src/user_manual/chapters/table_configuration.tex

elserj : 
Files : 
* /accumulo/branches/1.5/docs/src/user_manual/chapters/shell.tex
","03/Mar/13 08:08;hudson;Integrated in Accumulo-1.5 #11 (See [https://builds.apache.org/job/Accumulo-1.5/11/])
    ACCUMULO-1104 Another update to account for 1.5 changes in the user manual (Revision 1452010)
ACCUMULO-1104 ACCUMULO-1136 Applying additional wording for using config as opposed to setiter. Fix various other documentation which are now incorrect in 1.5. (Revision 1452005)
ACCUMULO-1104 Correcting documented option to show timestamps in shell in user manual. (Revision 1452000)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/branches/1.5/docs/src/user_manual/chapters/administration.tex

elserj : 
Files : 
* /accumulo/branches/1.5/docs/src/user_manual/accumulo_user_manual.tex
* /accumulo/branches/1.5/docs/src/user_manual/chapters/clients.tex
* /accumulo/branches/1.5/docs/src/user_manual/chapters/shell.tex
* /accumulo/branches/1.5/docs/src/user_manual/chapters/table_configuration.tex

elserj : 
Files : 
* /accumulo/branches/1.5/docs/src/user_manual/chapters/shell.tex
","04/Mar/13 18:16;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #115 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/115/])
    merged changes from 1.5
ACCUMULO-1142 Enable redirectTestOutputToFile in surefire plugin to nuke test output
ACCUMULO-1002 Apply override annotation to the close method on the BatchScanner implementation to be explicit
ACCUMULO-1002 Add a close method to ScannerBase and a no-op impl to ScannerOptions.
ACCUMULO-1104 Another update to account for 1.5 changes in the user manual
ACCUMULO-1071 Changing wording from ""hadoop library type"" to ""Accumulo memory-map type""
ACCUMULO-1104 ACCUMULO-1136 Applying additional wording for using config as opposed to setiter. Fix various other documentation which are now incorrect in 1.5.
ACCUMULO-1104 Correcting documented option to show timestamps in shell in user manual. (Revision 1452342)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/bootstrap_config.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/ScannerBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ScannerOptions.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReader.java
* /accumulo/trunk/docs/src/user_manual/accumulo_user_manual.tex
* /accumulo/trunk/docs/src/user_manual/chapters/administration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/NullScanner.java
* /accumulo/trunk/src
","04/Mar/13 18:23;hudson;Integrated in Accumulo-Trunk #756 (See [https://builds.apache.org/job/Accumulo-Trunk/756/])
    merged changes from 1.5
ACCUMULO-1142 Enable redirectTestOutputToFile in surefire plugin to nuke test output
ACCUMULO-1002 Apply override annotation to the close method on the BatchScanner implementation to be explicit
ACCUMULO-1002 Add a close method to ScannerBase and a no-op impl to ScannerOptions.
ACCUMULO-1104 Another update to account for 1.5 changes in the user manual
ACCUMULO-1071 Changing wording from ""hadoop library type"" to ""Accumulo memory-map type""
ACCUMULO-1104 ACCUMULO-1136 Applying additional wording for using config as opposed to setiter. Fix various other documentation which are now incorrect in 1.5.
ACCUMULO-1104 Correcting documented option to show timestamps in shell in user manual. (Revision 1452342)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/bootstrap_config.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/ScannerBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ScannerOptions.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReader.java
* /accumulo/trunk/docs/src/user_manual/accumulo_user_manual.tex
* /accumulo/trunk/docs/src/user_manual/chapters/administration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/NullScanner.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
System tests fail from clean checkout,ACCUMULO-1261,12641920,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,ctubbsii,ctubbsii,10/Apr/13 21:00,22/Apr/13 14:52,13/Mar/19 22:01,22/Apr/13 14:52,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"Running the SunnyDay tests fails on a clean checkout, because the scripts require the configuration directory to be initialized.

with -v 10, the output contains:
{code}
Accumulo is not properly configured.

Try running $ACCUMULO_HOME/bin/bootstrap_config.sh and then editing
$ACCUMULO_HOME/conf/accumulo-env.sh
DEBUG:test.auto:Exit code: 1
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-11 00:30:40.851,,,no_permission,,,,,,,,,,,,322335,,,Wed Apr 17 16:01:45 UTC 2013,,,,,,0|i1jm4n:,322680,,,,,,,,11/Apr/13 00:30;medined;What are the SunnyDay tests? Are there other test categories?,"11/Apr/13 13:34;kturner;bq. What are the SunnyDay tests? Are there other test categories?

The functional test.  These are test written in python and java that spin up an Accumulo instance to run test against.   See test/system/auto/ and test/system/auto/run.py.   Now that miniaccumulocluster exist, we may transistion some of these test to maven integration test.","16/Apr/13 21:09;vines;So, I tweaked it to ignore the bootstrap stuff in the tests. They require the various environment variables (java, zookeeper, and hadoop) to be set. One option is to have a configuration independent of the file in the tests. Or we can just depend on them being set. Or, a bit more convoluted, is the option to pass in a separate configuration to use if the accumulo-env.sh in conf is missing, but now we're starting to get a bit complex IMO for a set of tests. If I get no feedback in a few days, I'm resolving this ticket.","17/Apr/13 16:01;hudson;Integrated in Accumulo-Trunk #834 (See [https://builds.apache.org/job/Accumulo-Trunk/834/])
    ACCUMULO-1261 - missed a line in my commit (Revision 1468967)

     Result = FAILURE
vines : 
Files : 
* /accumulo/trunk/bin/config.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ShellTest.authsTests failing in trunk.,ACCUMULO-1326,12643687,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,medined,medined,19/Apr/13 21:26,20/Apr/13 03:23,13/Mar/19 22:01,20/Apr/13 03:23,,,,,,,,1.6.0,,,,,,,,,0,,,,,"-------------------------------------------------------------------------------
Test set: org.apache.accumulo.core.util.shell.ShellTest
-------------------------------------------------------------------------------
Tests run: 9, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.217 sec <<< FAILURE!
authsTest(org.apache.accumulo.core.util.shell.ShellTest)  Time elapsed: 0.015 sec  <<< FAILURE!
java.lang.AssertionError: y,z,x present in test@fake> getauths
x,y,z
 was not true expected:<true> but was:<false>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.apache.accumulo.core.util.shell.ShellTest.assertGoodExit(ShellTest.java:97)
	at org.apache.accumulo.core.util.shell.ShellTest.exec(ShellTest.java:79)
	at org.apache.accumulo.core.util.shell.ShellTest.exec(ShellTest.java:73)
	at org.apache.accumulo.core.util.shell.ShellTest.authsTest(ShellTest.java:158)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-19 21:40:02.339,,,no_permission,,,,,,,,,,,,324054,,,Sat Apr 20 03:23:38 UTC 2013,,,,,,0|i1jwqf:,324399,,,,,,,,19/Apr/13 21:40;billie.rinaldi;I think I just fixed this in r1470041.,20/Apr/13 03:23;medined;I pulled the latest trunk and all of the tests passed. Thanks.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accumulo shell broken if prompted for password,ACCUMULO-1323,12643297,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,vines,vines,18/Apr/13 18:23,19/Apr/13 19:54,13/Mar/19 22:01,18/Apr/13 23:20,,,,,,,,1.5.0,,,shell,,,,,,0,,,,,"Fresh initialization. ./accumulo shell -u root hangs for a second, prints a blank line, and then returns. ./accumulo shell -u root -p secret starts the shell fine.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-19 03:27:40.405,,,no_permission,,,,,,,,,,,,323707,,,Fri Apr 19 19:54:41 UTC 2013,,,,,,0|i1julb:,324052,,,,,,,,"19/Apr/13 03:27;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #84 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/84/])
    ACCUMULO-1314 - destroyable properties. Also, fixed the tests broken with the fix for ACCUMULO-1323 (Revision 1469650)
ACCUMULO-1323 fixed prompting for password in shell and added some option checks for user, password, and token options. (Revision 1469629)

     Result = FAILURE
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/security/tokens/AuthenticationToken.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/security/tokens/NullToken.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/security/tokens/PasswordToken.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java

kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
","19/Apr/13 03:31;hudson;Integrated in Accumulo-1.5 #85 (See [https://builds.apache.org/job/Accumulo-1.5/85/])
    ACCUMULO-1314 - destroyable properties. Also, fixed the tests broken with the fix for ACCUMULO-1323 (Revision 1469650)
ACCUMULO-1323 fixed prompting for password in shell and added some option checks for user, password, and token options. (Revision 1469629)

     Result = FAILURE
vines : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/security/tokens/AuthenticationToken.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/security/tokens/NullToken.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/security/tokens/PasswordToken.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java

kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
","19/Apr/13 04:17;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #195 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/195/])
    ACCUMULO-1314 - destroyable properties. Also, fixed the tests broken with the fix for ACCUMULO-1323 (Revision 1469651)
ACCUMULO-1323 fixed prompting for password in shell and added some option checks for user, password, and token options. (Revision 1469630)

     Result = FAILURE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/security/tokens/AuthenticationToken.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/security/tokens/NullToken.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/security/tokens/PasswordToken.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java

kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","19/Apr/13 04:21;hudson;Integrated in Accumulo-Trunk #837 (See [https://builds.apache.org/job/Accumulo-Trunk/837/])
    ACCUMULO-1314 - destroyable properties. Also, fixed the tests broken with the fix for ACCUMULO-1323 (Revision 1469651)
ACCUMULO-1323 fixed prompting for password in shell and added some option checks for user, password, and token options. (Revision 1469630)

     Result = FAILURE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/security/tokens/AuthenticationToken.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/security/tokens/NullToken.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/security/tokens/PasswordToken.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java

kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","19/Apr/13 19:28;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #85 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/85/])
    ACCUMULO-1323 made shell behave the way it did in 1.4 when no user was given and fixed shell unit test (Revision 1469860)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java
","19/Apr/13 19:41;hudson;Integrated in Accumulo-Trunk #838 (See [https://builds.apache.org/job/Accumulo-Trunk/838/])
    ACCUMULO-1323 made shell behave the way it did in 1.4 when no user was given and fixed shell unit test (Revision 1469896)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java
","19/Apr/13 19:47;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #196 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/196/])
    ACCUMULO-1323 made shell behave the way it did in 1.4 when no user was given and fixed shell unit test (Revision 1469896)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java
","19/Apr/13 19:54;hudson;Integrated in Accumulo-1.5 #86 (See [https://builds.apache.org/job/Accumulo-1.5/86/])
    ACCUMULO-1323 made shell behave the way it did in 1.4 when no user was given and fixed shell unit test (Revision 1469860)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/branches/1.5/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Username *'ed out during `accumulo init`,ACCUMULO-1317,12643113,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,18/Apr/13 02:28,18/Apr/13 16:08,13/Mar/19 22:01,18/Apr/13 02:34,,,,,,,,1.5.0,,,client,,,,,,0,15_qa_bug,,,,"I know we want to be security-conscious, but I think ****'ing out the username of the root user during `accumulo init` may be a little overzealous, no?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1319,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-18 07:46:01.861,,,no_permission,,,,,,,,,,,,323523,,,Thu Apr 18 07:52:15 UTC 2013,,,,,,0|i1jtgf:,323868,,,,,,,,18/Apr/13 02:34;elserj;5 char fix.,"18/Apr/13 07:46;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #83 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/83/])
    ACCUMULO-1317 Remove the '*' mask from user's input of the Accumulo root username (Revision 1469141)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
","18/Apr/13 07:52;hudson;Integrated in Accumulo-1.5 #84 (See [https://builds.apache.org/job/Accumulo-1.5/84/])
    ACCUMULO-1317 Remove the '*' mask from user's input of the Accumulo root username (Revision 1469141)

     Result = FAILURE
elserj : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Master uses wrong path to remove tserver lock from zookeeper,ACCUMULO-16,12526254,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,kturner,kturner,07/Oct/11 18:48,16/Apr/13 21:24,13/Mar/19 22:01,07/Oct/11 21:58,,,,,,,,1.3.5-incubating,1.4.0,,master,,,,,,0,14_qa_bug,,,,LiveTserverSet.remove() constructs a zookeeper path for the tserver that includes the session id.  It should use server.hostPort() to construct the path.  Found this bug while running random walk test.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-10-13 19:11:00.702,,,no_permission,,,,,,,,,,,,50485,,,Thu Oct 13 19:11:00 UTC 2011,,,,,,0|i07pqn:,42936,,,,,,,,"07/Oct/11 18:50;kturner;This could result in multiple tablet assignment.  The master unsuccessfully attempts to remove a tserver zookeeper lock, then reassigns that tservers tablets.","13/Oct/11 19:11;ecn;Also, if there's a problem talking to the tablet server, the lock would not be deleted.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to build git mirror,ACCUMULO-63,12528402,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,23/Oct/11 00:00,16/Apr/13 21:24,13/Mar/19 22:01,24/Oct/11 20:48,,,,,,,,1.3.5-incubating,1.4.0,,build,,,,,,0,git,svn,test,,Currently the git mirror can not be assembled directly off of a download. This is because lib/ext does not exist in the git mirror due to the difference between git being file based while svn is folder based. This can be quickly resolved via creating an empty file in the folder.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-10-23 00:04:42.792,,,no_permission,,,,,,,,,,,,214262,,,Wed Oct 26 17:46:27 UTC 2011,,,,,,0|i07pg7:,42889,,,,,,,,"23/Oct/11 00:04;jvines;Alternatively, this could be resolved via updating the test to create the folder if it doesn't exist (or the class loader itself)",24/Oct/11 20:48;jvines;Fixed the test,26/Oct/11 17:46;jvines;verified,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FirstEntryInRowIterator can scan through entire last row in range,ACCUMULO-794,12610991,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,afuchs,afuchs,afuchs,09/Oct/12 14:36,16/Apr/13 21:24,13/Mar/19 22:01,09/Oct/12 15:40,1.4.1,,,,,,,1.4.2,1.5.0,,client,,,,,,0,,,,,"If the range passed to the FirstEntryInRowIterator is seeked with a Range that has an end key, the FirstEntryInRowIterator will scan through all of the entries in the last row that match the range. This is due to a logic bug -- the if statement on line 93 needs an else clause.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-09 19:50:11.408,,,no_permission,,,,,,,,,,,,246155,,,Wed Oct 10 15:31:12 UTC 2012,,,,,,0|i07hsv:,41651,,,,,,,,09/Oct/12 19:50;kturner;Might have been worthwhile to create a unit test that reproduces the bug in the iterator.,"09/Oct/12 20:04;afuchs;I was thinking that would be non-trivial since this is a performance issue and not a correctness issue. However, I suppose one could write a source iterator that complains if next is called too many times in one row before seek is called. Still seems like more trouble than it's worth.","10/Oct/12 12:07;billie.rinaldi;You could use the CountingIterator (or some variation thereof) as the source of the FirstEntryInRowIterator, wrapping your test source.  That would tell you how many times next() is called.",10/Oct/12 14:30;afuchs;unit test added by popular demand,"10/Oct/12 15:31;kturner;bq. I was thinking that would be non-trivial since this is a performance issue and not a correctness issue. However, I suppose one could write a source iterator that complains if next is called too many times in one row before seek is called. Still seems like more trouble than it's worth.

I agree.  I did not realize it was just a performance issue.  I was not paying close attention.  I took a quick look at the bug and thought the iterator was returning more data than it should.  That do being said, I do like Billie's suggestion.  More test never hurt. Well, as long as they complete in a reasonable amount of time.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rpm fails to install on Centos 6.3 x86_64 using yum,ACCUMULO-1107,12633984,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,jmcmillion,jmcmillion,25/Feb/13 20:07,11/Apr/13 23:26,13/Mar/19 22:01,11/Apr/13 21:47,1.4.2,,,,,,,1.5.0,,,,,,,,,0,,,,,"[root@r01sv02 ~]# uname -a
Linux r01sv02 2.6.32-279.22.1.el6.x86_64 #1 SMP Wed Feb 6 03:10:46 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
[root@r01sv02 ~]# cat /etc/redhat-release
CentOS release 6.3 (Final)
[root@r01sv02 ~]# yum install accumulo-1.4.2-1.amd64.rpm
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
 * base: jnet.jnet.lan
 * epel: mirror.itc.virginia.edu
 * extras: mirror.us.leaseweb.net
 * updates: jnet.jnet.lan
Setting up Install Process
Examining accumulo-1.4.2-1.amd64.rpm: accumulo-1.4.2-1.amd64
Cannot add package accumulo-1.4.2-1.amd64.rpm to transaction. Not a compatible architecture: amd64
Error: Nothing to do

Using the rpm does work however:

[root@r01sv02 ~]# rpm -Uvh accumulo-1.4.2-1.amd64.rpm
Preparing...                ########################################### [100%]
   1:accumulo               ########################################### [100%]

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-05 22:24:50.204,,,no_permission,,,,,,,,,,,,314478,,,Thu Apr 11 23:26:45 UTC 2013,,,,,,0|i1i9nb:,314822,,,,,,,,"05/Apr/13 22:24;jpyeron;hmm, there are no binaries in the rpm, it should be a noarch.

<!--
          <needarch>true</needarch>
-->
 any objections to commenting it out?","08/Apr/13 15:58;ctubbsii;I've been looking at this. It's not possible to make it noarch... though it should be. This is because of the way it packages the native libraries. What really needs to happen is the native libs need to be put in their own RPM, with a dependency on the noarch Accumulo RPM. I'm looking into this, but if somebody wants to provide a patch, that'd be greatly appreciated.","08/Apr/13 17:08;jpyeron;I greped throu the rpm, I only saw java compiled code and shell scripts. Now the hadoop rpm does have shared libs.

Did I miss something, like code stored in jars?","08/Apr/13 20:37;ctubbsii;No, you didn't miss anything. It's not a problem with the RPM... there's no reason the RPM can't be noarch. It used to be that we included native libraries in the RPM build, which caused the rpm plugin to fail the build, but that has apparently been removed in the 1.5 branch. We can change the ""needsArch"" param to false for 1.5, but we still need to build and provide the native libraries for RPM users.","11/Apr/13 23:23;hudson;Integrated in Accumulo-Trunk #827 (See [https://builds.apache.org/job/Accumulo-Trunk/827/])
    ACCUMULO-1107 merge to trunk (Revision 1467098)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/dist.xml
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","11/Apr/13 23:23;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #73 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/73/])
    ACCUMULO-1107 Fix typo introduced in previous commit (Revision 1467093)
ACCUMULO-1107 Build rpm and deb better. Made rpm noarch. (Revision 1467086)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/pom.xml

ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/dist.xml
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/pom.xml
","11/Apr/13 23:25;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #185 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/185/])
    ACCUMULO-1107 merge to trunk (Revision 1467098)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/dist.xml
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","11/Apr/13 23:26;hudson;Integrated in Accumulo-1.5 #74 (See [https://builds.apache.org/job/Accumulo-1.5/74/])
    ACCUMULO-1107 Fix typo introduced in previous commit (Revision 1467093)
ACCUMULO-1107 Build rpm and deb better. Made rpm noarch. (Revision 1467086)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/pom.xml

ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/dist.xml
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fail the build when thrift profile activated and thrift fails,ACCUMULO-1250,12641231,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,07/Apr/13 04:35,11/Apr/13 21:12,13/Mar/19 22:01,11/Apr/13 18:34,,,,,,,,1.5.0,,,,,,,,,0,,,,,"Presently, the thrift script simply prints out a message and quits when thrift isn't available.

What it should do is exit with an error code, because the profile to run thrift was enabled explicitly.

It should also fail if the thrift code generation fails in any way, but I think those conditions are already handled.

see:
core/src/main/scripts/generate-thrift.sh
(the other thrift generation scripts in other modules reference this one)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-11 21:04:06.866,,,no_permission,,,,,,,,,,,,321647,,,Thu Apr 11 21:12:56 UTC 2013,,,,,,0|i1jhvr:,321992,,,,,,,,"11/Apr/13 21:04;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #184 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/184/])
    ACCUMULO-1265, ACCUMULO-1250, ACCUMULO-1244, ACCUMULO-1063 merged to trunk from 1.5 branch (Revision 1467036)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/scripts/generate-thrift.sh
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
","11/Apr/13 21:08;hudson;Integrated in Accumulo-1.5 #73 (See [https://builds.apache.org/job/Accumulo-1.5/73/])
    ACCUMULO-1250 Trivially fail the build when thrift profile is active (Revision 1467027)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/core/src/main/scripts/generate-thrift.sh
","11/Apr/13 21:12;hudson;Integrated in Accumulo-Trunk #826 (See [https://builds.apache.org/job/Accumulo-Trunk/826/])
    ACCUMULO-1265, ACCUMULO-1250, ACCUMULO-1244, ACCUMULO-1063 merged to trunk from 1.5 branch (Revision 1467036)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/scripts/generate-thrift.sh
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"copy dependencies breaks ""mvn compile""",ACCUMULO-1265,12642073,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,11/Apr/13 17:09,11/Apr/13 21:12,13/Mar/19 22:01,11/Apr/13 18:34,,,,,,,,1.5.0,,,,,,,,,0,,,,,"maven-dependencies-plugin:copy-dependencies in the parent pom breaks because it tries to copy Accumulo artifacts to the lib directory when they are listed as dependencies to sister modules. This is unnecessary, because the maven-jar-plugin is configured to place them there during the package phase.

This needs to be fixed so that both ""mvn compile"" and ""mvn package"" do the right thing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-11 21:04:06.665,,,no_permission,,,,,,,,,,,,322487,,,Thu Apr 11 21:12:56 UTC 2013,,,,,,0|i1jn2f:,322832,,,,,,,,"11/Apr/13 21:04;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #184 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/184/])
    ACCUMULO-1265, ACCUMULO-1250, ACCUMULO-1244, ACCUMULO-1063 merged to trunk from 1.5 branch (Revision 1467036)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/scripts/generate-thrift.sh
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
","11/Apr/13 21:08;hudson;Integrated in Accumulo-1.5 #73 (See [https://builds.apache.org/job/Accumulo-1.5/73/])
    ACCUMULO-1265 Fix 'mvn compile' (Revision 1467019)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/examples/simple/pom.xml
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/proxy/pom.xml
* /accumulo/branches/1.5/server/pom.xml
* /accumulo/branches/1.5/test/pom.xml
","11/Apr/13 21:12;hudson;Integrated in Accumulo-Trunk #826 (See [https://builds.apache.org/job/Accumulo-Trunk/826/])
    ACCUMULO-1265, ACCUMULO-1250, ACCUMULO-1244, ACCUMULO-1063 merged to trunk from 1.5 branch (Revision 1467036)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/scripts/generate-thrift.sh
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reject tablets with mutiple locations,ACCUMULO-1246,12641079,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,05/Apr/13 17:54,11/Apr/13 14:20,13/Mar/19 22:01,11/Apr/13 14:20,1.4.0,,,,,,,1.5.0,,,,,,,,,0,,,,,A tablet being assigned to multiple locations is a condition that indicates a bug in Accumulo.  Accumulo code that reads location information from the metadata table should not silently accept this condition if it occurs.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,321495,,,2013-04-05 17:54:58.0,,,,,,0|i1jgxz:,321840,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
docs/config.html generation broken,ACCUMULO-1253,12641420,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,08/Apr/13 18:24,10/Apr/13 23:38,13/Mar/19 22:01,10/Apr/13 21:15,,,,,,,,1.5.0,,,docs,,,,,,0,,,,,"There's a few things wrong with the docs/config.html generation

# It uses exec plugin to execute a script to execute java code. This can be made simpler by executing the java code direction with the exec plugin.
# The header doesn't get correctly prefixed to the generated html file.
# The file contents contain a bunch of invalid HTML that doesn't pass W3C validator checks.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-08 18:28:55.066,,,no_permission,,,,,,,,,,,,321836,,,Wed Apr 10 23:38:16 UTC 2013,,,,,,0|i1jj1r:,322181,,,,,,,,08/Apr/13 18:28;vines;1. The reason it's a script and not solely maven is to allow building it without having to run the a maven build.,"08/Apr/13 19:51;ctubbsii;Actually, the reason I made it a script when I originally wrote the configuration stuff was because I didn't know how to automate it otherwise. Maybe it's useful to build outside of maven, but I can't think of a reason, and I don't know that a reason has been proposed since the initial script was created.

On the other hand, I can think of at least one reason to execute it directly with the plugin: a script is one more thing that limits portability. A second reason: faster build, because a second JVM isn't launched.

Can you explain the requirement to build it outside of maven?","08/Apr/13 23:45;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #69 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/69/])
    ACCUMULO-1253 Fix build of docs/config.html; strike-through deprecated properties (Revision 1465796)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/build.sh
* /accumulo/branches/1.5/assemble/docgen.sh
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/PropertyType.java
* /accumulo/branches/1.5/core/src/main/resources/org/apache/accumulo/core/conf/config.html
* /accumulo/branches/1.5/docs/documentation.css
","08/Apr/13 23:49;hudson;Integrated in Accumulo-1.5 #70 (See [https://builds.apache.org/job/Accumulo-1.5/70/])
    ACCUMULO-1253 Fix build of docs/config.html; strike-through deprecated properties (Revision 1465796)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/build.sh
* /accumulo/branches/1.5/assemble/docgen.sh
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/PropertyType.java
* /accumulo/branches/1.5/core/src/main/resources/org/apache/accumulo/core/conf/config.html
* /accumulo/branches/1.5/docs/documentation.css
","10/Apr/13 23:29;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #183 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/183/])
    ACCUMULO-1253 Fix build of docs/config.html; strike-through deprecated properties (Revision 1466594)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/build.sh
* /accumulo/trunk/assemble/docgen.sh
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/PropertyType.java
* /accumulo/trunk/core/src/main/resources/org/apache/accumulo/core/conf/config.html
* /accumulo/trunk/docs/documentation.css
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","10/Apr/13 23:38;hudson;Integrated in Accumulo-Trunk #825 (See [https://builds.apache.org/job/Accumulo-Trunk/825/])
    ACCUMULO-1253 Fix build of docs/config.html; strike-through deprecated properties (Revision 1466594)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/build.sh
* /accumulo/trunk/assemble/docgen.sh
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/DefaultConfiguration.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/PropertyType.java
* /accumulo/trunk/core/src/main/resources/org/apache/accumulo/core/conf/config.html
* /accumulo/trunk/docs/documentation.css
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tests failing on CentOS,ACCUMULO-1118,12634247,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,vines,vines,26/Feb/13 20:59,03/Apr/13 19:18,13/Mar/19 22:01,26/Feb/13 21:08,,,,,,,,1.5.0,,,client,,,,,,0,,,,,"Several tests were failing, ultimately due to authentication issues in MockAccumulo. No idea why this only happened on CentOS (possibly related actually to java version?). However, by converting the cli to assume absence of a password is an empty string and not secret fixed it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-27 02:11:05.863,,,no_permission,,,,,,,,,,,,314740,,,Wed Apr 03 19:18:01 UTC 2013,,,,,,0|i1ib9j:,315084,,,,,,,,"27/Feb/13 02:11;hudson;Integrated in Accumulo-Trunk #746 (See [https://builds.apache.org/job/Accumulo-Trunk/746/])
    ACCUMULO-1118 - updating cli's default password to be empty, and some of the tests appropriately (Revision 1450423)

     Result = FAILURE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
","27/Feb/13 02:11;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #104 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/104/])
    ACCUMULO-1118 - updating cli's default password to be empty, and some of the tests appropriately (Revision 1450423)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
","27/Feb/13 17:19;hudson;Integrated in Accumulo-Trunk #747 (See [https://builds.apache.org/job/Accumulo-Trunk/747/])
    ACCUMULO-1118 reverting change that breaks ""admin stop"" (Revision 1450803)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
","27/Feb/13 17:21;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #105 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/105/])
    ACCUMULO-1118 reverting change that breaks ""admin stop"" (Revision 1450803)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
",27/Feb/13 18:10;vines;My fix in ACCUMULO-1120 seems to still be address it even though this was reverted...,"28/Feb/13 01:36;hudson;Integrated in Accumulo-Trunk #748 (See [https://builds.apache.org/job/Accumulo-Trunk/748/])
    merging changes from 1.5

ACCUMULO-1118 - updating cli's default password to be empty, and some of the tests appropriately
ACCUMULO-1104, ACCUMULO-1093, ACCUMULO-1094, ACCUMULO-1095, ACCUMULO-1099, ACCUMULO-1097, ACCUMULO-1102 - Improve documentation
ACCUMULO-858: Parse Exception During Run of Maven Changes Report Plugin
ACCUMULO-1120 - credentials now getting properly read (Revision 1451008)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_design.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/dirlist/CountTest.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","28/Feb/13 02:31;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #107 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/107/])
    merging changes from 1.5

ACCUMULO-1118 - updating cli's default password to be empty, and some of the tests appropriately
ACCUMULO-1104, ACCUMULO-1093, ACCUMULO-1094, ACCUMULO-1095, ACCUMULO-1099, ACCUMULO-1097, ACCUMULO-1102 - Improve documentation
ACCUMULO-858: Parse Exception During Run of Maven Changes Report Plugin
ACCUMULO-1120 - credentials now getting properly read (Revision 1451008)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_design.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/dirlist/CountTest.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","02/Mar/13 04:16;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #114 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/114/])
    ACCUMULO-1118 fixed upgrade test script, seems that test and verify ingest now require a username and password (Revision 1451791)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/upgrade_test.sh
","02/Mar/13 04:20;hudson;Integrated in Accumulo-Trunk #755 (See [https://builds.apache.org/job/Accumulo-Trunk/755/])
    ACCUMULO-1118 fixed upgrade test script, seems that test and verify ingest now require a username and password (Revision 1451791)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/upgrade_test.sh
","02/Mar/13 09:20;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #9 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/9/])
    ACCUMULO-1118 fixed upgrade test script, seems that test and verify ingest now require a username and password (Revision 1451790)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/test/system/upgrade_test.sh
","02/Mar/13 09:24;hudson;Integrated in Accumulo-1.5 #10 (See [https://builds.apache.org/job/Accumulo-1.5/10/])
    ACCUMULO-1118 fixed upgrade test script, seems that test and verify ingest now require a username and password (Revision 1451790)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/test/system/upgrade_test.sh
","03/Apr/13 06:50;hudson;Integrated in Accumulo-Trunk #812 (See [https://builds.apache.org/job/Accumulo-Trunk/812/])
    ACCUMULO-1118 re-introduce centos fix for ShellTest (Revision 1463798)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
","03/Apr/13 06:58;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #171 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/171/])
    ACCUMULO-1118 re-introduce centos fix for ShellTest (Revision 1463798)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
","03/Apr/13 19:11;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #60 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/60/])
    ACCUMULO-1118 merged shelltest fix to 1.5 branch (Revision 1464092)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/src
","03/Apr/13 19:12;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #172 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/172/])
    ACCUMULO-1118 merge prop changes back to trunk (Revision 1464097)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","03/Apr/13 19:16;hudson;Integrated in Accumulo-Trunk #813 (See [https://builds.apache.org/job/Accumulo-Trunk/813/])
    ACCUMULO-1118 merge prop changes back to trunk (Revision 1464097)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","03/Apr/13 19:18;hudson;Integrated in Accumulo-1.5 #62 (See [https://builds.apache.org/job/Accumulo-1.5/62/])
    ACCUMULO-1118 merged shelltest fix to 1.5 branch (Revision 1464092)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Sorting by ""Start"" in traces for ""foo"" doesn't actually sort correctly",ACCUMULO-1206,12639017,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,26/Mar/13 00:55,29/Mar/13 04:53,13/Mar/19 22:01,27/Mar/13 00:56,,,,,,,,1.5.0,,,monitor,,,,,,0,,,,,"Clicked on minorCompaction, clicked the ""time"" header, records returned not close to correct at all.",apache-accumulo-1.5.0-SNAPSHOT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-27 02:37:43.949,,,no_permission,,,,,,,,,,,,319487,,,Fri Mar 29 04:53:16 UTC 2013,,,,,,0|i1j4j3:,319828,,,,,,,,27/Mar/13 00:56;elserj;Fixed in r1461381. ShowTraceLinkType#compareTo was comparing the result of toString() on RemoteSpan instead of the start time.,"27/Mar/13 02:37;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #53 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/53/])
    ACCUMULO-1206 Override compareTo to sort the trace entries by start time instead of their toString(). Add a simple test to make sure the Comparator compares correctly. (Revision 1461381)

     Result = UNSTABLE
elserj : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ListType.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTraceLinkType.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/monitor/ShowTraceLinkTypeTest.java
","27/Mar/13 02:41;hudson;Integrated in Accumulo-1.5 #56 (See [https://builds.apache.org/job/Accumulo-1.5/56/])
    ACCUMULO-1206 Override compareTo to sort the trace entries by start time instead of their toString(). Add a simple test to make sure the Comparator compares correctly. (Revision 1461381)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ListType.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTraceLinkType.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/monitor/ShowTraceLinkTypeTest.java
","29/Mar/13 04:31;hudson;Integrated in Accumulo-Trunk #806 (See [https://builds.apache.org/job/Accumulo-Trunk/806/])
    ACCUMULO-1212 Add a whole bunch of log4j.properties that pretty much turn down the logging level on the same 5 classes.
ACCUMULO-1212 Fix formatting in start/pom.xml
ACCUMULO-1205 Stub in an onload for the ""Show Trace"" page which display:table-row's any trace line which has the 'addl data' checkbox already checked.
ACCUMULO-1215 add some extra time to tests to accumodate slower build servers
ACCUMULO-1206 Override compareTo to sort the trace entries by start time instead of their toString(). Add a simple test to make sure the Comparator compares correctly. (Revision 1462237)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/test/resources/log4j.properties
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/resources
* /accumulo/trunk/examples/simple/src/test/resources/log4j.properties
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/fate/src/test/resources/log4j.properties
* /accumulo/trunk/proxy/src/test/resources
* /accumulo/trunk/proxy/src/test/resources/log4j.properties
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/BasicServlet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ListType.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTrace.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTraceLinkType.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/monitor/ShowTraceLinkTypeTest.java
* /accumulo/trunk/server/src/test/resources
* /accumulo/trunk/server/src/test/resources/log4j.properties
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/start/src/test/resources/log4j.properties
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MiniAccumuloClusterTest.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java
* /accumulo/trunk/test/src/test/resources/log4j.properties
","29/Mar/13 04:53;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #165 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/165/])
    ACCUMULO-1212 Add a whole bunch of log4j.properties that pretty much turn down the logging level on the same 5 classes.
ACCUMULO-1212 Fix formatting in start/pom.xml
ACCUMULO-1205 Stub in an onload for the ""Show Trace"" page which display:table-row's any trace line which has the 'addl data' checkbox already checked.
ACCUMULO-1215 add some extra time to tests to accumodate slower build servers
ACCUMULO-1206 Override compareTo to sort the trace entries by start time instead of their toString(). Add a simple test to make sure the Comparator compares correctly. (Revision 1462237)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/test/resources/log4j.properties
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/resources
* /accumulo/trunk/examples/simple/src/test/resources/log4j.properties
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/fate/src/test/resources/log4j.properties
* /accumulo/trunk/proxy/src/test/resources
* /accumulo/trunk/proxy/src/test/resources/log4j.properties
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/BasicServlet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ListType.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTrace.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTraceLinkType.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/monitor/ShowTraceLinkTypeTest.java
* /accumulo/trunk/server/src/test/resources
* /accumulo/trunk/server/src/test/resources/log4j.properties
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/start/src/test/resources/log4j.properties
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MiniAccumuloClusterTest.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java
* /accumulo/trunk/test/src/test/resources/log4j.properties
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Addl Data"" checkboxes aren't observed on monitor auto-refresh",ACCUMULO-1205,12639016,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,26/Mar/13 00:52,29/Mar/13 04:53,13/Mar/19 22:01,28/Mar/13 01:25,,,,,,,,1.5.0,,,monitor,,,,,,0,,,,,"Checked the ""addl data"" checkbox for a trace, the monitor refreshed, left the box checked, but the ""addl data"" not actually shown.

Clicking the checkbox (deselecting it) showed me the data. Clicking it once more (selecting it) hides it.

I imagine it must be using onClick and not actually the state of the checkbox.",apache-accumulo-1.5.0-SNAPSHOT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-29 04:22:47.104,,,no_permission,,,,,,,,,,,,319486,,,Fri Mar 29 04:53:16 UTC 2013,,,,,,0|i1j4iv:,319827,,,,,,,,"28/Mar/13 01:25;elserj;Fixed in r1461914. Added a hook in the Basic Servlet to allow implementations to specify attributes on the body HTML tag. This let me stub in my own javascript method so I can re-expand the ""addl data"" segments which are checked.","29/Mar/13 04:22;hudson;Integrated in Accumulo-1.5 #59 (See [https://builds.apache.org/job/Accumulo-1.5/59/])
    ACCUMULO-1205 Stub in an onload for the ""Show Trace"" page which display:table-row's any trace line which has the 'addl data' checkbox already checked. (Revision 1461914)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/BasicServlet.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTrace.java
","29/Mar/13 04:26;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #57 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/57/])
    ACCUMULO-1205 Stub in an onload for the ""Show Trace"" page which display:table-row's any trace line which has the 'addl data' checkbox already checked. (Revision 1461914)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/BasicServlet.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTrace.java
","29/Mar/13 04:31;hudson;Integrated in Accumulo-Trunk #806 (See [https://builds.apache.org/job/Accumulo-Trunk/806/])
    ACCUMULO-1212 Add a whole bunch of log4j.properties that pretty much turn down the logging level on the same 5 classes.
ACCUMULO-1212 Fix formatting in start/pom.xml
ACCUMULO-1205 Stub in an onload for the ""Show Trace"" page which display:table-row's any trace line which has the 'addl data' checkbox already checked.
ACCUMULO-1215 add some extra time to tests to accumodate slower build servers
ACCUMULO-1206 Override compareTo to sort the trace entries by start time instead of their toString(). Add a simple test to make sure the Comparator compares correctly. (Revision 1462237)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/test/resources/log4j.properties
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/resources
* /accumulo/trunk/examples/simple/src/test/resources/log4j.properties
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/fate/src/test/resources/log4j.properties
* /accumulo/trunk/proxy/src/test/resources
* /accumulo/trunk/proxy/src/test/resources/log4j.properties
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/BasicServlet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ListType.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTrace.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTraceLinkType.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/monitor/ShowTraceLinkTypeTest.java
* /accumulo/trunk/server/src/test/resources
* /accumulo/trunk/server/src/test/resources/log4j.properties
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/start/src/test/resources/log4j.properties
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MiniAccumuloClusterTest.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java
* /accumulo/trunk/test/src/test/resources/log4j.properties
","29/Mar/13 04:53;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #165 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/165/])
    ACCUMULO-1212 Add a whole bunch of log4j.properties that pretty much turn down the logging level on the same 5 classes.
ACCUMULO-1212 Fix formatting in start/pom.xml
ACCUMULO-1205 Stub in an onload for the ""Show Trace"" page which display:table-row's any trace line which has the 'addl data' checkbox already checked.
ACCUMULO-1215 add some extra time to tests to accumodate slower build servers
ACCUMULO-1206 Override compareTo to sort the trace entries by start time instead of their toString(). Add a simple test to make sure the Comparator compares correctly. (Revision 1462237)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/test/resources/log4j.properties
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/resources
* /accumulo/trunk/examples/simple/src/test/resources/log4j.properties
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/fate/src/test/resources/log4j.properties
* /accumulo/trunk/proxy/src/test/resources
* /accumulo/trunk/proxy/src/test/resources/log4j.properties
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/BasicServlet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ListType.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTrace.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/ShowTraceLinkType.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/monitor/ShowTraceLinkTypeTest.java
* /accumulo/trunk/server/src/test/resources
* /accumulo/trunk/server/src/test/resources/log4j.properties
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/start/src/test/resources/log4j.properties
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MiniAccumuloClusterTest.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java
* /accumulo/trunk/test/src/test/resources/log4j.properties
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Makefile cannot be used to build just 32 or just 64 bit versions,ACCUMULO-1180,12637253,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,vines,vines,15/Mar/13 19:34,29/Mar/13 04:53,13/Mar/19 22:01,28/Mar/13 18:26,,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"The way the nativemap Makefile is written, there is no way to use it to generate just one of the libraries. There is the one question of why we generate both, the other issue is that we artificially bind the two of them together with the way the Makefile is written.",Linux,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1107,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-28 22:18:50.51,,,no_permission,,,,,,,,,,,,317745,,,Fri Mar 29 04:53:16 UTC 2013,,,,,,0|i1its7:,318086,,,,,,,,"18/Mar/13 20:52;vines;Furthermore, they cannot be used on a 32 bit system to make just 32bit libraries.",18/Mar/13 20:56;vines;I would like this fixed for 1.5 to ease distribution mechanisms.,"28/Mar/13 22:18;ctubbsii;I was looking at ACCUMULO-1107, and realized this also. I was considering moving the native stuff to its own sub-module, and with its own RPMS, so the main RPM can be noarch again, and avoid the problem experienced in ACCUMULO-1107. I don't know if that's the best solution, but I think it is.","28/Mar/13 22:19;ctubbsii;However, I was considering that fix for 1.6, not for 1.5","29/Mar/13 04:22;hudson;Integrated in Accumulo-1.5 #59 (See [https://builds.apache.org/job/Accumulo-1.5/59/])
    ACCUMULO-1180 testing DARCH=both (Revision 1462247)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/c++/nativeMap/Makefile
","29/Mar/13 04:26;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #57 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/57/])
    ACCUMULO-1180 testing DARCH=both (Revision 1462247)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/c++/nativeMap/Makefile
","29/Mar/13 04:31;hudson;Integrated in Accumulo-Trunk #806 (See [https://builds.apache.org/job/Accumulo-Trunk/806/])
    ACCUMULO-1180 testing DARCH=both (Revision 1462248)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/c++/nativeMap/Makefile
* /accumulo/trunk/src
","29/Mar/13 04:53;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #165 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/165/])
    ACCUMULO-1180 testing DARCH=both (Revision 1462248)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/c++/nativeMap/Makefile
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need timezone label to clarify the times on the monitoring graphs,ACCUMULO-597,12556235,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,akini,akini,17/May/12 13:28,27/Mar/13 02:47,13/Mar/19 22:01,26/Mar/13 21:27,1.4.0,,,,,,,1.5.0,,,monitor,,,,,,0,,,,,"It'd help to have the UTC label on the graphs, since a) it isn't obvious that they should be in UTC, and b) the timestamp up by ""Accumulo Overview"" is the local time zone of the monitoring service, so the two may differ leaving the user wondering which time zone the graphs are in. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,17/May/12 13:59;akini;graphs.jpg;https://issues.apache.org/jira/secure/attachment/12527837/graphs.jpg,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-10-13 01:14:23.525,,,no_permission,,,,,,,,,,,,246469,,,Wed Mar 27 02:47:31 UTC 2013,,,,,,0|i07m7z:,42366,,,,,,,,"13/Oct/12 01:14;elserj;Noting the ""EDT"" at the top of the screen in the attached screenshot, would it be better to display all notions of time as UTC or should we convert everything to the local timezone? (I assume EDT was determined and not just hardcoded). My gut feeling is to treat everything as UTC.","13/Oct/12 08:49;ctubbsii;I'd be very much opposed to forcing a user into a timezone that doesn't make sense for them, including anything generic like UTC/GMT. I'm pretty sure the monitor is using the timezone configured on the server running the monitor. Personally, that seems to make the most sense to me for most cases, but I can also see adding a drop-down configuration (saved cookie) on the client side to select the preferred timezone.",13/Oct/12 13:48;ecn;Users can just set the TZ env var in accumulo-env.sh if they want everything in UTC.  I say we keep it to the local time.,"02/Jan/13 15:49;crohling88;I believe the author's point was that the graphs still display the times in terms of UTC. The solution would be to modify the graph's to either have a label identifying the axis as UTC time, or to modify the graph to use the system's configured timezone.","27/Mar/13 02:33;hudson;Integrated in Accumulo-Trunk #802 (See [https://builds.apache.org/job/Accumulo-Trunk/802/])
    ACCUMULO-597 Merge changes to trunk (Revision 1461320)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
* /accumulo/trunk/src
","27/Mar/13 02:37;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #53 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/53/])
    ACCUMULO-597 Made graphs on monitor page respect, and show the local timezone. Can be overridden by setting the TZ environment variable in conf/accumulo-env.sh (Revision 1461315)

     Result = UNSTABLE
ctubbsii : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
","27/Mar/13 02:41;hudson;Integrated in Accumulo-1.5 #56 (See [https://builds.apache.org/job/Accumulo-1.5/56/])
    ACCUMULO-597 Made graphs on monitor page respect, and show the local timezone. Can be overridden by setting the TZ environment variable in conf/accumulo-env.sh (Revision 1461315)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
","27/Mar/13 02:47;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #161 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/161/])
    ACCUMULO-597 Merge changes to trunk (Revision 1461320)

     Result = UNSTABLE
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JSONServlet shows incorrect value for scans,ACCUMULO-1204,12639002,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ctubbsii,ctubbsii,25/Mar/13 22:46,26/Mar/13 14:12,13/Mar/19 22:01,26/Mar/13 13:05,,,,,,,,1.5.0,,,monitor,,,,,,0,,,,,"In JSONServlet, I see

{code:java}
map.put(""scans"", scans);
map.put(""scans"", scansessions);
{code}

This can't possibly be correct. It looks like a copy/paste error. A trivial fix is to rename the map key to ""scansessions"" to be consistent with the rest of the code around it. However, there's very little documentation on this API, so it's not quite clear what the value for the ""scansessions"" variable even represents. Is there a better key name that is more descriptive of what the value of that variable represents? If not, the trivial change should be implemented.",,,,,,,,,,,,,,,,,,,,,,,,900,900,,0%,900,900,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-26 13:05:32.738,,,no_permission,,,,,,,,,,,,319472,,,Tue Mar 26 14:12:38 UTC 2013,,,,,,0|i1j4fr:,319813,,,,,,,,"26/Mar/13 13:05;ecn;I put in the trivial fix.  I opened ACCUMULO-1207 to document what the values are.
","26/Mar/13 13:48;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #160 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/160/])
    ACCUMULO-1204 fix ""scansessions"" entry in json (Revision 1461106)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/JSONServlet.java
* /accumulo/trunk/src
","26/Mar/13 14:04;hudson;Integrated in Accumulo-1.5 #54 (See [https://builds.apache.org/job/Accumulo-1.5/54/])
    ACCUMULO-1204 fix ""scansessions"" entry in json (Revision 1461105)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/JSONServlet.java
","26/Mar/13 14:08;hudson;Integrated in Accumulo-Trunk #801 (See [https://builds.apache.org/job/Accumulo-Trunk/801/])
    ACCUMULO-1204 fix ""scansessions"" entry in json (Revision 1461106)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/JSONServlet.java
* /accumulo/trunk/src
","26/Mar/13 14:12;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #52 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/52/])
    ACCUMULO-1204 fix ""scansessions"" entry in json (Revision 1461105)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/JSONServlet.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master logs a warning if a backup master is started,ACCUMULO-1048,12631068,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,ecn,ecn,06/Feb/13 14:25,23/Mar/13 01:36,13/Mar/19 22:01,22/Mar/13 21:17,,,,,,,,1.5.0,,,master,,,,,,0,,,,,"Start a second master, and every second you see a message about a zlock ephemeral node being deleted.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-06 15:23:23.158,,,no_permission,,,,,,,,,,,,311564,,,Sat Mar 23 01:36:25 UTC 2013,,,,,,0|i1hro7:,311910,,,,,,,,"06/Feb/13 15:23;hudson;Integrated in Accumulo-Trunk #711 (See [https://builds.apache.org/job/Accumulo-Trunk/711/])
    ACCUMULO-1048 fix typo in message (Revision 1442988)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
","06/Feb/13 15:29;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #69 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/69/])
    ACCUMULO-1048 fix typo in message (Revision 1442988)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
","23/Mar/13 01:05;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #156 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/156/])
    ACCUMULO-1048 cleaned up master lock acquisition (Revision 1459993)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
","23/Mar/13 01:06;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #49 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/49/])
    ACCUMULO-1048 cleaned up master lock acquisition (Revision 1459990)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
","23/Mar/13 01:20;hudson;Integrated in Accumulo-1.5 #51 (See [https://builds.apache.org/job/Accumulo-1.5/51/])
    ACCUMULO-1048 cleaned up master lock acquisition (Revision 1459990)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
","23/Mar/13 01:36;hudson;Integrated in Accumulo-Trunk #797 (See [https://builds.apache.org/job/Accumulo-Trunk/797/])
    ACCUMULO-1048 cleaned up master lock acquisition (Revision 1459993)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
seeing long delays in gathering state from the master ,ACCUMULO-831,12613361,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,24/Oct/12 19:58,19/Mar/13 13:18,13/Mar/19 22:01,19/Mar/13 13:18,1.4.1,,,,,,,,,,master,,,,,,0,,,,,The data pulls from the master aren't changing for minutes.  It's difficult to determine if the master is having trouble talking to a particular server or if there's some other lock holding back the request.,large cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,250859,,,Tue Mar 19 13:18:04 UTC 2013,,,,,,0|i0b21j:,62443,,,,,,,,19/Mar/13 13:18;ecn;I think this is related to ACCUMULO-1062,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
allow the proxy to run miniaccumulo for simple testing,ACCUMULO-1037,12630734,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,04/Feb/13 19:36,19/Mar/13 13:16,13/Mar/19 22:01,19/Mar/13 13:15,,,,,,,,1.5.0,,,proxy,,,,,,0,,,,,"I would really like to run miniaccumulo under the proxy so I can just run a proxy and poke it with a script:

{noformat}
$ ./bin/accumulo proxy -p proxy.properties &
$ python myScript.py
$
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-04 23:07:28.474,,,no_permission,,,,,,,,,,,,311230,,,Mon Feb 04 23:59:54 UTC 2013,,,,,,0|i1hplz:,311576,,,,,,,,"04/Feb/13 23:07;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #60 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/60/])
    ACCUMULO-1037 add accumulo-test as a dependency of the proxy (Revision 1442322)
ACCUMULO-1037 allow the proxy to run a copy of miniaccumulo (Revision 1442310)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/proxy/pom.xml

ecn : 
Files : 
* /accumulo/trunk/proxy/examples/python/TestClient.py
* /accumulo/trunk/proxy/examples/ruby/test_client.rb
* /accumulo/trunk/proxy/proxy.properties
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/TestProxyInstanceOperations.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","04/Feb/13 23:59;hudson;Integrated in Accumulo-Trunk #702 (See [https://builds.apache.org/job/Accumulo-Trunk/702/])
    ACCUMULO-1037 add accumulo-test as a dependency of the proxy (Revision 1442322)
ACCUMULO-1037 allow the proxy to run a copy of miniaccumulo (Revision 1442310)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/proxy/pom.xml

ecn : 
Files : 
* /accumulo/trunk/proxy/examples/python/TestClient.py
* /accumulo/trunk/proxy/examples/ruby/test_client.rb
* /accumulo/trunk/proxy/proxy.properties
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/TestProxyInstanceOperations.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
shutdown doesn't use all minor compaction threads,ACCUMULO-892,12619354,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,ecn,ecn,06/Dec/12 21:02,16/Mar/13 12:01,13/Mar/19 22:01,16/Mar/13 01:02,1.3.6,1.4.2,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"I have a test cluster which is loaded with a very large number of disks per node.  I increased the number of minor compaction threads accordingly.  When I shut down accumulo, I saw it minor compacting just one tablet at a time.  In another shell, I forced a flush, and the data was pushed out much more quickly.  It would be nice if the minor compaction threads could be used to make shutdown run more quickly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-22 16:44:41.037,,,no_permission,,,,,,,,,,,,296382,,,Sat Mar 16 12:01:22 UTC 2013,,,,,,0|i148wv:,232907,,,,,,,,"12/Dec/12 17:08;ecn;See also ACCUMULO-901
","22/Jan/13 16:44;kturner;A simple workaround for 1.4 and 1.5 may be to add ""flush -p .*"" as a first step in the shutdown script.","24/Jan/13 14:50;kturner;If tablet unloads were to use the normal compaction queue, may want to prioritize unload related compactions on the queue.  ","16/Mar/13 11:21;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #33 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/33/])
    ACCUMULO-892 made stopAll flush tables (Revision 1457189)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/Admin.java
","16/Mar/13 11:45;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #138 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/138/])
    ACCUMULO-892 made stopAll flush tables
ACCUMULO-957 protect the visual table from autoformat (Revision 1457190)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Admin.java
* /accumulo/trunk/src
","16/Mar/13 11:55;hudson;Integrated in Accumulo-1.5 #35 (See [https://builds.apache.org/job/Accumulo-1.5/35/])
    ACCUMULO-892 made stopAll flush tables (Revision 1457189)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/Admin.java
","16/Mar/13 12:01;hudson;Integrated in Accumulo-Trunk #779 (See [https://builds.apache.org/job/Accumulo-Trunk/779/])
    ACCUMULO-892 made stopAll flush tables
ACCUMULO-957 protect the visual table from autoformat (Revision 1457190)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Admin.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bulk Import retry time needs to be longer/configurable,ACCUMULO-727,12603258,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,bfloss,bfloss,13/Aug/12 15:33,16/Mar/13 00:51,13/Mar/19 22:01,15/Mar/13 18:53,1.4.1,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"Bulk import retries way too fast (at least under some circumstances).  We had a tablet server that the master killed (we were overloading it with ingest and the hold time got too big so the master killed it).  At the same time, a bulk import operation had begun and several map files were assigned to the server that was just killed.  The bulk import retried three times in an 8 second span, each time failing with a connection refused error, and then gave up, failing the file completely.  Meanwhile, it took the master about 1m 20s to reassign the tablet to another server.

The bulk import process should account for this possibility.  Either it needs to recognize that it can't connect to a tablet server so it must be down and the tablet will be reassigned somewhere else, or it should wait longer (such that the default max wait time is > the average tablet reassignment time).  In the latter case, the retry interval should be made into a configurable option at the same time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-08-13 16:10:05.223,,,no_permission,,,,,,,,,,,,246347,,,Sat Mar 16 00:51:22 UTC 2013,,,,,,0|i07lgn:,42243,,,,,,,,13/Aug/12 16:10;kturner;Could use exponential backoff for the retry time and a max number of retries.,19/Dec/12 21:29;ecn;made communication timeout for bulk importing configurable,"14/Mar/13 17:29;bfloss;We don't need only configurable timeout, but need to retry slower.  If a tserver dies, bulk can try and fail on the dead tserver before the master ever has a chance to reassign the tablet.","15/Mar/13 18:53;ecn;Added exponential back-off, with a maximum wait between retries of 60 seconds.  Set the number of retries to 5, up from 3.
","15/Mar/13 19:14;kturner;A possible work around for 1.4 is to up tserver.bulk.retry.max.  1.4 does not have the exponential back off that Eric just added, it just sleeps 4 secs between retries.   So this may need to be set higher.  Like setting it to 120/4 to get at least 2 min of retries.","15/Mar/13 23:50;hudson;Integrated in Accumulo-Trunk #778 (See [https://builds.apache.org/job/Accumulo-Trunk/778/])
    ACCUMULO-727 retry more times (Revision 1457060)
ACCUMULO-727 add exponential back-off when bulk loading files (Revision 1457056)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/trunk/src
","16/Mar/13 00:03;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #32 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/32/])
    ACCUMULO-727 retry more times (Revision 1457059)
ACCUMULO-727 add exponential back-off when bulk loading files (Revision 1457055)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java

ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
","16/Mar/13 00:51;hudson;Integrated in Accumulo-1.5 #34 (See [https://builds.apache.org/job/Accumulo-1.5/34/])
    ACCUMULO-727 retry more times (Revision 1457059)
ACCUMULO-727 add exponential back-off when bulk loading files (Revision 1457055)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java

ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
","16/Mar/13 00:51;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #137 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/137/])
    ACCUMULO-727 retry more times (Revision 1457060)
ACCUMULO-727 add exponential back-off when bulk loading files (Revision 1457056)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TableOperations.getSplits hangs indefinately on bad credentials,ACCUMULO-1056,12631567,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,vines,vines,09/Feb/13 06:25,15/Mar/13 03:48,13/Mar/19 22:01,15/Mar/13 01:22,1.4.0,,,,,,,1.5.0,,,client,,,,,,0,,,,,noticed when debugging changes affecting the proxy. A get splits call backs off for 3 seconds and retries with no timeout or regard to exception time.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-14 20:02:14.038,,,no_permission,,,,,,,,,,,,312063,,,Fri Mar 15 03:48:26 UTC 2013,,,,,,0|i1huqv:,312409,,,,,,,,"14/Mar/13 20:02;kturner;Also noticed that getSplits could hang indef when table is deleted... the concurrent random walk test does not appear to call getSplits(), it would eventually catch the delete table race condition

unfortunately getSplits() does not throw AccumuloSecurityException(), seems like a new method will need to be created.   getTableSplits() was suggested on irc","15/Mar/13 03:21;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #136 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/136/])
    ACCUMULO-1056  Made getSplits more robust and renamed it to listSplits so it could throw another exception (Revision 1456739)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/CreateTableCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/GetSplitsCommand.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/admin/TableOperationsHelperTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mock/MockTableOperationsTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/main/java/org/apache/accumulo/examples/simple/mapreduce/bulk/BulkIngestExample.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/TestProxyTableOperations.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/AddSplitTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/BatchScanSplitTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/BulkSplitOptimizationTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/DeleteRowsTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/FunctionalTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/MergeTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/ListSplits.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/image/TableOp.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/BulkInsert.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/ExportIndex.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/Merge.java
* /accumulo/trunk/test/system/randomwalk/conf/modules/Concurrent.xml
","15/Mar/13 03:23;hudson;Integrated in Accumulo-Trunk #777 (See [https://builds.apache.org/job/Accumulo-Trunk/777/])
    ACCUMULO-1056  Made getSplits more robust and renamed it to listSplits so it could throw another exception (Revision 1456739)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/CreateTableCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/GetSplitsCommand.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/admin/TableOperationsHelperTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mock/MockTableOperationsTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/main/java/org/apache/accumulo/examples/simple/mapreduce/bulk/BulkIngestExample.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/TestProxyTableOperations.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/AddSplitTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/BatchScanSplitTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/BulkSplitOptimizationTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/DeleteRowsTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/FunctionalTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/functional/MergeTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/ListSplits.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/image/TableOp.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/BulkInsert.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/ExportIndex.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/Merge.java
* /accumulo/trunk/test/system/randomwalk/conf/modules/Concurrent.xml
","15/Mar/13 03:41;hudson;Integrated in Accumulo-1.5 #33 (See [https://builds.apache.org/job/Accumulo-1.5/33/])
    ACCUMULO-1056  Made getSplits more robust and renamed it to listSplits so it could throw another exception (Revision 1456738)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/CreateTableCommand.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/GetSplitsCommand.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/client/admin/TableOperationsHelperTest.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/client/mock/MockTableOperationsTest.java
* /accumulo/branches/1.5/examples/simple/src/main/java/org/apache/accumulo/examples/simple/mapreduce/bulk/BulkIngestExample.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/TestProxyTableOperations.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/AddSplitTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/BatchScanSplitTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/BulkSplitOptimizationTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/DeleteRowsTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/FunctionalTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/MergeTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/ListSplits.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/image/TableOp.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/BulkInsert.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/ExportIndex.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/Merge.java
* /accumulo/branches/1.5/test/system/randomwalk/conf/modules/Concurrent.xml
","15/Mar/13 03:48;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #31 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/31/])
    ACCUMULO-1056  Made getSplits more robust and renamed it to listSplits so it could throw another exception (Revision 1456738)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/TabletLocator.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/CreateTableCommand.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/GetSplitsCommand.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/client/admin/TableOperationsHelperTest.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/client/mock/MockTableOperationsTest.java
* /accumulo/branches/1.5/examples/simple/src/main/java/org/apache/accumulo/examples/simple/mapreduce/bulk/BulkIngestExample.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/TestProxyTableOperations.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/AddSplitTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/BatchScanSplitTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/BulkSplitOptimizationTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/DeleteRowsTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/FunctionalTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/functional/MergeTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/ListSplits.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/image/TableOp.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/BulkInsert.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/ExportIndex.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/shard/Merge.java
* /accumulo/branches/1.5/test/system/randomwalk/conf/modules/Concurrent.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Security random walk table out of sync,ACCUMULO-296,12537839,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,kturner,kturner,10/Jan/12 00:34,14/Mar/13 21:59,13/Mar/19 22:01,14/Mar/13 21:58,1.4.0,,,,,,,1.5.0,,,,,,,,,0,14_qa_bug,,,,"Saw the following while running random walk test

{noformat}
09 21:02:38,622 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Security.xml
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:236)
	at org.apache.accumulo.server.test.randomwalk.Framework.run(Framework.java:61)
	at org.apache.accumulo.server.test.randomwalk.Framework.main(Framework.java:114)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.accumulo.start.Main$1.run(Main.java:89)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node security.Validate
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:236)
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:234)
	... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloException: Table existance out of sync
	at org.apache.accumulo.server.test.randomwalk.security.Validate.validate(Validate.java:45)
	at org.apache.accumulo.server.test.randomwalk.security.Validate.visit(Validate.java:36)
	at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:234)
	... 9 more
{noformat}

Had the following uncommited change, could be causing the problem but I do not think so.

{noformat}
### Eclipse Workspace Patch 1.0
#P accumulo-core-1.4.0-incubating-SNAPSHOT
Index: src/main/java/org/apache/accumulo/core/client/impl/Tables.java
===================================================================
--- src/main/java/org/apache/accumulo/core/client/impl/Tables.java	(revision 1229298)
+++ src/main/java/org/apache/accumulo/core/client/impl/Tables.java	(working copy)
@@ -89,7 +89,7 @@
   }
   
   public static void clearCache(Instance instance) {
-    getZooCache(instance).clear();
+    getZooCache(instance).clear(ZooUtil.getRoot(instance) + Constants.ZTABLES);
   }
   
   public static String getPrintableTableNameFromId(Map<String,String> tidToNameMap, String tableId) {

{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-10 14:05:58.758,,,no_permission,,,,,,,,,,,,223345,,,Thu Mar 14 21:58:52 UTC 2013,,,,,,0|i07o13:,42659,,,,,,,,10/Jan/12 14:05;jvines;Your uncommitted change looks kosher,14/Mar/13 21:58;kturner;This was fixed by changes made for ACCUMULO-259,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Passing relative directories to bulk import fails w/ unhelpful error message,ACCUMULO-1171,12636436,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,11/Mar/13 19:56,11/Mar/13 23:29,13/Mar/19 22:01,11/Mar/13 21:43,1.4.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"Bulk import does some sanity checks on the client side so that it can fail fast. When a user passes relative directories to bulk import, these sanity checks may pass because cwd+reldir is ok.  Then code then passes these relative dirs to the server side which has a different cwd.  The relative paths fail in the server side and the user does not get a very useful error message.

There are at least two possible solutions :

 * In client code convert relative paths to URIs before passing to server.
 * Reject relative paths in client code

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-11 23:19:56.113,,,no_permission,,,,,,,,,,,,316928,,,Mon Mar 11 23:29:42 UTC 2013,,,,,,0|i1ior3:,317270,,,,,,,,"11/Mar/13 23:19;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #26 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/26/])
    ACCUMULO-1171 revert accidental checkin (Revision 1455315)
ACCUMULO-1171 converted bulk import paths to fully qualified (Revision 1455313)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/test/system/continuous/agitator.pl

kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/branches/1.5/test/system/continuous/agitator.pl
","11/Mar/13 23:23;hudson;Integrated in Accumulo-1.5 #28 (See [https://builds.apache.org/job/Accumulo-1.5/28/])
    ACCUMULO-1171 revert accidental checkin (Revision 1455315)
ACCUMULO-1171 converted bulk import paths to fully qualified (Revision 1455313)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/test/system/continuous/agitator.pl

kturner : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/branches/1.5/test/system/continuous/agitator.pl
","11/Mar/13 23:24;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #132 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/132/])
    ACCUMULO-1171 converted bulk import paths to fully qualified (Revision 1455322)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","11/Mar/13 23:29;hudson;Integrated in Accumulo-Trunk #773 (See [https://builds.apache.org/job/Accumulo-Trunk/773/])
    ACCUMULO-1171 converted bulk import paths to fully qualified (Revision 1455322)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client does not give informative message when user can not read table,ACCUMULO-1018,12630138,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kevin.faro,kturner,kturner,31/Jan/13 14:38,08/Mar/13 23:28,13/Mar/19 22:01,08/Mar/13 23:28,1.4.0,,,,,,,1.6.0,,,client,,,,,,0,,,,,"Saw this in 1.4, not sure if its an issue in later versions.

Assume a user has an application that is reading from many tables and does not have permission to read from one table.  In this case the exception does not tell them which table they can not read from.  If not familiar with the application, it can take a while to track this issue down on a system with many tables.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Mar/13 18:45;kevin.faro;ACCUMULO-1018-2.patch;https://issues.apache.org/jira/secure/attachment/12571921/ACCUMULO-1018-2.patch,06/Mar/13 12:47;kevin.faro;ACCUMULO-1018-3.patch;https://issues.apache.org/jira/secure/attachment/12572314/ACCUMULO-1018-3.patch,26/Feb/13 16:20;kevin.faro;ACCUMULO-1018.patch;https://issues.apache.org/jira/secure/attachment/12570997/ACCUMULO-1018.patch,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2013-01-31 16:28:35.557,,,no_permission,,,,,,,,,,,,310634,,,Fri Mar 08 23:28:59 UTC 2013,,,,,,0|i1hlxj:,310979,,,,,,,,"31/Jan/13 16:28;vines;With the changes made to the BatchWriter in 1.5 to provide SecurityErrorCodes, it shouldn't be that bad to extend it to also include KeyExtents or Tables they occured in. Hell, I think that's entirely possible client side since I know the impl has KeyExtent->ErrorCode pairings available to it.","31/Jan/13 16:54;kturner;I also think the client code will have all of the information needed, its just a matter of passing it along.  Maybe some client code does, I have not really looked into it.  Just saw a case in 1.4 where the scanner was not passing this info along. Need to look at scanner, batch scanner, batch writer, and table operations.","03/Feb/13 19:46;ctubbsii;Under what circumstances can a client not know which table it was trying to read when it got a permissions error? It seems to me that the client code should always have the table name when an exception occurs as a result of not having sufficient permissions. I imagine the observed behavior is the result of an application passing through an AccumuloSecurityException, instead of handling it properly. If that is the case, then this is a problem with the application using Accumulo, not Accumulo having insufficiently informative messages.","03/Feb/13 20:01;vines;I don't have the code in front of me, but I believe there is a case for this with any of the multi-table readers/writers we have.","03/Feb/13 20:22;ctubbsii;I think you're right. I just did a quick scan through the code, and it looks like the MultiTableBatchWriter can have this problem when it flushes, and the AccumuloOutputFormat probably also has this problem, since it uses the MultiTableBatchWriter.","04/Feb/13 14:59;kturner;bq. Under what circumstances can a client not know which table it was trying to read when it got a permissions error?

One situation is that Alice writes and application that reads from 20 tables using the scanner.  Bob deploys Alice's application on an Accumulo instance with 100's of tables.  When the application says it can not read something, Bob has to spend a lot of time figuring out what it can not read.  If the scanner exception gave the table name, it would make things a lot easier for Bob.  Sure Alice's application could have given a better error message, but it would be easy for the scanner to do this so I do not see why it should not.","15/Feb/13 20:01;kevin.faro;I started taking a look at this.  It wasn't too bad to add support for scanning.  I added an optional tableName field to AccumuloSecurityException that the ThriftScanner sets the tableName before it re-throws the excpetion.  TableOperations and BatchScanner was similar.

However, the (MultiTable)BatchWriter throws a MutationsRejectedException that has the KeyExtent->ErrorCode pairings (as John pointed out) but I do not see an effective way map KeyExtent.tableId to a tableName (that the client would probably prefer) since the MRE doesn't have access to the instance.  Any ideas?","19/Feb/13 15:14;kturner;bq. However, the (MultiTable)BatchWriter throws a MutationsRejectedException that has the KeyExtent->ErrorCode pairings (as John pointed out) but I do not see an effective way map KeyExtent.tableId to a tableName (that the client would probably prefer) since the MRE doesn't have access to the instance. Any ideas?

I looked around the code to see where else KeyExtent was used in the public API.   o.a.a.c.client.admin.ActiveScan and ActiveCompaction expose KeyExtent to the user.  Howerver these classes also provide getTable() methods which return the table name.  The implementation of these methods use code that is not part of the public API.

The  javadoc for MRE.getAuthorizationFailures() could point users to TableOperations.tableIdMap().  However, this map is not readily usable, because its keyed on table name.  So I guess basically we need an easy way for users to map table ids to table names thats in the public API.  If this existed, then the javadoc for MRE could point to it.  Maybe add something to  TableOperations that returns a map keyed on table id?  I looked for a built in java util in Collections that would invert a map and did not see anything.  If there was a simple way to invert the map, then we would not need to add anything to the public API, just add some javadoc pointing out this inversion util.

Another possibility is adding a convenience method ""String getTableName(Instance i)"" to KeyExtent.  This addresses the issue at hand, but I think a more general solution in TableOperations would be better.

",26/Feb/13 16:20;kevin.faro;Here is what I have so far.  There are things to clean up to make the code look a little nicer ... but I still haven't been able to crack the nut of getting tableNames from KeyExtent ...,26/Feb/13 16:43;vines;tableID is still better than nothing though. Looks good so far,26/Feb/13 18:59;ctubbsii;Try org.apache.accumulo.core.client.impl.Tables to get the name for an ID.,27/Feb/13 12:54;kevin.faro;I used o.a.a.c.c.i.Tables to get the name for an ID in the TabletServerBatchReaderIterator and the TriftScanner ... but I didn't know where to get a reference to instance in the KeyExtent to make that translation.,"01/Mar/13 22:22;kturner;MRE is only constructed by the TSBW (TabletServerBatchWriter).  The TSBW could pass its Instance to the MRE constructor.  Then MRE could use that Instance when calling methods on o.a.a.c.c.i.Tables.

If you are interested, the following changes would be nice :

 * Make the format() function you added to MRE reduce Map<KeyExtent,Set<SecurityErrorCode>> to Map<TableNameIdString, Set<SecurityErrorCode>> and print that out.   That would be much easier for a human to read.  If someone is interested in the details they can call getAuthorizationFailuresMap().
 * I am not sure all of the messages you added will have both table id and table name. Something like ""tablename(tableid)"" for all the messages would be nice.
 * I believe the scanState.tableName in thrift scanner is misnamed, I think that is actually a tableId.

","04/Mar/13 18:45;kevin.faro;- I changed the format of the tableName in the error Messages to be <tableName>(ID:<tableId>).
- I added instance to the MRE constructor
- I created ACCUMULO-1144 to capture that the tableName in the ThriftScanner$ScanState is really tableId","04/Mar/13 18:46;kevin.faro;ACCUMULO-1018-2.patch

Thanks Keith!  I incorporated your suggestions.","04/Mar/13 23:20;kturner;Patch #2 looks good, I have only one issue with it.   The format() function should create new set for a table if one does not exist.  Then it should add all security error codes to the tables set for each key extent.

I created a little test program to experiment with the patch.  I like the output.

{noformat}
Attemping batch scan : 
	org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED for user user2 on table table1(ID:3) - User does not have permission to perform this action
Attemping scan : 
	org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED for user user2 on table table1(ID:3) - User does not have permission to perform this action
Attemping batch write : 
	# constraint violations : 0  security codes: {table1(ID:3)=[PERMISSION_DENIED]}  # server errors 0 # exceptions 0
Attemping to delete table : 
	Error PERMISSION_DENIED for user user2 on table table1(ID:3) - User does not have permission to perform this action

{noformat}","05/Mar/13 14:07;kevin.faro;I am not sure I follow.  Do you mean that if you use a BatchWriter to write to multiple tables (a & b) and only fail on b, the format method would produce the following?

{a(ID:1)=[], b(ID:2)=[PERMISSION_DENIED]}

or do you mean something else?","05/Mar/13 15:05;kturner;I was thinking of something else.  Was thinking of the case where there are two extents E1 and E2, both from table T1.  The extents see different security errors.  So the input would be something like the following.

{noformat}
  {E1={SE1}, E2={SE2}}
{noformat}

I think the code will output the following

{noformat}
  {T1={SE2}}
{noformat}

It should output the following

{noformat}
  {T1={SE1, SE2}}
{noformat}


","05/Mar/13 15:49;kevin.faro;Gotcha ... makes total sense.  Thanks!

I will put out another patch with those changes.","06/Mar/13 12:47;kevin.faro;Thanks for the feedback Keith!  I incorporated your suggestions in ACCUMULO-1018-3.patch.

Let me know if you have any other suggestions.","08/Mar/13 02:50;hudson;Integrated in Accumulo-Trunk #768 (See [https://builds.apache.org/job/Accumulo-Trunk/768/])
    ACCUMULO-1018 applied patch from Kevin Faro that adds table info to security exception messages (Revision 1454126)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/AccumuloSecurityException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/MutationsRejectedException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/Tables.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReaderIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchWriter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftScanner.java
","08/Mar/13 02:51;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #127 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/127/])
    ACCUMULO-1018 applied patch from Kevin Faro that adds table info to security exception messages (Revision 1454126)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/AccumuloSecurityException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/MutationsRejectedException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/Tables.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReaderIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchWriter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftScanner.java
","08/Mar/13 23:28;kturner;patch 3 looks good, I applied it thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Throw TableDeletedException,ACCUMULO-1163,12635880,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,kturner,kturner,07/Mar/13 19:48,08/Mar/13 21:12,13/Mar/19 22:01,08/Mar/13 19:56,,,,,,,,1.6.0,,,client,,,,,,0,,,,,ACCUMULO-1115 highlights that TableOperations.setProperty is not throwing a TableDeleted exception.  It probably should throw this exception.  Need to determine what other methods should throw this exception. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-08 20:01:10.121,,,no_permission,,,,,,,,,,,,316372,,,Fri Mar 08 21:12:59 UTC 2013,,,,,,0|i1ilbr:,316715,,,,,,,,"07/Mar/13 20:59;kturner;Maybe throwing table deleted exception is not the right thing to do.  I just noticed that setProperty() is not handling deleted tables well when looking at the following code in test.randomwalk.concurrent.Config.

{code:java}
        try {
          state.getConnector().tableOperations().setProperty(table, property.getKey(), property.getDefaultValue());
        } catch (AccumuloException ex) {
          if (ex.toString().contains(""NoNode for"")) {
            // race condition for a table that has been deleted
          } else {
            throw ex;
          }
        }
{code}


{code:java}
    try {
      state.getConnector().tableOperations().setProperty(table, setting.property.getKey(), """" + newValue);
    } catch (AccumuloException ex) {
      if (ex.getCause() instanceof ThriftTableOperationException) {
        ThriftTableOperationException ttoe = (ThriftTableOperationException)ex.getCause();
        if (ttoe.type == TableOperationExceptionType.NOTFOUND)
          return;
      }
      throw ex;
    }
{code}","08/Mar/13 20:01;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #24 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/24/])
    ACCUMULO-1163 modify setProperty to throw a NotFound exception if the table is gone from zookeeper by the time we set the property (Revision 1454513)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","08/Mar/13 21:05;hudson;Integrated in Accumulo-Trunk #772 (See [https://builds.apache.org/job/Accumulo-Trunk/772/])
    ACCUMULO-1163 modify setProperty to throw a NotFound exception if the table is gone from zookeeper by the time we set the property (Revision 1454515)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","08/Mar/13 21:09;hudson;Integrated in Accumulo-1.5 #27 (See [https://builds.apache.org/job/Accumulo-1.5/27/])
    ACCUMULO-1163 modify setProperty to throw a NotFound exception if the table is gone from zookeeper by the time we set the property (Revision 1454513)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","08/Mar/13 21:12;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #131 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/131/])
    ACCUMULO-1163 modify setProperty to throw a NotFound exception if the table is gone from zookeeper by the time we set the property (Revision 1454515)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Randomwalk failure during/after Security.xml,ACCUMULO-1154,12635443,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,05/Mar/13 21:44,08/Mar/13 20:46,13/Mar/19 22:01,08/Mar/13 20:46,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"Got a strange error, first time occurring while running All.xml. It happened in Shard.xml, but died due to a PermissionDenied for a Tablet location cache update with the credentials for a user from Security.xml (which had run before it).

Second time it occured in Security.xml while the Table user didn't exist.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-05 22:29:27.205,,,no_permission,,,,,,,,,,,,315936,,,Fri Mar 08 20:46:09 UTC 2013,,,,,,0|i1iimv:,316279,,,,,,,,"05/Mar/13 21:45;vines;After talking with [~keith_turner], we think it's caused by ACCUMULO-295. That needs to be fixed before I am comfortable saying this has been addressed.","05/Mar/13 22:29;hudson;Integrated in Accumulo-1.5 #15 (See [https://builds.apache.org/job/Accumulo-1.5/15/])
    ACCUMULO-1154 - a little bit more safety in the scanners and writer to make sure they are cleaned up well (Revision 1453027)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
","05/Mar/13 22:31;hudson;Integrated in Accumulo-Trunk #759 (See [https://builds.apache.org/job/Accumulo-Trunk/759/])
    ACCUMULO-1154 - a little bit more safety in the scanners and writer to make sure they are cleaned up well (Revision 1453028)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
","05/Mar/13 22:32;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #118 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/118/])
    ACCUMULO-1154 - a little bit more safety in the scanners and writer to make sure they are cleaned up well (Revision 1453028)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
","05/Mar/13 22:32;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #15 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/15/])
    ACCUMULO-1154 - a little bit more safety in the scanners and writer to make sure they are cleaned up well (Revision 1453027)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
","05/Mar/13 22:50;vines;295 has been addressed, I'm okay closing this ticket if we can get through a day of randomwalk All.xml without hitting that issue again",08/Mar/13 20:46;vines;Resolved with ACCUMULO-295,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Randomwalk framework more framework debug info,ACCUMULO-1151,12635414,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,05/Mar/13 19:44,08/Mar/13 20:45,13/Mar/19 22:01,08/Mar/13 20:45,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"We dump the environment on exceptions to ease debugging. However, we don't deconstruct PasswordTokens, so the info is useless.

We also need to dump the Properties in the State",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-05 22:29:26.388,,,no_permission,,,,,,,,,,,,315907,,,Wed Mar 06 00:59:36 UTC 2013,,,,,,0|i1iigf:,316250,,,,,,,,"05/Mar/13 22:29;hudson;Integrated in Accumulo-1.5 #15 (See [https://builds.apache.org/job/Accumulo-1.5/15/])
    ACCUMULO-1151 - better debug on failure (Revision 1452982)
ACCUMULO-1151 - Now dumping state.properties, dumping PasswordToken contents, and spitting out Connector.whoami() (Revision 1452968)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java

vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/State.java
","05/Mar/13 22:31;hudson;Integrated in Accumulo-Trunk #759 (See [https://builds.apache.org/job/Accumulo-Trunk/759/])
    ACCUMULO-1151 - better logging on failure (Revision 1452983)
ACCUMULO-1151 - Now dumping state.properties, dumping PasswordToken contents, and spitting out Connector.whoami() (Revision 1452970)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java

vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/State.java
","05/Mar/13 22:32;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #118 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/118/])
    ACCUMULO-1151 - better logging on failure (Revision 1452983)
ACCUMULO-1151 - Now dumping state.properties, dumping PasswordToken contents, and spitting out Connector.whoami() (Revision 1452970)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java

vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/State.java
","05/Mar/13 22:32;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #15 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/15/])
    ACCUMULO-1151 - better debug on failure (Revision 1452982)
ACCUMULO-1151 - Now dumping state.properties, dumping PasswordToken contents, and spitting out Connector.whoami() (Revision 1452968)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java

vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/State.java
","06/Mar/13 00:50;hudson;Integrated in Accumulo-1.5 #16 (See [https://builds.apache.org/job/Accumulo-1.5/16/])
    ACCUMULO-1151 - Adding currentTimeMillis() to failure info (Revision 1453082)

     Result = FAILURE
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java
","06/Mar/13 00:51;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #119 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/119/])
    ACCUMULO-1151 - Adding currentTimeMillis() to failure info (Revision 1453084)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java
","06/Mar/13 00:54;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #16 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/16/])
    ACCUMULO-1151 - Adding currentTimeMillis() to failure info (Revision 1453082)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java
","06/Mar/13 00:59;hudson;Integrated in Accumulo-Trunk #760 (See [https://builds.apache.org/job/Accumulo-Trunk/760/])
    ACCUMULO-1151 - Adding currentTimeMillis() to failure info (Revision 1453084)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/Module.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Concurrent random walk test does not handle permission change,ACCUMULO-445,12545258,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,kturner,kturner,05/Mar/12 23:35,08/Mar/13 19:49,13/Mar/19 22:01,08/Mar/13 19:49,,,,,,,,1.5.0,,,test,,,,,,0,14_qa_bug,,,,"Saw the following bug while running the random walk test.  I think this is just a bug in the test, it does not handle case were permissions change during a scan.

{noformat}
03 14:08:15,431 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Concurrent.xml
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:259)
        at org.apache.accumulo.server.test.randomwalk.Framework.run(Framework.java:61)
        at org.apache.accumulo.server.test.randomwalk.Framework.main(Framework.java:114)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:89)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node ct.IsolatedScan
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:259)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
        ... 8 more
Caused by: java.lang.RuntimeException: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED - User does not have permission to perform this action
        at org.apache.accumulo.core.client.impl.ScannerIterator.hasNext(ScannerIterator.java:186)
        at org.apache.accumulo.core.client.IsolatedScanner$RowBufferingIterator.readRow(IsolatedScanner.java:68)
        at org.apache.accumulo.core.client.IsolatedScanner$RowBufferingIterator.<init>(IsolatedScanner.java:144)
        at org.apache.accumulo.core.client.IsolatedScanner.iterator(IsolatedScanner.java:230)
        at org.apache.accumulo.core.client.RowIterator.<init>(RowIterator.java:117)
        at org.apache.accumulo.server.test.randomwalk.concurrent.IsolatedScan.visit(IsolatedScan.java:51)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
        ... 9 more
Caused by: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED - User does not have permission to perform this action
        at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:470)
        at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:295)

{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-18 19:25:27.26,,,no_permission,,,,,,,,,,,,230444,,,Tue Dec 18 19:25:27 UTC 2012,,,,,,0|i07n5b:,42516,,,,,,,,"18/Dec/12 19:25;vines;This will be affected with the changes to ACCUMULO-259 (and with the last testing I did it held up resolutely). I don't know if this is something we want to fix for 1.4.3, but I think it will be fixed in 1.5",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Config node in concurrent random walk doesn't work for tables,ACCUMULO-1115,12634239,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,26/Feb/13 20:30,07/Mar/13 22:05,13/Mar/19 22:01,05/Mar/13 15:14,,,,,,,,1.5.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-27 02:11:05.229,,,no_permission,,,,,,,,,,,,314732,,,Thu Mar 07 22:05:10 UTC 2013,,,,,,0|i1ib7r:,315076,,,,,,,,"27/Feb/13 02:11;hudson;Integrated in Accumulo-Trunk #746 (See [https://builds.apache.org/job/Accumulo-Trunk/746/])
    ACCUMULO-1115 double check for table existence and use the proper keys to pull state (Revision 1450394)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","27/Feb/13 02:11;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #104 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/104/])
    ACCUMULO-1115 double check for table existence and use the proper keys to pull state (Revision 1450394)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","02/Mar/13 09:20;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #9 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/9/])
    ACCUMULO-1115 handle table deleted exception (Revision 1451664)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","02/Mar/13 09:24;hudson;Integrated in Accumulo-1.5 #10 (See [https://builds.apache.org/job/Accumulo-1.5/10/])
    ACCUMULO-1115 handle table deleted exception (Revision 1451664)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","07/Mar/13 21:54;hudson;Integrated in Accumulo-1.5 #22 (See [https://builds.apache.org/job/Accumulo-1.5/22/])
    ACCUMULO-1115 catch race condition setting properties on a table that is being deleted (Revision 1453998)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","07/Mar/13 22:01;hudson;Integrated in Accumulo-Trunk #767 (See [https://builds.apache.org/job/Accumulo-Trunk/767/])
    ACCUMULO-1115 catch race condition setting properties on a table that is being deleted (Revision 1453999)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","07/Mar/13 22:03;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #20 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/20/])
    ACCUMULO-1115 catch race condition setting properties on a table that is being deleted (Revision 1453998)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","07/Mar/13 22:05;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #126 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/126/])
    ACCUMULO-1115 catch race condition setting properties on a table that is being deleted (Revision 1453999)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
balance and tablet server shutdown conflict,ACCUMULO-1149,12635335,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,05/Mar/13 13:17,05/Mar/13 17:49,13/Mar/19 22:01,05/Mar/13 17:04,,,,,,,,1.5.0,,,master,,,,,,0,15_qa_bug,,,,"While running the random walk test, tablets were constantly assigned and unassigned to a tserver.  The master would unload the tablets from the server to shut it down and then the balancer would come back and assign tablets to it.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-05 17:26:42.19,,,no_permission,,,,,,,,,,,,315828,,,Tue Mar 05 17:49:49 UTC 2013,,,,,,0|i1ihyv:,316171,,,,,,,,"05/Mar/13 17:26;hudson;Integrated in Accumulo-1.5 #14 (See [https://builds.apache.org/job/Accumulo-1.5/14/])
    ACCUMULO-1149 prevent balancing during tserver shutdown; ensure that tservers with different ids but the same host/port are removed from the shutdown set (Revision 1452896)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
","05/Mar/13 17:35;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #117 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/117/])
    ACCUMULO-1149 prevent balancing during tserver shutdown; ensure that tservers with different ids but the same host/port are removed from the shutdown set (Revision 1452897)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
","05/Mar/13 17:44;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #14 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/14/])
    ACCUMULO-1149 prevent balancing during tserver shutdown; ensure that tservers with different ids but the same host/port are removed from the shutdown set (Revision 1452896)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/Master.java
","05/Mar/13 17:49;hudson;Integrated in Accumulo-Trunk #758 (See [https://builds.apache.org/job/Accumulo-Trunk/758/])
    ACCUMULO-1149 prevent balancing during tserver shutdown; ensure that tservers with different ids but the same host/port are removed from the shutdown set (Revision 1452897)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FATE Threads die when zookeeper shutdown,ACCUMULO-9,12526076,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,06/Oct/11 16:52,05/Mar/13 15:31,13/Mar/19 22:01,24/Oct/11 22:19,,,,,,,,1.4.0,,,master,,,,,,0,14_qa_bug,,,,"If zookeeper is shutdown all threads that execute FATE operations will die.  Once zookeeper and then the master is restarted, FATE operations will continue to execute.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,49642,,,Sat Oct 22 01:06:24 UTC 2011,,,,,,0|i07ps7:,42943,,,,,,,,22/Oct/11 01:06;kturner;I made some changes to make Fate tolerate zookeeper restarting.   I continually restarted zookeeper while running the Concurrent random walk test and noticed other places where accumulo fell down.  As a result I started working on implementing a more general fix.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DistributedWorkQueue not releasing lock on failure,ACCUMULO-1125,12634499,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,27/Feb/13 22:02,02/Mar/13 09:48,13/Mar/19 22:01,01/Mar/13 20:19,1.4.2,,,,,,,1.4.3,1.5.0,,,,,,,,0,,,,,The distributed work queue is not releasing its lock on a work item when that work item throws an exception.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-28 01:36:29.182,,,no_permission,,,,,,,,,,,,314992,,,Sat Mar 02 09:48:36 UTC 2013,,,,,,0|i1ictj:,315336,,,,,,,,"28/Feb/13 01:36;hudson;Integrated in Accumulo-Trunk #748 (See [https://builds.apache.org/job/Accumulo-Trunk/748/])
    ACCUMULO-1125 delete distributed work queue task lock when task fails (Revision 1451019)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
* /accumulo/trunk/src
","28/Feb/13 02:20;hudson;Integrated in Accumulo-1.5 #3 (See [https://builds.apache.org/job/Accumulo-1.5/3/])
    ACCUMULO-1125 delete distributed work queue task lock when task fails (Revision 1451015)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
","28/Feb/13 02:31;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #107 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/107/])
    ACCUMULO-1125 delete distributed work queue task lock when task fails (Revision 1451019)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
* /accumulo/trunk/src
","28/Feb/13 03:32;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #3 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/3/])
    ACCUMULO-1125 delete distributed work queue task lock when task fails (Revision 1451015)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
","02/Mar/13 09:48;hudson;Integrated in Accumulo-1.4.x #278 (See [https://builds.apache.org/job/Accumulo-1.4.x/278/])
    merged some bug fixes from 1.5:
ACCUMULO-1125 delete distributed work queue task lock when task fails
ACCUMULO-1049 modified master to stop locking tserver nodes and just monitor  tserver nodes in zookeeper
ACCUMULO-954 made zoolock report when its no longer able to monitor lock node and there does not know the status of the lock
ACCUMULO-954 Made zoolock rewatch its parent node and added some unit test for zoolock (Revision 1451708)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/TServerLockWatcher.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/test/functional
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/test/functional/SplitRecoveryTest.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/test/functional/ZombieTServer.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/zookeeper/ZooLock.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZKPermHandler needs to sync before reading uncached credentials,ACCUMULO-1138,12634902,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,01/Mar/13 21:00,02/Mar/13 09:24,13/Mar/19 22:01,01/Mar/13 21:06,,,,,,,,1.5.0,,,,,,,,,0,,,,,"The permission handler interface handles reading both cached and uncached permissions (for high and low frequency permissions). However, teh uncached reads do not do a sync before reading zookeeper, so it's possible they have stale information.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-02 04:16:14.709,,,no_permission,,,,,,,,,,,,315395,,,Sat Mar 02 09:24:02 UTC 2013,,,,,,0|i1ifb3:,315739,,,,,,,,"02/Mar/13 04:16;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #114 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/114/])
    ACCUMULO-1138 - syncing before uncached calls and ZKAuthenticator was kicking back the wrong class in getTokenLoginClass (Revision 1451718)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/security/handler/ZKAuthenticator.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/security/handler/ZKPermHandler.java
","02/Mar/13 04:20;hudson;Integrated in Accumulo-Trunk #755 (See [https://builds.apache.org/job/Accumulo-Trunk/755/])
    ACCUMULO-1138 - syncing before uncached calls and ZKAuthenticator was kicking back the wrong class in getTokenLoginClass (Revision 1451718)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/security/handler/ZKAuthenticator.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/security/handler/ZKPermHandler.java
","02/Mar/13 09:20;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #9 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/9/])
    ACCUMULO-1138 - syncing before uncached calls and ZKAuthenticator was kicking back the wrong class in getTokenLoginClass (Revision 1451717)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/security/handler/ZKAuthenticator.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/security/handler/ZKPermHandler.java
","02/Mar/13 09:24;hudson;Integrated in Accumulo-1.5 #10 (See [https://builds.apache.org/job/Accumulo-1.5/10/])
    ACCUMULO-1138 - syncing before uncached calls and ZKAuthenticator was kicking back the wrong class in getTokenLoginClass (Revision 1451717)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/security/handler/ZKAuthenticator.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/security/handler/ZKPermHandler.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
C++ proxy binding missing namespace,ACCUMULO-1137,12634749,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,01/Mar/13 03:34,02/Mar/13 04:20,13/Mar/19 22:01,01/Mar/13 04:04,,,,,,,,1.5.0,,,proxy,,,,,,0,,,,,The gen-cpp/AccumuloProxy_server.skeleton.cpp file is missing a namespace due to lack of a 'namespace cpp name' declaration in proxy.thrift.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-01 04:10:34.016,,,no_permission,,,,,,,,,,,,315242,,,Sat Mar 02 04:20:34 UTC 2013,,,,,,0|i1ied3:,315586,,,,,,,,01/Mar/13 04:04;elserj;Fixed in r1451465,"01/Mar/13 04:10;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #6 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/6/])
    ACCUMULO-1137 Set 'accumulo' namespace for c++ bindings (Revision 1451465)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
","01/Mar/13 04:11;hudson;Integrated in Accumulo-1.5 #7 (See [https://builds.apache.org/job/Accumulo-1.5/7/])
    ACCUMULO-1137 Set 'accumulo' namespace for c++ bindings (Revision 1451465)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
","02/Mar/13 04:16;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #114 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/114/])
    ACCUMULO-1133 Finish incomplete move of tokens
ACCUMULO-1137 Set 'accumulo' namespace for c++ bindings (Revision 1451648)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/tokens
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/server
* /accumulo/trunk/src
","02/Mar/13 04:20;hudson;Integrated in Accumulo-Trunk #755 (See [https://builds.apache.org/job/Accumulo-Trunk/755/])
    ACCUMULO-1133 Finish incomplete move of tokens
ACCUMULO-1137 Set 'accumulo' namespace for c++ bindings (Revision 1451648)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/tokens
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
unexpected exception in Split/MajC following importDirectory call,ACCUMULO-417,12543096,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,etseidl,etseidl,17/Feb/12 20:36,01/Mar/13 17:56,13/Mar/19 22:01,01/Mar/13 17:56,1.3.6,,,,,,,1.4.0,,,tserver,,,,,,0,,,,,"While attempting a bulk ingest from a mapreduce job, I noticed that after calling importDirectory() I started getting errors in the tservers like the following:
{quote}
16 11:04:53,337 [file.FileUtil] DEBUG: Too many indexes (31) to open at once for [snip...], reducing in tmpDir = /accumulo/tmp/idxReduce_2009963461
16 11:04:53,595 [tabletserver.TabletServer] ERROR: Unexpected exception in Split/MajC initiator
java.lang.NullPointerException
        at org.apache.accumulo.core.file.rfile.RFile$Writer.append(RFile.java:382)
        at org.apache.accumulo.core.file.FileUtil.reduceFiles(FileUtil.java:147)
        at org.apache.accumulo.core.file.FileUtil.findMidPoint(FileUtil.java:281)
        at org.apache.accumulo.core.file.FileUtil.findMidPoint(FileUtil.java:186)
        at org.apache.accumulo.server.tabletserver.Tablet.findSplitRow(Tablet.java:2939)
        at org.apache.accumulo.server.tabletserver.Tablet.needsSplit(Tablet.java:3013)
        at org.apache.accumulo.server.tabletserver.TabletServer$MajorCompactor.run(TabletServer.java:2066)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:619)
{quote}

As a result, my data was never showing up in the tables.  I poked around in RFile.java, and noticed
that the null pointer was the currentLocalityGroup.  To get past this, I threw in a call to
startDefaultLocalityGroup() if currentLocalityGroup is null (in RFile.append()).
This then lead to the following error

{quote}
6 15:15:46,989 [file.FileUtil] DEBUG: Too many indexes (40) to open at once for 10.252.
158.124 10.251.213.245:537, reducing in tmpDir = /accumulo/tmp/idxReduce_193905614116 15:15:48,060 [file.FileUtil] DEBUG: Finished reducing indexes for 10.252.158.124 10.2
51.213.245:537 in   1.07 secs16 15:15:48,068 [tabletserver.TabletServer] ERROR: Unexpected exception in Split/MajC initiator
java.lang.IllegalArgumentException: File name rf_0000 has no extension
        at org.apache.accumulo.core.file.DispatchingFileFactory.findFileFactory(FileOperations.java:51)
        at org.apache.accumulo.core.file.DispatchingFileFactory.openIndex(FileOperations.java:67)
        at org.apache.accumulo.core.file.FileUtil.countIndexEntries(FileUtil.java:392)
        at org.apache.accumulo.core.file.FileUtil.findMidPoint(FileUtil.java:294)
        at org.apache.accumulo.core.file.FileUtil.findMidPoint(FileUtil.java:186)
        at org.apache.accumulo.server.tabletserver.Tablet.findSplitRow(Tablet.java:2939)
        at org.apache.accumulo.server.tabletserver.Tablet.needsSplit(Tablet.java:3013)
        at org.apache.accumulo.server.tabletserver.TabletServer$MajorCompactor.run(TabletServer.java:2066)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:619)
{quote}

To get past this one, I threw a "".rf"" extension on the file being opened
(outFile in FileUtil.reduceFiles()), and I also changed the add call
immediately after from outFiles.add(newMapFile) to outFiles.add(outFile).

Now my bulk imports work again.  Don't know why this happens, and this
surely isn't the proper way to fix the problem, but thought I'd let you
know.
",running 1.5.0-SNAPSHOT from svn on cluster of 9 8-core linux boxes running Centos 5.6.  Hadoop 1.0 with zookeeper 3.3.3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-02-17 20:42:42.238,,,no_permission,,,,,,,,,,,,228382,,,Fri Feb 17 20:58:32 UTC 2012,,,,,,0|i07nbj:,42544,,,,,,,,17/Feb/12 20:42;jvines;I probably broke this with the purging of MapFile.,17/Feb/12 20:49;kturner;Great bug find.  The bug does not exist in 1.4.x its a result of work done for ACCUMULO-288,17/Feb/12 20:58;etseidl;Always fun to be on the bleeding edge...,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
org.apache.accumulo.proxy.SimpleTest.testSecurityOperations has inconsistent behavior,ACCUMULO-1036,12630729,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,vines,vines,04/Feb/13 19:25,28/Feb/13 23:58,13/Mar/19 22:01,28/Feb/13 23:58,,,,,,,,1.5.0,,,proxy,test,,,,,0,,,,,"org.apache.accumulo.proxy.SimpleTest.testSecurityOperations will fail the first attempt at use. I'm more inclined to believe this is an issue with spin-up time of Instamo than it is a proxy issue, but I could be mistaken as this is just speculation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-13 18:22:22.079,,,no_permission,,,,,,,,,,,,311225,,,Thu Feb 28 23:58:42 UTC 2013,,,,,,0|i1hpkv:,311571,,,,,,,,"13/Feb/13 18:22;kturner;If things are failing because instamo is not fully up, then I think thats a problem w/ client code not being fault tolerant that we should fix.","13/Feb/13 18:26;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #89 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/89/])
    ACCUMULO-1036 try to stabilize MAC-based tests (Revision 1445773)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","13/Feb/13 19:24;hudson;Integrated in Accumulo-Trunk #731 (See [https://builds.apache.org/job/Accumulo-Trunk/731/])
    ACCUMULO-1036 try harder to stabilize the proxy test (Revision 1445810)
ACCUMULO-1036 try to stabilize MAC-based tests (Revision 1445773)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java

ecn : 
Files : 
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","13/Feb/13 20:19;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #90 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/90/])
    ACCUMULO-1036 try harder to stabilize the proxy test (Revision 1445810)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","28/Feb/13 23:58;vines;I have not seen this issue again, think it's been resolved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stop-all.sh parameter passing does not accept -u root -p password params properly,ACCUMULO-995,12629352,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,supermallen,supermallen,supermallen,26/Jan/13 00:02,28/Feb/13 19:07,13/Mar/19 22:01,28/Feb/13 19:07,,,,,,,,1.5.0,,,scripts,,,,,,0,,,,,"Recreation steps:

1. Install Accumulo 1.5.0 from trunk, and start server (start-all.sh).
2. Now stop the server:

bin/stop-all.sh -u root -p password

Expected outcome: 

stop-all.sh command would use supplied credentials to attach to the server.

Actual outcome:

The eventual implementation class (o.a.a.s.util.Admin) throws a parse exception for the command line parameters:

Caused by: com.beust.jcommander.ParameterException: Unknown option: -u
	at com.beust.jcommander.JCommander.parseValues(JCommander.java:735)
	at com.beust.jcommander.JCommander.parse(JCommander.java:279)
	at com.beust.jcommander.JCommander.parse(JCommander.java:262)
	at com.beust.jcommander.JCommander.parseValues(JCommander.java:780)
	at com.beust.jcommander.JCommander.parse(JCommander.java:279)
	at com.beust.jcommander.JCommander.parse(JCommander.java:262)
	at org.apache.accumulo.server.util.Admin.main(Admin.java:76)
	... 6 more
","Accumulo 1.5.0 from trunk, running on my OS X laptop.",,,,,,,,,,,,,,,,,,,,,,,86400,86400,,0%,86400,86400,,,,,,,,,,,,,,,,,,,,,,,26/Jan/13 00:23;supermallen;accumulo-995.diff;https://issues.apache.org/jira/secure/attachment/12566583/accumulo-995.diff,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-01-26 00:08:19.615,,,no_permission,,,,,,,,,,,,309683,,,Thu Feb 28 18:28:54 UTC 2013,,,,,,0|i1g7nr:,302834,,,,,,,,"26/Jan/13 00:08;vines;I'm not too familiar with the jcommander stuff, assuming it's a jcommander issue.","26/Jan/13 00:13;supermallen;I think the root of this is the way JCommander parses ""commands"" versus ""options"", and how the shell script invokes the Java code.

The Java code gets invoked from stop-all.sh as follows:

${bin}/accumulo admin stopAll ""$@""

In other words, put all arguments to the stopAll ""command"" after the command, as though they are parameters to the command but not to the ""admin"" part of it.  In fact, the parser is set up such that stopAll expects no arguments, while the Admin class itself is expecting all the normal client options (-u, -p, etc.) plus an additional -f option for forcing.

I think the fix here is easy:

${bin}/accumulo admin ""$@"" stopAll

Just put the options behind the stopAll command.",26/Jan/13 00:23;supermallen;Here's my proposed patch.,28/Feb/13 18:28;kturner;Thanks for the patch.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Combiners lose data when reading off of disk,ACCUMULO-338,12539196,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,vines,jvines,20/Jan/12 18:54,27/Feb/13 02:11,13/Mar/19 22:01,20/Jan/12 19:56,,,,,,,,1.4.0,,,,,,,,,0,,,,,"There is a bug with Combiners in 1.4 resulting in bad data-

to recreate-
createtable test;
config -t test -s table.iterator.minc.vers=10
config -t test -s table.iterator.majc.vers=10
config -t test -s table.iterator.scan.vers=10
insert r f q 1
insert r f q 2
insert r f q 3
setiter -class org.apache.accumulo.core.iterators.user.SummingCombiner -scan -n summer -p 60 -t test
true

STRING
scan
flush
scan
deleteiter -t test -n summer -scan
scan

You will see all three values the first scan, 6 for the second scan, 4 for the third scan, and all three values for the 4th scan. In debug I saw teh values 2, 1, and 1 in that order in the Viterator.next method.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-20 19:33:22.014,,,no_permission,,,,,,,,,,,,224698,,,Wed Feb 27 02:11:24 UTC 2013,,,,,,0|i07ns7:,42619,,,,,,,,"20/Jan/12 19:33;billie.rinaldi;We tracked this down to reuse of Value objects by the RFile.  Combiner should make a copy of the Values.  I'll make a functional test for this, too.  Nice catch, John!","27/Feb/13 02:11;hudson;Integrated in Accumulo-Trunk #746 (See [https://builds.apache.org/job/Accumulo-Trunk/746/])
    ACCUMULO-338 - Committing Chris McCubbin's patch, with some updated usage information. (Revision 1450447)

     Result = FAILURE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/system/continuous/agitator.pl
","27/Feb/13 02:11;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #104 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/104/])
    ACCUMULO-338 - Committing Chris McCubbin's patch, with some updated usage information. (Revision 1450447)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/test/system/continuous/agitator.pl
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
continuous ingest fails with class not found,ACCUMULO-1054,12631480,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,ecn,ecn,08/Feb/13 16:42,26/Feb/13 18:13,13/Mar/19 22:01,26/Feb/13 18:12,,,,,,,,1.5.0,,,test,,,,,,0,15_qa_bug,,,,FastForward is in the server package which is not in the test package.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-08 18:48:55.031,,,no_permission,,,,,,,,,,,,311976,,,Fri Feb 08 18:56:49 UTC 2013,,,,,,0|i1hu7j:,312322,,,,,,,,"08/Feb/13 18:48;hudson;Integrated in Accumulo-Trunk #717 (See [https://builds.apache.org/job/Accumulo-Trunk/717/])
    ACCUMULO-1054 refactor FastFormat from server to core (Revision 1444119)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/FastFormat.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/ImportTable.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/UniqueNameAllocator.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/FastFormat.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/NativeMapConcurrencyTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/NativeMapPerformanceTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/TestIngest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/continuous/ContinuousIngest.java
","08/Feb/13 18:56;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #75 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/75/])
    ACCUMULO-1054 refactor FastFormat from server to core (Revision 1444119)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/FastFormat.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/ImportTable.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/UniqueNameAllocator.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/FastFormat.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/NativeMapConcurrencyTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/NativeMapPerformanceTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/TestIngest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/continuous/ContinuousIngest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ChangeSecret fails to change password,ACCUMULO-1057,12631594,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,dab5879,dab5879,dab5879,09/Feb/13 17:59,12/Feb/13 19:56,13/Mar/19 22:01,12/Feb/13 18:12,,,,,,,,1.5.0,,,client,,,,,,0,patch,,,,"ChangeSecret fails to change secret.

The argsList uses Arrays.asList(...), which returns an immutable array.  Adding to the array produces an exception:

{code}
Thread ""org.apache.accumulo.server.util.ChangeSecret"" died null
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.accumulo.start.Main$1.run(Main.java:97)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.lang.UnsupportedOperationException
	at java.util.AbstractList.add(AbstractList.java:148)
	at java.util.AbstractList.add(AbstractList.java:108)
	at org.apache.accumulo.server.util.ChangeSecret.main(ChangeSecret.java:55)
	... 6 more
{code}",,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,09/Feb/13 18:17;dab5879;ChangeSecret.patch;https://issues.apache.org/jira/secure/attachment/12568710/ChangeSecret.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-02-12 18:06:31.777,,,no_permission,,,,,,,,,,,,312090,,,Tue Feb 12 19:56:05 UTC 2013,,,,,,0|i1huwv:,312436,,,,,,,,09/Feb/13 18:00;dab5879;Patch creates a new dynamic array list and then adds the args to the list.,12/Feb/13 18:06;kturner;Thanks for the patch.  It looks good.,"12/Feb/13 18:12;kturner;seems this is a new issue in trunk... looked at 1.4 code, does not have this bug","12/Feb/13 19:48;hudson;Integrated in Accumulo-Trunk #728 (See [https://builds.apache.org/job/Accumulo-Trunk/728/])
    ACCUMULO-1057 applied patch from Damon A Brown (Revision 1445292)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/ChangeSecret.java
","12/Feb/13 19:56;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #86 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/86/])
    ACCUMULO-1057 applied patch from Damon A Brown (Revision 1445292)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/ChangeSecret.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
log file contains no tablet definition,ACCUMULO-1033,12630667,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,04/Feb/13 16:26,05/Feb/13 21:20,13/Mar/19 22:01,05/Feb/13 21:20,,,,,,,,1.5.0,,,,,,,,,0,,,,,"It is possible that a tablet will be marked as using a WAL, but there are no updates in that log for the tablet, because the log was closed or the tablet server dies before the data can be written out.  Presently, this is treated as an error, and it should be allowed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-04 19:08:22.33,,,no_permission,,,,,,,,,,,,311163,,,Mon Feb 04 19:15:54 UTC 2013,,,,,,0|i1hp7b:,311510,,,,,,,,"04/Feb/13 19:08;hudson;Integrated in Accumulo-Trunk #701 (See [https://builds.apache.org/job/Accumulo-Trunk/701/])
    ACCUMULO-1033 ignore WALs that contain no definition for the given key extent (Revision 1442166)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/SortedLogRecovery.java
","04/Feb/13 19:15;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #59 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/59/])
    ACCUMULO-1033 ignore WALs that contain no definition for the given key extent (Revision 1442166)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/SortedLogRecovery.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LocalityCheck is missing a path separator,ACCUMULO-982,12628775,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,elserj,elserj,22/Jan/13 19:33,05/Feb/13 16:26,13/Mar/19 22:01,05/Feb/13 15:40,1.4.2,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"When running o.a.a.s.u.LocalityCheck over an instance with a cloned table, the path for the files for the cloned table are missing a path separator.

e.g An original table id of '1a' and a cloned table off of '1a' called '1b', LocalityCheck tries to find '/accumulo/$\{INSTANCE_ID}/tables/1b../1a/default_tablet/A0123456.rf'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-05 16:15:07.588,,,no_permission,,,,,,,,,,,,308253,,,Tue Feb 05 16:26:56 UTC 2013,,,,,,0|i1b1b3:,272510,,,,,,,,"05/Feb/13 16:15;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #63 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/63/])
    ACCUMULO-982 deal with cloned tables (Revision 1442627)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/LocalityCheck.java
","05/Feb/13 16:26;hudson;Integrated in Accumulo-Trunk #705 (See [https://builds.apache.org/job/Accumulo-Trunk/705/])
    ACCUMULO-982 deal with cloned tables (Revision 1442627)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/LocalityCheck.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
user initiated compactions not preempting system initiated ones,ACCUMULO-976,12628295,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,18/Jan/13 22:27,05/Feb/13 15:53,13/Mar/19 22:01,05/Feb/13 15:53,1.4.0,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"I noticed this while experimenting with the new list compactions command.   If a tablets server queues a compaction for a sub set of files and then a user request a compaction of all files, then the users reuqest should preempt the system.  The compaction queue sorts so that this should happen, but compactions are not added if anything is on the queue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-30 00:56:51.389,,,no_permission,,,,,,,,,,,,305421,,,Wed Jan 30 01:06:30 UTC 2013,,,,,,0|i18c9r:,256790,,,,,,,,"30/Jan/13 00:56;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #47 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/47/])
    ACCUMULO-976 allow user compactions to queue when system compaction is queued (Revision 1440221)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
","30/Jan/13 01:06;hudson;Integrated in Accumulo-Trunk #689 (See [https://builds.apache.org/job/Accumulo-Trunk/689/])
    ACCUMULO-976 allow user compactions to queue when system compaction is queued (Revision 1440221)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Scripts don't deal with empty variables well,ACCUMULO-1035,12630724,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,04/Feb/13 18:55,04/Feb/13 23:59,13/Mar/19 22:01,04/Feb/13 21:19,1.4.2,,,,,,,1.5.0,,,scripts,,,,,,0,,,,,"We do a bit of checking for various variables which come in through different avenues. Occasionally, an odd, but acceptable, configuration can result in an empty variable, which causes scripts to throw errors. Wrapping shell variables in quotations should resolve most of these.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-04 23:07:27.606,,,no_permission,,,,,,,,,,,,311220,,,Mon Feb 04 23:59:53 UTC 2013,,,,,,0|i1hpjr:,311566,,,,,,,,"04/Feb/13 23:07;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #60 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/60/])
    ACCUMULO-1035 - more quoting (Revision 1442363)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/bin/generate_monitor_certificate.sh
* /accumulo/trunk/bin/start-all.sh
* /accumulo/trunk/bin/start-here.sh
* /accumulo/trunk/bin/stop-all.sh
* /accumulo/trunk/bin/tool.sh
","04/Feb/13 23:59;hudson;Integrated in Accumulo-Trunk #702 (See [https://builds.apache.org/job/Accumulo-Trunk/702/])
    ACCUMULO-1035 - more quoting (Revision 1442363)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/bin/generate_monitor_certificate.sh
* /accumulo/trunk/bin/start-all.sh
* /accumulo/trunk/bin/start-here.sh
* /accumulo/trunk/bin/stop-all.sh
* /accumulo/trunk/bin/tool.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Example config files contain erroneous newlines,ACCUMULO-1023,12630500,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,jklucar,jklucar,02/Feb/13 03:12,04/Feb/13 19:15,13/Mar/19 22:01,04/Feb/13 17:47,,,,,,,,,,,scripts,,,,,,0,,,,,Some of the properties in the provided accumulo-site.xml files contain line-breaks and spaces before closing </value> tags. Looks like it is on all of the ZKAuthenticator/Authorizor/PermHandler properties.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-02 03:16:36.049,,,no_permission,,,,,,,,,,,,310994,,,Mon Feb 04 19:15:55 UTC 2013,,,,,,0|i1ho5b:,311339,,,,,,,,02/Feb/13 03:16;vines;We don't trim those? Gross!,"03/Feb/13 19:07;ctubbsii;I think it's probably over-ambitious to trim the contents of text nodes in *all* XML elements (whitespace may matter for some XML nodes), but we should handle it in all cases where it makes sense to. A work-around might be to fix the script, but we should do something in the configuration loading/parsing to address this more broadly.","04/Feb/13 17:32;vines;Wait, I'm looking at the examples right now, and I'm seeing no line breaks or spaces involved with the instance.security properties in the value tags.","04/Feb/13 17:46;billie.rinaldi;It's conf/examples/512MB/standalone/accumulo-site.xml.  The values have a newline at the end, e.g. 
{noformat}
<value>stuff
</value>
{noformat}","04/Feb/13 17:47;vines;Aha, my grep missed that. Thanks","04/Feb/13 19:08;hudson;Integrated in Accumulo-Trunk #701 (See [https://builds.apache.org/job/Accumulo-Trunk/701/])
    Fixes ACCUMULO-1023 (Revision 1442198)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-site.xml
","04/Feb/13 19:15;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #59 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/59/])
    Fixes ACCUMULO-1023 (Revision 1442198)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-site.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Generated code needs license headers,ACCUMULO-940,12626148,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ctubbsii,ctubbsii,ctubbsii,05/Jan/13 01:40,31/Jan/13 01:34,13/Mar/19 22:01,08/Jan/13 19:11,,,,,,,,1.5.0,,,rpc,trace,,,,,0,,,,,License headers need to be included in thrift-generated code.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-913,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-05 02:13:51.715,,,no_permission,,,,,,,,,,,,302731,,,Sat Jan 05 02:13:51 UTC 2013,,,,,,0|i1750n:,249781,,,,,,,,"05/Jan/13 02:13;hudson;Integrated in Accumulo-Trunk #610 (See [https://builds.apache.org/job/Accumulo-Trunk/610/])
    ACCUMULO-940 Added license headers to generated java code, and cleaned up scripts to generate that code (Revision 1429190)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ClientService.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ConfigurationType.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/TableOperation.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/TableOperationExceptionType.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ThriftTableOperationException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/thrift/ThriftTest.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/InitialMultiScan.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/InitialScan.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/IterInfo.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/MapFileInfo.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/MultiScanResult.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/ScanResult.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TColumn.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TConstraintViolationSummary.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TKey.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TKeyExtent.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TKeyValue.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TMutation.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/TRange.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/data/thrift/UpdateErrors.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/gc/thrift/GCMonitorService.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/gc/thrift/GCStatus.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/gc/thrift/GcCycleStats.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/Compacting.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/DeadServer.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/MasterClientService.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/MasterGoalState.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/MasterMonitorInfo.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/MasterState.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/RecoveryException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/RecoveryStatus.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TableInfo.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TableOperation.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TabletLoadState.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TabletServerStatus.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TabletSplit.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/thrift/AuthInfo.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/thrift/SecurityErrorCode.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/thrift/ThriftSecurityException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/ActionStats.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/ActiveScan.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/ConstraintViolationException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/IteratorConfig.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/NoSuchScanIDException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/NotServingTabletException.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/ScanState.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/ScanType.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/TIteratorSetting.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/TabletClientService.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/TabletStats.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/tabletserver/thrift/TooManyFilesException.java
* /accumulo/trunk/core/src/main/scripts
* /accumulo/trunk/core/src/main/scripts/generate-thrift.sh
* /accumulo/trunk/core/src/main/thrift/thrift.sh
* /accumulo/trunk/trace/pom.xml
* /accumulo/trunk/trace/src/main/java/org/apache/accumulo/cloudtrace/thrift/RemoteSpan.java
* /accumulo/trunk/trace/src/main/java/org/apache/accumulo/cloudtrace/thrift/SpanReceiver.java
* /accumulo/trunk/trace/src/main/java/org/apache/accumulo/cloudtrace/thrift/TInfo.java
* /accumulo/trunk/trace/src/main/java/org/apache/accumulo/cloudtrace/thrift/TestService.java
* /accumulo/trunk/trace/src/main/scripts
* /accumulo/trunk/trace/src/main/scripts/generate-thrift.sh
* /accumulo/trunk/trace/thrift.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
listscans and listcompaction commands can get stuck on bad server,ACCUMULO-977,12628299,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,18/Jan/13 22:28,29/Jan/13 00:33,13/Mar/19 22:01,28/Jan/13 23:41,1.4.0,,,,,,,1.4.3,1.5.0,,,,,,,,0,,,,,listscans and list compactions can get stuck on a bad server.   Should timeout and print an error for that server.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-22 17:39:52.071,,,no_permission,,,,,,,,,,,,305425,,,Tue Jan 29 00:33:44 UTC 2013,,,,,,0|i18can:,256794,,,,,,,,22/Jan/13 17:25;kturner;listcompactions does not exist in 1.4.X.  But listscans in 1.4 has this issue.,"22/Jan/13 17:39;mdrob;Keith, any chance this can make it back into 1.4.3?","22/Jan/13 17:40;mdrob;Also, I think that this might be enough of a debugging tool to cover the intent of ACCUMULO-513.","22/Jan/13 17:51;kturner;sure, this could be backported to 1.4","22/Jan/13 18:49;hudson;Integrated in Accumulo-Trunk #653 (See [https://builds.apache.org/job/Accumulo-Trunk/653/])
    ACCUMULO-977 modified listscans and listcompactions to not retry on a bad tserver (Revision 1437054)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
","22/Jan/13 19:00;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #11 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/11/])
    ACCUMULO-977 modified listscans and listcompactions to not retry on a bad tserver (Revision 1437054)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
","29/Jan/13 00:33;hudson;Integrated in Accumulo-1.4.x #271 (See [https://builds.apache.org/job/Accumulo-1.4.x/271/])
    ACCUMULO-977 made listscans continue on bad tserver (merged from trunk) (Revision 1439694)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
start-here doesn't work if you define your roles by IP,ACCUMULO-944,12626579,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,08/Jan/13 17:23,28/Jan/13 23:35,13/Mar/19 22:01,28/Jan/13 22:30,1.4.2,,,,,,,1.5.0,,,scripts,,,,,,0,,,,,"Start-here does checks for localhost/hostname matching, but no logic for IP. We do some IP based work in the other scripts, we should add that logic to start-here.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-28 23:31:15.762,,,no_permission,,,,,,,,,,,,303186,,,Mon Jan 28 23:35:17 UTC 2013,,,,,,0|i178iv:,250349,,,,,,,,"28/Jan/13 23:31;hudson;Integrated in Accumulo-Trunk #683 (See [https://builds.apache.org/job/Accumulo-Trunk/683/])
    ACCUMULO-944 - start-here now considers IPs, including 127.0.0.1. So does stop-here (Revision 1439675)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/bin/start-here.sh
* /accumulo/trunk/bin/stop-here.sh
","28/Jan/13 23:35;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #41 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/41/])
    ACCUMULO-944 - start-here now considers IPs, including 127.0.0.1. So does stop-here (Revision 1439675)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/bin/start-here.sh
* /accumulo/trunk/bin/stop-here.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
start-here tries to start a logger,ACCUMULO-994,12629348,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,25/Jan/13 23:54,26/Jan/13 01:35,13/Mar/19 22:01,25/Jan/13 23:55,,,,,,,,1.5.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-26 01:21:06.202,,,no_permission,,,,,,,,,,,,309679,,,Sat Jan 26 01:35:03 UTC 2013,,,,,,0|i1g7mv:,302830,,,,,,,,"26/Jan/13 01:21;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #31 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/31/])
    ACCUMULO-994 - no more loggers here (Revision 1438779)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/bin/start-here.sh
","26/Jan/13 01:35;hudson;Integrated in Accumulo-Trunk #673 (See [https://builds.apache.org/job/Accumulo-Trunk/673/])
    ACCUMULO-994 - no more loggers here (Revision 1438779)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/bin/start-here.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
deletemany does not configure the scan-time iterator,ACCUMULO-968,12627831,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,16/Jan/13 14:25,24/Jan/13 21:45,13/Mar/19 22:01,24/Jan/13 21:45,1.3.5-incubating,1.4.2,,,,,,1.5.0,,,shell,,,,,,0,,,,,"Was trying to delete fields using a Regex iterator, but deletemany doesn't add the scan iterator.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-16 20:35:41.093,,,no_permission,,,,,,,,,,,,304619,,,Wed Jan 16 20:35:41 UTC 2013,,,,,,0|i17nqf:,252814,,,,,,,,"16/Jan/13 20:35;hudson;Integrated in Accumulo-Trunk #641 (See [https://builds.apache.org/job/Accumulo-Trunk/641/])
    ACCUMULO-968 add scan-time iterators to the scanner (Revision 1434038)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/DeleteManyCommand.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Constraints do not seem to reload easily,ACCUMULO-462,12546215,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,vines,jvines,13/Mar/12 10:46,24/Jan/13 14:23,13/Mar/19 22:01,24/Jan/13 14:23,1.3.5-incubating,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"Constraints do not seem to reload. Once you create them, I believe they remain loaded until the tablet is unloaded for whatever reason. This means the dynamic class loader has no effect on constraints in any consistent measure of time. We should look into means to have constraints reload themselves or some other mechanism to ensure the reloading capability works nicely with constraints.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-24 01:41:09.597,,,no_permission,,,,,,,,,,,,231373,,,Thu Jan 24 01:47:53 UTC 2013,,,,,,0|i07n1j:,42499,,,,,,,,"24/Jan/13 01:41;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #19 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/19/])
    ACCUMULO-462 ACCUMULO-867 made constraints reload and use new context classloader (Revision 1437810)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/ConstraintChecker.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/ConstraintLoader.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/FileManager.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServerResourceManager.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/time/SimpleTimer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/vfs/ContextManager.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","24/Jan/13 01:47;hudson;Integrated in Accumulo-Trunk #661 (See [https://builds.apache.org/job/Accumulo-Trunk/661/])
    ACCUMULO-462 ACCUMULO-867 made constraints reload and use new context classloader (Revision 1437810)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/ConstraintChecker.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/constraints/ConstraintLoader.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/FileManager.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServerResourceManager.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/time/SimpleTimer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/zookeeper/DistributedWorkQueue.java
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/vfs/ContextManager.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Options validation is inconsistent,ACCUMULO-846,12615349,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,08/Nov/12 16:49,17/Jan/13 20:06,13/Mar/19 22:01,17/Jan/13 20:06,,,,,,,,1.5.0,,,client,,,,,,0,,,,,"The validateOptions method is used to validate iterator options when configuring them via the setiter command in the shell.  It is implemented inconsistently, sometimes throwing an exception to indicate bad options and sometimes catching the exception and returning false.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-17 17:14:23.303,,,no_permission,,,,,,,,,,,,255984,,,Thu Jan 17 17:14:23 UTC 2013,,,,,,0|i0gkhr:,94750,,,,,,,,"18/Dec/12 16:05;billie.rinaldi;It's a better practice to throw exceptions so information about what went wrong is propagated, so the methods should do that when possible.  Iterators should also make sure to check the boolean returned by super.validateOptions.","17/Jan/13 17:14;hudson;Integrated in Accumulo-Trunk #643 (See [https://builds.apache.org/job/Accumulo-Trunk/643/])
    ACCUMULO-846 cleaned up options validation (Revision 1434751)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/AggregatingIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/Filter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/FirstEntryInRowIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/LongCombiner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/OptionDescriber.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/SortedKeyIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/TypedValueCombiner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/user/AgeOffFilter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/user/ColumnAgeOffFilter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/user/LargeRowFilter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/user/SummingArrayCombiner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/user/VersioningIterator.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java
* /accumulo/trunk/examples/simple/src/main/java/org/apache/accumulo/examples/simple/combiner/StatsCombiner.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Native debian package won't install due to make or makefile error,ACCUMULO-789,12610616,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,ekohlwey,ekohlwey,05/Oct/12 18:53,02/Jan/13 23:13,13/Mar/19 22:01,02/Jan/13 22:51,1.4.0,1.4.1,,,,,,1.4.3,1.5.0,,,,,,,,0,Packaging,,,,"Discussion reproduced from mailing list:

After fixing the quote problem, I'm still getting this error from dpkg itself:

(Reading database ... 128812 files and directories currently installed.)
Preparing to replace accumulo-native 1.4.1 (using accumulo-native_1.4.1-amd64.deb) ...
Unpacking replacement accumulo-native ...
Setting up accumulo-native (1.4.1) ...
cd: 25: can't cd to /usr/lib/accumulo/src/server/src/main/c++
make: *** No targets specified and no makefile found.  Stop.
dpkg: error processing accumulo-native (--install):
 subprocess installed post-installation script returned error exit status 2
Errors were encountered while processing:
 accumulo-native

After investigating the error I've found that dpkg seems to make all the new files in directories with the suffix .dpkg-new, and then it renames them at some point. I was unable to determine via a casual google if this should happen before or after the postinst script is run, but I'm wondering if the assumption that the makefile and its dependencies will have their normal names is an error.

Either way, that shouldn't cause the cd command to fail (although it might cause the subsequent 'make' command to fail). I'm unsure at this point why cd is failing because it appears that dpkg unpacks the data.tar.gz file (although with its contents renamed), which I determined from running ls while dpkg is running.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-788,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-02 23:11:48.953,,,no_permission,,,,,,,,,,,,244042,,,Wed Jan 02 23:13:19 UTC 2013,,,,,,0|i05fhb:,29605,,,,,,,,"02/Jan/13 23:11;hudson;Integrated in Accumulo-Trunk #601 (See [https://builds.apache.org/job/Accumulo-Trunk/601/])
    Merging ACCUMULO-789 1428098 to trunk (Revision 1428099)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/packages
* /accumulo/trunk/packages/deb/accumulo-native/postinst
* /accumulo/trunk/packages/deb/accumulo/postinst
","02/Jan/13 23:13;hudson;Integrated in Accumulo-1.4.x #263 (See [https://builds.apache.org/job/Accumulo-1.4.x/263/])
    ACCUMULO-789 - went through debian scripts and gave them some overall loving. They should run well now (Revision 1428098)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.4/pom.xml
* /accumulo/branches/1.4/src/packages/deb/accumulo-native/postinst
* /accumulo/branches/1.4/src/packages/deb/accumulo/postinst
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Debian native package postinst scripts reference a bare $JAVA_HOME environment variable,ACCUMULO-788,12610615,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ekohlwey,ekohlwey,ekohlwey,05/Oct/12 18:49,02/Jan/13 22:26,13/Mar/19 22:01,02/Jan/13 21:19,1.4.1,1.4.2,,,,,,1.4.3,1.5.0,,,,,,,,0,Packaging,,,,"The postinst native debian package scripts reference a bare $JAVA_HOME library in two places that will cause them to fail if $JAVA_HOME is unset or contains spaces.

The variable should be quoted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-02 22:20:18.236,,,no_permission,,,,,,,,,,,,244040,,,Wed Jan 02 22:26:00 UTC 2013,,,,,,0|i05fgv:,29603,,,,,,,,"02/Jan/13 22:20;hudson;Integrated in Accumulo-Trunk #600 (See [https://builds.apache.org/job/Accumulo-Trunk/600/])
    ACCUMULO-788 - merging 1428054 (Revision 1428055)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/packages/deb/accumulo-native/postinst
* /accumulo/trunk/packages/deb/accumulo/postinst
* /accumulo/trunk/server
* /accumulo/trunk/src
","02/Jan/13 22:26;hudson;Integrated in Accumulo-1.4.x #262 (See [https://builds.apache.org/job/Accumulo-1.4.x/262/])
    ACCUMULO-788 - quoting JAVA_HOME (Revision 1428054)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.4/src/packages/deb/accumulo-native/postinst
* /accumulo/branches/1.4/src/packages/deb/accumulo/postinst
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create directory for debug logs,ACCUMULO-832,12613484,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,kturner,kturner,25/Oct/12 13:30,02/Jan/13 22:20,13/Mar/19 22:01,02/Jan/13 20:33,1.4.0,1.4.1,1.4.2,,,,,1.5.0,,,,,,,,,0,newbie,,,,"While evaluating the 1.4.2 tarball, I noticed the empty logs dir was missing.  With default config, this needs to be create before accumulo will start.  It would be nice if this were there for new users.  

Seems like we have the following options : 

 * create in svn (does not work well w/ git)
 * create at build time (i.e. maven puts empty dir in tarball)
 * create at run time (scripts that start services create dir if needed)

I kinda like the run time option.  This way the dir will be created even when the user changes the config.

I think we used to have an empty dir in the tar ball.  Can not remember if this was in svn or created by maven, but it seems that was lost somehow.  

Not sure if we should do something for 1.4.  It seems like we should since this an unnecessary speed bump for new users.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-02 20:57:21.185,,,no_permission,,,,,,,,,,,,251022,,,Wed Jan 02 22:20:18 UTC 2013,,,,,,0|i0b3bj:,62650,,,,,,,,"02/Jan/13 20:57;ecn;John, can you alter the scripts to check for a failure to create ACCUMULO_LOG_DIR?","02/Jan/13 21:19;hudson;Integrated in Accumulo-Trunk #599 (See [https://builds.apache.org/job/Accumulo-Trunk/599/])
    ACCUMULO-832 - accumulo script will now make ACCUMULO_LOG_DIR if it does not exist. Explicit check for ACCUMULO_LOG_DIR to be set (Revision 1428004)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/trunk/bin/accumulo
","02/Jan/13 22:20;hudson;Integrated in Accumulo-Trunk #600 (See [https://builds.apache.org/job/Accumulo-Trunk/600/])
    ACCUMULO-832 - now mkdir -p (Revision 1428082)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/trunk/bin/accumulo
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Debian packages rely on old hadoop-zookeeper package,ACCUMULO-787,12610611,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,ekohlwey,ekohlwey,05/Oct/12 18:46,02/Jan/13 20:19,13/Mar/19 22:01,02/Jan/13 19:14,1.4.1,1.4.2,,,,,,1.4.3,1.5.0,,,,,,,,0,,,,,"The accumulo debian packages rely on hadoop-zookeeper, which is not a standard package name for zookeeper outside of CDH3.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-02 19:57:03.025,,,no_permission,,,,,,,,,,,,244036,,,Wed Jan 02 20:19:29 UTC 2013,,,,,,0|i05ffz:,29599,,,,,,,,"02/Jan/13 19:57;hudson;Integrated in Accumulo-Trunk #598 (See [https://builds.apache.org/job/Accumulo-Trunk/598/])
    ACCUMULO-787 - Merging 1427919 (Revision 1427920)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/packages/deb/accumulo/control
* /accumulo/trunk/server
* /accumulo/trunk/src
","02/Jan/13 20:19;hudson;Integrated in Accumulo-1.4.x #260 (See [https://builds.apache.org/job/Accumulo-1.4.x/260/])
    ACCUMULO-787 - switching dependency to vanilla zookeeper (Revision 1427919)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.4/src/packages/deb/accumulo/control
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stop-server has unecessary SSHs,ACCUMULO-921,12624890,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,20/Dec/12 21:04,02/Jan/13 18:17,13/Mar/19 22:01,02/Jan/13 17:08,1.4.2,,,,,,,1.4.3,1.5.0,,scripts,,,,,,0,,,,,stop-server only checks for the argument to match `hostname` without doing any further checks like those which were added to start-server.sh. We should propagate these changes over.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-02 18:11:15.079,,,no_permission,,,,,,,,,,,,301404,,,Wed Jan 02 18:17:15 UTC 2013,,,,,,0|i16se7:,247732,,,,,,,,"02/Jan/13 18:11;hudson;Integrated in Accumulo-Trunk #597 (See [https://builds.apache.org/job/Accumulo-Trunk/597/])
    ACCUMULO-921 -merging 1427864 (Revision 1427869)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/bin/start-server.sh
* /accumulo/trunk/bin/stop-server.sh
","02/Jan/13 18:17;hudson;Integrated in Accumulo-1.4.x #259 (See [https://builds.apache.org/job/Accumulo-1.4.x/259/])
    ACCUMULO-921 - fixing unecessary SSH, also making arguments a bit more safe (and bourne friendly) (Revision 1427864)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.4/bin/start-server.sh
* /accumulo/branches/1.4/bin/stop-server.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
getConnector in MockAccumulo clobber's existing user authorizations,ACCUMULO-912,12624372,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,17/Dec/12 23:40,02/Jan/13 16:28,13/Mar/19 22:01,02/Jan/13 16:28,1.4.1,1.4.2,,,,,,1.4.3,1.5.0,,client,,,,,,0,,,,,"If a user exists in MockAccumulo with a set of authorizations, and you do a getConnector for the user, it will clobber that user's authorizations and remake them. It should do a check before creating the internal user object. On top of that, it should also check the password if the user does exist.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-18 16:38:13.748,,,no_permission,,,,,,,,,,,,299211,,,Tue Dec 18 21:26:57 UTC 2012,,,,,,0|i160a7:,243178,,,,,,,,"18/Dec/12 16:38;hudson;Integrated in Accumulo-1.4.x #253 (See [https://builds.apache.org/job/Accumulo-1.4.x/253/])
    Accumulo-912 - no password clobbering, bonus password checking (Revision 1423518)

     Result = UNSTABLE","18/Dec/12 16:42;hudson;Integrated in Accumulo-Trunk #583 (See [https://builds.apache.org/job/Accumulo-Trunk/583/])
    Accumulo-912 - Merging to trunk (Revision 1423519)

     Result = UNSTABLE",18/Dec/12 17:13;vines;I broke tests,"18/Dec/12 18:37;hudson;Integrated in Accumulo-1.4.x #254 (See [https://builds.apache.org/job/Accumulo-1.4.x/254/])
    ACCUMULO-912 - fixing tests for fixed Mock (Revision 1423547)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.4/src/core/src/test/java/org/apache/accumulo/core/client/admin/FindMaxTest.java
* /accumulo/branches/1.4/src/examples/wikisearch/query/src/test/java/org/apache/accumulo/examples/wikisearch/logic/TestQueryLogic.java
* /accumulo/branches/1.4/src/server/src/test/java/org/apache/accumulo/server/gc/TestConfirmDeletes.java
* /accumulo/branches/1.4/src/server/src/test/java/org/apache/accumulo/server/master/TestMergeState.java
","18/Dec/12 21:26;hudson;Integrated in Accumulo-Trunk #584 (See [https://builds.apache.org/job/Accumulo-Trunk/584/])
    ACCUMULO-912 - fixing broken tests (Revision 1423636)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/master/thrift/TabletServerStatus.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/admin/FindMaxTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/command/FormatterCommandTest.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/gc/TestConfirmDeletes.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/master/TestMergeState.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need age off finished fate operations,ACCUMULO-785,12610570,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,05/Oct/12 14:20,28/Dec/12 04:16,13/Mar/19 22:01,28/Dec/12 03:40,,,,,,,,1.5.0,,,,,,,,,0,,,,,When a fate operation finishes and the client never checks for the result an entry is left in zookeeper forever.,,,,,,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-28 04:16:53.715,,,no_permission,,,,,,,,,,,,243524,,,Fri Dec 28 04:16:53 UTC 2012,,,,,,0|i03j3z:,18529,,,,,,,,"28/Dec/12 04:16;hudson;Integrated in Accumulo-Trunk #594 (See [https://builds.apache.org/job/Accumulo-Trunk/594/])
    ACCUMULO-785 added code to age off old finished FATE ops.  Also fixed Fate Admin util. (Revision 1426384)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/AdminUtil.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/AgeOffStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/TStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/test/java/org/apache/accumulo/fate/AgeOffStoreTest.java
* /accumulo/trunk/fate/src/test/java/org/apache/accumulo/fate/SimpleStore.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/fate/Admin.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
VFS unit tests fail on Hadoop FS check,ACCUMULO-908,12624155,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,elserj,elserj,elserj,16/Dec/12 03:23,25/Dec/12 04:15,13/Mar/19 22:01,25/Dec/12 03:21,,,,,,,,1.5.0,,,start,,,,,,0,,,,,"AccumuloReloadingVFSClassLoaderTest and VfsClassLoaderTest both fail for me on an assertion ""Wrong FS: hdfs://localhost:8620/test-dir, expected: hdfs://localhost.localdomain:8620"". I would guess that there's something better to specify in these tests to make them work on all platforms?

{noformat}
testReloading(org.apache.accumulo.start.classloader.vfs.AccumuloReloadingVFSClassLoaderTest)  Time elapsed: 0.008 sec  <<< ERROR!
java.lang.IllegalArgumentException: Wrong FS: hdfs://localhost:8620/test-dir, expected: hdfs://localhost.localdomain:8620
        at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:381)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:129)
        at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:321)
        at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1126)
        at org.apache.accumulo.start.classloader.vfs.AccumuloReloadingVFSClassLoaderTest.setup(AccumuloReloadingVFSClassLoaderTest.java:44)
{noformat}","CentOS 5.7, Maven 3.0.4, Oracle JRE 1.6.0_30",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-18 18:51:29.389,,,no_permission,,,,,,,,,,,,298532,,,Tue Dec 25 04:15:04 UTC 2012,,,,,,0|i15t87:,242035,,,,,,,,18/Dec/12 17:13;elserj;I'm not actively working on this.,"18/Dec/12 18:51;vines;I'm getting a similar issue with a majority of the tests, mayor may not be the same -

Wrong FS: hdfs://localhost:8020/test-dir, expected: hdfs://localhost:8620","18/Dec/12 19:59;elserj;Perhaps the difference in domain is a red-herring in regards to the real issue? What's your platform/environment, vines?","18/Dec/12 20:08;vines;This is on ubuntu12.04, happens in both eclipse and mvn command line

Sent from my phone, please pardon the typos and brevity.

",18/Dec/12 20:57;vines;And now it works for me. Interesting.,"18/Dec/12 20:57;vines;Unless I inadvertently fixed it with the classloader changes, but I don't think so.","25/Dec/12 03:20;elserj;Fixed for me in r1425709. The tests as previously written failed if the FQDN for 127.0.0.1 is anything other than ""localhost"".

[~vines], if you can replicate again, can you see if the changes fixes it for you as well?",25/Dec/12 03:21;elserj;Fixed in r1425709,"25/Dec/12 04:15;hudson;Integrated in Accumulo-Trunk #592 (See [https://builds.apache.org/job/Accumulo-Trunk/592/])
    ACCUMULO-908 Fix VFS unit test cases which fail when run on any system which specifies a FQDN for 127.0.0.1 other than ""localhost"" (Revision 1425709)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/trunk/start/src/test/java/org/apache/accumulo/start/classloader/vfs/AccumuloVFSClassLoaderTest.java
* /accumulo/trunk/start/src/test/java/org/apache/accumulo/test/AccumuloDFSBase.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
System throws no errors on !METADATA table constraint violations,ACCUMULO-322,12538854,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,vines,jvines,18/Jan/12 18:18,20/Dec/12 16:15,13/Mar/19 22:01,20/Dec/12 15:18,1.4.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"After messing around with constraints, I ended up putting a Numeric Value Constraint on the whole system. This caused the !METADATA table to be constrained against updating after a restart. While there are larger issues at hand regarding system level constraints (I will be putting in more tickets around this), we should look into why there are ZERO error messages in the logs about this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-20 16:15:25.768,,,no_permission,,,,,,,,,,,,224357,,,Thu Dec 20 16:15:25 UTC 2012,,,,,,0|i07nvr:,42635,,,,,,,,"20/Dec/12 16:15;hudson;Integrated in Accumulo-Trunk #588 (See [https://builds.apache.org/job/Accumulo-Trunk/588/])
    ACCUMULO-322 do not hide errors writing to the !METADATA table (Revision 1424517)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/Writer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/EventCoordinator.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
sometimes loggers don't stop,ACCUMULO-848,12615539,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,09/Nov/12 19:12,19/Dec/12 23:00,13/Mar/19 22:01,19/Dec/12 20:43,1.4.1,,,,,,,1.4.3,,,logger,scripts,,,,,0,,,,,"Sometimes stop-all does not stop loggers.  I cannot reliably reproduce it, but if someone can, please investigate.",large cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-09 19:20:00.365,,,no_permission,,,,,,,,,,,,256827,,,Wed Dec 19 23:00:02 UTC 2012,,,,,,0|i0iwef:,108343,,,,,,,,09/Nov/12 19:20;elserj;I've noticed this before on a single node; monitor and gc also didn't stop if memory serves. I haven't ever taken the time to look into it. Will try to keep my eyes open for it again,"09/Nov/12 19:26;kturner;Looking at the code, I think I see one issue.  LogService.process() does not reregister the watch.   Zookeeper watches only fire once.   ",19/Dec/12 20:43;ecn;fixed with 1424099,"19/Dec/12 22:50;hudson;Integrated in Accumulo-Trunk #586 (See [https://builds.apache.org/job/Accumulo-Trunk/586/])
    ACCUMULO-848 tracer has the same issue as the logger (stupid cut-n-paste) (Revision 1424115)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
","19/Dec/12 23:00;hudson;Integrated in Accumulo-1.4.x #256 (See [https://builds.apache.org/job/Accumulo-1.4.x/256/])
    ACCUMULO-848 tracer has the same issue as the logger (stupid cut-n-paste) (Revision 1424145)
ACCUMULO-848 reset the watch on our registration in zookeeper (Revision 1424099)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java

ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/logger/LogService.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AddFilesWithMissingEntries adds tmp files,ACCUMULO-709,12600884,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,31/Jul/12 16:46,19/Dec/12 22:50,13/Mar/19 22:01,19/Dec/12 21:40,,,,,,,,1.5.0,,,,,,,,,0,newbie,,,,"The little utility AddFilesWithMissingEntries adds tmp files.  It should not do this.  Also, it will not reference bulk files.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-19 21:40:19.686,,,no_permission,,,,,,,,,,,,246361,,,Wed Dec 19 22:50:10 UTC 2012,,,,,,0|i07ljr:,42257,,,,,,,,"31/Jul/12 16:55;kturner;Maybe this little utility should be transformed.  It could finds all files that are not referenced by the metadata table and move them out for bulk import.  It could look for reference from tablets and delete entries.

In addition to not handling bulk imports, the tool does not handle the case of tablet dirs that are not referenced.  This could happen if the user reverts to an older version of the metadata table, and newer tablets that were created are not referenced.

","19/Dec/12 21:40;ecn;Fixed with r1424150, created ticket ACCUMULO-917 for further improvements.","19/Dec/12 22:50;hudson;Integrated in Accumulo-Trunk #586 (See [https://builds.apache.org/job/Accumulo-Trunk/586/])
    ACCUMULO-709 do not add _tmp files to tables (Revision 1424150)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/AddFilesWithMissingEntries.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ACCUMULO_LOG_HOST is set incorrectly,ACCUMULO-852,12615883,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,13/Nov/12 12:59,19/Dec/12 22:50,13/Mar/19 22:01,19/Dec/12 20:36,,,,,,,,1.5.0,,,scripts,,,,,,0,,,,,"I put the monitor on a different host than the master, and didn't get any log messages.

This setting:
{noformat}
export ACCUMULO_LOG_HOST=`(grep -v '^#' $ACCUMULO_HOME/conf/masters ; echo localhost ) 2>/dev/null | head -1`
{noformat}
should read from monitors, not masters.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-19 22:50:10.58,,,no_permission,,,,,,,,,,,,257368,,,Wed Dec 19 22:50:10 UTC 2012,,,,,,0|i0jy5r:,114466,,,,,,,,19/Dec/12 20:36;ecn;fixed in  1424092,"19/Dec/12 22:50;hudson;Integrated in Accumulo-Trunk #586 (See [https://builds.apache.org/job/Accumulo-Trunk/586/])
    ACCUMULO-852 logs are forwarded to the monitor (Revision 1424092)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/trunk/conf/examples/1GB/native-standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/1GB/standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/2GB/native-standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/2GB/standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/512MB/native-standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-env.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Junit tests in eclipse fail due to Classloader poorly parsing classpath locations,ACCUMULO-914,12624524,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,vines,vines,vines,18/Dec/12 20:26,18/Dec/12 21:26,13/Mar/19 22:01,18/Dec/12 20:41,1.4.2,,,,,,,1.4.3,1.5.0,,start,,,,,,0,,,,,"Accumulo uses $ACCUMULO_HOME/lib/ext/[.*].jar to find files to watch. If ACCUMULO_HOME isn't set (like in a test environment such as eclipse), it drops the $ACCUMULO_HOME. From there, it ends up turning it into watching /lib. On OSX, which a majority of the developers here use, it's not an issue. However, watching /lib introduces a heapload of issues. I do not know why this does not affect mvn tests, I didn't dig into it.

I think if ACCUMULO_HOME isn't set, we should just ignore that directory (instead of inserting empty string for the portion).","eclipse, ubuntu 12.04",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-18 21:16:58.044,,,no_permission,,,,,,,,,,,,300345,,,Tue Dec 18 21:26:57 UTC 2012,,,,,,0|i167cv:,244324,,,,,,,,"18/Dec/12 21:16;hudson;Integrated in Accumulo-1.4.x #255 (See [https://builds.apache.org/job/Accumulo-1.4.x/255/])
    ACCUMULO-914 - drop entries which use an unset environment variable (Revision 1423624)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.4/src/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java
","18/Dec/12 21:26;hudson;Integrated in Accumulo-Trunk #584 (See [https://builds.apache.org/job/Accumulo-Trunk/584/])
    Merging ACCUMULO-914 (Revision 1423633)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tup.sh script can run out of file descriptors on large numbers of nodes,ACCUMULO-237,12536420,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,ecn,ecn,27/Dec/11 14:53,18/Dec/12 18:39,13/Mar/19 22:01,27/Dec/11 14:54,1.3.5-incubating,,,,,,,1.3.6,,,scripts,,,,,,0,,,,,"The number of concurrent ssh jobs started on a large cluster can exceed the number of allowed file descriptors for a single user. A fix exists in the 1.4 branch: back-port it to 1.3.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,222103,,,2011-12-27 14:53:04.0,,,,,,0|i07oe7:,42718,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DeleteMany breaks with aggregators/combiners,ACCUMULO-413,12542961,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,16/Feb/12 22:38,18/Dec/12 18:39,13/Mar/19 22:01,16/Feb/12 22:47,1.3.5-incubating,,,,,,,1.3.6,1.4.0,,,,,,,,0,,,,,"DeleteMany runs an iterator which replaces the Value with NOVALUE because it doesn't make sense to pull back values. This runs at priority 1, so if you have an aggregator expecting things at a level above it, then it could break hard, preventing the deletemany to work. The priority for this iterator should be maxint.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,228247,,,2012-02-16 22:38:29.0,,,,,,0|i07ncf:,42548,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix random walk start script to not require environment variables,ACCUMULO-345,12539635,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,ecn,ecn,24/Jan/12 17:19,18/Dec/12 18:39,13/Mar/19 22:01,31/Jan/12 14:49,,,,,,,,1.4.0,,,test,,,,,,0,,,,,"The scripts should figure out ACCUMULO_HOME and HADOOP_HOME using accumulo-env.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,225137,,,2012-01-24 17:19:23.0,,,,,,0|i07nqn:,42612,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AccumuloInputFormat and AccumuloOutputFormat configuration methods don't match,ACCUMULO-310,12538228,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,afuchs,afuchs,12/Jan/12 16:56,18/Dec/12 18:39,13/Mar/19 22:01,12/Jan/12 19:17,1.4.0,,,,,,,1.4.0,,,client,,,,,,0,,,,,"setInputInfo and setZooKeeperInstance on AccumuloInputFormat take a Configuration (JobContext input is deprecated), while setOutputInfo and setZooKeeperInstance on AccumuloOutputFormat take only a JobContext. These should probably at least match each other.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-12 19:17:28.098,,,no_permission,,,,,,,,,,,,223734,,,Thu Jan 12 19:17:28 UTC 2012,,,,,,0|i07ny7:,42646,,,,,,,,12/Jan/12 19:17;jvines;All better,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
simple.gc.GCLotsOfCandidatesTest does not use the TestUtils settings properly,ACCUMULO-108,12529697,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,01/Nov/11 16:53,18/Dec/12 18:39,13/Mar/19 22:01,01/Nov/11 16:55,,,,,,,,1.4.0,1.5.0,,,,,,,,0,,,,,"simple.gc.GCLotsOfCandidatesTest does not load the default settings and update them as needed, instead using the defaults. This leads to the tserver dying (and test stalling) due to memory errors.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215556,,,2011-11-01 16:53:29.0,,,,,,0|i07p67:,42844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TableOperations.getProperties forces an HDFSZooInstance even if ZooKeeperInstance is used,ACCUMULO-567,12553480,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,01/May/12 12:37,18/Dec/12 18:39,13/Mar/19 22:01,03/May/12 16:48,1.3.5-incubating,,,,,,,1.3.6,,,client,,,,,,0,,,,,"The bug stems from the getZooConfiguration call in CBConfiguration.getTableConfiguration. We should get the instance object passed in through to that getZooConfiguration call, which will set the instance to that instance rather then HDFSZooInstance.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,237644,,,2012-05-01 12:37:30.0,,,,,,0|i07men:,42396,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dependency is not satisfiable:accumulo(=1.4.1),ACCUMULO-680,12598120,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,yhjhoo,yhjhoo,10/Jul/12 02:00,18/Dec/12 18:39,13/Mar/19 22:01,10/Jul/12 17:24,1.4.1,,,,,,,,,,,,,,,,0,,,,,"During the first installation I encounter this issue, can not going on",Ubuntu 12.04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-07-10 02:19:04.252,,,no_permission,,,,,,,,,,,,246387,,,Tue Jul 10 17:23:53 UTC 2012,,,,,,0|i07lpj:,42283,,,,,,,,10/Jul/12 02:19;jvines;Are you using the accumulo_native deb on the downloads page?,"10/Jul/12 03:55;yhjhoo;Yes, i am using the deb on the download page.",10/Jul/12 17:23;jvines;I have updated the downloads page to include both the native and the core. The native deb is dependant on the core deb.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE when getting user authorizations,ACCUMULO-328,12538987,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,kturner,kturner,19/Jan/12 16:01,18/Dec/12 18:39,13/Mar/19 22:01,19/Jan/12 17:41,,,,,,,,1.4.0,,,client,tserver,,,,,0,14_qa_bug,,,,"While running the concurrent random walk test, saw the following bug.  I think a user was deleted at around the same time the request for user auths came in.

Saw the follwing error in the random walk logs.

{noformat}
19 01:42:10,810 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Concurrent.xml
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:253)
        at org.apache.accumulo.server.test.randomwalk.Framework.run(Framework.java:61)
        at org.apache.accumulo.server.test.randomwalk.Framework.main(Framework.java:114)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:89)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node ct.ChangeAuthorizations
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:253)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:249)
        ... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloException: org.apache.thrift.TApplicationException: Internal error processing getUserAuthorizations
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.execute(SecurityOperationsImpl.java:78)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.getUserAuthorizations(SecurityOperationsImpl.java:221)
        at org.apache.accumulo.server.test.randomwalk.concurrent.ChangeAuthorizations.visit(ChangeAuthorizations.java:43)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:249)
        ... 9 more
Caused by: org.apache.thrift.TApplicationException: Internal error processing getUserAuthorizations
        at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$Client.recv_getUserAuthorizations(ClientService.java:644)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$Client.getUserAuthorizations(ClientService.java:625)
        at sun.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at cloudtrace.instrument.thrift.TraceWrap$2.invoke(TraceWrap.java:83)
        at $Proxy0.getUserAuthorizations(Unknown Source)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl$6.execute(SecurityOperationsImpl.java:224)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl$6.execute(SecurityOperationsImpl.java:221)
        at org.apache.accumulo.core.client.impl.ServerClient.executeRaw(ServerClient.java:84)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.execute(SecurityOperationsImpl.java:66)
        ... 12 more
{noformat}

Searched the tablet server logs by time to find the server that execute the security operation and found the following.

{noformat}

19 01:42:10,808 [thrift.ClientService$Processor] ERROR: Internal error processing getUserAuthorizations
java.lang.IllegalArgumentException: argument was null:Is null- arg1? true
        at org.apache.accumulo.core.util.ArgumentChecker.notNull(ArgumentChecker.java:31)
        at org.apache.accumulo.core.security.Authorizations.<init>(Authorizations.java:102)
        at org.apache.accumulo.server.security.ZKAuthenticator$Tool.convertAuthorizations(ZKAuthenticator.java:641)
        at org.apache.accumulo.server.security.ZKAuthenticator.getUserAuthorizations(ZKAuthenticator.java:341)
        at org.apache.accumulo.server.security.Auditor.getUserAuthorizations(Auditor.java:137)
        at org.apache.accumulo.server.client.ClientServiceHandler.getUserAuthorizations(ClientServiceHandler.java:145)
        at sun.reflect.GeneratedMethodAccessor44.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at cloudtrace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:58)
        at $Proxy2.getUserAuthorizations(Unknown Source)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$Processor$getUserAuthorizations.process(ClientService.java:2371)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor.process(TabletClientService.java:2037)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:151)
        at org.apache.thrift.server.TNonblockingServer$FrameBuffer.invoke(TNonblockingServer.java:631)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:199)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
{noformat}

Need better debugging info when this occurs on the client side, need to know which tablet server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-19 17:21:59.475,,,no_permission,,,,,,,,,,,,224489,,,Thu Jan 19 17:21:59 UTC 2012,,,,,,0|i07nuf:,42629,,,,,,,,19/Jan/12 17:21;jvines;I was playing fast and loose. Should be more specific about checking values instead of just catching exceptions.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Documentation for 1.3 mis-identifies Authorizations() constructor.,ACCUMULO-253,12537370,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,05/Jan/12 17:59,18/Dec/12 18:39,13/Mar/19 22:01,05/Jan/12 18:04,1.3.5-incubating,,,,,,,1.3.6,,,,,,,,,0,documentation,,,,The user manual for 1.3 defines the constructor for Authorizations as expected a comma-seperated list String. Instead it should be a list of Strings.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,222878,,,2012-01-05 17:59:25.0,,,,,,0|i07oan:,42702,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
mvn clean package is not enough to allow the config.html page to be generated for the monitor,ACCUMULO-102,12529546,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,31/Oct/11 20:31,18/Dec/12 18:39,13/Mar/19 22:01,24/Jan/12 13:25,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,build,docs,monitor,,,,0,docs,maven,,,"mvn clean package will not allow the monitors configuration page to be generated accurately because the config.html page is generated with the core. This will result in attempts to access the monitors documentation->configuration page to fail. Running a second package will remedy this, but it's an ugly solution. Perhaps this can be remedied when we create the distribution module.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-24 13:25:17.023,,,no_permission,,,,,,,,,,,,215406,,,Tue Jan 24 13:25:17 UTC 2012,,,,,,0|i07p7j:,42850,,,,,,,,24/Jan/12 13:25;jvines;This got fixed with the changes I made to the pom file.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
general.dynamic.classpaths property exists but is never used,ACCUMULO-64,12528509,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,24/Oct/11 15:50,18/Dec/12 18:39,13/Mar/19 22:01,26/Oct/11 11:34,1.3.5-incubating,,,,,,,1.4.0,,,start,,,,,,0,classloader,directory,,,"We have a property, general.dynamic.classpaths, used for setting the directories to be dynamically loaded (and reloaded). Unfortunately, this property doesn't actually get used and instead we only utilize the hardcoded lib/ext directory instead. An appropriate test should also be implemented to ensure all of the directories for the class loader are used correctly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-10-26 03:23:43.02,,,no_permission,,,,,,,,,,,,214369,,,Wed Oct 26 03:23:43 UTC 2011,,,,,,0|i07pfz:,42888,,,,,,,,26/Oct/11 03:23;jvines;I broke the build,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Merge tablet fails when tablet have empty files,ACCUMULO-56,12527954,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,kturner,kturner,20/Oct/11 15:52,18/Dec/12 18:39,13/Mar/19 22:01,01/Nov/11 20:52,,,,,,,,1.4.0,,,tserver,,,,,,0,,,,,"While working on ACCUMULO-52, I was trying to think of what problems an empty file could cause.  Major compaction and split seem ok w/ empty files.  The chop operation that is called as part of merge may throw an NPE.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,92368,,,2011-10-20 15:52:22.0,,,,,,0|i07phr:,42896,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE on MasterMonitorInfo also spammy,ACCUMULO-605,12557449,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,24/May/12 14:31,18/Dec/12 18:39,13/Mar/19 22:01,29/May/12 17:51,,,,,,,,1.5.0,,,monitor,,,,,,0,,,,,"Just like ACCUMULO-604, this message started occuring when the master went down. Got the following message-
23 11:06:33,862 [monitor.Monitor] WARN : 
java.lang.NullPointerException
        at org.apache.accumulo.server.monitor.Monitor.fetchData(Monitor.java:320)
        at org.apache.accumulo.server.monitor.Monitor$2.run(Monitor.java:501)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:680)

This message occurred very ~5 seconds or so, and we had instances of it occurring around 7k times as well. The frequency of this and ACCUMULO-604 makes me wonder if we have a weird threading issue, or something along those lines (however, when I jstacked the monitor I didn't see thousands of threads, so I'm doubtful).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-05-24 17:38:40.708,,,no_permission,,,,,,,,,,,,246461,,,Tue May 29 17:51:42 UTC 2012,,,,,,0|i07m67:,42358,,,,,,,,24/May/12 17:38;jvines;Might be a side affect from ACCUMULO-337,"29/May/12 17:51;jvines;May have been a side affect, but we now will ignore the mmi stats if it's null.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LICENSE file (and others) need to be included in any jars we build,ACCUMULO-205,12533648,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,afuchs,afuchs,02/Dec/11 16:05,18/Dec/12 18:39,13/Mar/19 22:01,11/Jan/12 18:09,,,,,,,,1.3.5-incubating,,,,,,,,,0,,,,,"Jars should include LICENSE, CHANGES, NOTICE, DISCLAIMER in the META-INF directory.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,219375,,,2011-12-02 16:05:43.0,,,,,,0|i07ol3:,42749,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accumulo debian packaging does not handle JAVA_HOMEs properly,ACCUMULO-435,12544541,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,29/Feb/12 00:51,18/Dec/12 18:39,13/Mar/19 22:01,02/Mar/12 15:53,,,,,,,,1.4.0,,,build,,,,,,0,,,,,"the Accumulo native scripts for building the native libraries do not resolve java home accurately. we should handle a better variety of java installations. Additionally, the scripts for updating the env examples to use the appropriate paths suffer from teh same issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,229727,,,2012-02-29 00:51:20.0,,,,,,0|i07n7j:,42526,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
thrift.sh does not point to the correct directories,ACCUMULO-26,12526915,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,12/Oct/11 19:32,18/Dec/12 18:39,13/Mar/19 22:01,14/Oct/11 13:43,,,,,,,,1.3.5-incubating,,,rpc,,,,,,0,thrift,,,,thrift.sh in 1.3.5 does not use the correct directories.,,,,,,,,,,,,,,,,,,,,,,,,600,600,,0%,600,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,74284,,,2011-10-12 19:32:56.0,,,,,,0|i07pof:,42926,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mapreduce API should not use JobContext to set configuration information,ACCUMULO-267,12537412,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,05/Jan/12 20:18,18/Dec/12 18:39,13/Mar/19 22:01,20/Sep/12 17:32,,,,,,,,1.4.0,,,client,,,,,,0,mapreduce,,,,"JobContext specifically says that it is a read-only view of job information. Our inputformat's configuration calls take JobContext as an input, rip out the Configuration object, and writes to it.

Instead, calls should just take in a Configuration object directly (or a Job object, but that passes in more information than is needed, and can cause discrepancies depending on which mapreduce api).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-06 21:28:06.151,,,no_permission,,,,,,,,,,,,222920,,,Thu Sep 20 17:31:49 UTC 2012,,,,,,0|i07o7j:,42688,,,,,,,,06/Jan/12 21:28;jvines;We should fix in 1.4 so we can deprecate it there and remove in 1.5,"20/Sep/12 17:21;ctubbsii;This is the wrong way to go about doing this fix. The reason why it took a JobContext is so that it could accept a ""Job"" object. This was modeled after the pattern Hadoop was using for FileOutputFormat, which is somewhat the standard for conventions in configuring MR jobs.

While JobContext does specifically state that's what it's purpose is, it is a base class, and Job extends JobContext, and includes a comment that describes it as holding the state of the job at submission time. This API should really be taking a ""Job"" object, rather than a ""JobContext"" object. Further, because Job is the only JobContext that actually works as intended here, the change from JobContext to Job does not require any deprecation, because Job will still work, and any other JobContext that isn't a Job will still fail. (We *would* have to deprecate the ones that were added in 1.4 that took a Configuration object, though... because those were never ""correct"", if we are going off of the conventions set by Hadoop's provided OutputFormats).

It is somewhat annoying to deprecate something in 1.5 that was added in 1.4... especially since it allows people to go back to what they were doing before. But, I think it might be worth it to be consistent with the established conventions, and to clarify the semantics of the methods (we are, after all, modifying the state of a job we are about to submit, and not just an arbitrary configuration, which is used for all sorts of things).",20/Sep/12 17:31;ctubbsii;New ticket created for the previous comment: see ACCUMULO-769,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tar contains contents of logs and walogs directories - maybe others,ACCUMULO-177,12532494,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,23/Nov/11 16:58,18/Dec/12 18:39,13/Mar/19 22:01,28/Nov/11 17:02,,,,,,,,,,,build,,,,,,0,,,,,"My refactoring of the maven code has resulted in files ending up in the tgz that shouldn't belong. These include, but may not be limited to, contents of the logs and walogs directories. This MUST be fixed and we need to check this for other possible directories/files as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-11-28 17:02:42.041,,,no_permission,,,,,,,,,,,,218227,,,Mon Nov 28 17:02:42 UTC 2011,,,,,,0|i07orb:,42777,,,,,,,,"28/Nov/11 17:02;jvines;Bug was introduced in the trunk, so it shouldn't be a standing issue anywhere. dist.xml was slightly refactored to cover this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
error running Concurrent randomwalk test,ACCUMULO-686,12598606,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,ecn,ecn,12/Jul/12 19:51,18/Dec/12 18:39,13/Mar/19 22:01,12/Jul/12 19:59,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"{noformat}

ava.lang.Exception: Error running node Concurrent.xml
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:259)
        at org.apache.accumulo.server.test.randomwalk.Framework.run(Framework.java:61)
        at org.apache.accumulo.server.test.randomwalk.Framework.main(Framework.java:116)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:87)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node ct.StopTabletServer
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:259)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
        ... 8 more
Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /accumulo/69f0ae98-dd92-4af4-b522-1e237aba5777/tservers/192.168.117.12:9997
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:102)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)
        at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1243)
        at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1271)
        at org.apache.accumulo.fate.zookeeper.ZooReader.getChildren(ZooReader.java:56)
        at org.apache.accumulo.server.test.randomwalk.concurrent.StopTabletServer.getTServers(StopTabletServer.java:29)
        at org.apache.accumulo.server.test.randomwalk.concurrent.StopTabletServer.visit(StopTabletServer.java:47)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
        ... 9 more
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246382,,,2012-07-12 19:51:37.0,,,,,,0|i07lof:,42278,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accumulo Output Format can create numerous empty files,ACCUMULO-55,12527935,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,20/Oct/11 14:53,18/Dec/12 18:39,13/Mar/19 22:01,15/Nov/11 17:21,1.3.5-incubating,,,,,,,1.4.0,,,client,,,,,,0,empty,file,output_format,,"In conjuction with Accumulo-52, large amounts of empty files can cause problems. The short problem is when a reducer is empty, due to the partitioner used, the file for it will still be created. We do not want empty files lingering around, especially do not want them bulk imported. It should be as simple as either not creating the file until a write on it is attempted (more complex) or the file should be deleted at close time if there were no records written (simpler but more overhead due to file creation and deletion in the process).

Due to the complexity of the patch, I do not think it should be applied before the 1.4 version. It should simply delete the file after closing it if there are no writes to the file.

EDIT: As of 1.4 we now delete empty files on close() in the RecordWriter. I would like to implement a more robust version which does not create a file until the first write. I will do this for version 1.5 so as not to worry about breaking things.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-11-15 17:21:30.658,,,no_permission,,,,,,,,,,,,92346,,,Tue Nov 15 17:21:30 UTC 2011,,,,,,0|i07phz:,42897,,,,,,,,15/Nov/11 17:21;jvines;Fixed for 1.4 with somewhat hacky solution,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
eclipse is getting an NPE when using M2E to look at the pom.xml,ACCUMULO-219,12534980,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,kturner,kturner,13/Dec/11 16:48,18/Dec/12 18:39,13/Mar/19 22:01,14/Dec/11 16:28,,,,,,,,1.3.6,,,,,,,,,0,,,,,"When checking out any of the accumulo projects as maven projects in eclipse, you get an NPE.  This seems to have started when the <resources> section was added the <build> section in the top level pom. If I comment out the <resources> section and tell maven to update in eclipse, then it is happy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-12-14 16:28:54.403,,,no_permission,,,,,,,,,,,,220664,,,Wed Dec 14 16:28:54 UTC 2011,,,,,,0|i07oi7:,42736,,,,,,,,14/Dec/11 16:28;jvines;Fixed by letting apache-10 do the work.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Complain loudly when env file is missing,ACCUMULO-585,12554723,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,10/May/12 17:55,18/Dec/12 18:39,13/Mar/19 22:01,16/May/12 15:19,1.4.0,,,,,,,1.4.1,,,scripts,,,,,,0,,,,,"With the creation of example configurations, we made it really easy for users to get started. Unfortunately, we also took away the default nature to copy a configuration and move on. This can lead to problems when a user tried to run it out of the box without any sort of configuration. It will default to using 5 or 10g of memory total, without the user being aware of it until things start swapping.

Now that we have the sample configurations, if accumulo-env.sh isn't there, we should error out instead of poorly guestimating these values.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-05-16 02:03:36.957,,,no_permission,,,,,,,,,,,,238973,,,Wed May 16 15:19:32 UTC 2012,,,,,,0|i07man:,42378,,,,,,,,"16/May/12 02:03;ecn;It would be good if it tested the three destinations exist and fail-fast.  I think it does that for HADOOP_HOME now.
","16/May/12 14:21;jvines;I'm not disagreeing that it would be good, but I'm wondering if that's something we really need to get done in the 1.4 branch. I imagine a lot will change with the refactor of the scripts in 1.5",16/May/12 15:01;jvines;I broke the python tests,16/May/12 15:19;jvines;I think we're really done this time.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockBatchScanner is broken,ACCUMULO-309,12538208,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,12/Jan/12 15:31,18/Dec/12 18:39,13/Mar/19 22:01,12/Jan/12 16:31,1.4.0,,,,,,,,,,,,,,,,0,,,,,"In my attempt to test a potential fix for ACCUMULO-175, I discovered the following code did not return any results-
{noformat}
public class TestRunningAgainstMock {
  public static void main(String[] args) throws AccumuloException, AccumuloSecurityException, TableExistsException, TableNotFoundException,
      InterruptedException
  {
    MockInstance mi = new MockInstance(""test"");
    Connector conn = mi.getConnector(""root"", new byte[0]);
    conn.tableOperations().create(""testTable"", true);
    Mutation m = new Mutation(""row"");
    m.put(""cf"", ""cq"", ""val"");
    BatchWriter bw = conn.createBatchWriter(""testTable"", 500, 500, 1);
    bw.addMutation(m);
    bw.flush();
    bw.close();
    Scanner bs = conn.createBatchScanner(""testTable"", new Authorizations(), 1);
    Iterator<Entry<Key,Value>> iter = bs.iterator();
    if (!iter.hasNext())
      System.out.println(""No values"");
    while (iter.hasNext())
      System.out.println(iter.next());
  }
}{noformat}

Switching it to a regular scanner did work though.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-12 16:31:02.636,,,no_permission,,,,,,,,,,,,223714,,,Thu Jan 12 16:31:02 UTC 2012,,,,,,0|i07nyf:,42647,,,,,,,,"12/Jan/12 16:31;jvines;Error was on my end, I never set the range. However, MockBatchScanner should more closely emulate the behavior of TabletServerBatchScanner, so I went ahead and changed it's setup behavior to error the same way the real batchScanner does.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Users with the create permission but no tthe grant permission have the ability to create a new user with arbitrary scan authorizations,ACCUMULO-264,12537409,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,05/Jan/12 20:11,18/Dec/12 18:39,13/Mar/19 22:01,10/Jan/12 18:15,,,,,,,,1.4.0,,,client,master,,,,,0,security,,,,"Possible solutions- check both create and grant when doing an operation that does two actions
OR
only allow users to create a new user with a subset of their own authorizations.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-10 18:15:20.479,,,no_permission,,,,,,,,,,,,222917,,,Tue Jan 10 18:15:20 UTC 2012,,,,,,0|i07o87:,42691,,,,,,,,"10/Jan/12 18:15;jvines;We now through BAD_AUTHORIZATIONS if the new users permissions are not held by the creator, if the creator does not have ALTER_USER.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Default map does not accurately count bytes in memory,ACCUMULO-228,12536072,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,21/Dec/11 19:12,18/Dec/12 18:39,13/Mar/19 22:01,15/Mar/12 10:10,,,,,,,,1.5.0,,,tserver,,,,,,0,memory,,,,"Discovered that bytesInMemory does not accurately count all bytes for the MemKey object, which is used internally. It needs to be reeavaluated to make sure we account for all internals. Additionally, we should go ahead and recalculate getOverheadPerEntry().",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-03-15 10:10:41.182,,,no_permission,,,,,,,,,,,,221755,,,Thu Mar 15 10:10:41 UTC 2012,,,,,,0|i07og7:,42727,,,,,,,,15/Mar/12 10:10;jvines;This got adjusted back in January,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
properly generate the native code headers,ACCUMULO-207,12533928,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,05/Dec/11 19:45,18/Dec/12 18:39,13/Mar/19 22:01,06/Dec/11 17:41,1.3.5-incubating,,,,,,,1.3.6,,,tserver,,,,,,0,generated,,,,"Small renaming snafu, some of the header files are not being created properly due to the lack of org_apache prefix. These need to be added. Additionally, thsi means that org_apache*.h files in the native map and mlock directories can be purged on a full clean.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,219654,,,2011-12-05 19:45:43.0,,,,,,0|i07okn:,42747,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cloudtrace.thrift needs to have it's namespace updated to the new package,ACCUMULO-496,12548134,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,26/Mar/12 15:43,18/Dec/12 18:39,13/Mar/19 22:01,26/Mar/12 15:56,1.4.0,,,,,,,1.4.1,1.5.0,,rpc,trace,,,,,0,,,,,cloudtrace.thrift still has it's namespace set to cloudtrace.thrift. It should be updated to org.apache.accumulo.cloudtrace.thrift. Any users who have thrift installed will be unable to build until this is resolved.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,233231,,,2012-03-26 15:43:56.0,,,,,,0|i07mtz:,42465,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Connecting To Shell With Incorrect Password Should Fail,ACCUMULO-691,12598786,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,medined,medined,14/Jul/12 01:22,18/Dec/12 18:39,13/Mar/19 22:01,18/Jul/12 19:01,,,,,,,,1.5.0,,,,,,,,,0,,,,,"I ran this command:

  accumulo shell -u root -p bad_password

And was connected to the shell. I did not expect this to work. I could
run the ""tables"" command. I could even choose a table to work with.
However the scan and insert failed as shown below.

root@development> table david
root@development david> scan
14 00:18:11,063 [shell.Shell] ERROR:
org.apache.accumulo.core.client.AccumuloSecurityException: Error
BAD_CREDENTIALS - Username or Password is Invalid
root@development david> insert row1 cf1 cq1 value
14 00:18:25,952 [impl.ThriftScanner] WARN : Security Violation in scan
request to 66.175.213.65:9997: ThriftSecurityException(user:root,
code:BAD_CREDENTIALS)
14 00:18:26,046 [shell.Shell] ERROR:
org.apache.accumulo.core.client.MutationsRejectedException: #
constraint violations : 0  # authorization failures : 1  # server
errors 0 # exceptions 0

The config -T command did work which is probably not good.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-07-16 21:11:37.937,,,no_permission,,,,,,,,,,,,246377,,,Wed Jul 18 18:01:07 UTC 2012,,,,,,0|i07lnb:,42273,,,,,,,,"16/Jul/12 21:11;jvines;This was broken in trunk alone, fixed now","16/Jul/12 21:21;ecn;Please add a functional test before closing the ticket.  This should have been caught by one of the shell tests, and if it wasn't, let's add to the test.
",16/Jul/12 21:34;jvines;Need to add test,"18/Jul/12 18:01;jvines;This was a side effect of thrift-1474. I fixed it by adding another check, which is excessive. We should keep the unit test, pull out the shell code I added, and get the thrift issue fixed. 3 authentications for a single login seems excessive to me.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accumulo examples tests are loud and (partially) broken,ACCUMULO-292,12537775,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,vines,jvines,09/Jan/12 15:29,18/Dec/12 18:39,13/Mar/19 22:01,09/Jan/12 18:05,1.4.0,,,,,,,1.4.0,,,,,,,,,0,,,,,Running the mvn test over 1.4 branch is obnoxiously loud and a bit broken. We need to trim down the amount of System.outs and make sure it tests well enough.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-09 18:05:52.512,,,no_permission,,,,,,,,,,,,223281,,,Mon Jan 09 18:05:52 UTC 2012,,,,,,0|i07o1z:,42663,,,,,,,,09/Jan/12 18:05;jvines;Should be resolved now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LiveTServerSet.scanServers makes connections at scan time,ACCUMULO-79,12528950,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,vines,jvines,26/Oct/11 19:53,18/Dec/12 18:38,13/Mar/19 22:01,01/Nov/11 18:32,1.3.5-incubating,,,,,,,1.4.0,,,master,,,,,,0,connection,,,,"LiveTServerSet.scanServers will make connections when it adds them to the list of live servers. This should instead be handled when the result of scanServers is used, so we don't waste cycles creating connections which just end up timing out anyway. This also lends to the connection wrapper used should reconnect once on failover and then fail instead of outright failing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,214810,,,2011-10-26 19:53:11.0,,,,,,0|i07pcn:,42873,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
shell's GrepCommand sets options under same flag,ACCUMULO-107,12529675,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,vines,jvines,01/Nov/11 15:02,18/Dec/12 18:38,13/Mar/19 22:01,30/Nov/11 20:24,1.3.5-incubating,,,,,,,1.4.0,,,client,,,,,,0,,,,,"The shell sets two options for GrepCommand (and child class EgrepCommand) - numThreads and table. numThreads uses the flag ""t"" while table uses an enum which is ""t"". Not only that, but GrepCommand extends ScanCommand (and also calls the super.getOptions) which also sets the table Option. The strange part is that num-threads takes precedence even though it's sandwiched within calls. This may call for a check of all Shell Commands to make sure this isn't done elsewhere. We may want to create of a master index of Shell options to make sure we don't have this collision space again.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-11-01 19:40:26.994,,,no_permission,,,,,,,,,,,,215534,,,Tue Nov 01 19:40:26 UTC 2011,,,,,,0|i07p6f:,42845,,,,,,,,01/Nov/11 19:40;jvines;For 1.5 I think we want to create a master map of Options to use so we can be aware of everything used.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Batch Scanner can get stuck when external thread closes scanner,ACCUMULO-487,12547629,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,vines,jvines,22/Mar/12 16:50,18/Dec/12 18:38,13/Mar/19 22:01,29/May/12 19:39,1.3.5-incubating,1.4.0,,,,,,1.4.1,1.5.0,,client,,,,,,0,newbie,,,,"Scenario- client is using batch scanner to run queries with complex server side iterators. They run long. User has external thread which determines thread is running long, so that thread calls close on the batch scanner. Query threads exit nicely, but there is a thread which is constantly polling an internal queue. It only breaks out of that loop if there is a next key or an error thrown. If neither occur, it continues to poll. We should probably have an exit condition get set on close() which is used in that query loop.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-08-09 21:15:17.566,,,no_permission,,,,,,,,,,,,232727,,,Thu Aug 09 21:44:27 UTC 2012,,,,,,0|i07mvz:,42474,,,,,,,,09/Aug/12 21:15;jstoneham;Would it be possible to have this fix backported to 1.3.x for those of us whose systems haven't been upgraded to 1.4 yet? This leaks a lot of threads for our use case and eventually runs the process out of threads.,09/Aug/12 21:44;jstoneham;Nevermind. This is a different resource leak I'll file later if it hasn't been fixed on trunk.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change in jetty dependency is causing compile failure,ACCUMULO-758,12606466,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,06/Sep/12 19:05,18/Dec/12 17:22,13/Mar/19 22:01,18/Dec/12 17:22,,,,,,,,1.5.0,,,,,,,,,0,,,,,"I am seeing the following compile failure when running ""mvn clean compile package"".  I think this is because a jetty 7 version is all of a sudden being pulled from a maven repo.  One fix is to adjust the pom to exclude jetty >= 7.0

{noformat}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project accumulo-server: Compilation failure: Compilation failure:
[ERROR] /disk1/rkturn2/workspace/accumulo-TRUNK/server/src/main/java/org/apache/accumulo/server/util/EmbeddedWebServer.java:[26,33] package org.mortbay.jetty.security does not exist
[ERROR] /disk1/rkturn2/workspace/accumulo-TRUNK/server/src/main/java/org/apache/accumulo/server/util/EmbeddedWebServer.java:[78,19] cannot find symbol
[ERROR] symbol  : class SslSocketConnector
[ERROR] location: class org.apache.accumulo.server.util.EmbeddedWebServer.EmbeddedWebServer6_1
[ERROR] /disk1/rkturn2/workspace/accumulo-TRUNK/server/src/main/java/org/apache/accumulo/server/util/EmbeddedWebServer.java:[79,10] cannot find symbol
[ERROR] symbol  : class SslSocketConnector
[ERROR] location: class org.apache.accumulo.server.util.EmbeddedWebServer.EmbeddedWebServer6_1
[ERROR] /disk1/rkturn2/workspace/accumulo-TRUNK/server/src/main/java/org/apache/accumulo/server/util/EmbeddedWebServer.java:[80,10] cannot find symbol
[ERROR] symbol  : class SslSocketConnector
[ERROR] location: class org.apache.accumulo.server.util.EmbeddedWebServer.EmbeddedWebServer6_1
[ERROR] /disk1/rkturn2/workspace/accumulo-TRUNK/server/src/main/java/org/apache/accumulo/server/util/EmbeddedWebServer.java:[81,10] cannot find symbol
[ERROR] symbol  : class SslSocketConnector
[ERROR] location: class org.apache.accumulo.server.util.EmbeddedWebServer.EmbeddedWebServer6_1
[ERROR] /disk1/rkturn2/workspace/accumulo-TRUNK/server/src/main/java/org/apache/accumulo/server/util/EmbeddedWebServer.java:[82,10] cannot find symbol
[ERROR] symbol  : class SslSocketConnector
[ERROR] location: class org.apache.accumulo.server.util.EmbeddedWebServer.EmbeddedWebServer6_1

{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-09-28 18:57:02.648,,,no_permission,,,,,,,,,,,,246316,,,Sun Sep 30 01:53:26 UTC 2012,,,,,,0|i07l9z:,42213,,,,,,,,"28/Sep/12 18:57;vines;I also agree with setting hte version range to [5.1,7), at least as a quick fix.","30/Sep/12 01:53;ctubbsii;That's a good quick fix, but I prefer to have the monitor webapp separated from the server, to run as its own thing, with direct dependencies on the version it runs against, and simply exclude any conflicting dependencies that get pulled in transitively.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stacking combiners produces a strange result,ACCUMULO-907,12624014,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,14/Dec/12 17:30,17/Dec/12 18:34,13/Mar/19 22:01,14/Dec/12 19:19,1.4.2,,,,,,,1.4.3,1.5.0,,tserver,,,,,,0,,,,,"Paste the following into your shell:

{noformat}
deletetable test
createtable test
setiter -t test -p 16 -scan -n test_1 -class org.apache.accumulo.core.iterators.user.SummingCombiner

count:a

STRING
setiter -t test -p 17 -scan -n test_2 -class org.apache.accumulo.core.iterators.user.SummingCombiner

count:a

STRING
setiter -t test -p 18 -scan -n test_3 -class org.apache.accumulo.core.iterators.user.SummingCombiner

count:a

STRING
setiter -t test -p 10 -scan -n test_4 -class org.apache.accumulo.core.iterators.user.SummingCombiner

count

STRING
insert row count a 1
insert row count a 1
insert row count b 1
insert row count b 1
insert row count b 1
insert row count c 1
scan
{noformat}

I expect:

{noformat}
row count:a []    2
row count:b []    3
row count:c []    1
{noformat}

But instead, I get this:
{noformat}
row count:a []    12
{noformat}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-12-14 19:15:55.583,,,no_permission,,,,,,,,,,,,297915,,,Mon Dec 17 18:34:33 UTC 2012,,,,,,0|i14w87:,236686,,,,,,,,"14/Dec/12 19:15;hudson;Integrated in Accumulo-Trunk #579 (See [https://builds.apache.org/job/Accumulo-Trunk/579/])
    ACCUMULO-907 fix combiners over iterators that mutate their top key (Revision 1422040)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/iterators/user/CombinerTest.java
",14/Dec/12 19:19;ecn;Fixed with 1422040 and 1422050.,"14/Dec/12 20:08;hudson;Integrated in Accumulo-1.4.x #251 (See [https://builds.apache.org/job/Accumulo-1.4.x/251/])
    ACCUMULO-907 fix combiners over iterators that mutate their top key (Revision 1422050)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java
* /accumulo/branches/1.4/src/core/src/test/java/org/apache/accumulo/core/iterators/user/CombinerTest.java
","17/Dec/12 18:34;hudson;Integrated in Accumulo-1.4.x #252 (See [https://builds.apache.org/job/Accumulo-1.4.x/252/])
    ACCUMULO-907 need to commit the merge metadata (Revision 1423029)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Example accumulo-env.sh's specify min stack size that is too small for Java 1.7.4+,ACCUMULO-685,12598349,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,jasontrost,jasontrost,jasontrost,11/Jul/12 10:28,17/Dec/12 14:37,13/Mar/19 22:01,17/Dec/12 14:37,1.3.6,1.4.1,,,,,,1.5.0,,,,,,,,,0,,,,,"In Java 1.7.4+ the minimum stack size is 160k.  All of the example configs attempt to set it to 128k which causes the tserver to fail to start.

tserver.err
{noformat}
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.
{noformat}

tserver.out
{noformat}
The stack size specified is too small, Specify at least 160k
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246383,,,Mon Dec 17 14:37:30 UTC 2012,,,,,,0|i07lon:,42279,,,,,,,,11/Jul/12 10:34;jasontrost;fix committed in revision 1360110,17/Dec/12 14:37;jasontrost;This has been fixed since svn revision 1360110. Closing out.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make maven profiles for builds against different versions of hadoop,ACCUMULO-876,12617846,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,27/Nov/12 18:01,11/Dec/12 13:48,13/Mar/19 22:01,11/Dec/12 13:48,,,,,,,,1.5.0,,,build,,,,,,0,,,,,See http://svn.apache.org/repos/asf/hbase/trunk/pom.xml for an example.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,01/Dec/12 16:02;billie.rinaldi;ACCUMULO-876.patch;https://issues.apache.org/jira/secure/attachment/12555636/ACCUMULO-876.patch,29/Nov/12 18:05;billie.rinaldi;ACCUMULO-876.patch;https://issues.apache.org/jira/secure/attachment/12555378/ACCUMULO-876.patch,27/Nov/12 20:06;billie.rinaldi;ACCUMULO-876.patch;https://issues.apache.org/jira/secure/attachment/12555055/ACCUMULO-876.patch,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2012-12-01 04:22:49.963,,,no_permission,,,,,,,,,,,,292412,,,Tue Dec 11 01:37:40 UTC 2012,,,,,,0|i0ry67:,161180,,,,,,,,"27/Nov/12 20:06;billie.rinaldi;Anyone want to take a look at this patch?  By default, if you run mvn clean package it will compile against hadoop 1.0.4.  If you use mvn clean package -Dhadoop.profile=2.0, it will use hadoop 2.0.2-alpha.  You can also change which 1.0 or 2.0 compatible version you'd like to compile against by using -Dhadoop-one.version=<version> or -Dhadoop-two.version=<version>.  I tested with 0.20.205.0 and 1.1.0 in addition to the main versions.  It doesn't work yet with hadoop 0.23.  The only issue I had is that occasionally the first run of mvn clean package would fail on the classloader test, then the second run would complete successfully.

I removed the JobTracker table from the monitor page to make this work.

Does anyone think I should use hadoop.version as the property name instead of hadoop-one and hadoop-two?  Any additional profiles I should add from the start?","29/Nov/12 18:05;billie.rinaldi;Updated patch: switched to hadoop.version as the property name and got the build working with 0.23.5.  Tested the following builds:

mvn clean package (uses hadoop 1.0.4)
mvn clean package -Dhadoop.version=0.20.205.0
mvn clean package -Dhadoop.version=1.1.0
mvn clean package -Dhadoop.profile=2.0 (uses hadoop 2.0.2-alpha)
mvn clean package -Dhadoop.profile=2.0 -Dhadoop.version=0.23.5

To get 0.23.5 to pass the tests, I had to add avro as a dependency for the hadoop 2.0 profile in the top-level pom and the server pom.  I didn't think that was worth making a whole new 0.23 profile.","01/Dec/12 04:22;elserj;Initial glance looks good to me, Billie.

What are you opinions on also including profiles for CDH and HDP as a part of this effort?","01/Dec/12 16:02;billie.rinaldi;I'm not sure if HDP comes with jars that are distinct from the Apache releases, so a profile should not be necessary for HDP at this point.  I was going to say you should feel free to add a CDH profile, but I'm suspicious because HBase doesn't have one.  I think having vendor-specific dependencies might not be a good practice here.

I have a suggestion for an alternate solution, though.  I just noticed that the zookeeper groupId has changed, so we should be using org.apache.zookeeper everywhere anyway.  I'll upload a new patch with that change.  If I make zookeeper.version a variable, you should be able to compile against CDH by using something like the following, as long as you have your settings.xml configured as you've described (https://github.com/joshelser/accumulo/blob/trunk-cdh3/README.cdh3).  Could you try these out for me, with the new patch?

mvn clean package -Dhadoop.version=0.20.2-cdh3u5 -Dzookeeper.version=3.3.5-cdh3u5
mvn clean package -Dhadoop.profile=2.0 -Dhadoop.version=2.0.0-cdh4.1.2 -Dzookeeper.version=?

I don't think we should include that README in our release, but we could put the information on our site or link to your instructions from our site.","03/Dec/12 13:24;elserj;You hit on what I was curious about: is there a reason HBase doesn't provide some target to compile against CDH? I'm not entirely sure how I feel either way. From a practical standpoint, if people want to use CDH and Accumulo doesn't provide an option to build against CDH, someone will create a fork/copy that does.

I do like your proposed idea. We could provide the means to build against any version of Hadoop and ZooKeeper (given the groupId hasn't changed), so that users can build against whatever their system is using. I'll try to pull down your new patch tonight.","10/Dec/12 02:34;elserj;Sorry for the delay, Billie. I finally pulled down the patch. It looks great to me. I was able to build all of the targets out of the box.

I think the only thing really missing are the README changes that enumerate the information you put above about the defaults and how to use the options. This is a really nice change that will allow appropriate Accumulo distros to be build for specific environments.

As far as the CDH stuff goes, I could build against CDH3 and CDH4 by using the options you created. I think I've moved my opinion into the ""3rd-party camp"" (documentation not included in the Apache Accumulo release). We can revisit the discussion if anyone else wants to.","11/Dec/12 01:37;hudson;Integrated in Accumulo-Trunk #572 (See [https://builds.apache.org/job/Accumulo-Trunk/572/])
    ACCUMULO-876 added maven profiles to assist in compiling against different versions of hadoop (Revision 1419924)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk/README
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/examples/instamo/pom.xml
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Random walk unit test is throwing an error,ACCUMULO-881,12617891,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,27/Nov/12 22:33,29/Nov/12 18:15,13/Mar/19 22:01,29/Nov/12 18:15,,,,,,,,1.5.0,,,start,,,,,,0,,,,,"A change to the ACCUMULO_HOME property in the top-level pom for ACCUMULO-708 is causing the following issue:

{noformat}
Running org.apache.accumulo.server.test.randomwalk.FrameworkTest
12/11/27 00:53:52 ERROR randomwalk.Module: Failed to parse: ../test/src/test/resources/test/system/randomwalk/conf/modules/unit/Basic.xml
java.io.FileNotFoundException: /home/jenkins/jenkins-slave/workspace/Accumulo-Trunk/accumulo-trunk/server/../test/src/test/resources/test/system/randomwalk/conf/modules/unit/Basic.xml (No such file or directory)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,27/Nov/12 22:35;billie.rinaldi;ACCUMULO-881.patch;https://issues.apache.org/jira/secure/attachment/12555079/ACCUMULO-881.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-11-29 18:11:26.273,,,no_permission,,,,,,,,,,,,292470,,,Thu Nov 29 18:11:26 UTC 2012,,,,,,0|i0s32v:,161975,,,,,,,,27/Nov/12 22:35;billie.rinaldi;I propose the attached solution.,"29/Nov/12 18:11;hudson;Integrated in Accumulo-Trunk #569 (See [https://builds.apache.org/job/Accumulo-Trunk/569/])
    ACCUMULO-881 fixed unit test failures due to ACCUMULO_HOME issue (Revision 1415296)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk/pom.xml
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/vfs/AccumuloVFSClassLoader.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
site:site build takes too long; use profiles and/or tweaks to improve,ACCUMULO-861,12616729,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bmargulies,bmargulies,bmargulies,19/Nov/12 13:23,19/Nov/12 15:11,13/Mar/19 22:01,19/Nov/12 14:06,1.5.0,,,,,,,,,,,,,,,,0,,,,,"Running mvn site:site takes a very long time. This is due to an unsolved Maven problem, in which reporting plugins that use 'forked executions' result in vast amounts of repeated activity.

Cobertura is a known offender in this respect, and in some cases the javadoc 'reports' can also participate.


Another problem is aggregate javadoc. Reducing to project-by-project javadoc is claimed to help (see http://jira.codehaus.org/browse/MJAVADOC-171).

The 'DOD' here is to get to the point where a basic site build has no lengthy forked executions, by moving cobertura to a profile (and perhaps tweaking the javadoc reports).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-19 15:11:10.809,,,no_permission,,,,,,,,,,,,258590,,,Mon Nov 19 15:11:10 UTC 2012,,,,,,0|i0kvaf:,119887,,,,,,,,19/Nov/12 14:06;bmargulies;Done in 1411183.,"19/Nov/12 15:11;hudson;Integrated in Accumulo-Trunk #559 (See [https://builds.apache.org/job/Accumulo-Trunk/559/])
    ACCUMULO-861: speed up (in a relative sense) site:site by moving cobertura to a profile and eliminating aggregated javadoc. (Revision 1411183)

     Result = SUCCESS
bimargulies : 
Files : 
* /accumulo/trunk/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade to current reporting plugin versions,ACCUMULO-859,12616658,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bmargulies,bmargulies,bmargulies,18/Nov/12 21:41,19/Nov/12 00:25,13/Mar/19 22:01,18/Nov/12 22:26,1.5.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"We might get better results from 3.2 of site, 2.8 of changes, and 2.6 of m-p-i-r.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-19 00:25:59.016,,,no_permission,,,,,,,,,,,,258514,,,Mon Nov 19 00:25:59 UTC 2012,,,,,,0|i0ktuv:,119655,,,,,,,,18/Nov/12 22:26;bmargulies;Fixed in 1411004.,"19/Nov/12 00:25;hudson;Integrated in Accumulo-Trunk #558 (See [https://builds.apache.org/job/Accumulo-Trunk/558/])
    ACCUMULO-859: site 3.2, m-p-i-r 2.6, changes 2.8, findbugs 2.5.2.

Update to current versions of various reporting-related plugins. (Revision 1411004)

     Result = SUCCESS
bimargulies : 
Files : 
* /accumulo/trunk/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Thrift version error displays 0.8 instead of 0.9,ACCUMULO-860,12616660,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,bmargulies,bmargulies,bmargulies,18/Nov/12 22:07,19/Nov/12 00:25,13/Mar/19 22:01,18/Nov/12 22:12,1.5.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"the thrift shell script complains that it lacks 0.8 when it is in fact looking for 0.9.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-19 00:25:59.175,,,no_permission,,,,,,,,,,,,258516,,,Mon Nov 19 00:25:59 UTC 2012,,,,,,0|i0ktvb:,119657,,,,,,,,"18/Nov/12 22:09;bmargulies;I fixed this in 1411001., but I lack access to close the issue out. Could someone please close it and figure out why, as a committer (let alone PMC member) I cannot close it?
","19/Nov/12 00:25;hudson;Integrated in Accumulo-Trunk #558 (See [https://builds.apache.org/job/Accumulo-Trunk/558/])
    ACCUMULO-860: fix error message for insufficient Thrift version. (Revision 1411001)

     Result = SUCCESS
bimargulies : 
Files : 
* /accumulo/trunk/core/src/main/thrift/thrift.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockBatchScanner inappropriately filters on ranges,ACCUMULO-821,12612330,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,ivan.bella,ivan.bella,17/Oct/12 22:26,19/Oct/12 19:16,13/Mar/19 22:01,19/Oct/12 17:14,1.4.1,1.4.2,,,,,,1.5.0,,,tserver,,,,,,0,test,,,,"I believe I have a legitimate case where an iterator will return something outside of the seeked-to range.  This appears to work in a live system, but fails to work in test cases using the MockBatchScanner.  I believe this is because the MockBatchScanner filters on the supplied ranges in addition to seeking the iterators to each range.  Either we need to remove this range filter, or fix the real system to do the same thing.  I prefer the former of course.","Accumulo 1.4.1, zookeeper 3.3.1, java 1.6.0_33",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-18 11:36:23.628,,,no_permission,,,,,,,,,,,,249426,,,Fri Oct 19 19:16:08 UTC 2012,,,,,,0|i0a86v:,57600,,,,,,,,18/Oct/12 11:36;ecn;Can you provide a short unit test?,19/Oct/12 17:14;ecn;fixed with rev 1400171,"19/Oct/12 17:24;hudson;Integrated in Accumulo-Trunk #530 (See [https://builds.apache.org/job/Accumulo-Trunk/530/])
    ACCUMULO-821 unit test out-of-range keys returned from an iterator stack (Revision 1400171)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockBatchScanner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockScanner.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/TestThrift1474.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mock/TestBatchScanner821.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mock/TransformIterator.java
","19/Oct/12 19:16;hudson;Integrated in Accumulo-Trunk #531 (See [https://builds.apache.org/job/Accumulo-Trunk/531/])
    ACCUMULO-821 RangesFilter no longer needed (Revision 1400201)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockBatchScanner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockScanner.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stack overflow when starting tablet server after recent java update to 1.6.0_35,ACCUMULO-764,12607474,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,afuchs,afuchs,13/Sep/12 15:01,19/Oct/12 18:11,13/Mar/19 22:01,19/Oct/12 18:11,1.4.1,,,,,,,1.4.2,1.5.0,,,,,,,,0,,,,,"{code}
Thread ""tserver"" died null
java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:89)
        at java.lang.Thread.run(Thread.java:680)
Caused by: java.lang.StackOverflowError
        at java.util.HashMap.put(HashMap.java:370)
        at java.util.HashSet.add(HashSet.java:200)
        at java.lang.ClassLoader.checkPackageAccess(ClassLoader.java:336)
        at java.lang.ClassLoader.defineClass1(Native Method)
        at java.lang.ClassLoader.defineClassCond(ClassLoader.java:631)
        at java.lang.ClassLoader.defineClass(ClassLoader.java:615)
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)
        at java.net.URLClassLoader.access$000(URLClassLoader.java:58)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:197)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
        at java.lang.ClassLoader.defineClass1(Native Method)
        at java.lang.ClassLoader.defineClassCond(ClassLoader.java:631)
        at java.lang.ClassLoader.defineClass(ClassLoader.java:615)
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)
        at java.net.URLClassLoader.access$000(URLClassLoader.java:58)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:197)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
        at java.lang.ClassLoader.defineClass1(Native Method)
        at java.lang.ClassLoader.defineClassCond(ClassLoader.java:631)
        at java.lang.ClassLoader.defineClass(ClassLoader.java:615)
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)
        at java.net.URLClassLoader.access$000(URLClassLoader.java:58)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:197)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
        at java.lang.ClassLoader.defineClass1(Native Method)
        at java.lang.ClassLoader.defineClassCond(ClassLoader.java:631)
        at java.lang.ClassLoader.defineClass(ClassLoader.java:615)
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)
        at java.net.URLClassLoader.access$000(URLClassLoader.java:58)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:197)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
        at org.apache.commons.configuration.BaseConfiguration.<init>(BaseConfiguration.java:54)
        at org.apache.commons.configuration.AbstractFileConfiguration.<init>(AbstractFileConfiguration.java:117)
        at org.apache.commons.configuration.AbstractHierarchicalFileConfiguration$FileConfigurationDelegate.<init>(AbstractHierarchicalFileConfiguration.java:439)
        at org.apache.commons.configuration.XMLConfiguration$XMLFileConfigurationDelegate.<init>(XMLConfiguration.java:1279)
        at org.apache.commons.configuration.XMLConfiguration$XMLFileConfigurationDelegate.<init>(XMLConfiguration.java:1279)
        at org.apache.commons.configuration.XMLConfiguration.createDelegate(XMLConfiguration.java:788)
        at org.apache.commons.configuration.AbstractHierarchicalFileConfiguration.initialize(AbstractHierarchicalFileConfiguration.java:134)
        at org.apache.commons.configuration.AbstractHierarchicalFileConfiguration.<init>(AbstractHierarchicalFileConfiguration.java:61)
        at org.apache.commons.configuration.AbstractHierarchicalFileConfiguration.<init>(AbstractHierarchicalFileConfiguration.java:102)
        at org.apache.commons.configuration.XMLConfiguration.<init>(XMLConfiguration.java:226)
        at org.apache.accumulo.server.metrics.MetricsConfiguration.loadConfiguration(MetricsConfiguration.java:155)
        at org.apache.accumulo.server.metrics.MetricsConfiguration.getMetricsConfiguration(MetricsConfiguration.java:138)
        at org.apache.accumulo.server.metrics.MetricsConfiguration.<init>(MetricsConfiguration.java:106)
        at org.apache.accumulo.server.metrics.AbstractMetricsImpl.<init>(AbstractMetricsImpl.java:112)
        at org.apache.accumulo.server.tabletserver.TabletServer.<init>(TabletServer.java:225)
        at org.apache.accumulo.server.tabletserver.TabletServer.main(TabletServer.java:3120)
        ... 6 more
{code}",Java 1.6.0_35 on a macbook pro running Mountain Lion,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-09-13 17:48:27.758,,,no_permission,,,,,,,,,,,,246310,,,Fri Oct 19 18:11:58 UTC 2012,,,,,,0|i07l8n:,42207,,,,,,,,13/Sep/12 15:03;afuchs;Workaround: change ACCUMULO_TSERVER_OPTS in conf/accumulo-env.sh to use -Xss256k instead of -Xss128k.,"13/Sep/12 17:48;kturner;I think we should remove this stack size setting.  It was added to make mlock work properly, but I do not think anyone is using mlock.",19/Oct/12 18:11;vines;Apparently an Xss purge was already committed.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
/bin/start-server.sh: line 40: ifconfig: command not found ,ACCUMULO-823,12612428,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,18/Oct/12 14:19,18/Oct/12 17:44,13/Mar/19 22:01,18/Oct/12 17:25,,,,,,,,1.4.2,,,scripts,,,,,,0,,,,,ifconfig is not in a normal user's path,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-18 15:30:25.791,,,no_permission,,,,,,,,,,,,249569,,,Thu Oct 18 17:10:49 UTC 2012,,,,,,0|i0aflz:,58802,,,,,,,,18/Oct/12 14:22;ecn;ifconfig is also not runnable by the regular user (Permission Denied) on RHEL5,18/Oct/12 15:30;dlmarion;Take a look at Hyperic SIGAR (https://issues.apache.org/jira/browse/ACCUMULO-823). It's licensed under ASL 2.0 and provides a single api to get system information for many platforms.,"18/Oct/12 17:07;hudson;Integrated in Accumulo-Trunk #527 (See [https://builds.apache.org/job/Accumulo-Trunk/527/])
    ACCUMULO-823 use alternatives to ipconfig, merge to trunk (Revision 1399721)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/start-server.sh
* /accumulo/trunk/core
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","18/Oct/12 17:10;hudson;Integrated in Accumulo-1.4.x #243 (See [https://builds.apache.org/job/Accumulo-1.4.x/243/])
    ACCUMULO-823 use alternatives to ipconfig (Revision 1399717)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/bin/start-server.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZookeeperInstance gets stuck when given bad host,ACCUMULO-131,12530889,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,09/Nov/11 15:37,15/Oct/12 17:27,13/Mar/19 22:01,15/Oct/12 17:27,1.4.0,1.4.1,,,,,,1.4.2,,,client,,,,,,1,,,,,"Keith Massey reported the following issue on the mailing list.

{quote}
A user of our recently filed a bug with us because our code hung forever when she gave us an address for a zookeeper that was not running. I think I've traced the problem into org.apache.accumulo.core.zookeeper.ZooSession.connect(). If the connection to the zookeeper fails it throws a ConnectException, which gets caught by the catch (IOException) block, which logs the message and keeps trying infinitely. It's definitely user error passing in an invalid zookeeper. But shouldn't that method bail out after some time?
Thanks.

Keith
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10/Oct/12 00:54;kturner;ACCUMULO-131-1.patch;https://issues.apache.org/jira/secure/attachment/12548500/ACCUMULO-131-1.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-10-15 17:27:11.927,,,no_permission,,,,,,,,,,,,216627,,,Mon Oct 15 17:27:11 UTC 2012,,,,,,0|i07p13:,42821,,,,,,,,"10/Oct/12 00:34;kturner;I am able to reproduce in 1.4 branch with the following simple test program.   Zookeeper is not running on port 5689.

{code:java}
import org.apache.accumulo.core.client.ZooKeeperInstance;

public class TestZK {
  public static void main(String[] args) throws Exception {
    ZooKeeperInstance zki = new ZooKeeperInstance(""test14"", ""localhost:5689"");
  }  
}
{code}


ZooSession never sees a ConnectException as this ticket describes.  That may have been 1.3 behavior.  Internal zookeeper code sees this exception, and logs it.  ZooSession sees that the ZooKeeper client state never transitions to the CONNECTED state and keeps waiting for this to happen.  I see the stack traces below when running the test program.

{noformat}
12/10/09 20:24:15 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:5689
12/10/09 20:24:15 WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1078)
12/10/09 20:24:15 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:5689
12/10/09 20:24:15 WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1078)
{noformat}





","10/Oct/12 00:53;kturner;There is no way to distinguish being given a bogus host from a good host.  I define a bogus host as a reachable machine:port where zookeeper will never run.  A good host is a machine:port where zookeeper is running or will run in the future.  The code code already handles the case where you give it a bad DNS name, this is clearly a bad host and it does not retry.

I have attached a patch that changes the behavior of ZooSession.  The patch throws an exception if zookeeper can not be connected to within 2x the zookeeper timeout.  This patch significantly changes the behavior of Accumulo.  Without this patch, if zookeeper went down a new Accumulo client would just wait indefinitely till it came back up.  With this patch it will timeout. What are peoples opinions about applying this to 1.4?","15/Oct/12 17:27;ecn;I applied the patch.  It's better to know about a problem than to just hide it, and not being able to contact zookeeper for two timeout periods is a problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stack trace in MockTableOperationsTest,ACCUMULO-805,12611373,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,afuchs,afuchs,11/Oct/12 15:50,11/Oct/12 18:29,13/Mar/19 22:01,11/Oct/12 18:13,,,,,,,,1.4.2,,,test,,,,,,0,,,,,"{code}
Running org.apache.accumulo.core.client.mock.MockTableOperationsTest
12/10/11 11:44:57 INFO compress.CodecPool: Got brand-new compressor
12/10/11 11:44:57 INFO compress.CodecPool: Got brand-new decompressor
12/10/11 11:44:57 INFO compress.CodecPool: Got brand-new decompressor
12/10/11 11:44:57 INFO compress.CodecPool: Got brand-new decompressor
12/10/11 11:44:57 INFO compress.CodecPool: Got brand-new decompressor
12/10/11 11:44:57 INFO compress.CodecPool: Got brand-new decompressor
12/10/11 11:44:57 INFO compress.CodecPool: Got brand-new decompressor
12/10/11 11:44:57 INFO compress.CodecPool: Got brand-new decompressor
12/10/11 11:44:57 INFO compress.CodecPool: Got brand-new decompressor
12/10/11 11:44:57 ERROR map.MapFileUtil: Map file target/accumulo-test/import/sample.map already exists
java.lang.Exception
	at org.apache.accumulo.core.file.map.MapFileUtil.openMapFileWriter(MapFileUtil.java:120)
	at org.apache.accumulo.core.file.map.MapFileOperations.openWriter(MapFileOperations.java:152)
	at org.apache.accumulo.core.file.DispatchingFileFactory.openWriter(FileOperations.java:81)
	at org.apache.accumulo.core.client.mock.MockTableOperationsTest.prepareTestFiles(MockTableOperationsTest.java:149)
	at org.apache.accumulo.core.client.mock.MockTableOperationsTest.testFailsWithNonEmptyFailureDirectory(MockTableOperationsTest.java:187)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.internal.runners.TestMethod.invoke(TestMethod.java:59)
	at org.junit.internal.runners.MethodRoadie.runTestMethod(MethodRoadie.java:98)
	at org.junit.internal.runners.MethodRoadie$2.run(MethodRoadie.java:79)
	at org.junit.internal.runners.MethodRoadie.runBeforesThenTestThenAfters(MethodRoadie.java:87)
	at org.junit.internal.runners.MethodRoadie.runTest(MethodRoadie.java:77)
	at org.junit.internal.runners.MethodRoadie.run(MethodRoadie.java:42)
	at org.junit.internal.runners.JUnit4ClassRunner.invokeTestMethod(JUnit4ClassRunner.java:88)
	at org.junit.internal.runners.JUnit4ClassRunner.runMethods(JUnit4ClassRunner.java:51)
	at org.junit.internal.runners.JUnit4ClassRunner$1.run(JUnit4ClassRunner.java:44)
	at org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:27)
	at org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:37)
	at org.junit.internal.runners.JUnit4ClassRunner.run(JUnit4ClassRunner.java:42)
	at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)
	at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:172)
	at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:104)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:70)
{code}

Test did not fail. Should it have?

Could this be a race condition?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-11 18:13:48.699,,,no_permission,,,,,,,,,,,,247648,,,Thu Oct 11 18:29:08 UTC 2012,,,,,,0|i08mxb:,48313,,,,,,,,11/Oct/12 18:13;ecn;Fixed the new test to run correctly every time.,11/Oct/12 18:29;kturner;I do not think this bug exist in 1.4.1.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TableLoadBalancer / DefaultLoadBalancer assigns tables unevenly,ACCUMULO-770,12608506,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,20/Sep/12 18:02,11/Oct/12 16:24,13/Mar/19 22:01,11/Oct/12 16:24,1.4.1,,,,,,,1.4.2,,,master,,,,,,0,,,,,"During assignment, each table balancer starts assigning tablets in order.  This ensures the the ""lowest"" tabletserver gets at least one tablet for each table.  This can make for an unbalanced cluster when there are many small tables.  Randomize the list of tablets in the DefaultLoadBalancer to evenly distribute tablets on a new cluster.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-11 15:56:53.768,,,no_permission,,,,,,,,,,,,246306,,,Thu Oct 11 16:24:12 UTC 2012,,,,,,0|i07l7r:,42203,,,,,,,,11/Oct/12 13:47;ecn;resolved with r1397048 and r1397050,"11/Oct/12 15:56;vines;On Ubuntu systems, tests are inconsistently failing. Occured on both Ubuntu 12.04 and 12.10 Beta2 with openjdk as well as Oracle java 6u35. Was able to recreate with just running junit tests in eclipse, as well as maven runs. Specifically, org.apache.accumulo.server.master.balancer.DefaultLoadBalancerTest#testAssignMigrations(). I saw successes as well as failures where 3 was expected and got 4 or 2.",11/Oct/12 16:24;ecn;fixed the unit test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
isLockHeld needs better bullet-proofing against transient errors,ACCUMULO-777,12609440,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,27/Sep/12 19:36,11/Oct/12 15:47,13/Mar/19 22:01,11/Oct/12 15:47,1.3.5-incubating,1.3.6,1.4.0,1.4.1,,,,1.4.2,,,client,,,,,,0,,,,,"During the minor compaction, the zookeeper lock for the tablet server is double-checked prior to updating the METADATA table information.  In one unlucky moment, the zookeeper connection was lost during this check.  The tablet server failed the check, but the lock was not lost.  As a result, the root tablet remained hosted for another 4 weeks, but did not flush mutations to disk.  When memory filled, the operator noticed a long hold time and killed the server.  This caused a log recovery of 98 1G of logs, some of which were very old.",medium sized cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246299,,,Thu Oct 11 15:47:39 UTC 2012,,,,,,0|i07l67:,42196,,,,,,,,11/Oct/12 15:47;ecn;fixed in r1397117 r1397120.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
port to thrift 0.8,ACCUMULO-672,12597636,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,05/Jul/12 19:36,10/Oct/12 23:51,13/Mar/19 22:01,10/Oct/12 23:51,,,,,,,,1.5.0,,,client,,,,,,0,,,,,Thrift 0.6.1 is now the oldest release still in the repos.  Consider going to a newer version.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-07-13 21:52:27.698,,,no_permission,,,,,,,,,,,,246395,,,Wed Oct 10 23:51:11 UTC 2012,,,,,,0|i07lrb:,42291,,,,,,,,"13/Jul/12 21:52;jvines;Merged the changes in and reran thrift and I noticed a lot of minor comment tweaks in my branch. But in the main trunk I also saw comments and ""+        __isset_bit_vector = new BitSet(1); "". I don't know if you built the current ones with some setting or what, but it makes me hesitant to commit anything",10/Oct/12 23:51;ecn;Still need 0.9 to fix the problems in 0.8.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Location for tablet assigned to dead server not removed when table offline,ACCUMULO-757,12606455,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,06/Sep/12 18:20,06/Sep/12 18:33,13/Mar/19 22:01,06/Sep/12 18:33,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,,,,,,,0,,,,,"When a table is offline and some of its tablets have locations that map to dead servers, those locations are never removed.   Some features wait for a table to go offline by scanning the metadata table until no tablet has a location.  These features will get stuck in this case.

I was trying to test a recent patch to ACCUMULO-456 before applying the patch.  To test the patch I needed a offline tablet to have a walog and no location.   In an attempt to create this situation I did the following :

  * create table X
  * write data to table X
  * kill tablet server serving table X tablet
  * offline table before tablet is reassigned 

When the above steps happen, the tablets location is never removed by the master.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246317,,,2012-09-06 18:20:11.0,,,,,,0|i07la7:,42214,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SimpleThreadPool ignores the max number of threads,ACCUMULO-669,12597572,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,05/Jul/12 11:47,06/Sep/12 18:13,13/Mar/19 22:01,05/Jul/12 11:50,,,,,,,,1.5.0,,,,,,,,,0,,,,,keith@deenlo.com discovered that SimpleThreadPool is ignoring the first argument to its ctor.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246398,,,2012-07-05 11:47:51.0,,,,,,0|i07lrz:,42294,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooZap not handling -loggers parameter,ACCUMULO-630,12559771,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,medined,medined,07/Jun/12 22:40,06/Sep/12 18:13,13/Mar/19 22:01,10/Jul/12 11:54,,,,,,,,1.5.0,,,client,,,,,,0,,,,,"I am seeing this message when I run bin/stop-all.sh:

Usage : org.apache.accumulo.server.util.ZooZap [-verbose] [-tservers] [-master] [-loggers]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246436,,,Thu Jun 07 22:42:58 UTC 2012,,,,,,0|i07m0n:,42333,,,,,,,,"07/Jun/12 22:42;medined;The end of the batch file has:

$ACCUMULO_HOME/bin/accumulo org.apache.accumulo.server.util.ZooZap -master -tservers -loggers -tracers

It seems like the problem resides in the -loggers option so I am changing the title.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
graphs on the monitor page always read zero,ACCUMULO-565,12553354,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,30/Apr/12 12:19,06/Sep/12 18:13,13/Mar/19 22:01,01/May/12 12:29,,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"While testing other improvements, I noticed the top four graphs are always reading zero.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-04-30 16:47:30.062,,,no_permission,,,,,,,,,,,,237508,,,Tue May 01 12:29:53 UTC 2012,,,,,,0|i07mf3:,42398,,,,,,,,"30/Apr/12 16:47;kturner;A new timer task was added in the TSRM.  This task is throwing an excpetion and killing the timer that a lot of tablet server task use.  There is a timer task that collects stats from tablets that is not running as a result.  I added a try/catch/log to the task and saw the following.   Now that the exception is caught, the counts are showing up.

{noformat}
30 12:41:59,598 [tabletserver.TabletServerResourceManager] WARN : java.lang.ClassCastException: org.apache.accumulo.cloudtrace.instrument.TraceExecutorService cannot be cast to java.util.concurrent.ThreadPoolExecutor
java.lang.ClassCastException: org.apache.accumulo.cloudtrace.instrument.TraceExecutorService cannot be cast to java.util.concurrent.ThreadPoolExecutor
        at org.apache.accumulo.server.tabletserver.TabletServerResourceManager$1.run(TabletServerResourceManager.java:209)
        at java.util.TimerThread.mainLoop(Timer.java:512)
        at java.util.TimerThread.run(Timer.java:462)
{noformat}",30/Apr/12 16:49;kturner;The timer task was added as part of ACCUMULO-401,"01/May/12 12:29;ecn;Fixed. Added a functional test for ACCUMULO-401, too.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
shell functional test is failing,ACCUMULO-535,12550870,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,13/Apr/12 19:57,06/Sep/12 18:13,13/Mar/19 22:01,27/Apr/12 15:08,,,,,,,,1.5.0,,,client,,,,,,0,qa-ft-1.5.0,,,,"select and selectrow were removed, but the test was not updated",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235734,,,2012-04-13 19:57:32.0,,,,,,0|i07mlr:,42428,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
simple.logicalTime.LogicalTimeTest is timing out,ACCUMULO-534,12550862,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,13/Apr/12 19:09,06/Sep/12 18:13,13/Mar/19 22:01,16/Apr/12 13:09,,,,,,,,1.5.0,,,client,,,,,,0,qa-ft-1.5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235726,,,2012-04-13 19:09:51.0,,,,,,0|i07mlz:,42429,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestConfirmDeletes hangs,ACCUMULO-531,12550725,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,billie.rinaldi,billie.rinaldi,12/Apr/12 18:59,06/Sep/12 18:13,13/Mar/19 22:01,12/Apr/12 19:30,,,,,,,,1.5.0,,,test,,,,,,0,qa-ft-1.5.0,,,,"The test org.apache.accumulo.server.gc.TestConfirmDeletes is causing the trunk Jenkins builds to time out.  I recreated the issue on my local machine by running mvn clean package with no Zookeeper running.  Oddly, the test passes when I run it in Eclipse.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235589,,,2012-04-12 18:59:15.0,,,,,,0|i07mmn:,42432,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SimpleBalancerFairness functional test is failing,ACCUMULO-537,12551051,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,16/Apr/12 12:54,06/Sep/12 18:13,13/Mar/19 22:01,16/Apr/12 13:13,,,,,,,,1.5.0,,,master,,,,,,0,qa-ft-1.5.0,,,,getting an NPE during balance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235915,,,2012-04-16 12:54:35.0,,,,,,0|i07mlb:,42426,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
examples functional test is failing,ACCUMULO-538,12551053,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,16/Apr/12 13:00,06/Sep/12 18:13,13/Mar/19 22:01,30/Apr/12 16:29,,,,,,,,1.5.0,,,test,,,,,,0,,,,,the dirlist example is failing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235917,,,2012-04-16 13:00:08.0,,,,,,0|i07ml3:,42425,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Generated thrift produces warnings on enums,ACCUMULO-754,12606298,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ctubbsii,ctubbsii,05/Sep/12 21:24,05/Sep/12 22:50,13/Mar/19 22:01,05/Sep/12 22:50,1.4.1,,,,,,,1.5.0,,,rpc,,,,,,0,generated,java,script,thrift,"Thrift generates lots of warnings. ACCUMULO-30 says that it won't be fixed, but a post-processing step was added to suppress warnings in the script that calls the thrift binary to generate the code.

A post-processing step needs to be added to suppress warnings in the enums generated also, not just the classes.",,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,05/Sep/12 22:13;ctubbsii;accumulo-754.patch;https://issues.apache.org/jira/secure/attachment/12543925/accumulo-754.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-09-05 22:38:42.387,,,no_permission,,,,,,,,,,,,246320,,,Wed Sep 05 22:48:54 UTC 2012,,,,,,0|i07lav:,42217,,,,,,,,05/Sep/12 22:13;ctubbsii;The first part of this patch adds the line to suppress warnings for enums. The rest are the resulting changes to the version-controlled thrift-generated files.,05/Sep/12 22:38;kturner;Patch looks good.  I just committed it.  Now there are only two warnings in eclipse.,05/Sep/12 22:48;ctubbsii;I have a few more in Eclipse Juno (default settings).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multiple deletes cause a RuntimeException,ACCUMULO-53,12527862,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,jesse_yates,jesse_yates,20/Oct/11 01:08,04/Sep/12 18:01,13/Mar/19 22:01,15/Nov/11 19:06,1.3.5-incubating,,,,,,,1.4.0,,,client,,,,,,0,,,,,"Pretty sure this affects 1.3.5, though it may also on 1.4.0 (haven't tested on the latter, but the code looks the same).

When a BatchDeleter is used multiple times on the same time, it doesn't reset the scan iterators, leading to runtime exceptions when there are multiple calls to delete().

Below, we can see that it adds a scan iterator to get the list of values in the table. Since it just sets the name of the deleter to ""org.apache.accumulo.core.client.BatchDeleter.NOVALUE"" every time. So when you go to run the scan a second time, it attempts set the same scan iterator again.

{code}
	public void delete() throws MutationsRejectedException, TableNotFoundException {
		super.addScanIterator(new IteratorSetting(Integer.MAX_VALUE, BatchDeleter.class.getName() + "".NOVALUE"", SortedKeyIterator.class));
{code}

This results in a RuntimeException telling you that the 'Iterator name is already in use'.

After doing the delete, the BatchDeleter should remove that iterator (possibly just clear all iterators) when done with the delete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,22/Oct/11 22:50;jesse_yates;java_ACCUMULO-53.patch;https://issues.apache.org/jira/secure/attachment/12500338/java_ACCUMULO-53.patch,27/Oct/11 03:17;jesse_yates;java_ACCUMULO-53_v2.patch;https://issues.apache.org/jira/secure/attachment/12501024/java_ACCUMULO-53_v2.patch,02/Nov/11 18:05;jesse_yates;java_ACCUMULO-53_v3.patch;https://issues.apache.org/jira/secure/attachment/12501996/java_ACCUMULO-53_v3.patch,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2011-10-20 17:30:56.635,,,no_permission,,,,,,,,,,,,92125,,,Wed Nov 02 18:05:36 UTC 2011,,,,,,0|i07pif:,42899,,,,,,,,"20/Oct/11 01:09;jesse_yates;Glad to work put a patch for this, but just wanted to get the community input on the right way to do it (clearing all or just the set one)","20/Oct/11 17:30;billie.rinaldi;I would suggest moving the super.addScanIterator statement to the constructor.  That way it will just happen once, and the iterator will remain in place for all subsequent calls to delete().  I suppose the user might manually clear the iterators, in which case it wouldn't be put back in place.  However, the iterator is for performance rather than necessity, so delete() would still work correctly.

You don't want to clear all iterators, because that will also wipe out any that the user has added.

We could discuss adding some new methods to the ScannerBase interface that would let you see if an iterator name is already in use and clear a specific named iterator.","20/Oct/11 17:44;jesse_yates;{quote}
You don't want to clear all iterators, because that will also wipe out any that the user has added.
{quote}
We could go in by hand an delete the iterator after each use of the delete, but that just seems excessive. 

I like the idea of just setting the iterator at object creation - its clean and solves the problem.

bq. We could discuss adding some new methods to the ScannerBase interface that would let you see if an iterator name is already in use and clear a specific named iterator.

This could be interesting, but don't know how often this would be used. There are some cases where I've done some nested, automated scanning and you get around that by just having random names for the iterators and rely on the improbability of overlap - mathematically it should work :)

So yeah, adding something like that would be cool.

I'll work on patches for both.","22/Oct/11 22:50;jesse_yates;Fixing BatchDeleterImpl and adding ScannerOptions.removeIterator()
 - Adding removeIterator() method
 - Moved adding the whole-row-iterator option to BatchDeleterImpl constructor
 - Added tests for the above
 - Added EasyMock and Powermock for testing.","25/Oct/11 13:44;billie.rinaldi;I wonder if we should make the serverSideIteratorList a Map<String,IterInfo> that maps names to iterators.  Then we could remove an iterator more easily, and we could have a hasIterator(String iteratorName) method.  That would let us keep the addScanIterator statement in the BatchDeleter in the delete() method, with a check to see if it already exists before adding.

We'd have to convert the serverSideIteratorList.values() into a List when it is passed to various other classes (e.g. it's a List that gets passed via thrift from the client to the tablet server -- I'm not sure that's the best data structure for the purpose, but we probably shouldn't change it for this version).

Any thoughts?","25/Oct/11 14:48;kturner;Converting serverSideIteratorList to map seems fine.  Doing linear scans of the list is probably ok, as it will normally be a small list.  However, a map will make the code more concise.","25/Oct/11 15:34;jesse_yates;Agreed on the fact that number of iterators is small. Since its small, the memory footprint of the map shouldn't be too bad either - assuming we go with hashmap. I like the idea of switching it over to a map and then deserializing that on the server (this plays into another idea I'm stil percolating).

I'll start working on a revised patch.","27/Oct/11 03:17;jesse_yates;Switching ScannerOptions to just keep a map of iterator settings.

Kept BatchDeleter's setting of iterator in the constructor since it is going to be much more efficient to just set it once, rather than do a lookup on the keys and then add it, every time. Only issue is the case where people are messing with the iterators settings on the deleter, and if you are doing that, you should know what you are doing (since you are messing with the internals).","27/Oct/11 11:31;ecn;I have some concerns about introducing a new (test-time) dependency for a single unit test.  Anyone else?
","27/Oct/11 14:14;billie.rinaldi;The patch produces errors.  (Also, its formatting does not follow our spec -- see http://incubator.apache.org/accumulo/source.html.)  Other classes are expecting ScannerOptions to have serverSideIteratorList and serverSideIteratorOptions.  Merging these into a single object throughout the code might be a good idea, but is a much bigger change.  If we want to go that route, I think we should do it in 1.5 instead of 1.4.  Perhaps we should just do the BatchDeleter fix in this ticket, create another ticket for improving ScannerOptions and IteratorSetting handling, and branch 1.4 so that we can start larger changes in the trunk.

Deciding upon which mock testing frameworks we should use sounds like something we should do as a community.  Perhaps start a discussion on the mailing list?","27/Oct/11 16:28;jesse_yates;@Billie:
bq. The patch produces errors... Other classes are expecting ScannerOptions to have serverSideIteratorList and serverSideIteratorOptions. 

Hmm, my eclipse wasn't throwing any errors on this. However, I think this is the _right_ way that code should be implemented. Looking into the erorrs now. 

bq. branch 1.4 so that we can start larger changes in the trunk.

Any reason we need to branch 1.4? The numbering implies it is a major(ish) release, so making this update (since it is under the hood) should be fine. If it was a change on user interfaces, then yeah, branching makes sense.

@Eric
bq. I have some concerns about introducing a new (test-time) dependency for a single unit test

This was an attempt to start using mocking for better test coverage in the unit test suite, which is actually pretty sparse.

I'll put a comment up on dev. around the issue.","27/Oct/11 17:18;jvines;To do a full implementation of your changes, which is the way to go IMO, requires a change in the thrift API. And a change that disruptive is not good for something which we have been trying to freeze for a little while now. By branching we can officially do a feature freeze so we can finalize our testing on it without forcing you and other contributors to sit on your patches until we deem otherwise.","27/Oct/11 17:25;jesse_yates;@John: +1 

I'll create a new ticket for doing the refactor of the options and target it at 1.5

@Billie:
I think if the community is ok with the mocking I'm using here, then v1 of the patch can be accepted. It just does the change for the batch deleter and adds unit tests.",02/Nov/11 18:05;jesse_yates;Just doing the fix described in the initial ticket as well as doing some cleanup in associated code. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Infinite loop in RFile code,ACCUMULO-740,12604634,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,23/Aug/12 16:23,30/Aug/12 12:58,13/Mar/19 22:01,30/Aug/12 12:58,,,,,,,,1.5.0,,,,,,,,,0,,,,,"Saw an infinite loop in RFile code when new on demand indexing was turned on and table contained zero length values.  I think this is only an issue in trunk, but need to analyze 1.4 code to make sure it does not happen. 

The problematic code is 

{noformat}
org.apache.accumulo.core.file.rfile.RelativeKey.read(DataInput in, MByteSequence mbseq, int len){...}
{noformat}

When the input mbseq is backed by a zero length array, an infinite loop will occur.  Also noticed that the code could overflow the integer and cause an inifinite loop (a key or value > 2^30 would be needed to trigger this).  I suspect 1.4 will never generate an input that will cause the infinite loop, but I am not 100% sure about this.  

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246334,,,Thu Aug 30 12:58:33 UTC 2012,,,,,,0|i07ldz:,42231,,,,,,,,23/Aug/12 16:27;kturner;Changes made for ACCUMULO-473 exposed this bug,"30/Aug/12 12:58;kturner;I looked at 1.4, this bug will not occur there.  I do not think it will ever call the function w/ a zero length array.  Code changes for 1.5 introduced the possibility of calling the function with a zero length array.

I do not think this bug fix needs to be back ported to 1.4",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bulk import may copy successful files into fail dir,ACCUMULO-410,12542779,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,kturner,kturner,15/Feb/12 22:56,16/Jul/12 16:36,13/Mar/19 22:01,16/Jul/12 16:36,1.4.0,,,,,,,1.4.2,,,master,,,,,,0,,,,,"The bulk import FATE operation LoadFile bulk imports files and copies failed files.  If master dies in the middle of coping the failed files, when it restarts it will start the FATE op from the beginning.  In this situation previously failed files could succeed.  However the failed files would still be in the fail dir.  To overcome this the copying for failed files could be a follow on FATE op, of the FATE op could clear the failed dir before copying to make idempotent. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,228065,,,Mon Jul 16 16:36:50 UTC 2012,,,,,,0|i07nd3:,42551,,,,,,,,16/Jul/12 16:36;kturner;This issue was fixed by the changes made for ACCUMULO-409,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
first index block reader not closed in RFile,ACCUMULO-668,12597331,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,afuchs,afuchs,afuchs,03/Jul/12 19:42,05/Jul/12 20:36,13/Mar/19 22:01,05/Jul/12 20:36,,,,,,,,1.5.0,,,,,,,,,0,,,,,"If an RFile is read without index caching, the reader it uses does not get closed. We saw this happen in an RFile unit test, where several Decompressors were not being returned to the CompressorPool. Inside of BCFile.Reader.Reader(...) the cachedDataIndex object never gets closed. The object eventually gets garbage collected, which frees up the resources, but it should be closed to properly return its Decompressor to the pool. This probably has little or no effect on any running instance, but it is nonetheless a bug.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246399,,,2012-07-03 19:42:02.0,,,,,,0|i07ls7:,42295,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockScanner and MockBatchScanner do not seek their Filters,ACCUMULO-17,12526259,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,07/Oct/11 19:09,29/Jun/12 14:34,13/Mar/19 22:01,29/Jun/12 14:34,,,,,,,,1.4.1,,,client,,,,,,0,iterators,mock,,,MockScanner and MockBatchScanner do not seek their RangeFilters before iterating over them.  The Filters are expecting to be seeked and are returning keys out of range in some cases.  See also ACCUMULO-15.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-06-27 18:18:21.128,,,no_permission,,,,,,,,,,,,50490,,,Wed Jun 27 18:18:21 UTC 2012,,,,,,0|i07pqf:,42935,,,,,,,,27/Jun/12 18:18;ecn;MockBatchScanner needs to seek *all* the ranges,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
consider making the ColumnVisibility parse tree public,ACCUMULO-646,12595131,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,,ecn,ecn,19/Jun/12 15:31,29/Jun/12 13:00,13/Mar/19 22:01,29/Jun/12 13:00,,,,,,,,,,,client,,,,,,0,,,,,"Several users have expressed the need to manipulate visibility expressions in a symbolic way, and the parse tree is mostly private, and unable to be used directly to construct new expressions.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246421,,,Fri Jun 29 13:00:46 UTC 2012,,,,,,0|i07lxb:,42318,,,,,,,,"29/Jun/12 13:00;ecn;Actually, it was already mostly public.  Just needed to tweak the accessibility of the ctor of NodeComparator.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tablet last location deleted and set,ACCUMULO-628,12559768,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,07/Jun/12 22:33,19/Jun/12 22:19,13/Mar/19 22:01,19/Jun/12 22:19,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"While doing some experiments related to ACCUMULO-549 I was looking at mutations.  I noticed the following mutation and thought it was odd that it was deleting and setting the last location.  The delete will win because it sorts first.  Looking at the code this happens on the first compaction after tablet load when the last and current location are the same.  Need a check to make the delete conditional and only do it when last and current differ.

{noformat}
1 mutations:
  2<
      file:/default_tablet/F0000000.rf [system]:45 [] <deleted>
      file:/t-0000002/F0000005.rf [system]:45 [] <deleted>
      file:/t-0000003/F0000006.rf [system]:45 [] <deleted>
      file:/default_tablet/A0000007.rf [system]:45 [] 227,3
      srv:compact [system]:45 [] 0
      last:137c84429e10002 [system]:45 [] <deleted>
      last:137c84429e10002 [system]:45 [] 127.0.0.1:40200
      srv:lock [system]:45 [] tservers/127.0.0.1:40200/zlock-0000000000$137c84429e10002
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246438,,,2012-06-07 22:33:10.0,,,,,,0|i07m13:,42335,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TServer log recovery code talks to zookeeper too much and is not aggressive enough,ACCUMULO-649,12595146,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,19/Jun/12 18:35,19/Jun/12 20:42,13/Mar/19 22:01,19/Jun/12 20:42,,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"Noticed the following two issues while looking at the attemptRecoveries() method in the tabletServer.

  * Keeps trying to get locks in zookeeper when it will likely just return them immediately
  * Does not check for new work when it finishes sorting a log.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246418,,,Tue Jun 19 20:42:14 UTC 2012,,,,,,0|i07lwn:,42315,,,,,,,,"19/Jun/12 20:42;kturner;Also noticed that watcher were not being set after triggering, fixed this too.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
functional tests should run under a non-hadoop user,ACCUMULO-355,12540427,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,30/Jan/12 20:47,18/Jun/12 18:05,13/Mar/19 22:01,18/Jun/12 18:05,,,,,,,,1.4.1,,,,,,,,,0,,,,,,"run the functional tests as me, not the hadoop hdfs super-user",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,225840,,,2012-01-30 20:47:30.0,,,,,,0|i07non:,42603,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"NPE when doing shell ""config"" command",ACCUMULO-232,12536200,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,22/Dec/11 19:49,10/Jun/12 17:06,13/Mar/19 22:01,27/Dec/11 20:40,1.3.5-incubating,,,,,,,1.3.6,,,client,,,,,,0,,,,,"if the user creates a bad setting in the shell, or by using zookeeper, the shell will NPE when displaying the configuration.",create a bad setting in the shell ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-06-08 20:05:04.959,,,no_permission,,,,,,,,,,,,221883,,,Sun Jun 10 17:06:13 UTC 2012,,,,,,0|i07ofb:,42723,,,,,,,,08/Jun/12 20:05;mkirwan;Is there a way to fix this other than upgrading to 1.3.6.  I'm using 1.3.5 and encountering this same problem.  Is there a file that can be edited to remove the bad setting?,"08/Jun/12 20:07;mkirwan;More specifically, I used the config -d command to delete an iterator.  Whenever I run the config command I get the NullPointerException",09/Jun/12 22:19;billie.rinaldi;I don't immediately understand how deleting config settings would create a bad setting.  Do you recall the commands you ran so I can try to replicate the issue?,10/Jun/12 17:06;mkirwan;It turns out when I set the property using “config” I forgot to include the table name.  That property was set across all tables so config was returning a NullPointer when I executed the command.  To resolve I tried deleting the property without setting the table explicitly which did in fact work.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ageoff functional test fails,ACCUMULO-619,12559422,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,05/Jun/12 18:07,05/Jun/12 19:22,13/Mar/19 22:01,05/Jun/12 19:22,,,,,,,,1.3.6,,,,,,,,,0,,,,,Found during release testing: iterator configuration was not set properly,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246447,,,2012-06-05 18:07:36.0,,,,,,0|i07m33:,42344,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Table setting table.scan.max.memory ignored,ACCUMULO-616,12559268,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,04/Jun/12 20:39,04/Jun/12 22:02,13/Mar/19 22:01,04/Jun/12 22:02,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,tserver,,,,,,0,,,,,When the setting table.scan.max.memory is set at the table level its ignored by the batch scanner.  The setting is always read from the system level configuration.  It should be read from the table level configuration.  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246450,,,2012-06-04 20:39:18.0,,,,,,0|i07m3r:,42347,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
client fails to resolve master hostname when not using fully qualified domain name,ACCUMULO-601,12556700,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,pines,pines,21/May/12 15:29,30/May/12 17:41,13/Mar/19 22:01,30/May/12 17:41,1.4.0,,,,,,,1.4.1,1.5.0,,client,,,,,,0,,,,,"After upgrade I am unable to create or delete a table via java using either the 
conn.tableOperations().delete(tableName); 

and/or 

conn.tableOperations().create(tableName);

The error presents itself by hanging the code when it executes this line in the code. 

Important:

Table scans via java are working fine.
Table mutations via java also work fine. 

The same user account can create and deleted the table via accumulo shell. 

The cause of the code hanging cannot be determined further since there is nothing in the Eclipse logs or Server logs that provide any more information. 

I can verify that the connection to Zookeeper completes successfully... however there is no indication after that on the Server side that a call is being made to Accumulo to create/delete the table.



",Cloud was upgraded from Cloudbase 1.3.4 to Accumulo 1.3.5 and then upgraded to accumulo 1.4.0. Hadoop version is 0.20.2r911707,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-05-21 15:42:58.307,,,no_permission,,,,,,,,,,,,246465,,,Fri May 25 12:35:54 UTC 2012,,,,,,0|i07m73:,42362,,,,,,,,"21/May/12 15:42;jvines;If the shell works fine and your code does not, that leads me to think that your code is depending on the old API. How are you executing your jar? And are there any cloudbase-1.3.4 jars shaded with your code? Some of the code for create/delete changed, which would explain that code breaking between 1.3.x and 1.4.","21/May/12 21:23;pines;After narrowing down the list of jar files I needed I ran the new project and it also hangs at the same place (when it calls the create). 

Below is the List of Referenced Libraries I attached to the new Project:

 accumulo-core-1.4.0.jar
 log4j-1.2.16.jar
 zookeeper-3.3.1.jar
 libthrift-0.6.1.jar
 hadoop-0.20.2-core.jar
 commons-logging-1.0.4.jar
 slf4j-api-1.4.3.jar
 slf4j-log4j-1.4.3.jar
 cloudtrace-1.4.0.jar


","21/May/12 21:27;pines;I wanted to pass on my further testing for completness.

I still have not been able to resolve this problem. It still hangs during the create or delete from my workstation it doesn't matter whether I run this inside eclipse or from the command line. 

I Tested the following: 

Server Side (Linux): 
1. Ran my java source code on the Server and it works. 
2. I Generated a jar via Eclipse (after dumb-ing it down to 1.6 jre) and it also ran fine on the Server. 

Workstation side (Windows): 
1. Running the java source via Eclipse hangs at the create line of the code.
2. Running the jar from the Windows command line also hangs at the create line. 

Note: I re-copied the jar files from the server to the Workstation just to ensure that I was running with the exact same jar files. 

This narrows down my ideas to two possibilities: 

1. Some Firewall rule is intercepting traffic so that it hangs and never completes (however I can Scan and perform mutation on tables from my workstation). 
2. There is some kind of dependency be it Linux or some object on the Server that the create/delete class depends on that is not there in Windows. 

Note: Keeping in mind that I can run java code to scan and perform mutations against Accumulo tables and they work fine from within Eclipse (on my Workstation)leads me to lean more towards option 2 (unless there is some specific traffic that occurs when creating/deleting tables that does not occur when you scan or perform mutations).
","21/May/12 22:05;kturner;In 1.4 createtable and deletetable start FATE operations.   You can see if any of those are stuck with the following command.

{noformat}
  ./bin/accumulo org.apache.accumulo.server.fate.Admin print
{noformat}

If the client can not even reach the master to start a FATE op, then the nothing will be printed.

You can also enable log4j tracing in your client code to see if this reveals anything of interest.

{code}
public class CreateTableTest {
  
  /**
   * @param args
   */
  public static void main(String[] args) throws Exception {
    org.apache.log4j.Logger.getLogger(""org.apache.accumulo.core.client"").setLevel(Level.TRACE);
    
    ZooKeeperInstance zki = new ZooKeeperInstance(""test14"", ""localhost"");
    Connector conn = zki.getConnector(""user"", ""pass"");
    conn.tableOperations().create(""foo1"");
  }
  
}
{code}

I saw the output below when running the program above.  You can see it getting connections to the master to walk the fate operation through its steps.

{noformat}
$ ./bin/accumulo org.apache.accumulo.core.CreateTableTest
21 17:58:33,883 [impl.ThriftTransportPool] TRACE: Creating new connection to connection to 127.0.0.1:9997:9997
21 17:58:34,498 [impl.ThriftTransportPool] TRACE: Returned connection 127.0.0.1:9997:9997 (120000) ioCount : 122
21 17:58:34,584 [client.ZooKeeperInstance] TRACE: tid=12 oid=0  Looking up master location in zoocache.
21 17:58:34,596 [client.ZooKeeperInstance] TRACE: tid=12 oid=0  Found master at localhost:9999 in 0.005 secs
21 17:58:34,601 [impl.ThriftTransportPool] TRACE: Creating new connection to connection to localhost:9999:9999
21 17:58:34,660 [impl.ThriftTransportPool] TRACE: Returned connection localhost:9999:9999 (0) ioCount : 116
21 17:58:34,661 [client.ZooKeeperInstance] TRACE: tid=12 oid=1  Looking up master location in zoocache.
21 17:58:34,661 [client.ZooKeeperInstance] TRACE: tid=12 oid=1  Found master at localhost:9999 in 0.000 secs
21 17:58:34,662 [impl.ThriftTransportPool] TRACE: Using existing connection to localhost:9999:9999
21 17:58:34,709 [impl.ThriftTransportPool] TRACE: Returned connection localhost:9999:9999 (0) ioCount : 168
21 17:58:34,709 [client.ZooKeeperInstance] TRACE: tid=12 oid=2  Looking up master location in zoocache.
21 17:58:34,711 [client.ZooKeeperInstance] TRACE: tid=12 oid=2  Found master at localhost:9999 in 0.000 secs
21 17:58:34,712 [impl.ThriftTransportPool] TRACE: Using existing connection to localhost:9999:9999
21 17:58:35,748 [impl.ThriftTransportPool] TRACE: Returned connection localhost:9999:9999 (0) ioCount : 132
21 17:58:35,749 [client.ZooKeeperInstance] TRACE: tid=12 oid=3  Looking up master location in zoocache.
21 17:58:35,749 [client.ZooKeeperInstance] TRACE: tid=12 oid=3  Found master at localhost:9999 in 0.000 secs
21 17:58:35,749 [impl.ThriftTransportPool] TRACE: Using existing connection to localhost:9999:9999
21 17:58:35,806 [impl.ThriftTransportPool] TRACE: Returned connection localhost:9999:9999 (0) ioCount : 96
$
{noformat}","21/May/12 22:08;kturner;Another useful thing to do is jstack the client process that called create table.  Then look for the thread stack that called tabletOperations().create("""") and see what that thread is doing.  You could post that here.","22/May/12 22:10;pines;I think I found the problem. After turning on trace level logging I found that the code (while hanging on the create command) was repeatedly 
Indicating that ""Found master at <host name only>:9999 and throwing a ""java.net.UnknownHostException: <host name only>

I don't believe my java code on the workstation is able to resolve <host name only> to the fully qualified host name. Causing the hanging I am seeing. 

My next questions are how do I get around this: 

1. Is the entry I found in Zookeeper wrong as <host name only>:9999. Should it be <Fully Qualified Hostname>:9999 ?
2. Is there something else I need to do? 
3. What is the best approach to work around this issue (and what are the implications if any)?","22/May/12 22:39;kturner;I am not sure about this, but it may be that whatever is in your accumulo/conf/masters file ends up in zookeeper.  Try setting that to the FQDN.   ","23/May/12 12:55;kturner;This issue was too hard to debug.  What can we do to make it better?  Below are some thoughts.

  * Not retry on UnknownHostException.  It extends IOException, so we probably catch that and retry.   
  * For tablet servers we put an ip address in zookeeper and metadata table I think, look into why something different is done for the master.
  * Maybe make retry code log one warning after a certain amount of retries?  I think some of the retry code does this.","23/May/12 13:37;pines;Check inside zookeeper and I believe I found the node where it is pulling this value from. Can you confirm this? 

get /accumulo/<Instance ID>/masters/lock/lock-<8 digit number>

Note: Values in <> will be specific to the Accumulo cloud you have installed. 

The get yields the value we are seeing in the trace: <host name only>:9999
",23/May/12 13:42;kturner;The zookeeper path looks right.   Did you try changing the contents of the file <ACCUMULO_HOME>/conf/masters to contain the FQDN and restarting that master?,"23/May/12 14:21;pines;I tested changing conf/masters first using the IP address. That fixed it but as A side note zookeeper had the <fully qualified hostname>:9999 stored.

I also tested placing the <fully qualified hostname> into conf/masters. That also worked. During the first startup I got and RSA message ""The authenticity pf host ..... can't be established"" message and accepted it the first time. Subsequent starts no longer prompted and everything appears to be working normally. The value stored in zookeeper was also <fully qualified hostname>:9999. 

Not sure why (when I put the IP Address in conf/masters) the IP address was converted to the <fully qualified hostname> in zookeeper instead of keeping the IP Address.

The question is whether it would be better to let it store the IP Address (making it more consistent with other zookeeper entries) and this might work better in cases where these type of tasks want to be handled via remote administration. 

For now we have a workaround which is to either place the IP Address or since it doesn't matter put the fully qualified hostname into conf/masters.","25/May/12 12:35;afuchs;We've also had some success getting around this issue in the past by setting the domain name on all the nodes (using domainname).

The RSA message is because your ssh known hosts database doesn't have a mapping for the FQDN. The start-all.sh script uses ssh to launch processes.

Unfortunately, there are many ways to set up DNS and Linux networking, and most of them usually work for most applications. Accumulo should probably be more robust and work with a broader set of common linux networking configurations.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Table tablets not evenly spread.,ACCUMULO-398,12542567,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,14/Feb/12 17:03,29/May/12 17:49,13/Mar/19 22:01,29/May/12 17:49,,,,,,,,1.4.1,1.5.0,,,,,,,,0,14_qa_bug,,,,"I was running random walk test (with agitation) and wanted to switch to running continuous ingest test.  So I killed the random walk test (left all of its tables), created a continuous ingest table w/ 16 tablets, and started continuous ingest.  I noticed that the 16 tablets were not evenly spread across the 10 tablet servers.  2 tservers had 0, 2 tservers had 1, 5 tservers had 2, 1 tserver had 4.  I do not think this is caused by ACCUMULO-393 because I keep seeing the following in the logs.

{noformat}
14 17:02:03,325 [balancer.DefaultLoadBalancer] DEBUG: balance ended with 0 migrations
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,227853,,,Wed Feb 15 19:06:56 UTC 2012,,,,,,0|i07nfb:,42561,,,,,,,,14/Feb/12 17:10;kturner;Tried restartig the master and this did not help.  I deleted all of the other tables and then it spread the tablets out evenly.,"15/Feb/12 19:06;kturner;The current code is probably working as expected.  I was under the impression that the default Accumulo configuration would evenly balance each tables tablets across tablet servers.  However this is not the default behavior.  The default behavior is to spread all tablets in the system evenly across tablet servers.  To spread table tablets evenly the configuration master.tablet.balancer would need to be set to org.apache.accumulo.server.master.balancer.TableLoadBalancer.  This should probably be the system default.  However I am not sure I am comfortable making this change for 1.4.0 w/ all of the testing that has already been done.  Maybe this change could be made for 1.4.1?

Oh when I saw the CI tables tablets were not evenly balanced, I did not notice that all tablets were evenly balanced.  Each tablet server had about the same # of tablets.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to set system properties in shell,ACCUMULO-589,12554897,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,kturner,kturner,11/May/12 12:38,17/May/12 18:48,13/Mar/19 22:01,17/May/12 18:48,,,,,,,,1.5.0,,,client,,,,,,0,,,,,"{noformat}
root@test15> config -s master.tablet.balancer=org.apache.accumulo.server.master.balancer.TableLoadBalancer
11 12:35:08,206 [shell.Shell] ERROR: java.lang.IllegalStateException: Not in a table context. Please use 'table <tableName>' to switch to a table, or use '-t' to specify a table if option is available.
root@test15> table

table              tablepermissions   tables
root@test15> table !METADATA
root@test15 !METADATA> config -s master.tablet.balancer=org.apache.accumulo.server.master.balancer.TableLoadBalancer
11 12:35:31,581 [shell.Shell] ERROR: org.apache.accumulo.core.util.BadArgumentException: Invalid per-table property. near index 10
config -s master.tablet.balancer=org.apache.accumulo.server.master.balancer.TableLoadBalancer
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-05-11 21:26:38.267,,,no_permission,,,,,,,,,,,,239150,,,Fri May 11 23:48:10 UTC 2012,,,,,,0|i07m9r:,42374,,,,,,,,"11/May/12 21:26;billie.rinaldi;How do people feel about stability of shell command usage?  I am trying to decide what to do about this bug.  The problem is that config used the presence of the -t tableName flag to determine whether to use a table context or a system context.  Thus, config could not be made consistent with the other commands in terms of sensing the current table context and using that.  What I would really like to do is change config to use the new -a (-add) | -d (-delete) | -l (-list) set of flags (see the new ConstraintCommand), and then have -t <tableName> | -s (-system) flags to indicate the context (as grant and revoke do).  This sounds like it could make users unhappy, however.  I'll call this -a | -d | -l style of command an ADL command.  I hope to transition more of the commands to ADL options, anyway.

Another option for config would be to only allow the user to set system properties when outside of a table context.  This would still change the behavior, but less radically.  A third option would be to revert to the old config, deprecate it, and create a new ADL command with a different name.","11/May/12 23:48;ecn;I think it's ok to break this going from 1.4 to 1.5.  The shell is not so great that people are writing large, complex scripts with it.

I think that improving the user experience with day-to-day activities is better than some 12-month old 6-line script someone wrote to automatically reconfigure their development database.

We should mark changes that might cause an incompatibility with a tag so we can clearly document them at release time.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shell doesn't accept hex characters with nonzero first bit,ACCUMULO-596,12556113,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,16/May/12 20:06,17/May/12 18:48,13/Mar/19 22:01,17/May/12 18:48,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,client,,,,,,0,,,,,The shell throws BadArgumentException: unsupported non-ascii character for hex characters \x80 or greater.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246470,,,Thu May 17 13:25:52 UTC 2012,,,,,,0|i07m87:,42367,,,,,,,,"17/May/12 13:25;billie.rinaldi;It turns out that this error is thrown deliberately, which is to say that the shell cannot interpret hex characters \x80 or greater since an appropriate charset is not specified.  Calling getBytes() on a string consisting of \x80 returns a three-byte array.  Using getBytes(""ISO-8859-1"") should fix this issue as long as the same charset is used when the string is created.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
mvn assembly:single is putting logs and walogs in tar.gz,ACCUMULO-269,12537415,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,05/Jan/12 21:10,16/May/12 19:38,13/Mar/19 22:01,16/May/12 19:38,1.4.0,,,,,,,1.4.0,,,,,,,,,0,,,,,While building 1.4 I noticed that the tar ball it produced contained the contents of my logs and walogs dir.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,222923,,,2012-01-05 21:10:29.0,,,,,,0|i07o73:,42686,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Restructure contrib,ACCUMULO-593,12556041,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,16/May/12 14:40,16/May/12 17:42,13/Mar/19 22:01,16/May/12 17:42,,,,,,,,,,,contrib,,,,,,0,,,,,"So that contribs can depend on different versions of Accumulo and be released separately, the contrib directory should be restructured from contrib/trunk/project to contrib/project/trunk format.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246473,,,2012-05-16 14:40:17.0,,,,,,0|i07m8v:,42370,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to clear tablet location cache before computing input splits in input format,ACCUMULO-591,12554918,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,11/May/12 15:01,11/May/12 17:13,13/Mar/19 22:01,11/May/12 17:13,1.3.5-incubating,1.4.0,,,,,,1.4.1,1.5.0,,client,,,,,,0,,,,,Accumulo input format has the same issue as the gora accumulo input format described in GORA-130.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,239171,,,2012-05-11 15:01:35.0,,,,,,0|i07m9b:,42372,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in TableLoadBalancer,ACCUMULO-590,12554899,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,11/May/12 12:40,11/May/12 13:33,13/Mar/19 22:01,11/May/12 13:33,,,,,,,,1.5.0,,,master,,,,,,0,,,,,"I tried using the TableLoadBalancer and got an NPE

{noformat}
11 12:13:28,197 [balancer.DefaultLoadBalancer] ERROR: Unable to select a tablet to movejava.lang.NullPointerException
    at org.apache.accumulo.server.master.balancer.TabletBalancer.getOnlineTabletsForTable(TabletBalancer.java:98)
    at org.apache.accumulo.server.master.balancer.DefaultLoadBalancer.move(DefaultLoadBalancer.java:224)
    at org.apache.accumulo.server.master.balancer.DefaultLoadBalancer.getMigrations(DefaultLoadBalancer.java:152)
    at org.apache.accumulo.server.master.balancer.DefaultLoadBalancer.balance(DefaultLoadBalancer.java:305)
    at org.apache.accumulo.server.master.balancer.TableLoadBalancer.balance(TableLoadBalancer.java:145)
    at org.apache.accumulo.server.master.Master$StatusThread.balanceTablets(Master.java:2020)
    at org.apache.accumulo.server.master.Master$StatusThread.updateStatus(Master.java:1960)
    at org.apache.accumulo.server.master.Master$StatusThread.run(Master.java:1939)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,239152,,,Fri May 11 13:15:40 UTC 2012,,,,,,0|i07m9j:,42373,,,,,,,,"11/May/12 13:15;kturner;seeing npe at same spot, different cuase",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multi term grep in shell fails,ACCUMULO-562,12553144,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,kturner,kturner,27/Apr/12 14:05,01/May/12 16:24,13/Mar/19 22:01,01/May/12 16:24,1.4.0,,,,,,,1.4.1,1.5.0,,client,,,,,,0,,,,,"Tried to grep for multiple terms from the shell and it failed.

$ ./bin/accumulo shell -u ***** -p ***** -e 'grep -np -t test_ingest N A' 
27 10:00:00,426 [shell.Shell] ERROR: java.lang.IllegalArgumentException: Iterator priority is already in use 2147483647
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,237191,,,2012-04-27 14:05:48.0,,,,,,0|i07mfr:,42401,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Monitor scan mb/s does not show batch scan activity,ACCUMULO-561,12553139,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,27/Apr/12 13:34,30/Apr/12 19:33,13/Mar/19 22:01,30/Apr/12 19:33,1.3.5-incubating,1.4.0,,,,,,1.4.1,1.5.0,,tserver,,,,,,0,,,,,The monitor page has a plot for scan mb/s on the monitor page.  This plot does not show activity by the batch scanner.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,237186,,,2012-04-27 13:34:02.0,,,,,,0|i07mfz:,42402,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master retries failed bulk imports too quickly,ACCUMULO-369,12541124,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,03/Feb/12 19:53,30/Apr/12 16:30,13/Mar/19 22:01,30/Apr/12 16:30,,,,,,,,1.5.0,,,master,,,,,,0,14_qa_bug,,,,"Master retries assignments without delay, so the failures due to splits/recoveries are likely to fail, or spend time busy checking the metadata table.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,226476,,,2012-02-03 19:53:32.0,,,,,,0|i07nlj:,42589,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
metadata table needs merge,ACCUMULO-528,12550568,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,11/Apr/12 19:02,27/Apr/12 15:09,13/Mar/19 22:01,27/Apr/12 15:09,,,,,,,,1.5.0,,,master,,,,,,0,,,,,"creating and deleting many tables, especially large ones, creates empty metadata table tablets",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235432,,,2012-04-11 19:02:46.0,,,,,,0|i07mnb:,42435,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
monitor is not showing the master as down,ACCUMULO-553,12552122,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,23/Apr/12 12:41,27/Apr/12 15:06,13/Mar/19 22:01,27/Apr/12 15:06,1.3.5-incubating,,,,,,,,,,monitor,,,,,,0,,,,,"on a large cluster, master lost its zookeeper lock, but the monitor did not display/warn that the master was down",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,237206,,,2012-04-23 12:41:28.0,,,,,,0|i07mhr:,42410,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Garbage collector should call Tracer.offNoFlush instead of Tracer.off,ACCUMULO-499,12548540,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,28/Mar/12 20:04,27/Apr/12 12:10,13/Mar/19 22:01,27/Apr/12 12:10,,,,,,,,1.3.6,1.4.1,1.5.0,trace,,,,,,0,,,,,"trace table went offline, eventually GC stopped, hung on sending traces",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,233637,,,2012-03-28 20:04:24.0,,,,,,0|i07mtj:,42463,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failed log copy is not restarted,ACCUMULO-449,12545415,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,06/Mar/12 22:14,20/Apr/12 20:54,13/Mar/19 22:01,20/Apr/12 20:53,1.3.5-incubating,1.4.0,,,,,,1.4.1,1.5.0,,logger,master,,,,,0,14_qa_bug,,,,"I shut a single node instance down uncleanly.  When I restarted it the logger did not have enough memory to preform the log sort, it got an OOME and died.  I edited accumulo-env.sh and gave the logger process more memory.  I restarted the logger process.  However, the log recovery never restarted.   

The master was continually printing message like the following.

{noformat}
06 17:07:16,609 [master.CoordinateRecoveryTask] DEBUG: Copying 65c48045-88c1-48e4-93d3-4865a9a86050 from xxx.xxx.xxx.xxx:11224 (for 1210.306000 seconds) 0.0
{noformat}

After 20m I restarted the master and then log recovery proceeded.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-03-07 00:31:21.369,,,no_permission,,,,,,,,,,,,230601,,,Fri Apr 20 20:53:49 UTC 2012,,,,,,0|i07n4f:,42512,,,,,,,,06/Mar/12 22:44;kturner;Originally the logger had a max of 128m of heap.  I think I copied accumulo-env.sh.512MBBstandalone-native-example.  I upped the logger heap to 512m max.,"07/Mar/12 00:31;ecn;It does restart, but it takes a long time to timeout (an hour?!?).  We need to use an API to get the status from the logger: using HDFS to communicate is too much of a kludge.
",07/Mar/12 16:01;kturner;Should probably notice that the logger lost its zookeeper lock.,20/Apr/12 20:53;kturner;ACCUMULO-388 should test the fix for this issue,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
make system iterators thread-safer,ACCUMULO-533,12550861,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,afuchs,afuchs,afuchs,13/Apr/12 19:06,16/Apr/12 19:32,13/Mar/19 22:01,16/Apr/12 19:32,1.4.0,,,,,,,1.4.1,1.5.0,,,,,,,,0,,,,,"It is possible that at some point in the future users will want to write multi-threaded iterators. This could possibly introduce thread safety problems in the system iterators, especially in the case where multiple threads might be calling ""next"", ""getTopKey"", etc. at the same time. In order to maintain some semblance of sanity, we need to synchronize these methods at the top of the system iterator tree. Eventually, we might also want to change the iterator API to make it useful to call multiple of these methods concurrently, but that will be in another ticket.

The immediate solution calls for a simple iterator that is similar to the WrappingIterator called the SynchronizedIterator, all of whose public methods are synchronized on the object's monitor. In single-node performance testing we found the read performance cost of this solution to be below the noise threshold, approximately less than a 1% cost.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-04-16 14:05:04.226,,,no_permission,,,,,,,,,,,,235725,,,Mon Apr 16 19:32:35 UTC 2012,,,,,,0|i07mm7:,42430,,,,,,,,"16/Apr/12 14:05;billie.rinaldi;Adam, you need to use our format and code template.  New files must contain an Apache header.  Eclipse configuration instructions are here:
http://accumulo.apache.org/source.html",16/Apr/12 19:32;afuchs;Formatting fixed.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master is not reseting connections to tservers after communication errors,ACCUMULO-530,12550703,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,12/Apr/12 16:14,12/Apr/12 18:47,13/Mar/19 22:01,12/Apr/12 18:47,1.3.5-incubating,,,,,,,1.3.6,,,master,,,,,,0,,,,,"After having an I/O error (timeout), the master never reset the connection to the server, causing tablet assignment to fail continuously.",large customer cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235567,,,Thu Apr 12 16:15:11 UTC 2012,,,,,,0|i07mmv:,42433,,,,,,,,12/Apr/12 16:15;ecn;this bug does not exist in 1.4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Build Errors - CentOS with Trunk,ACCUMULO-88,12529191,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,karafman,karafman,28/Oct/11 03:16,03/Apr/12 17:46,13/Mar/19 22:01,03/Apr/12 17:46,,,,,,,,1.3.5-incubating,,,tserver,,,,,,0,,,,,"[INFO] ------------------------------------------------------------------------
[INFO] Building accumulo-server
[INFO]    task-segment: [package]
[INFO] ------------------------------------------------------------------------
[INFO] [enforcer:enforce {execution: enforce-mvn}]
[INFO] [resources:resources {execution: default-resources}]
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 38 resources
[INFO] [dependency:copy-dependencies {execution: copy-dependencies}]
[INFO] commons-configuration-1.5.jar already exists in destination.
[INFO] commons-io-1.4.jar already exists in destination.
[INFO] commons-lang-2.4.jar already exists in destination.
[INFO] jline-0.9.94.jar already exists in destination.
[INFO] log4j-1.2.16.jar already exists in destination.
[INFO] [compiler:compile {execution: default-compile}]
[INFO] Compiling 410 source files to /home/blue/workspace/accumulo-trunk/src/server/target/classes
[INFO] ------------------------------------------------------------------------
[ERROR] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Compilation failure

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[207,65] cannot find symbol
symbol: class TabletServerMBean
public class TabletServer extends AbstractMetricsImpl implements TabletServerMBean {

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[2649,28] cannot find symbol
symbol  : constructor StandardMBean(org.apache.accumulo.server.tabletserver.TabletServer,java.lang.Class<org.apache.accumulo.server.tabletserver.metrics.TabletServerMBean>,boolean)
location: class javax.management.StandardMBean

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3137,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3149,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3161,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3173,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3186,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3199,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3212,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3225,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3232,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3239,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3251,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3258,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3265,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3272,2] method does not override or implement a method from a supertype

/home/blue/workspace/accumulo-trunk/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java:[3279,2] method does not override or implement a method from a supertype


[INFO] ------------------------------------------------------------------------
[INFO] Trace
org.apache.maven.BuildFailureException: Compilation failure
	at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:715)
	at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalWithLifecycle(DefaultLifecycleExecutor.java:556)
	at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoal(DefaultLifecycleExecutor.java:535)
	at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalAndHandleFailures(DefaultLifecycleExecutor.java:387)
	at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeTaskSegments(DefaultLifecycleExecutor.java:348)
	at org.apache.maven.lifecycle.DefaultLifecycleExecutor.execute(DefaultLifecycleExecutor.java:180)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:328)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:138)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:362)
	at org.apache.maven.cli.compat.CompatibleMain.main(CompatibleMain.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.codehaus.classworlds.Launcher.launchEnhanced(Launcher.java:315)
	at org.codehaus.classworlds.Launcher.launch(Launcher.java:255)
	at org.codehaus.classworlds.Launcher.mainWithExitCode(Launcher.java:430)
	at org.codehaus.classworlds.Launcher.main(Launcher.java:375)
Caused by: org.apache.maven.plugin.CompilationFailureException: Compilation failure
	at org.apache.maven.plugin.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:516)
	at org.apache.maven.plugin.CompilerMojo.execute(CompilerMojo.java:114)
	at org.apache.maven.plugin.DefaultPluginManager.executeMojo(DefaultPluginManager.java:490)
	at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:694)
	... 17 more
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2 minutes 5 seconds
[INFO] Finished at: Thu Oct 27 23:07:46 EDT 2011
[INFO] Final Memory: 45M/120M
[INFO] ------------------------------------------------------------------------
","[blue@localhost accumulo-trunk]$ mvn --version
Apache Maven 2.2.1 (r801777; 2009-08-06 15:16:01-0400)
Java version: 1.6.0_29
Java home: /home/blue/Development/jdk1.6.0_29/jre
Default locale: en_US, platform encoding: UTF-8
OS name: ""linux"" version: ""2.6.32-71.29.1.el6.x86_64"" arch: ""amd64"" Family: ""unix""

This issue also came up using the equivelent version of OpenJDK.  Am reporting this because I was able to validate that this error was not isolated to open jdk.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-10-30 01:15:11.937,,,no_permission,,,,,,,,,,,,215051,,,Tue Apr 03 17:46:15 UTC 2012,,,,,,0|i07pan:,42864,,,,,,,,"28/Oct/11 03:20;karafman;This issue came up when I downloaded the trunk, and attemped to compile it.  This error was reproduced by Oracle JDK 1.6.0_29 and the equivelent version of OpenJDK.  Because I was able to verify this was an issue, I thought it was worthy of reporting.

The problem is, that for whatever reason, maven isn't compiling the referenced class before the class that needs it. As such, it is not present, and the compiler cannot find it.  At least, that's the best I can think of regarding this issue.",28/Oct/11 03:21;karafman;The source code I used was updated tonight at about 7 pm EST.,"30/Oct/11 01:15;billie.rinaldi;I've been able to reproduce this error.  If I change the class declaration to ""implements org.apache.accumulo.server.tabletserver.metrics.TabletServerMBean"", it works.  If instead I add a cast to the first argument of the StandardMBean constructor ""StandardMBean mbean = new StandardMBean((TabletServerMBean)this, TabletServerMBean.class, false);"" it leaves out the cannot find symbol error for the constructor, but the other errors are still there.  (More information about the StandardMBean constructor is here: http://www.oracle.com/technetwork/java/javase/adoptionguide-137484.html)","31/Oct/11 14:44;ecn;eclipse probably compiled the TabletServerMBean while I was trying to figure out this error, which allowed the command-line build to succeed.  However if I performed a ""mvn clean"" the problem came back.

Micheal, can you verify that the work-around works for you, too? (svn update)

",03/Apr/12 17:46;ecn;Verified this is fixed.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
root tablet fails to load after recovery when all minor compaction threads are busy,ACCUMULO-484,12547611,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,22/Mar/12 15:18,27/Mar/12 17:23,13/Mar/19 22:01,27/Mar/12 17:23,,,,,,,,1.4.0,,,,,,,,,0,14_qa_bug,,,,8 of 10 servers on a small test cluster failed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,232709,,,2012-03-22 15:18:45.0,,,,,,0|i07mwn:,42477,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tablet server runs out of memory after 8 hours of continuous ingest,ACCUMULO-486,12547618,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,22/Mar/12 15:41,27/Mar/12 17:22,13/Mar/19 22:01,27/Mar/12 17:21,1.3.5-incubating,,,,,,,1.3.6,1.4.0,,scripts,,,,,,0,14_qa_bug,,,,This happened using the new conf/examples/3GB/native config,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-03-22 16:04:48.917,,,no_permission,,,,,,,,,,,,232716,,,Thu Mar 22 18:30:03 UTC 2012,,,,,,0|i07mw7:,42475,,,,,,,,"22/Mar/12 16:04;kturner;This was not caused by the cache.   I looked at one of the servers that died.  The cache was not being used.  this makes sense, I only ran ingest clients for the test.  I did not run query clients.  I set compression to snappy for the test, so there could be a memory leak there.

{noformat}
22 06:31:08,329 [cache.LruBlockCache] DEBUG: Cache Stats: Sizes: Total=0.0043945312MB (4608), Free=49.995605MB (52424192), Max=50.0MB (52428800), Counts: Blocks=0, Access=0, Hit=0, Miss=0, Evictions=0, Evicted=0, Ratios: Hit Ratio=NaN%, Miss Ratio=NaN%, Evicted/Run=NaN, Duplicate Reads=0
22 06:31:08,329 [cache.LruBlockCache] DEBUG: Cache Stats: Sizes: Total=0.03403473MB (35688), Free=511.96597MB (536835224), Max=512.0MB (536870912), Counts: Blocks=0, Access=0, Hit=0, Miss=0, Evictions=0, Evicted=0, Ratios: Hit Ratio=NaN%, Miss Ratio=NaN%, Evicted/Run=NaN, Duplicate Reads=0
22 06:31:08,342 [tabletserver.TabletServer] DEBUG: gc ParNew=185.62(+0.00) secs ConcurrentMarkSweep=530.86(+0.10) secs freemem=5,457,224(+3,473,976) totalmem=1,060,372,480
{noformat}","22/Mar/12 18:20;kturner;Eric and I looked at a heap dump of one the servers that was still alive and had a little bit of free memory.  We figured out why the servers ran out of memory.  Looks like thrift transports were not being returned to the pool.  These transports have a .5M buffer.  The logger was not returning these.  This bug has existed for a while, but config changes made it happen faster. Tablet server memory was lowered and the log size was lowered, making logger connections more frequent. Every new logger connection consumed .5M.","22/Mar/12 18:30;kturner;This bug occurred after 8 hours of continuous ingest.  The config changes lowered memory from 3G to 1G and walog size from 1G to 100M.  So under the old config this bug would take ~240 hours to occur, which is why we did not see it in previous testing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make sure iterators handle deletion entries properly,ACCUMULO-414,12542964,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,16/Feb/12 22:55,12/Mar/12 19:36,13/Mar/19 22:01,12/Mar/12 19:36,1.3.5-incubating,,,,,,,1.4.0,,,client,,,,,,0,iterators,,,,In minor compaction scope and in non-full major compaction scopes the iterator may see deletion entries. These entries should be preserved by all iterators except ones that are strictly scan-time iterators that will never be configured for the minc or majc scopes. Deletion entries are only removed during full major compactions.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,228250,,,Mon Mar 12 19:36:11 UTC 2012,,,,,,0|i07nc7:,42547,,,,,,,,"12/Mar/12 19:36;billie.rinaldi;This is done for relevant user iterators in 1.4.0.  We should keep it in mind for the future, though.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BooleanLogicIterator cannot handle ORs correctly,ACCUMULO-447,12545376,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,06/Mar/12 17:35,12/Mar/12 19:18,13/Mar/19 22:01,12/Mar/12 19:18,,,,,,,,1.4.0,,,wikisearch,,,,,,0,,,,,"When an OR clause in a query tree has negations in that subtree and does not have a document which matches the query, the BooleanLogicIterator cannot ascertain whether that subtree has more results to search or whether the subtree is exhausted.

eg. if we search for 
{noformat}
(field1 == 'a' && field2 != 'a') || (field2 == 'a' && field1 != 'a')
{noformat}
 and say DOC1 has both field1 and field2 equal to 'a', BooleanLogicIterator cannot determine whether it needs to call next() to find more reults ore whether to set its own topKey to null and quit. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,230562,,,2012-03-06 17:35:28.0,,,,,,0|i07n4v:,42514,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"boolean logic iterators do not correctly ""jump()""",ACCUMULO-446,12545375,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,06/Mar/12 17:29,12/Mar/12 19:18,13/Mar/19 22:01,12/Mar/12 19:18,,,,,,,,1.4.0,,,wikisearch,,,,,,0,,,,,"When a scan is interrupted and reinitialized, the state is not properly recreated which can cause large amounts of query results to never be returned.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,230561,,,2012-03-06 17:29:22.0,,,,,,0|i07n53:,42515,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shell in mock mode doesn't use instance name,ACCUMULO-396,12542455,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,13/Feb/12 22:56,02/Mar/12 20:42,13/Mar/19 22:01,02/Mar/12 20:42,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,client,,,,,,0,mock,shell,,,"When you specify the --fake option to the shell, it uses a MockInstance without specifying an instance name.  Under some conditions this won't persist data the way we would want.  We should specify an instance name, e.g. ""fake"" or ""mock"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,227741,,,2012-02-13 22:56:28.0,,,,,,0|i07nfr:,42563,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
References to accumulo-examples still exist,ACCUMULO-405,12542739,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,15/Feb/12 19:51,02/Mar/12 20:37,13/Mar/19 22:01,02/Mar/12 20:37,,,,,,,,1.4.0,,,docs,scripts,,,,,0,,,,,"Some scripts and documentation refer to the accumulo-examples jar, which is now examples-simple.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,228025,,,2012-02-15 19:51:07.0,,,,,,0|i07ndr:,42554,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Web site lacks link to actual svn,ACCUMULO-386,12542117,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,bmargulies,bmargulies,10/Feb/12 14:22,02/Mar/12 20:22,13/Mar/19 22:01,02/Mar/12 20:22,,,,,,,,,,,docs,,,,,,0,,,,,"http://incubator.apache.org/accumulo/get_involved.html should have a link to the actual svn repo, not just to the generic ASF svn docs.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-02-10 15:21:22.067,,,no_permission,,,,,,,,,,,,227404,,,Fri Feb 10 15:38:41 UTC 2012,,,,,,0|i07nhr:,42572,,,,,,,,10/Feb/12 15:21;kturner;Which one of our pages should have this link?,10/Feb/12 15:33;bmargulies;I fixed the link in the description.,"10/Feb/12 15:36;bmargulies;OK, something funny is happening here. I followed some link that I thought was to an Accumulo-specific 'get involved' page, and instead ended up on a Foundation-generic page, and I didn't realize. Thus the original text of this JIRA.

Now I've looked at your specific get_involved page. I don't mean to dictate that this has a link to your svn repo, but maybe it should have a link to http://incubator.apache.org/accumulo/source.html?

My original self-misdirection may have been a stray click or it may have been a link, if I can find it I'll add it.

","10/Feb/12 15:38;bmargulies;I checked my browser history, and I can't find any explanation for how I landed on the foundation-generic svn page except for misreading a google result. So feel free to close this out, though i still think it would be good to connect from the get involved page to the source page.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tablet merge stuck,ACCUMULO-436,12544607,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,29/Feb/12 13:14,02/Mar/12 17:57,13/Mar/19 22:01,02/Mar/12 17:57,,,,,,,,1.4.0,,,master,,,,,,0,14_qa_bug,,,,"After 14 hours of randomwalk, a merge operation appeared to be stuck.


Garbage collector was stuck, some tablets were offline:
||\# Online Tablet Servers||	\# Total Tablet Servers||	Loggers	Last GC	||\# Tablets	||\# Unassigned||Tablets||Entries||Ingest||Query||Hold Time||OS Load||
|10	|10	|10	|*Running 2/29/12 12:14 PM*	|299	|*4*	|277.50M	|311	|5.53K	|—	|0.50|


Garbage collector could not get a consistent !METADATA table scan:
{noformat}
29 13:04:10,808 [util.TabletIterator] INFO : Resetting !METADATA scanner to [24q;5f83b8f927c41c9d%00; : [] 9223372036854775807 false,~ : [] 9223372036854775807 false)
29 13:04:11,071 [util.TabletIterator] INFO : Metadata inconsistency : 1419e44259517c51 != 5f83b8f927c41c9d metadataKey = 24q< ~tab:~pr [] 724883 false
{noformat}

Table (id 24q) had a merge in progress:
{noformat}
./bin/accumulo org.apache.accumulo.server.fate.Admin print
txid: 7bea12fa46c40a72  status: IN_PROGRESS         op: BulkImport       locked: []              locking: [R:24q]         top: BulkImport
txid: 08db6105a25c0788  status: IN_PROGRESS         op: CloneTable       locked: []              locking: [R:24q]         top: CloneTable
txid: 5f798db1cab5fdea  status: IN_PROGRESS         op: BulkImport       locked: []              locking: [R:24q]         top: BulkImport
txid: 6aa9a8a9b36a4f4d  status: IN_PROGRESS         op: TableRangeOp     locked: []              locking: [W:24q]         top: TableRangeOp
txid: 5c6e82e235ec3855  status: IN_PROGRESS         op: TableRangeOp     locked: []              locking: [W:24q]         top: TableRangeOp
txid: 653a9293ba9f1cdc  status: IN_PROGRESS         op: RenameTable      locked: []              locking: [W:24q]         top: RenameTable
txid: 651c62eb37136b6e  status: IN_PROGRESS         op: TableRangeOp     locked: [W:24q]         locking: []              top: TableRangeOpWait
{noformat}

Scan of table 24q:
{noformat}
scan -b 24q; -e 24q<
24q;073b220b74a75059 loc:135396fb191d4b6 []    192.168.117.6:9997
24q;073b220b74a75059 srv:compact []    3
24q;073b220b74a75059 srv:dir []    /t-00031y0
24q;073b220b74a75059 srv:lock []    tservers/192.168.117.7:9997/zlock-0000000002$3353986642ea7f3
24q;073b220b74a75059 srv:time []    M0
24q;073b220b74a75059 ~tab:~pr []    \x00
24q;1419e44259517c51 loc:235396fb184b5cd []    192.168.117.12:9997
24q;1419e44259517c51 srv:compact []    3
24q;1419e44259517c51 srv:dir []    /t-00031y1
24q;1419e44259517c51 srv:lock []    tservers/192.168.117.7:9997/zlock-0000000002$3353986642ea7f3
24q;1419e44259517c51 srv:time []    M0
24q;1419e44259517c51 ~tab:~pr []    \x01073b220b74a75059
24q;51fc3e7faea2b7e9 chopped:chopped []    chopped
24q;51fc3e7faea2b7e9 srv:compact []    3
24q;51fc3e7faea2b7e9 srv:dir []    /t-00031y2
24q;51fc3e7faea2b7e9 srv:lock []    tservers/192.168.117.7:9997/zlock-0000000002$3353986642ea7f3
24q;51fc3e7faea2b7e9 srv:time []    M0
24q;51fc3e7faea2b7e9 ~tab:~pr []    \x011419e44259517c51
24q;5e65b844f2c7f868 chopped:chopped []    chopped
24q;5e65b844f2c7f868 srv:compact []    3
24q;5e65b844f2c7f868 srv:dir []    /t-00031e1
24q;5e65b844f2c7f868 srv:lock []    tservers/192.168.117.7:9997/zlock-0000000002$3353986642ea7f3
24q;5e65b844f2c7f868 srv:time []    M0
24q;5e65b844f2c7f868 ~tab:~pr []    \x0151fc3e7faea2b7e9
24q;5f83b8f927c41c9d chopped:chopped []    chopped
24q;5f83b8f927c41c9d srv:compact []    3
24q;5f83b8f927c41c9d srv:dir []    /t-000329w
24q;5f83b8f927c41c9d srv:lock []    tservers/192.168.117.6:9997/zlock-0000000002$135396fb191c4f3
24q;5f83b8f927c41c9d srv:time []    M0
24q;5f83b8f927c41c9d ~tab:~pr []    \x015e65b844f2c7f868
24q< chopped:chopped []    chopped
24q< srv:compact []    3
24q< srv:dir []    /default_tablet
24q< srv:lock []    tservers/192.168.117.6:9997/zlock-0000000002$135396fb191c4f3
24q< srv:time []    M0
24q< ~tab:~pr []    \x011419e44259517c51
{noformat}

Master Logs
{noformat}
29 13:11:49,903 [state.MergeStats] INFO : Computing next merge state for 24q;6badf28df1d8ece7;37f3488aa92ac056 which is presently MERGING isDelete : false
29 13:11:49,903 [state.MergeStats] INFO : 4 tablets are unassigned 24q;6badf28df1d8ece7;37f3488aa92ac056
{noformat}

The final consistency check is failing because the merge is partially complete.  The final step is not ""adampotent"" enough: partial execution leaves the Repo in a state in which it cannot continue after restart.
",randomwalk with agitation on 10-node test cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-02-29 16:05:30.717,,,no_permission,,,,,,,,,,,,229793,,,Wed Feb 29 16:25:34 UTC 2012,,,,,,0|i07n7b:,42525,,,,,,,,"29/Feb/12 16:05;kturner;I think a further change needs to be made.  The new mergeStarted() function looks at the prevRow to determine if a merge was started.  The deleteTablets() funtion will deletes stuff from !METADATA and then modifies prevrow.  So if deleteTablets() is terminated between deleting stuff and updating the prevrow, then I think mergeStarted() and verifyMergeConsistency() will both return false indefinitely. I thought of switching the order of operations, but this is tricky because the high tablet could be deleted (this would cause the getHighTablet() method to throw an exception).

I am thinking a solution is to put a marker in zookeeper when the merge starts, and if that is there continue.  I thought of putting a marker in the !METADATA table, but the way deleteTablets() works there is no good place to put it.","29/Feb/12 16:21;ecn;Good catch.  Zookeeper is probably the simplest option for now. We should use Fate/Repo to perform the last part of the merge in 1.4.1 or 1.5.
",29/Feb/12 16:25;kturner;Looking at the code I noticed that getHighTablet() may throw an exception of read a tablet form the next table in the case where the high tablet does not exist.  This a case that could occur if deleteTablets() is run twice.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tablet being unassigned/reassigned frequently,ACCUMULO-329,12538992,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,19/Jan/12 16:32,28/Feb/12 19:46,13/Mar/19 22:01,28/Feb/12 19:46,,,,,,,,1.4.0,,,master,,,,,,0,14_qa_bug,,,,"See the following (summary) of tablet history on a tablet server:

{noformat}
19 04:38:17,053 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:17,061 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:17,200 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:17,225 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:17,359 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:17,369 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:17,504 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:17,512 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:17,686 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:17,694 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:17,843 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:17,851 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:17,996 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:18,005 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:18,144 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:18,153 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:18,311 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:18,320 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:18,507 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:18,517 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:18,674 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:18,686 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:18,833 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:18,842 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:19,017 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:19,027 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:19,172 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:19,182 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:19,326 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:19,336 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
19 04:38:19,477 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< opened 
19 04:38:19,485 [tabletserver.Tablet] TABLET_HIST: !0;~;!0< closed
{noformat}",doing random walk tests on a small cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-02-01 20:52:57.305,,,no_permission,,,,,,,,,,,,224494,,,Mon Feb 27 19:07:33 UTC 2012,,,,,,0|i07nu7:,42628,,,,,,,,01/Feb/12 20:52;kturner;LAst night we had a successful run of random walk.  I looked in the logs from this run and did not see the metadata tablets being bounced around like the master had too much mountain dew.  When we saw this behavior before there were also other issues that have since been fixed.  Not sure if those issues caused this in some way.  We will keep looking for this issue as we test.,27/Feb/12 19:07;kturner;We are seing this issue with tables other than !METADATA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
importdirectory failing on split table,ACCUMULO-412,12542959,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,16/Feb/12 22:33,17/Feb/12 20:05,13/Mar/19 22:01,17/Feb/12 20:05,,,,,,,,1.4.0,,,tserver,,,,,,0,,,,,bulk import for the wikisearch example isn't working properly: files are not being assigned to partitions if there are splits.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,228245,,,2012-02-16 22:33:09.0,,,,,,0|i07ncn:,42549,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Master not balancing after agitation,ACCUMULO-393,12542420,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,13/Feb/12 16:52,16/Feb/12 15:50,13/Mar/19 22:01,16/Feb/12 15:50,,,,,,,,1.4.0,,,,,,,,,0,14_qa_bug,,,,"Ran continuous ingest with agitation for 14 hours.  After this the tablets were left in an unbalanced state.  Saw the following in the master logs.

See a new tablet server xxx.xxx.xxx.12:9997[235396fb181e0c6]

{noformat}
12 07:47:19,370 [master.Master] INFO : New servers: [xxx.xxx.xxx.12:9997[235396fb181e0c6]]
12 07:50:27,199 [master.Master] INFO : New servers: [xxx.xxx.xxx.4:9997[135396fb18ee67f], xxx.xxx.xxx.7:9997[3353986642be160], xxx.xxx.xxx.5:9997[3353986642be24f], xxx.xxx.xxx.13:9997[135396fb18ee715], xxx.xxx.xxx.9:9997[3353986642be24e], xxx.xxx.xxx.6:9997[135396fb18ee6ca], xxx.xxx.xxx.10:9997[235396fb181df91], xxx.xxx.xxx.8:9997[135396fb18ee6cb], xxx.xxx.xxx.12:9997[235396fb181e0c6]]
{noformat}

The tablet server dies

{noformat}
12 07:57:44,868 [master.Master] DEBUG: Normal Tablets assigning tablet 6;06e04e;06c056=xxx.xxx.xxx.12:9997[235396fb181e0c6]
12 08:05:30,984 [master.Master] INFO : New servers: [xxx.xxx.xxx.4:9997[235396fb181e109], xxx.xxx.xxx.7:9997[3353986642be160], xxx.xxx.xxx.5:9997[3353986642be24f], xxx.xxx.xxx.9:9997[3353986642be300], xxx.xxx.xxx.6:9997[235396fb181e107], xxx.xxx.xxx.10:9997[235396fb181df91], xxx.xxx.xxx.8:9997[135396fb18ee7ab], xxx.xxx.xxx.12:9997[235396fb181e0c6], xxx.xxx.xxx.13:9997[235396fb181e108]]
12 08:05:56,044 [master.Master] WARN : Lost servers [xxx.xxx.xxx.12:9997[235396fb181e0c6]]
12 08:05:58,718 [master.Master] ERROR: unable to get tablet server status xxx.xxx.xxx.12:9997[235396fb181e0c6] null
12 08:05:58,718 [master.Master] DEBUG: unable to get tablet server status xxx.xxx.xxx.12:9997[235396fb181e0c6]
12 08:05:58,721 [master.Master] DEBUG: not balancing because the balance information is out-of-date [xxx.xxx.xxx.7:9997[3353986642be160], xxx.xxx.xxx.5:9997[3353986642be24f], xxx.xxx.xxx.8:9997[135396fb18ee7ab], xxx.xxx.xxx.12:9997[235396fb181e0c6]]
12 08:05:58,728 [master.Master] DEBUG: not balancing because the balance information is out-of-date [xxx.xxx.xxx.7:9997[3353986642be160], xxx.xxx.xxx.5:9997[3353986642be24f], xxx.xxx.xxx.8:9997[135396fb18ee7ab], xxx.xxx.xxx.12:9997[235396fb181e0c6]]
12 08:05:59,065 [master.Master] DEBUG: not balancing because the balance information is out-of-date [xxx.xxx.xxx.7:9997[3353986642be160], xxx.xxx.xxx.5:9997[3353986642be24f], xxx.xxx.xxx.8:9997[135396fb18ee7ab], xxx.xxx.xxx.12:9997[235396fb181e0c6]]
12 08:05:59,641 [master.Master] DEBUG: 1 assigned to dead servers: [6;3d40b2;3d20b1@(null,xxx.xxx.xxx.12:9997[235396fb181e0c6],null)]...
12 08:05:59,715 [master.Master] DEBUG: not balancing because the balance information is out-of-date [xxx.xxx.xxx.12:9997[235396fb181e0c6]]
{noformat}

Another instance of a tablet server start on xxx.xxx.xxx.12

{noformat}
12 08:07:35,245 [master.Master] INFO : New servers: [xxx.xxx.xxx.7:9997[3353986642be345], xxx.xxx.xxx.12:9997[235396fb181e15c]]
{noformat}


Much later its still not balancing for some reason.

{noformat}
13 16:31:24,131 [master.Master] DEBUG: not balancing because the balance information is out-of-date [xxx.xxx.xxx.12:9997[235396fb181e0c6]]
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-02-16 15:50:22.489,,,no_permission,,,,,,,,,,,,227706,,,Thu Feb 16 15:50:22 UTC 2012,,,,,,0|i07ngf:,42566,,,,,,,,16/Feb/12 15:50;ecn;needed to shrink the list of badServers to the list of the current servers,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cache consistency bug in ClientServiceHandler.checkTableId(),ACCUMULO-270,12537424,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,05/Jan/12 22:00,09/Feb/12 22:27,13/Mar/19 22:01,10/Jan/12 17:09,,,,,,,,1.4.0,,,tserver,,,,,,0,14_qa_bug,,,,"While running the random walk test on 10 node cluster the security random walk test failed.

{noformat}
Caused by: org.apache.accumulo.core.client.AccumuloSecurityException: Error TABLE_DOESNT_EXIST - Unknown security exception
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.execute(SecurityOperationsImpl.java:70)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.hasTablePermission(SecurityOperationsImpl.java:269)
        at org.apache.accumulo.server.test.randomwalk.security.AlterTablePerm.alter(AlterTablePerm.java:81)
{noformat}

The test was trying to check permissions on a table, and got an error saying that the table did not exist.  Looking at the master logs it seems like the table was created about 40ms before the check.  The hasTablePermission code chooses a random tablet server to do the check.  I suspect the zoo cache on the random tablet server was not yet updated.  Many places in the 1.4 code have the pattern that if something fails, then clear the cache and retry.  The code that threw the table not found exception does not do this, but needs to.  org.apache.accumulo.server.client.ClientServiceHandler.checkTableId() or something it calls should clear the cache and retry when it thinks the table does not exist.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,222932,,,2012-01-05 22:00:04.0,,,,,,0|i07o6v:,42685,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
WholeRowIterator may call hasTop on unseeked source,ACCUMULO-271,12537429,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,05/Jan/12 22:38,09/Feb/12 22:26,13/Mar/19 22:01,10/Jan/12 17:10,,,,,,,,1.4.0,,,,,,,,,0,14_qa_bug,,,,"A random walker failed while running the security test against 1.4.  Saw the following :

{noformat}
05 21:11:02,632 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Security.xml
  .
  . 
  .
Caused by: org.apache.thrift.TApplicationException: Internal error processing waitForTableOperation
        at org.apache.thrift.TApplicationException.read(TApplicationException.java:108)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Client.recv_waitForTableOperation(MasterClientService.java:684)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Client.waitForTableOperation(MasterClientService.java:665)
  .
  .
  .
{noformat}

Looked in the master log around that time and saw the following :

{noformat}
05 21:11:02,560 [fate.Fate] WARN : Failed to execute Repo, tid=07a6674a2cad866e
java.lang.RuntimeException: org.apache.accumulo.core.client.impl.AccumuloServerException: Error on server xxx.xxx.xxx.xxx:9997
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.hasNext(TabletServerBatchReaderIterator.java:188)
        at org.apache.accumulo.server.master.state.MetaDataTableScanner.hasNext(MetaDataTableScanner.java:93)
        at org.apache.accumulo.server.master.tableOps.CleanUp.isReady(DeleteTable.java:94)
{noformat}

Went to that tablet server and saw the following :

{noformat}
05 21:11:02,523 [tabletserver.TabletServer] WARN : exception while doing multi-scan
java.lang.IllegalStateException: never been seeked
        at org.apache.accumulo.core.iterators.WrappingIterator.hasTop(WrappingIterator.java:71)
        at org.apache.accumulo.core.iterators.user.VersioningIterator.hasTop(VersioningIterator.java:81)
        at org.apache.accumulo.core.iterators.user.WholeRowIterator.hasTop(WholeRowIterator.java:207)
        at org.apache.accumulo.server.master.state.TabletStateChangeIterator.consume(TabletStateChangeIterator.java:113)
        at org.apache.accumulo.core.iterators.SkippingIterator.seek(SkippingIterator.java:38)
        at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.readNext(SourceSwitchingIterator.java:118)
        at org.apache.accumulo.core.iterators.system.SourceSwitchingIterator.next(SourceSwitchingIterator.java:105)
        at org.apache.accumulo.server.tabletserver.Tablet.lookup(Tablet.java:1622)
        at org.apache.accumulo.server.tabletserver.Tablet.lookup(Tablet.java:1706)
{noformat}


Looking at the code I think the WholeRowIterator may call hasTop on its source iterator w/o seeking it sometimes.  This is because its seek function may return w/o seeking the source iterator.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,222937,,,2012-01-05 22:38:16.0,,,,,,0|i07o6n:,42684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Master has thousands of threads while running random walk,ACCUMULO-316,12538385,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,14/Jan/12 02:50,09/Feb/12 22:25,13/Mar/19 22:01,24/Jan/12 20:23,,,,,,,,1.4.0,,,master,,,,,,0,14_qa_bug,,,,While running the random walk test I jstacked the master and saw thousands of batch scanner threads.  The number of threads was growing.  Something is not closing a batch scanner.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,223891,,,2012-01-14 02:50:33.0,,,,,,0|i07nx3:,42641,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master lost all tablet servers,ACCUMULO-327,12538985,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,ecn,ecn,19/Jan/12 15:50,09/Feb/12 22:24,13/Mar/19 22:01,01/Feb/12 20:42,,,,,,,,1.4.0,,,tserver,,,,,,0,14_qa_bug,,,,"Master would occasionally take a long time to collect status information from a tablet server.  The connection would timeout after the default 120 second RPC time.  This probably left the connection in a bad state because I am seeing

{noformat}
org.apache.thrift.protocol.TProtocolException: Expected protocol id ffffff82 but got 0
        at org.apache.thrift.protocol.TCompactProtocol.readMessageBegin(TCompactProtocol.java:445)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.recv_halt(TabletClientService.java:893)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Client.halt(TabletClientService.java:876)
{noformat}

If the master is unable to collect statistics on the tablet server, it attempts to halt it (as above) and then it removes its lock in zookeeper.

Eventually, under the pressure of random walk operations, the master killed every tablet server.

Guess: a lock in the tablet server is delaying status reporting.

I wrote a script to process the master logs.  It saves each line that refers to the IP address of a tablet server.  When it sees the zookeeper lock has been deleted, it prints the last N lines that refer to that tablet server.

In 7 out of the 10 cases, a split timed out prior or during the status request failures.

In 5 cases, the tablet server was hosting the root tablet (a necessary condition when the last server died).

In 5 cases, the table_table info tablet was being hosted.

",running the random walk test on a small cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-20 16:49:31.992,,,no_permission,,,,,,,,,,,,224487,,,Mon Jan 30 18:15:41 UTC 2012,,,,,,0|i07nun:,42630,,,,,,,,"20/Jan/12 16:49;kturner;I added the following and reran the random walk test overnight.  The patch makes the java process print a stack track before killing itself.  I only saw one tablet server die.  Its look was deleted.  I did not see anything suspicious in its jstack.

{noformat}
Index: src/main/java/org/apache/accumulo/server/util/Halt.java
===================================================================
--- src/main/java/org/apache/accumulo/server/util/Halt.java	(revision 1233105)
+++ src/main/java/org/apache/accumulo/server/util/Halt.java	(working copy)
@@ -41,6 +41,15 @@
   
   public static void halt(final int status, Runnable runnable) {
     try {
+      // print stack trace on exit
+      ProcessBuilder processBuilder = new ProcessBuilder(""/bin/sh"", ""-c"", ""kill -3 $PPID"");
+      Process process = processBuilder.start();
+      process.waitFor();
+    } catch (Exception e) {
+      e.printStackTrace();
+    }
+    
+    try {
       // give ourselves a little time to try and do something
       new Daemon() {
         public void run() {

{noformat}","27/Jan/12 21:48;kturner;We have a possible cause for this problem.  The master has one connection to tablet servers that is protected with a lock.  A merge operation asked a tablet to split on tablet server X, the split operation was waiting for a !METADATA tablet to load.  The master asked tablet server X to load the metadata tablet that the split was waiting on, but blocked on the lock held by the split operation.  So deadlock, which snowballs and causes the master to kill all the tablet server because it thinks they are unresponsive.",27/Jan/12 21:49;kturner;A possible solution to this problem is to replace the single connection to tablet server with a connection pool.,27/Jan/12 21:55;kturner;This may not be an issue in 1.3 because there is no merge operation where the master ask a tablet server to split.  I am not sure if there are other tserver operations where the synchronization of the connection could cause deadlock.,"30/Jan/12 18:15;kturner;Now that the master code was switched to use a connection pool, I am concerned that will change behavior on a large cluster where the master needs to talk to alot on nodes.   By default the connection pool times out idle connections after 3 second.  I am going to look into upping this for the master process.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
merge failed to complete,ACCUMULO-356,12540554,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,31/Jan/12 14:09,09/Feb/12 22:23,13/Mar/19 22:01,09/Feb/12 14:09,,,,,,,,1.4.0,,,master,,,,,,0,14_qa_bug,,,,"Noticed the random walk test was generally hung.  There was a tablet offline.  Listed the Fate operations:

{noformat}
$ ./bin/accumulo org.apache.accumulo.server.fate.Admin print
txid: 59c0403614dc0c39  status: IN_PROGRESS         op: RenameTable      locked: []              locking: [W:cz]          top: RenameTable
txid: 37539f8d61548764  status: IN_PROGRESS         op: ChangeTableState  locked: []              locking: [W:cz]          top: ChangeTableState
txid: 02f8323a3136e60d  status: IN_PROGRESS         op: TableRangeOp     locked: []              locking: [W:cz]          top: TableRangeOp
txid: 044015732e97eec1  status: IN_PROGRESS         op: CompactRange     locked: []              locking: [R:cz]          top: CompactRange
txid: 6ce9dd63f9d51448  status: IN_PROGRESS         op: CompactRange     locked: []              locking: [R:cz]          top: CompactRange
txid: 417cb9b60e44ecd9  status: IN_PROGRESS         op: TableRangeOp     locked: []              locking: [W:cz]          top: TableRangeOp
txid: 5e7c5284a4677d6c  status: IN_PROGRESS         op: DeleteTable      locked: []              locking: [W:cz]          top: DeleteTable
txid: 6633d3d841d66995  status: IN_PROGRESS         op: TableRangeOp     locked: [W:cz]          locking: []              top: TableRangeOpWait
{noformat}

Quick check of master logs finds that Fate tx 6633d3d841d66995 did not complete.  Here's what the master saw for this transaction:

The transaction is seeded, and a write lock is put into the queue; but there are other operations going on
{noformat}
30 20:52:29,387 [zookeeper.DistributedReadWriteLock] INFO : Added lock entry 4 userData 6633d3d841d66995 lockType WRITE
{noformat}

For example, there was a read lock for transaction 56fada3359bfb4c7
{noformat}
30 20:52:29,391 [tableOps.Utils] INFO : table cz (56fada3359bfb4c7) unlocked for read
{noformat}

And yet another write lock ahead of us for transaction 62c3cecaf387398e
{noformat}
30 20:52:29,486 [tableOps.Utils] INFO : table cz (62c3cecaf387398e) locked for write operation: ONLINE
30 20:52:29,488 [tables.TableManager] DEBUG: Transitioning state for table cz from OFFLINE to ONLINE
30 20:52:29,491 [tables.TableManager] DEBUG: State transition to ONLINE @ WatchedEvent state:SyncConnected type:NodeDataChanged path:/accumulo/88cd0f63-a36a-4218-86b1-9ba1d2cccf08/tables/cz/state
30 20:52:29,491 [master.EventCoordinator] INFO : Table state in zookeeper changed for cz to ONLINE
30 20:52:29,494 [tableOps.Utils] INFO : table cz (62c3cecaf387398e) unlocked for write
{noformat}

So now our table is in the online state... but the tablets may not be (yet). Our Fate operation gets the write lock and starts to execute
{noformat}
30 20:52:29,494 [tableOps.ChangeTableState] DEBUG: Changed table state cz ONLINE
30 20:52:29,494 [master.EventCoordinator] INFO : Set table state of cz to ONLINE
30 20:52:29,495 [tableOps.Utils] INFO : table cz (6633d3d841d66995) locked for write operation: MERGE
{noformat}

Hmm... this seems strange... we went from STARTED directly to MERGING: no OFFLINE, no CHOPPING.  Those are very strange MergeStats, too.  I'm not 100% sure that these merge stats go with this operation, but the timing suggests that it does (need to fix that log message).
{noformat}
30 20:52:29,500 [master.EventCoordinator] INFO : Merge state of cz;7c9131203e34514c;39ceaf91dd1db6ef set to STARTED
30 20:52:29,516 [state.MergeStats] INFO : 0 are hosted, total 0
30 20:52:29,517 [state.MergeStats] INFO : 0 tablets are chopped
30 20:52:29,517 [state.MergeStats] INFO : 0 tablets are chopped, 0 are offline
30 20:52:29,517 [state.MergeStats] INFO : 0 tablets are unassigned
30 20:52:29,535 [master.EventCoordinator] INFO : Merge state of cz;7c9131203e34514c;39ceaf91dd1db6ef set to MERGING
{noformat}

Looks like the tablets were offline, too, because the main master loop is trying to assign them:
{noformat}
30 20:52:29,598 [master.Master] DEBUG: Normal Tablets assigning tablet cz;08498ad358a45bb0;050754dd3cc35c16=192.168.117.4:9997[134d7425fc8959e]
30 20:52:29,598 [master.Master] DEBUG: Normal Tablets assigning tablet cz;050754dd3cc35c16<=192.168.117.5:9997[334c843791cb78b]
30 20:52:29,598 [master.Master] DEBUG: Normal Tablets assigning tablet cz;137d382d52b8fbd9;08498ad358a45bb0=192.168.117.6:9997[134d7425fc8959f]
30 20:52:29,615 [master.EventCoordinator] INFO : tablet cz;08498ad358a45bb0;050754dd3cc35c16 was loaded
30 20:52:29,616 [master.EventCoordinator] INFO : tablet cz;137d382d52b8fbd9;08498ad358a45bb0 was loaded
{noformat}


And, just to make this more interesting, a tablet splits shortly after being loaded:
{noformat}
30 20:52:29,603 [state.MergeStats] INFO : 1 tablets are unassigned
30 20:52:29,688 [master.EventCoordinator] INFO : tablet cz<;137d382d52b8fbd9 was unloaded
30 20:52:30,081 [master.EventCoordinator] INFO : 192.168.117.9:9997 reported split cz;08498ad358a45bb0;050754dd3cc35c16, cz;137d382d52b8fbd9;08498ad358a45bb0
{noformat}

Master takes some of the tablets offline
{noformat}
30 20:52:30,083 [master.EventCoordinator] INFO : tablet cz;050754dd3cc35c16< was unloaded
30 20:52:30,083 [master.EventCoordinator] INFO : tablet cz;08498ad358a45bb0;050754dd3cc35c16 was unloaded
30 20:52:30,084 [master.EventCoordinator] INFO : tablet cz;137d382d52b8fbd9;08498ad358a45bb0 was unloaded
{noformat}

But not all of them
{noformat}
30 20:52:30,445 [master.EventCoordinator] INFO : tablet cz;050754dd3cc35c16< was loaded
{noformat}

The !METADATA status
{noformat}
!METADATA> scan -b cz; -e d
cz;050754dd3cc35c16 file:/b-00006eb/I00006ec.rf []    50848,0
cz;050754dd3cc35c16 file:/t-00006p2/F0000qra.rf []    2936,660
cz;050754dd3cc35c16 file:/t-00006p2/F00023p9.rf []    3176,720
cz;050754dd3cc35c16 last:334c843791cb78b []    192.168.117.5:9997
cz;050754dd3cc35c16 loc:334c843791cb78b []    192.168.117.5:9997
cz;050754dd3cc35c16 srv:dir []    /t-00006p2
cz;050754dd3cc35c16 srv:flush []    0
cz;050754dd3cc35c16 srv:lock []    tservers/192.168.117.5:9997/zlock-0000000000$334c843791cb78b
cz;050754dd3cc35c16 srv:time []    M1327993277526
cz;050754dd3cc35c16 ~tab:~pr []    \x00
cz;08498ad358a45bb0 file:/b-00006eb/I00006ec.rf []    47216,0
cz;08498ad358a45bb0 file:/t-00006p3/F0000qj9.rf []    1883,400
cz;08498ad358a45bb0 file:/t-00006p3/F00022u1.rf []    1717,360
cz;08498ad358a45bb0 last:134d7425fc8959e []    192.168.117.4:9997
cz;08498ad358a45bb0 loc:134d7425fc8959e []    192.168.117.4:9997
cz;08498ad358a45bb0 srv:dir []    /t-00006p3
cz;08498ad358a45bb0 srv:flush []    0
cz;08498ad358a45bb0 srv:lock []    tservers/192.168.117.4:9997/zlock-0000000000$134d7425fc8959e
cz;08498ad358a45bb0 srv:time []    M1327993277506
cz;08498ad358a45bb0 ~tab:~pr []    \x01050754dd3cc35c16
cz;137d382d52b8fbd9 file:/b-00006eb/I00006ec.rf []    118041,0
cz;137d382d52b8fbd9 file:/t-00006os/F0000quc.rf []    6017,1430
cz;137d382d52b8fbd9 file:/t-00006os/F00023gh.rf []    5409,1270
cz;137d382d52b8fbd9 last:134d7425fc8959f []    192.168.117.6:9997
cz;137d382d52b8fbd9 loc:134d7425fc8959f []    192.168.117.6:9997
cz;137d382d52b8fbd9 srv:dir []    /t-00006os
cz;137d382d52b8fbd9 srv:flush []    0
cz;137d382d52b8fbd9 srv:lock []    tservers/192.168.117.6:9997/zlock-0000000000$134d7425fc8959f
cz;137d382d52b8fbd9 srv:time []    M1327993277515
cz;137d382d52b8fbd9 ~tab:~pr []    \x0108498ad358a45bb0
cz< chopped:chopped []    chopped
cz< file:/b-00006eb/I00006ec.rf []    1210190,0
cz< srv:compact []    1
cz< srv:dir []    /default_tablet
cz< srv:lock []    tservers/192.168.117.10:9997/zlock-0000000000$334c843791cb78f
cz< srv:time []    M0
cz< ~tab:~pr []    \x01137d382d52b8fbd9
{noformat}

4 tablets, consistent splits, 3 are online, the offline tablet is chopped.  The offline tablet doesn't have a last location, which is strange.","random walk test of ""All"" without ""Security"" on a 10-node test cluster",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-31 16:30:52.676,,,no_permission,,,,,,,,,,,,225967,,,Thu Feb 09 14:09:20 UTC 2012,,,,,,0|i07nof:,42602,,,,,,,,31/Jan/12 14:12;ecn;Ugh... switched to using jira's markup.,"31/Jan/12 16:30;kturner;I was concerned about the lack of a last location.  Discussed it w/ Eric we determined it is not an issue.  Last is set when a minor compaction occurs and is used for maintaining locality during assignment.   This tablet never minor compacted, its file was created via bulk import.","09/Feb/12 14:09;ecn;There was an inconsistent read of the METADATA table due to a split occurring in the tablet during the merge.  Operations, such as merge and deleteTable will need to perform a consistent scan of the metadata table, ensuring that all necessary tablets are offline and the end-row/prev-row entries match before writing to the METADATA table.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in hasSystemPermission,ACCUMULO-357,12540596,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,31/Jan/12 18:54,09/Feb/12 22:23,13/Mar/19 22:01,31/Jan/12 19:39,,,,,,,,1.4.0,,,tserver,,,,,,0,14_qa_bug,,,,"call to hasSystemPermission failed in the randomwalk, which was a result of the following server-side exception:

{noformat}
31 15:00:05,267 [thrift.ClientService$Processor] ERROR: Internal error processing hasSystemPermission
java.lang.NullPointerException
        at java.io.ByteArrayInputStream.<init>(ByteArrayInputStream.java:89)
        at org.apache.accumulo.server.security.ZKAuthenticator$Tool.convertSystemPermissions(ZKAuthenticator.java:675)
        at org.apache.accumulo.server.security.ZKAuthenticator.hasSystemPermission(ZKAuthenticator.java:373)
        at org.apache.accumulo.server.security.Auditor.hasSystemPermission(Auditor.java:149)
        at org.apache.accumulo.server.client.ClientServiceHandler.hasSystemPermission(ClientServiceHandler.java:194)
        at sun.reflect.GeneratedMethodAccessor41.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at cloudtrace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:58)
        at $Proxy2.hasSystemPermission(Unknown Source)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$Processor$hasSystemPermission.process(ClientService.java:2409)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor.process(TabletClientService.java:2037)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:151)
        at org.apache.thrift.server.TNonblockingServer$FrameBuffer.invoke(TNonblockingServer.java:631)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:199)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
{noformat}
",randomwalk test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,226009,,,2012-01-31 18:54:50.0,,,,,,0|i07no7:,42601,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
randomwalk bulk test verify failed,ACCUMULO-365,12540950,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,02/Feb/12 16:24,09/Feb/12 22:23,13/Mar/19 22:01,08/Feb/12 20:15,,,,,,,,1.4.0,,,master,test,,,,,0,14_qa_bug,,,,"A verify failed: all the markers for a single import were missing.

The master is presently spewing log messages, so the debug log rolled... making this difficult to debug postmortem.

The test is not looking into the failed directory properly, so that needs to be fixed to truly verify data loss.
",randomwalk test on 10 node test cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,226303,,,Wed Feb 08 20:15:57 UTC 2012,,,,,,0|i07nmf:,42593,,,,,,,,08/Feb/12 20:15;ecn;increasing the retries for the bulk loading fixed the problem,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master killed a tablet server,ACCUMULO-366,12540983,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,ecn,ecn,02/Feb/12 19:15,09/Feb/12 22:22,13/Mar/19 22:01,08/Feb/12 22:25,,,,,,,,1.4.0,,,master,,,,,,0,14_qa_bug,,,,"Master killed a tablet server for having long hold times.

The tablet server had this error during minor compaction:

{noformat}
01 23:57:20,073 [security.ZKAuthenticator] ERROR: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /accumulo/88cd0f63-a36a-4218-86b1-9ba1d2cccf08/users/user004
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /accumulo/88cd0f63-a36a-4218-86b1-9ba1d2cccf08/users/user004
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:102)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)
        at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1243)
        at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1271)
        at org.apache.accumulo.core.zookeeper.ZooUtil.recursiveDelete(ZooUtil.java:103)
        at org.apache.accumulo.core.zookeeper.ZooUtil.recursiveDelete(ZooUtil.java:117)
        at org.apache.accumulo.server.zookeeper.ZooReaderWriter.recursiveDelete(ZooReaderWriter.java:67)
        at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.server.zookeeper.ZooReaderWriter$1.invoke(ZooReaderWriter.java:169)
        at $Proxy4.recursiveDelete(Unknown Source)
        at org.apache.accumulo.server.security.ZKAuthenticator.dropUser(ZKAuthenticator.java:252)
        at org.apache.accumulo.server.security.Auditor.dropUser(Auditor.java:104)
        at org.apache.accumulo.server.client.ClientServiceHandler.dropUser(ClientServiceHandler.java:136)
        at sun.reflect.GeneratedMethodAccessor52.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at cloudtrace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:58)
        at $Proxy2.dropUser(Unknown Source)
        at org.apache.accumulo.core.client.impl.thrift.ClientService$Processor$dropUser.process(ClientService.java:2257)
        at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor.process(TabletClientService.java:2037)
        at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:151)
        at org.apache.thrift.server.TNonblockingServer$FrameBuffer.invoke(TNonblockingServer.java:631)
        at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:199)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)

{noformat}

This tablet was the result of a split that occurred during a delete.  The master missed this tablet when taking tablets offline.

We need to do a consistency check on the offline tablets before deleting the table information in zookeeper.

",randomwalk test on a 10 node test cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-02-07 18:53:45.468,,,no_permission,,,,,,,,,,,,226336,,,Tue Feb 07 18:53:45 UTC 2012,,,,,,0|i07nm7:,42592,,,,,,,,"07/Feb/12 18:53;kturner;Saw this bug again.  A minor compaction was attempted after the tablet was closed.  Looking at the code, the initiateMinorCompaction function tries to get the flush id from zookeeper, even if the tablet is closed.   Trying to call initiateMinroCompaction on a closed tablet should do nothing.

{noformat}
07 08:10:38,419 [tabletserver.Tablet] TABLET_HIST: f5i;10a579089cf842a0< closed

07 08:15:38,426 [tabletserver.LargestFirstMemoryManager] DEBUG: IDLE minor compaction chosen
07 08:15:38,427 [tabletserver.LargestFirstMemoryManager] DEBUG: COMPACTING f5i;10a579089cf842a0<  total = 32,091,937 ingestMemory = 32,091,937
07 08:15:38,427 [tabletserver.LargestFirstMemoryManager] DEBUG: chosenMem = 99,252 chosenIT = 300.01 load 125,050
07 08:15:38,427 [tabletserver.TabletServerResourceManager] ERROR: Minor compactions for memory managment failed
java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /accumulo/fbebb086-960c-4a97-b502-154fc333d766/tables/f5i/flush-id
        at org.apache.accumulo.server.tabletserver.Tablet.getFlushID(Tablet.java:2349)
        at org.apache.accumulo.server.tabletserver.Tablet.initiateMinorCompaction(Tablet.java:2287)
        at org.apache.accumulo.server.tabletserver.TabletServerResourceManager$MemoryManagementFramework.manageMemory(TabletServerResourceManager.java:328)
        at org.apache.accumulo.server.tabletserver.TabletServerResourceManager$MemoryManagementFramework.access$1(TabletServerResourceManager.java:303)
        at org.apache.accumulo.server.tabletserver.TabletServerResourceManager$MemoryManagementFramework$2.run(TabletServerResourceManager.java:252)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /accumulo/fbebb086-960c-4a97-b502-154fc333d766/tables/f5i/flush-id
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:102)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)
        at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:921)
        at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:950)
        at org.apache.accumulo.core.zookeeper.ZooReader.getData(ZooReader.java:42)
        at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.server.zookeeper.ZooReaderWriter$1.invoke(ZooReaderWriter.java:169)
        at $Proxy4.getData(Unknown Source)
        at org.apache.accumulo.server.tabletserver.Tablet.getFlushID(Tablet.java:2347)
        ... 6 more

{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tablet had location but was not loaded,ACCUMULO-368,12541123,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,03/Feb/12 19:42,09/Feb/12 22:22,13/Mar/19 22:01,03/Feb/12 22:19,1.3.5-incubating,,,,,,,1.4.0,,,tserver,,,,,,0,14_qa_bug,,,,"While running the random walk test a delete range operation got hung because it could not split a tablet.  The tablet in question failed to load because the tablet server thought it was already serving it.

{noformat}
03 11:19:18,249 [tabletserver.Tablet] TABLET_HIST: 3nq;77cd1e415c4547a4< split 3nq;133660072804a502< 3nq;77cd1e415c4547a4;133660072804a502
03 11:19:18,249 [tabletserver.Tablet] TABLET_HIST: 3nq;133660072804a502< opened 
03 11:19:26,236 [tabletserver.Tablet] TABLET_HIST: 3nq;133660072804a502< import /b-0005t8f/I0005t8g.rf 388308 0
03 11:19:45,672 [tabletserver.Tablet] TABLET_HIST: 3nq;133660072804a502< MinC [memory] -> /t-0005typ/F0005tz4.rf
03 11:19:45,686 [tabletserver.Tablet] TABLET_HIST: 3nq;133660072804a502< closed
03 11:19:45,840 [tabletserver.Tablet] TABLET_HIST: 3nq;133660072804a502< opened
03 11:19:45,987 [tabletserver.Tablet] TABLET_HIST: 3nq;133660072804a502< closed
03 11:19:46,142 [tabletserver.TabletServer] INFO : Loading tablet 3nq;133660072804a502<
03 11:19:46,144 [tabletserver.TabletServer] ERROR: Tablet seems to be already assigned to xxx.xxx.xxx.9:9997[135396fb18d3fb0]
03 11:19:46,144 [tabletserver.TabletServer] INFO : Reporting tablet 3nq;133660072804a502< assignment failure: unable to verify Tablet Information
{noformat}

Looking at the walogs below it seems that the data mutations for the last successful open and close were written in reverse order.

{noformat}
1 mutations:
  3nq;133660072804a502
      ~tab:~pr [system]:959756 [] ^@
      srv:dir [system]:959756 [] /t-0005typ
      srv:time [system]:959756 [] M1328267935757
      loc:135396fb18d3fb0 [system]:959756 [] xxx.xxx.xxx.9:9997
      future:135396fb18d3fb0 [system]:959756 [] <deleted>
      srv:lock [system]:959756 [] tservers/xxx.xxx.xxx.9:9997/zlock-0000000000$135396fb18d3fb0

MUTATION 6462 5
1 mutations:
  3nq;133660072804a502
      file:/b-0005t8f/I0005t8g.rf [system]:959986 [] 388308,0
      loaded:/b-0005t8f/I0005t8g.rf [system]:959986 [] 1681970597222144296
      srv:time [system]:959986 [] M1328267935757
      srv:lock [system]:959986 [] tservers/xxx.xxx.xxx.9:9997/zlock-0000000000$135396fb18d3fb0

MUTATION 6462 5
1 mutations:
  3nq;133660072804a502
      file:/t-0005typ/F0005tz4.rf [system]:960298 [] 185156,44330
      srv:time [system]:960298 [] M1328267963158
      last:135396fb18d3fb0 [system]:960298 [] xxx.xxx.xxx.9:9997
      log:xxx.xxx.xxx.12:11224/cad1617c-5fb2-4057-abec-8edd46d0cf7a [system]:960298 [] <deleted>
      log:xxx.xxx.xxx.5:11224/50611604-8e6c-48a8-8e16-eb739a991721 [system]:960298 [] <deleted>
      srv:flush [system]:960298 [] 0
      srv:lock [system]:960298 [] tservers/xxx.xxx.xxx.9:9997/zlock-0000000000$135396fb18d3fb0

MANY_MUTATIONS 6462 5
1 mutations:
  3nq;133660072804a502
      loc:135396fb18d3fb0 [system]:960302 [] <deleted>

MANY_MUTATIONS 6462 5
1 mutations:
  3nq;133660072804a502
      future:135396fb18d3fb0 [system]:960321 [] xxx.xxx.xxx.9:9997

MANY_MUTATIONS 6462 5
1 mutations:
  3nq;133660072804a502
      loc:135396fb18d3fb0 [system]:960326 [] <deleted>

MANY_MUTATIONS 6462 5
1 mutations:
  3nq;133660072804a502
      loc:135396fb18d3fb0 [system]:960332 [] xxx.xxx.xxx.9:9997
      future:135396fb18d3fb0 [system]:960332 [] <deleted>
{noformat}

Looking at the tablet server code, a tablet is put in online tablets and then the location is written to the metadata table.  Since the tablet is in online tablets it could be unloaded.  I think that is what happened here.  In the short period of time between putting the tablet in onlinetablets and writing the location to the metadata table, the tablet was unloaded.",Running random walktest against 1.4.0-SNAP on 10 node cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,226475,,,2012-02-03 19:42:09.0,,,,,,0|i07nlr:,42590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
file missing during a major compaction,ACCUMULO-373,12541458,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,06/Feb/12 18:43,09/Feb/12 22:21,13/Mar/19 22:01,06/Feb/12 19:06,,,,,,,,1.4.0,,,gc,tserver,,,,,0,14_qa_bug,,,,"Saw a complaint about a missing file in a major compaction.

The file was recently created by a flush.

After looking around, I found the file was deleted when the directory containing the file was deleted by the gc.  The gc is not supposed to delete directories that have entries in the METADATA table.  From the loading of the tablet, I can definitely see the directory entry.

Create a unit test for this case against MockAccumulo to verify the problem.
",randomwalk test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,226745,,,2012-02-06 18:43:31.0,,,,,,0|i07nkn:,42585,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
wikisearch-ingest stop list should be removed,ACCUMULO-374,12541469,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,afuchs,afuchs,afuchs,06/Feb/12 19:35,08/Feb/12 03:04,13/Mar/19 22:01,08/Feb/12 03:04,,,,,,,,1.4.0,,,,,,,,,0,,,,,"Wikisearch-ingest's WikipediaMapper has a list of stop words that presumably are supposed to be ignored (not indexed). This feature should be removed because:
1. The StopFilter code does not work. Stop words are indexed anyway. Not sure why.
2. Stop lists are not a significant performance concern with this type of indexing. It's better for cross-language search, phrase search, and for overall search efficiency not to use a stop list.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-02-07 00:10:55.507,,,no_permission,,,,,,,,,,,,226756,,,Wed Feb 08 03:03:45 UTC 2012,,,,,,0|i07nkf:,42584,,,,,,,,07/Feb/12 00:10;medined;Would it make sense to use Lucene parsers?,"08/Feb/12 03:03;afuchs;Wikisearch does use Lucene parsers, so I guess it must make some sense. We're trying out the experimental org.apache.lucene.wikipedia.analysis.WikipediaTokenizer within org.apache.accumulo.examples.wikisearch.ingest.WikipediaMapper.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CME in cleanupMutations,ACCUMULO-352,12540186,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,27/Jan/12 20:26,07/Feb/12 22:44,13/Mar/19 22:01,07/Feb/12 22:44,1.3.5-incubating,,,,,,,,,,master,,,,,,0,,,,,,seen on a large cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,225601,,,2012-01-27 20:26:21.0,,,,,,0|i07npb:,42606,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockAccumulo doesn't throw informative errors,ACCUMULO-217,12534850,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,12/Dec/11 22:48,26/Jan/12 15:22,13/Mar/19 22:01,26/Jan/12 15:22,1.3.5-incubating,,,,,,,1.4.0,,,client,,,,,,0,mock,,,,Users are unable to tell if an error has occurred and whether it is due to unimplemented features in MockAccumulo.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,220534,,,2011-12-12 22:48:24.0,,,,,,0|i07oin:,42738,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Managing FATE operations is difficult,ACCUMULO-317,12538703,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,17/Jan/12 22:07,18/Jan/12 20:13,13/Mar/19 22:01,18/Jan/12 20:13,,,,,,,,1.4.0,,,master,,,,,,0,,,,,"When a FATE operation gets stuck, its hard to know whats happening.  When I first started looking into ACCUMULO-315 I knew a table operation was stuck.  But finding out which table and what operation was not easy.  Need to write a little utility that will print out information about current fate operations and table locks held by fate operations.

It would be nice to have this before 1.4 ships as it will make debugging problems in the field easier.

In addition to printing fate operations, we need a utility to fail and delete a fate operations (and locks). This will give a workaround to unforseen bugs in FATE operations.  When things go bad a user can try to fail the operation and if that does not work, they can delete it (which may leave the system in an inconsistent state).  Failing an operation should undo it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-18 01:49:35.98,,,no_permission,,,,,,,,,,,,224206,,,Wed Jan 18 19:58:52 UTC 2012,,,,,,0|i07nwv:,42640,,,,,,,,18/Jan/12 01:49;ecn;+1 for making the support easier,"18/Jan/12 17:44;kturner;I modified the CloneTable operation so that it would get stuck, cloned a table, and deleted the table I was trying to clone. Then I ran the new print util and its output is below.  I killed the master and fixed the clone table operation and it all ran.

{noformat}
$ ./bin/accumulo org.apache.accumulo.server.fate.Print
txid: 5c9c7a705293008f  status: IN_PROGRESS      op: DeleteTable      locked: []              locking: [W:2]           top: DeleteTable
txid: 4830c0e4d610a7a3  status: IN_PROGRESS      op: CloneTable       locked: [W:3, R:2]      locking: []              top: FinishCloneTable
{noformat}","18/Jan/12 19:58;kturner;Removed the Print command mentioned above and replaced it with the Admin command.

{noformat}
$ ./bin/accumulo org.apache.accumulo.server.fate.Admin 
Usage : Admin fail <txid> | delete <txid> | print
$ ./bin/accumulo org.apache.accumulo.server.fate.Admin print
txid: 136db1610cc74e3a  status: IN_PROGRESS      op: DeleteTable      locked: []              locking: [W:2]           top: DeleteTable
txid: 623e4ad83da848bf  status: IN_PROGRESS      op: CloneTable       locked: [W:3, R:2]      locking: []              top: FinishCloneTable
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
documented the need to create the write-ahead logs directory ,ACCUMULO-182,12532539,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,mnguyen,mnguyen,23/Nov/11 22:07,13/Jan/12 14:23,13/Mar/19 22:01,01/Dec/11 16:10,1.3.5-incubating,,,,,,,1.3.6,,,client,,,,,,0,,,,,"I am following the Accumulo 1.3 manual for basic admin with version 1.3.5rc7 on CentOS release 5.6:

I can't create a user table.

http://incubator.apache.org/accumulo/user_manual_1.3-incubating/Accumulo_Shell.html#Basic_Administration

In a single node setup, I can run the accumulo shell, create a user, and grant privileges to user (like creating a table).  I can't create a table as either root or another user.

For example, running 'createtable mytable' the shell doesn't provide any response and after some time provides this warning:

23 14:12:04,026 [impl.ThriftTransportPool] WARN : Thread ""shell"" stuck on IO  to localhost:9999:9999 (0) for at least 120478 ms

Looking through the logs, I don't see any errors regarding the master or port 9999, but there are errors in the logs:

-------------------------------------------------------------------------------------------------------------------

gc_server1.bericotechnologies.com.debug.log:23 15:06:39,569 [impl.ThriftScanner] DEBUG: Error getting transport to 127.0.0.1:9997 : org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: 120000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:53730 remote=/127.0.0.1:9997]

monitor_server1.bericotechnologies.com.debug.log.2:23 15:10:10,935 [impl.ThriftScanner] DEBUG:  Error getting transport to 127.0.0.1:9997 : org.apache.thrift.transport.TTransportException: java.net.SocketTimeoutException: 120000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:53982 remote=/127.0.0.1:9997]

tracer_server1.bericotechnologies.com.log:23 15:11:55,935 [trace.TraceServer] INFO : waiting to checking/create t
he trace table: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_CREDENTIALS - Username or Password is Invalid

tserver_server1.bericotechnologies.com.debug.log.2:23 15:10:51,713 [tabletserver.NativeMap] ERROR: Failed to load native map library /opt/accumulo/lib/native/map/libNativeMap-Linux-amd64-64.so
tserver_server1.bericotechnologies.com.debug.log.2:java.lang.UnsatisfiedLinkError: Can't load library: /opt/accumulo/lib/native/map/libNativeMap-Linux-amd64-64.so

-------------------------------------------------------------------------------------------------------------------

When running Accumulo 1.4 (trunk), I am able to create a table, but I would like to run Accumulo 1.3 release.  I am working with some other software that has only been tested with Cloudbase 1.3.2 and 1.3.4.

If there's anything specifically I should be looking for in the log, please direct.","CentOS release 5.6
single node Accumulo setup",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-11-23 22:44:05.762,,,no_permission,,,,,,,,,,,,218272,,,Wed Nov 23 22:58:05 UTC 2011,,,,,,0|i07oq7:,42772,,,,,,,,"23/Nov/11 22:28;mnguyen;My workaround for https://issues.apache.org/jira/browse/ACCUMULO-183 also fixed this issue for me.

I manually create walogs directory and walogs/.lock file, and then run bin/start-all.

I can now create/delete tables, insert/delete rows, etc.","23/Nov/11 22:44;ecn;Right... that's the way it's supposed to work.  You have to manually create the walog directory.  You don't need to create the .lock file: the logger does that (which ensures it has write permissions to the directory, that the OS hasn't made the directory read-only due to partial disk failure, and prevents the files from being served by multiple servers).
","23/Nov/11 22:58;mnguyen;I see in the v1.3 manual where it mentions that you have to create the walog directory.  It may be helpful for other people to 1) make this step more explicit in the manual, 2) check that the directory doesn't exist and output an appropriate error message in the log, or 3) if the directory doesn't exist, just go ahead and create it.

In whichever case, thanks for the help.  It is appreciated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
shutdown is very slow after all tservers are down,ACCUMULO-236,12536415,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,27/Dec/11 12:13,13/Jan/12 13:14,13/Mar/19 22:01,13/Jan/12 13:14,1.3.5-incubating,,,,,,,1.3.6,,,master,,,,,,0,,,,,"After all tablets are unloaded (as reported in the monitor web pages) and all tablet servers appear to be down, the shutdown command hangs.  The master log messages show something like 

{noformat}
... Unable to halt server 10.1.2.3:9997[abc123456789]: org.apache.thrift.transport.TTransportException 
{noformat}

One error for every server, making this problem much worse on a large cluster.  Thought we fixed this for 1.3.5, but it was reported again after the release.",on a larger cluster shutdown takes a long time,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,222098,,,2011-12-27 12:13:41.0,,,,,,0|i07oef:,42719,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bulk loading causing an consistency check failure,ACCUMULO-293,12537777,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,09/Jan/12 15:32,13/Jan/12 13:09,13/Mar/19 22:01,13/Jan/12 13:09,1.3.5-incubating,,,,,,,1.3.6,1.4.0,,tserver,,,,,,0,,,,,"Client requests that a tablet server bulk-load a file.  The file is loaded, and then major compacted away.  The client also retries the load, which succeeds, but the changes for the major compaction are also making changes.  These must conflict because it results in an inconsistency: the bulk file is in the tablet server's list of files, but it is not in the metadata table.

This is probably fixed in the much improved bulk loading code in the 1.4 branch.
",using bulk loading heavily: bulk loader client retry is causing inconsistency,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,223283,,,2012-01-09 15:32:05.0,,,,,,0|i07o1r:,42662,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
garbage collector (sometimes) hangs if the tracer is not running,ACCUMULO-243,12537094,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,03/Jan/12 20:30,13/Jan/12 12:45,13/Mar/19 22:01,13/Jan/12 12:45,1.3.5-incubating,,,,,,,1.3.6,,,client,,,,,,0,,,,,"The GC randomly selects to trace GC cycles.  At the end of the run, it flushes the trace spans to the tracer.  This hangs, which causes the GC to fail to run again on a regular cycle.
","user noticed the accumulo garbage collector was running with erratically long times, no tracer was running",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,222604,,,2012-01-03 20:30:37.0,,,,,,0|i07ocv:,42712,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tracing not working,ACCUMULO-299,12537961,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,10/Jan/12 20:41,12/Jan/12 20:39,13/Mar/19 22:01,12/Jan/12 20:39,,,,,,,,1.4.0,,,trace,,,,,,0,,,,,"all table operations should be traced: not seeing them in the trace table, however.",running wikisearch ingest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,223467,,,Thu Jan 12 20:39:22 UTC 2012,,,,,,0|i07o0f:,42656,,,,,,,,"12/Jan/12 20:39;ecn;Fixed with r1230753, r1230755 and r1230736",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Isolation example is broken,ACCUMULO-308,12538112,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,11/Jan/12 22:06,12/Jan/12 16:20,13/Mar/19 22:01,12/Jan/12 16:20,,,,,,,,1.4.0,,,docs,,,,,,0,,,,,The read thread in the isolation example is not running.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,223618,,,2012-01-11 22:06:06.0,,,,,,0|i07nyn:,42648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
compact tables by pattern only compacts the METADATA table,ACCUMULO-213,12534533,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,09/Dec/11 19:42,11/Jan/12 18:10,13/Mar/19 22:01,11/Jan/12 18:10,,,,,,,,1.4.0,,,client,,,,,,0,,,,,"{noformat}


root@ecnewt2 !METADATA> compact -p .*
09 19:37:45,860 [shell.Shell] INFO : Compaction of table !METADATA started for given range
09 19:37:45,933 [shell.Shell] INFO : Compaction of table !METADATA started for given range
09 19:37:46,008 [shell.Shell] INFO : Compaction of table !METADATA started for given range
09 19:37:46,087 [shell.Shell] INFO : Compaction of table !METADATA started for given range
09 19:37:46,163 [shell.Shell] INFO : Compaction of table !METADATA started for given range
09 19:37:46,239 [shell.Shell] INFO : Compaction of table !METADATA started for given range
09 19:37:46,317 [shell.Shell] INFO : Compaction of table !METADATA started for given range

{noformat}
","trunk, running the contrib/accumulo_sample",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,220255,,,2011-12-09 19:42:06.0,,,,,,0|i07ojj:,42742,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TApplicationException running example in README.shard,ACCUMULO-301,12537970,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,10/Jan/12 21:39,10/Jan/12 22:07,13/Mar/19 22:01,10/Jan/12 22:07,,,,,,,,1.4.0,,,,,,,,,0,,,,,See http://mail-archives.apache.org/mod_mbox/incubator-accumulo-user/201201.mbox/%3CCAOiJXP5K%2BGg8OA%3DOFXNFrGt2X7q8vV2Z-jEJfpdqYx6t0KincA%40mail.gmail.com%3E,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,223476,,,2012-01-10 21:39:00.0,,,,,,0|i07nzz:,42654,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
User could delete table after permission to do so was removed,ACCUMULO-297,12537841,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,10/Jan/12 00:37,10/Jan/12 17:24,13/Mar/19 22:01,10/Jan/12 17:24,,,,,,,,1.4.0,,,,,,,,,0,,,,,"While running the security random walk test it failed because a user could delete a table after their permission to do so was removed.  I think this was a cache consistency issues.  The permission was removed by tablet server A, and then the master was requested to do a remove.  The permission cache update from zookeeper to the master was inflight.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,223347,,,2012-01-10 00:37:46.0,,,,,,0|i07o0v:,42658,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"took a table offline, remaining tablets did not balance",ACCUMULO-214,12534541,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,09/Dec/11 20:21,06/Jan/12 18:35,13/Mar/19 22:01,06/Jan/12 18:35,,,,,,,,1.4.0,,,master,,,,,,0,,,,,"Ran the accumulo_sample and continuous ingest.  Took the continuous ingest table offline, and that left the servers unbalanced.  The master never rebalanced the servers.
",trunk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,09/Dec/11 20:24;ecn;unbalanced.png;https://issues.apache.org/jira/secure/attachment/12506787/unbalanced.png,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,220263,,,Fri Dec 09 20:24:48 UTC 2011,,,,,,0|i07ojb:,42741,,,,,,,,09/Dec/11 20:24;ecn;still unbalanced after waiting several minutes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FATE operations do not preserve trace information,ACCUMULO-195,12533295,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,30/Nov/11 14:42,05/Jan/12 22:41,13/Mar/19 22:01,30/Nov/11 18:51,,,,,,,,1.4.0,,,master,,,,,,0,,,,,attempted to trace createtable and there's nothing traced under FATE,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,219023,,,2011-11-30 14:42:24.0,,,,,,0|i07onb:,42759,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mock Accumulo Inverts order of mutations w/ same timestamp,ACCUMULO-218,12534896,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,13/Dec/11 02:23,04/Jan/12 19:33,13/Mar/19 22:01,04/Jan/12 19:33,,,,,,,,1.4.0,,,client,,,,,,0,,,,,Mock accumulo has different behavior than real accumulo when the same key is updated in the same millisecond.  The hidden in memory map counter in mock accumulo needs to sort descending.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,220580,,,2011-12-13 02:23:47.0,,,,,,0|i07oif:,42737,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
getBatchScanner java docs are wrong,ACCUMULO-223,12535357,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,kturner,kturner,15/Dec/11 19:28,04/Jan/12 16:47,13/Mar/19 22:01,04/Jan/12 16:47,1.3.5-incubating,,,,,,,1.3.6,,,client,docs,,,,,0,,,,,"The documentation for Connector.getBatchScanner() implies scan auths are interesected w/ user auths.  This is not the case anymore.  Currently if scan auths exceed the users auths, an exception is thrown.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,221041,,,2011-12-15 19:28:40.0,,,,,,0|i07ohb:,42732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BatchScanner iterator implementation erroneously returns true for hasNext upon subsequent hasNext calls,ACCUMULO-226,12535717,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,ventralnet,ventralnet,19/Dec/11 16:14,04/Jan/12 14:00,13/Mar/19 22:01,04/Jan/12 14:00,1.3.5-incubating,,,,,,,1.4.0,1.5.0,,client,,,,,,0,accumulo,batchscanner,,,"If you open a batch scanner and iterate through its contents, after hasNext has returned false, subsequent calls to hasNext will return true. Below is a testcase which shows the issue.

        Connector conn = new Connector(new ZooKeeperInstance(""accumulo"",""localhost""),""root"",""password"".getBytes());
        BatchScanner scanner = conn.createBatchScanner(""test"", Constants.NO_AUTHS, 1);
        scanner.setRanges(Collections.singletonList(new Range()));
        
        //exhaust the iterator
        Iterator it = scanner.iterator();
        while (it.hasNext()){
            it.next();
        }
        assertFalse(""hasNext should be false"", it.hasNext());

I found this issue when wrapping a BatchScanner in a IteratorChain which subsequently seems to call hasNext twice in it's hasNext method.  I will attach a patch which resolves the issue.",Platform independent ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Jan/12 13:52;ventralnet;accumulo_TabletServerBatchReaderIterator.patch;https://issues.apache.org/jira/secure/attachment/12509402/accumulo_TabletServerBatchReaderIterator.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2011-12-23 15:59:03.964,,,no_permission,,,,,,,,,,,,221401,,,Wed Jan 04 14:00:27 UTC 2012,,,,,,0|i07ogn:,42729,,,,,,,,19/Dec/11 16:28;ventralnet;Patch fixing the iterator issue in TabletServerBatchReaderIterator,19/Dec/11 16:30;ventralnet;Patch for TabletServerBatchReaderIterator fixing erroneous hasNext returns of true even after iterator is exhausted.,23/Dec/11 15:59;kturner;Patch looks good.  I applied it to 1.4 and trunk/1.5,"03/Jan/12 16:41;billie.rinaldi;Please resubmit the patch with the ""Grant license to ASF"" box checked.",04/Jan/12 13:52;ventralnet;Resubmit of patch with license granted to ASF,04/Jan/12 13:53;ventralnet;Patch has been resubmitted with license granted to ASF,"04/Jan/12 14:00;billie.rinaldi;Thanks! I've added you to our contributors list in JIRA so you can modify tickets and be assigned tickets, if you'd like.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
start-here.sh doesn't SetGoalState,ACCUMULO-234,12536209,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,afuchs,afuchs,afuchs,22/Dec/11 20:37,22/Dec/11 20:40,13/Mar/19 22:01,22/Dec/11 20:40,1.3.5-incubating,,,,,,,1.3.6,,,scripts,,,,,,0,,,,,"The following command is necessary to properly start up an Accumulo instance:
{noformat}
accumulo org.apache.accumulo.server.master.state.SetGoalState NORMAL
{noformat}

bin/start-all.sh includes this line, but bin/start-here.sh does not.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,221892,,,2011-12-22 20:37:46.0,,,,,,0|i07oev:,42721,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockAccumulo does not support InstanceOperations,ACCUMULO-216,12534834,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,12/Dec/11 21:03,16/Dec/11 21:04,13/Mar/19 22:01,16/Dec/11 21:04,1.3.5-incubating,,,,,,,1.4.0,,,client,,,,,,0,mock,,,,It might be nice if InstanceOperations were an interface so that we could have a MockInstanceOperations.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,220518,,,2011-12-12 21:03:58.0,,,,,,0|i07oiv:,42739,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RegExFilter does not properly regex when using multi-byte characters,ACCUMULO-209,12534248,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,jklucar,jklucar,07/Dec/11 21:12,12/Dec/11 15:39,13/Mar/19 22:01,09/Dec/11 17:23,1.3.5-incubating,,,,,,,1.4.0,1.5.0,,client,,,,,,2,,,,,"The current RegExFilter class uses a ByteArrayBackedCharSequence to set the data to match against. The ByteArrayBackedCharSequence contains a line of code that prevents the matcher from properly matching multi-byte characters.

Line 49 of ByteArrayBackedCharSequence.java is:
return (char) (0xff & data[offset + index]);                                                                                              

This incorrectly casts a single byte from the byte array to a char, which is 2 bytes in Java. This prevents the RegExFilter from properly performing Regular Expressions on multi-byte character encoded values.

A patch for the RegExFilter.java file has been created and will be submitted.",,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,08/Dec/11 22:00;jklucar;accumulo-209-RegExFilter.patch;https://issues.apache.org/jira/secure/attachment/12506666/accumulo-209-RegExFilter.patch,08/Dec/11 22:00;jklucar;accumulo-209-RegExFilterTest.patch;https://issues.apache.org/jira/secure/attachment/12506667/accumulo-209-RegExFilterTest.patch,07/Dec/11 21:16;jklucar;accumulo-209.patch;https://issues.apache.org/jira/secure/attachment/12506514/accumulo-209.patch,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2011-12-08 16:13:10.972,,,no_permission,,,,,,,,,,,,219970,,,Mon Dec 12 15:39:37 UTC 2011,,,,,,0|i07ok7:,42745,,,,,,,,07/Dec/11 21:14;jklucar;Patch is for the current Accumulo trunk.,"08/Dec/11 16:13;billie.rinaldi;Jim, thanks for finding and fixing this bug.  Could you write a test that reveals the issue and is fixed by your patch?  Also, please Apache-license your patches.","08/Dec/11 16:41;jklucar;You're welcome.  Is it ok just to patch the existing RegExFilterTest.java or should I create a new test class?
",08/Dec/11 16:49;billie.rinaldi;Feel free to add things to the existing test class.,"08/Dec/11 21:56;jklucar;Updated patch generated from base trunk directory. Also, added static setEncoding method ",08/Dec/11 22:00;jklucar;Patches RegExFilter class to properly handle multi-byte character encodings. Test case updated to handle regression.,"09/Dec/11 17:09;kturner;I noticed a problem with the patch.  I needs to do the following :

{noformat}
     matcher.reset(new String(bs.getBackingArray(), bs.offset(), bs.length(), encoding));
{noformat}

instead of 

{noformat}
     matcher.reset(new String(bs.getBackingArray(), encoding));
{noformat}

The byte sequence may use a subset of the backing array.","12/Dec/11 15:39;billie.rinaldi;ByteArrayBackedCharSequence doesn't appear to be used by anything else.  Keith pointed out that the new code copies the data each time, which the old code did not.  We may want to take a look at the performance difference.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
system scope libthrift dependency breaks transitive dependencies,ACCUMULO-191,12533164,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,afuchs,afuchs,afuchs,29/Nov/11 18:26,02/Dec/11 15:47,13/Mar/19 22:01,02/Dec/11 15:46,,,,,,,,1.3.5-incubating,,,,,,,,,0,,,,,"libthrift-0.3.jar is not available in any public maven repository, so we included it in the contrib directory and referred to it as a system scope dependency. However, building client that includes accumulo-core as a dependency results in:

{noformat}
[WARNING] The POM for org.apache.accumulo:accumulo-core:jar:1.3.5-incubating-SNAPSHOT is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
{noformat}

The system scope dependency in the current pom.xml refers to a path that is not an absolute path when the pom.xml is referenced by external projects.

One solution would be to host libthrift-0.3 in a semi-private repository (e.g. incubator.apache.org/accumulo/mvn_repo), and change the pom to include that repository with libthrift version 0.3 with a compile scope.

This is only a 1.3 branch problem, since 1.4 and later use a thrift version that is in the apache maven repository.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,218892,,,Fri Dec 02 15:46:28 UTC 2011,,,,,,0|i07oo7:,42763,,,,,,,,02/Dec/11 15:46;afuchs;Need to merge into 1.3.5rc branch,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LICENSE file needs work,ACCUMULO-204,12533639,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,afuchs,afuchs,afuchs,02/Dec/11 15:16,02/Dec/11 15:38,13/Mar/19 22:01,02/Dec/11 15:38,,,,,,,,,,,,,,,,,0,,,,,LICENSE file should include other licenses that are used by components of Accumulo. These licenses include the OneLab license for some bloomfilter classes and the MIT license for the flot javascript content.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,219366,,,2011-12-02 15:16:28.0,,,,,,0|i07olb:,42750,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bulk import may not use configured file system,ACCUMULO-168,12532246,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,22/Nov/11 00:59,30/Nov/11 20:09,13/Mar/19 22:01,30/Nov/11 20:09,,,,,,,,1.4.0,,,,,,,,,0,,,,,Bulk import fate operations may need to use org.apache.accumulo.core.file.FileUtil.getFileSystem() to get the file system configured for an accumulo instance.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,217979,,,2011-11-22 00:59:10.0,,,,,,0|i07otb:,42786,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
user manual font encoding breaks on some systems,ACCUMULO-166,12532183,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,afuchs,afuchs,afuchs,21/Nov/11 17:47,29/Nov/11 19:22,13/Mar/19 22:01,29/Nov/11 19:22,,,,,,,,1.3.6,,,docs,,,,,,0,,,,,See http://tex.stackexchange.com/questions/664/why-should-i-use-usepackaget1fontenc for a description of the problem and solution.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,217919,,,Mon Nov 21 20:28:53 UTC 2011,,,,,,0|i07otr:,42788,,,,,,,,"21/Nov/11 20:28;afuchs;User manual should be complete, but still need to look at the dev manual to see if this is an issue.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incorrect or missing SVN property settings,ACCUMULO-157,12531932,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,sebb@apache.org,sebb@apache.org,18/Nov/11 12:45,21/Nov/11 18:56,13/Mar/19 22:01,21/Nov/11 18:56,,,,,,,,1.3.5-incubating,,,,,,,,,0,,,,,"There are lots of missing or incorrect SVN properties.
Probably some committers have not set up SVN correctly, see:
http://www.apache.org/dev/version-control.html#https-svn-config

Attachments to follow, which are Unix scripts to fix them.
Rename as .cmd to use on Windows.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,18/Nov/11 12:50;sebb@apache.org;accumulo_LF.sh;https://issues.apache.org/jira/secure/attachment/12504209/accumulo_LF.sh,18/Nov/11 12:48;sebb@apache.org;accumulo_native.sh;https://issues.apache.org/jira/secure/attachment/12504208/accumulo_native.sh,18/Nov/11 12:46;sebb@apache.org;accumulo_no_exe.sh;https://issues.apache.org/jira/secure/attachment/12504206/accumulo_no_exe.sh,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,217668,,,Fri Nov 18 12:50:12 UTC 2011,,,,,,0|i07ovj:,42796,,,,,,,,18/Nov/11 12:46;sebb@apache.org;accumulo_no_exe.sh - Script to remove executable status,"18/Nov/11 12:48;sebb@apache.org;accumulo_native.sh - Script to set native EOL on source files

This includes non-Java files, so check that all the fixes are appropriate.","18/Nov/11 12:50;sebb@apache.org;accumulo_LF.sh - Script to set EOL = LF on Unix script files.

Some projects prefer to use native for these, and fix the EOL when creating the archives.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockConnector should return a MockDeleter,ACCUMULO-3,12525731,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,jesse_yates,jesse_yates,jesse_yates,04/Oct/11 20:57,18/Nov/11 15:31,13/Mar/19 22:01,20/Oct/11 17:31,,,,,,,,1.4.0,,,client,,,,,,0,,,,,"The MockConnector currently only returns MockScanners,  MockWriters, MockMultiTableMockWriter. However, for real testing of Accumulo, we need to have a real deleter as well. 

There were rumblings that the BatchDelete mechanism would be removed, but in the mean time, we should still support it because at the very least it breaks testing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,05/Oct/11 04:49;jesse_yates;java_ACCUMULO-3.txt;https://issues.apache.org/jira/secure/attachment/12497748/java_ACCUMULO-3.txt,18/Oct/11 19:49;jesse_yates;java_ACCUMULO-3_v3.txt;https://issues.apache.org/jira/secure/attachment/12499586/java_ACCUMULO-3_v3.txt,09/Oct/11 13:13;jesse_yates;java_ACCUMULO_3_v2.txt;https://issues.apache.org/jira/secure/attachment/12498346/java_ACCUMULO_3_v2.txt,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2011-10-05 21:06:40.27,,,no_permission,,,,,,,,,,,,45263,,,Tue Oct 18 21:25:21 UTC 2011,,,,,,0|i07ptj:,42949,,,,,,,,04/Oct/11 21:01;jesse_yates;I'm working on a patch for this - shouldn't be too long to get it up.,05/Oct/11 04:49;jesse_yates;Adding patch for adding MockDeleter. Also updated MockConnectorTest to test using the MockDeleter.,05/Oct/11 21:06;billie.rinaldi;We may want to keep the existing testDelete method along with a new test method for the MockBatchDeleter.  Perhaps we could check to see if removing testDelete changes the code coverage.,"07/Oct/11 13:10;jesse_yates;That's fair. Here's the numbers from running ECL Emma in Eclipse on accumulo-core:

Before:
Covered: 24.2%, 84525 lines
Misses: 264316

After:
Covered: 24.2%, 84556 lines
Missed: 264341 lines

Which honestly doesn't tell the full story. I don't think it would be that bad to have both tests. Still want me to add it back in?","07/Oct/11 19:57;billie.rinaldi;Yes, I would keep both tests.  Also, you should add some data and delete it in the test.  I would suggest changing the setRanges to something like the following: deleter.setRanges(Collections.singletonList(new Range(""r1""))); this will range over the entire row r1 (you don't have to specify ""r1"" twice).  It probably doesn't matter for a test, but I think Collections.singletonList is more efficient than Arrays.asList.

I was experimenting with it a little, and found unexpected behavior when you do a deleter.delete() without first calling setRanges on the deleter.  The real BatchScanner (TabletServerBatchReader) throws IllegalStateException(""ranges not set"") when you get an iterator from it without setting ranges, but the MockBatchScanner does not.","09/Oct/11 09:25;jesse_yates;bq. doesn't matter for a test, but I think Collections.singletonList is more efficient than Arrays.asList. 

Yeah, that is really miniscule - difference is the allocation of 1 element array and a 10 element array (assuming the Harmony source code is pretty close to the actual), though I like the former for expressing the actual intent.

Don't know why I was specifying both ends of the range - total oversight.

Working on on new patch.

bq. I was experimenting with it a little, and found unexpected behavior when you do a deleter.delete() without first calling setRanges on the deleter. The real BatchScanner (TabletServerBatchReader) throws IllegalStateException(""ranges not set"") when you get an iterator from it without setting ranges, but the MockBatchScanner does not. 

I think that should be handled in a separate patch, though I agree its a problem. Want me to open a new ticket?

Your point also ties back into the bigger issue of the mock instances lagging behind the actual implementation (ACCUMULO-14).",09/Oct/11 13:13;jesse_yates;Uploading new version: adding back in original delete test and adding in more testing for the batch deleter.,"12/Oct/11 17:53;billie.rinaldi;In the new test, I think you used the ""testDelete"" method instead of the new ""checkDeleted"" method.  You may want to pass an int into checkDeleted that has the expected count.  The last test in testDeletewithBatchDeleter leaves one entry in the table.",17/Oct/11 19:08;jesse_yates;Working on this - didn't see your post come up with notifications not working.,"18/Oct/11 18:22;jesse_yates;Hmm, it seems like the checkDeleted method isn't present anymore (checked both the svn and github) on MockConnectorTest, though I don't see a patch changing that anywhere, though it was definitely present in older versions (e.g. the first svn checkout).

Am I losing my mind or is that right? If I'm still sane, I'll just throw the check into the test method and then open a ticket to refactor the whole test to use the check.",18/Oct/11 18:41;billie.rinaldi;The checkDeleted method is in your second patch; there are +s next to it.  It doesn't appear to have been in any older svn versions.,"18/Oct/11 18:54;jesse_yates;Ok, im clearly losing my mind. Sorry about about.

You are right - my bad",18/Oct/11 19:49;jesse_yates;Making changes to use checkDeleted (renamed) rather than testDelete (dumb mistake).,18/Oct/11 21:25;billie.rinaldi;Accidentally checked in the patch without a comment.  http://svn.apache.org/viewvc?rev=1185873&view=rev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clean up bin dir,ACCUMULO-32,12527075,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,kturner,kturner,13/Oct/11 19:00,18/Nov/11 15:16,13/Mar/19 22:01,20/Oct/11 15:17,,,,,,,,1.3.5-incubating,1.4.0,,client,,,,,,0,,,,,"The accumulo bin dir has evolved over time, and has built up some cruft.  It needs to be cleaned up.

Need to remove zoo scripts, inspect, netblocked, install.

Need to add documentation to the top of check-slaves.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,85442,,,Thu Oct 20 14:53:48 UTC 2011,,,,,,0|i07pn3:,42920,,,,,,,,"20/Oct/11 14:53;kturner;Removed the scripts, just need to document check slaves.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix functional tests,ACCUMULO-46,12527623,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,18/Oct/11 17:15,18/Nov/11 15:11,13/Mar/19 22:01,25/Oct/11 20:09,,,,,,,,1.3.5-incubating,1.4.0,,test,,,,,,0,,,,,Make sure all the functional tests complete successfully.  Also make it so that they don't have to be run from the ACCUMULO_HOME directory.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,88874,,,2011-10-18 17:15:11.0,,,,,,0|i07pjz:,42906,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix references to thrift jar,ACCUMULO-51,12527809,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,19/Oct/11 19:26,18/Nov/11 15:09,13/Mar/19 22:01,19/Oct/11 19:36,,,,,,,,1.3.5-incubating,,,rpc,,,,,,0,,,,,A number of classes and scripts still look for thrift-*.jar instead of libthrift-*.jar.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,92050,,,2011-10-19 19:26:37.0,,,,,,0|i07piv:,42901,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Empty bulk imported files hang around forever,ACCUMULO-52,12527826,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,19/Oct/11 20:52,18/Nov/11 15:08,13/Mar/19 22:01,20/Oct/11 19:19,,,,,,,,1.3.5-incubating,,,client,,,,,,0,,,,,"When an emprty rfile or map file is bulk imported, it is never referenced and never deleted.  It sits around using namenode memory.  

In 1.4 its eventually deleted, when the bulk dir is deleted.  In 1.3 its never deleted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,92081,,,2011-10-19 20:52:43.0,,,,,,0|i07pin:,42900,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
missing minor compaction files under heavy namenode load,ACCUMULO-65,12528525,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,24/Oct/11 17:19,18/Nov/11 15:00,13/Mar/19 22:01,24/Oct/11 20:43,,,,,,,,1.3.5-incubating,1.4.0,,tserver,,,,,,0,,,,,"Monitor was showing lots of errors for missing files.  Analysis of any single file shows that the tablet was not moved, nor assigned to multiple servers.  All the errors are for files that were minor compacted with many namenode operations failing/retried.  The files were not deleted by the accumulo garbage collector.  Checking the name node logs, there is no mention of the file being created, but there is a mention of the final rename of the file failing.  Possible HDFS issue: file open and write succeeds, close succeeds, the file is then re-opened, and checked; yet the file is not created.

The return code of the rename to bring the file online was not checked. ","dynamic ingest on a large cluster, hadoop cdh3beta2",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,214385,,,2011-10-24 17:19:16.0,,,,,,0|i07pfr:,42887,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
prepareBulkImport swallows an exception,ACCUMULO-89,12529241,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,28/Oct/11 12:28,18/Nov/11 14:52,13/Mar/19 22:01,28/Oct/11 16:30,,,,,,,,1.3.5-incubating,,,master,tserver,,,,,0,,,,,bulk import a non-existing directory: no error message,,,,,,,,,,,,,,,,,,,,,,,,300,300,,0%,300,300,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215101,,,2011-10-28 12:28:10.0,,,,,,0|i07paf:,42863,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
createMultiTableBatchWriter has arguments that are inconsistent with createTableBatchWriter,ACCUMULO-94,12529276,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,28/Oct/11 16:08,18/Nov/11 14:50,13/Mar/19 22:01,28/Oct/11 16:30,,,,,,,,1.3.5-incubating,1.4.0,,client,,,,,,0,,,,,second argument should be a long,,,,,,,,,,,,,,,,,,,,,,,,600,600,,0%,600,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215136,,,2011-10-28 16:08:32.0,,,,,,0|i07p9b:,42858,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
close consistency check fails: Start key must be less than end key,ACCUMULO-128,12530754,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,08/Nov/11 18:40,18/Nov/11 14:35,13/Mar/19 22:01,08/Nov/11 19:23,,,,,,,,1.3.5-incubating,1.4.0,,tserver,,,,,,0,,,,,"Tablet server failed consistency check and would not unload the server.

{noformat}
08 13:38:56,959 [tabletserver.Tablet] ERROR: Failed to do close consistency check for tablet 2;<
java.lang.IllegalArgumentException: Start key must be less than end key in range (2;%00; file: [] 9223372036854775807 true, 2; log%00;: [] 9223372036854775807 false)
        at org.apache.accumulo.core.data.Range.<init>(Range.java:158)
        at org.apache.accumulo.core.data.Range.bound(Range.java:454)
        at org.apache.accumulo.core.client.impl.ScannerIterator.<init>(ScannerIterator.java:129)
        at org.apache.accumulo.core.client.impl.ScannerImpl.iterator(ScannerImpl.java:119)
        at org.apache.accumulo.server.util.MetadataTable.getFileAndLogEntries(MetadataTable.java:873)
        at org.apache.accumulo.server.tabletserver.Tablet.closeConsistencyCheck(Tablet.java:2666)
        at org.apache.accumulo.server.tabletserver.Tablet.completeClose(Tablet.java:2621)
        at org.apache.accumulo.server.tabletserver.Tablet.close(Tablet.java:2515)
        at org.apache.accumulo.server.tabletserver.TabletServer$UnloadTabletHandler.run(TabletServer.java:2228)
        at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
        at cloudtrace.instrument.TraceRunnable.run(TraceRunnable.java:47)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:679)

{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,14400,14400,,0%,14400,14400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-11-18 14:35:53.9,,,no_permission,,,,,,,,,,,,216492,,,Fri Nov 18 14:35:53 UTC 2011,,,,,,0|i07p1r:,42824,,,,,,,,"08/Nov/11 18:44;ecn;To reproduce, create an empty split point:

{noformat}
shell > addsplits -t mytable """" a b c d e f g
shell >
$ ./bin/stop-all.sh
{noformat}
","18/Nov/11 14:35;kturner;When we create rc7, this fix will be pulled in 1.3.5",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Combiner default behavior is dangerous,ACCUMULO-151,12531633,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,kturner,kturner,16/Nov/11 15:24,16/Nov/11 18:07,13/Mar/19 22:01,16/Nov/11 18:07,,,,,,,,1.4.0,,,client,tserver,,,,,0,,,,,"Currently if the users does not give the combiner any columns to work against, it will work against all columns.  This is dangerous, if a user accidentally forgets to specify columns then their data could be unintentionally corrupted.  Something different needs to be done.  

Also classes that extend combiner should call super.validateOptions(). ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,217369,,,2011-11-16 15:24:45.0,,,,,,0|i07owv:,42802,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Scanner creates threads too frequently,ACCUMULO-110,12529870,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,02/Nov/11 14:50,03/Nov/11 19:44,13/Mar/19 22:01,03/Nov/11 19:44,,,,,,,,1.4.0,,,client,,,,,,0,,,,,"After the scanner has read a few batches of data from the tablet server it starts creating read ahead threads to read batches.  A thread is created per batch.  After a thread reads a batch it exits.  A thread pool was not used because the scanner does not have a close method.  A user suggested using a static thread pool, see the following email chain.  

http://mail-archives.apache.org/mod_mbox/incubator-accumulo-dev/201111.mbox/%3C4EB04FE3.5020005@digitalreasoning.com%3E

This static pool should be unbounded, time out threads, use a Synchronous Queue, and create daemon threads.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215729,,,2011-11-02 14:50:12.0,,,,,,0|i07p5r:,42842,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bloom filter should ignore duplicate inserts,ACCUMULO-98,12529328,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,28/Oct/11 22:34,01/Nov/11 18:40,13/Mar/19 22:01,01/Nov/11 18:40,,,,,,,,1.4.0,,,tserver,,,,,,0,,,,,Duplicate data inserted into the bloom filter should not cause its entry count to grow.  This causes the filter to grow larger than it should.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215188,,,2011-10-28 22:34:55.0,,,,,,0|i07p8f:,42854,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"importDirectory does not verify the input is a directory, and does not send absolute paths to the servers",ACCUMULO-91,12529250,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,ecn,ecn,28/Oct/11 13:47,28/Oct/11 14:40,13/Mar/19 22:01,28/Oct/11 14:40,,,,,,,,1.3.5-incubating,,,client,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1800,1800,,0%,1800,1800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215110,,,2011-10-28 13:47:57.0,,,,,,0|i07p9z:,42861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
exec-maven-plugin not finding bin/bash,ACCUMULO-73,12528780,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,ecn,karafman,karafman,25/Oct/11 23:08,26/Oct/11 19:17,13/Mar/19 22:01,26/Oct/11 19:17,,,,,,,,,,,build,,,,,,0,packaging,,,,"Downloaded the source using the direction from http://incubator.apache.org/accumulo/source.html and attempted to build.  Received the following eror:

[INFO] ------------------------------------------------------------------------
[INFO] Building accumulo
[INFO]    task-segment: [package]
[INFO] ------------------------------------------------------------------------
[INFO] [enforcer:enforce {execution: enforce-mvn}]
[INFO] [dependency:copy-dependencies {execution: copy-dependencies}]
[INFO] [exec:exec {execution: user-manual}]
[INFO] ------------------------------------------------------------------------
[ERROR] BUILD ERROR
[INFO] ------------------------------------------------------------------------
[INFO] Command execution failed.

Embedded error: Cannot run program ""\bin\bash"" (in directory ""C:\workspace\accumulo-trunk""): CreateProcess error=2, The system can
not find the file specified
[INFO] ------------------------------------------------------------------------
[INFO] For more information, run Maven with the -e switch
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 6 seconds
[INFO] Finished at: Tue Oct 25 19:07:52 EDT 2011
[INFO] Final Memory: 30M/239M
[INFO] ------------------------------------------------------------------------

Opened up the parent pom.xml file and noticed the exec-maven-plugin is looking for thie file and not finding it.","Windows7, via Cygwin.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-10-26 19:16:44.082,,,no_permission,,,,,,,,,,,,214640,,,Wed Oct 26 19:16:44 UTC 2011,,,,,,0|i07pdz:,42879,,,,,,,,26/Oct/11 19:16;billie.rinaldi;eric checked in a fix,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Random walk logging config wrong,ACCUMULO-62,12528342,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,kturner,kturner,kturner,22/Oct/11 01:23,22/Oct/11 01:24,13/Mar/19 22:01,22/Oct/11 01:24,,,,,,,,1.3.5-incubating,1.4.0,,,,,,,,0,,,,,The log4j config for random walk test does not properly log the DEBUG level.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,113476,,,2011-10-22 01:23:11.0,,,,,,0|i07pgf:,42890,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mailing list links are incorrect,ACCUMULO-59,12527989,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Major,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,20/Oct/11 17:40,20/Oct/11 17:45,13/Mar/19 22:01,20/Oct/11 17:45,,,,,,,,,,,docs,,,,,,0,links,mailing-list,,,The links reference -users instead of -user.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,92454,,,2011-10-20 17:40:25.0,,,,,,0|i07ph3:,42893,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Range constructors call overridable method,ACCUMULO-1972,12683145,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,coffeethulhu,bhavanki,bhavanki,06/Dec/13 16:07,04/Jan/18 20:44,13/Mar/19 22:01,31/Dec/17 09:13,1.4.4,1.5.0,,,,,,1.7.4,1.9.0,2.0.0,,,,,,,0,newbie,,,,"Several {{Range}} constructors call {{Range.beforeStartKey()}}, which is not final. This is dangerous:

bq. The superclass constructor runs before the subclass constructor, so the overriding method in the subclass will get invoked before the subclass constructor has run. If the overriding method depends on any initialization performed by the subclass constructor, the method will not behave as expected.  ??Item 17, Effective Java Vol. 2, Bloch??

If {{beforeStartKey()}} cannot be made final, the code should be refactored to make the constructors safe.",,"Commit 21d2ea28494005fcd6860244b9d7d86d4f29993b in accumulo's branch refs/heads/1.7 from [~coffeethulhu]
[ https://gitbox.apache.org/repos/asf?p=accumulo.git;h=21d2ea2 ]

ACCUMULO-1972 fix Range constructor

Updated Range constructor to use a private implementation of
beforeStartKey, so that it does not cause a problem if a subclass
overrides the public beforeStartKey method.

(commit message updated by ctubbsii to provide additional detail)
;31/Dec/17 09:12;jira-bot;600","Commit 21d2ea28494005fcd6860244b9d7d86d4f29993b in accumulo's branch refs/heads/1.8 from [~coffeethulhu]
[ https://gitbox.apache.org/repos/asf?p=accumulo.git;h=21d2ea2 ]

ACCUMULO-1972 fix Range constructor

Updated Range constructor to use a private implementation of
beforeStartKey, so that it does not cause a problem if a subclass
overrides the public beforeStartKey method.

(commit message updated by ctubbsii to provide additional detail)
;31/Dec/17 09:12;jira-bot;600","Commit 21d2ea28494005fcd6860244b9d7d86d4f29993b in accumulo's branch refs/heads/master from [~coffeethulhu]
[ https://gitbox.apache.org/repos/asf?p=accumulo.git;h=21d2ea2 ]

ACCUMULO-1972 fix Range constructor

Updated Range constructor to use a private implementation of
beforeStartKey, so that it does not cause a problem if a subclass
overrides the public beforeStartKey method.

(commit message updated by ctubbsii to provide additional detail)
;31/Dec/17 09:12;jira-bot;600",,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,,,,31/Dec/17 00:16;coffeethulhu;0001-ACCUMULO-1972-updated-beforeStartKey-to-private-impl.patch;https://issues.apache.org/jira/secure/attachment/12904084/0001-ACCUMULO-1972-updated-beforeStartKey-to-private-impl.patch,06/Nov/17 22:32;coffeethulhu;accumulo-1972.patch;https://issues.apache.org/jira/secure/attachment/12896281/accumulo-1972.patch,26/Nov/17 23:31;coffeethulhu;accumulo-1972_2.patch;https://issues.apache.org/jira/secure/attachment/12899316/accumulo-1972_2.patch,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2017-11-06 22:34:13.31,,,no_permission,,,,,,,,,,,,362397,,,Thu Jan 04 20:44:24 UTC 2018,,,,,,0|i1qgvb:,362691,,,,,,,,06/Nov/17 22:34;coffeethulhu;Fix added. beforeStartKey and afterEndKey methods both made final and tested locally as working.,"09/Nov/17 00:25;ctubbsii;Thanks for the patch, [~coffeethulhu].

I have some concerns about the patch.

Doing nothing means it is possible for careful developers to override the method. Applying this fix prevents users from doing the thing they needed to do that would have caused the bug in the first place (that is, override the method). I don't think this is the best fix we can do, as it breaks the API and prevents the only use case that would have been affected by the bug.

It seems to me that a better fix might be to move the implementation to a private method, which can be safely called in the constructor, and also be called in the public method. That way, if the user overrides the public method, the behavior of the constructor will be unaffected. This fix would also allows us to avoid an API breakage, which means we can fix it in 1.7.x and 1.8.x, instead of waiting for 2.x.","26/Nov/17 23:32;coffeethulhu;[~ctubbsii] Good call. Updated code moving logic for beforeStartKey and afterEndKey to private implementation methods with public methods to call them, returning the resulting output. Also  added/updated comments to reflect this. Unit tests are all still good and the change seems to function fine locally.","09/Dec/17 00:04;ctubbsii;[~coffeethulhu], thanks, I have a few comments before applying your updated patch.

* The constructor should be updated to reference the new {{beforeStartKeyImpl}} instead of {{beforeStartKey}}. That would fix the original problem, because the private method can't be overridden.
* I don't think we need the new private method for {{afterEndKeyImpl}}, because that was never called in the constructor.
* I think the original javadocs on the original public methods do not need to be changed. We want the javadocs on the public methods to reflect the user experience, not the internal implementation. The user does not need to know that it calls the private method.
* If you strip trailing whitespace off of the lines in your patch, and run {{mvn clean package -DskipTests}}, your code will be formatted using our built-in code formatter during the build. I can also do this before applying the patch, but I wanted to let you know about it.

Also, a hint for creating your patch: if you create a ""git-formatted"" patch (for example: {{git format-patch HEAD~1}}) to create a patch file, instead of {{git diff}}, the patch will include your authorship information, so you will get credit when we apply the patch. If it's more convenient, you can also submit a pull request against the 1.7 branch at https://github.com/apache/accumulo ; I can still give you credit if I create the git commit, but only by mentioning your name in the log message. Whatever you prefer is fine with me, but thought I'd mention it, so you had the opportunity to get credit in the git commit history of Accumulo. :)
","31/Dec/17 00:17;coffeethulhu;[~ctubbsii] Really appreciate the feedback. As per the comments, I updated the code and have added a new git-formatted patch after testing locally.","31/Dec/17 08:52;ctubbsii;Thanks, [~coffeethulhu]! Since you had more than one commit, my advice to use {{HEAD~1}} was bad advice. I should have suggested to squash it first, or to do {{git format-patch origin/1.7}} instead.

For expediency, rather than have you mess about further with git commands, I will simply combine your previous patch with this git-formatted one, to produce a single squashed commit in your local branch, with you as the author and based on what we discussed. :) I will also update the commit message to provide a little more detail about the change.

Thank you very much for investigating this bug and contributing the code to fix it. Since this appears to be your first contribution to Accumulo, would you like to be added to our 'people' page (https://accumulo.apache.org/people/)? If so, you can perform a pull request to https://github.com/apache/accumulo-website/blob/master/pages/people.md or simply comment with the details you'd like to be added, and one of us can add you directly.

Also, if you'd like your first contribution to be mentioned on Twitter, let us know your Twitter handle and we can '@' mention you. :)",04/Jan/18 20:44;coffeethulhu;[~ctubbsii] Happy to contribute! I've been working with Accumulo for years ever since my time up in Central MD. Figured it was well past time to actually start getting involved (and brush the dust off my Java skills). I went updated the people.md file and made a pull request as suggested. Thanks!,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Separate Controller and View logic in Monitor,ACCUMULO-1589,12659001,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,,jklucar,jklucar,22/Jul/13 02:29,14/Nov/17 21:27,13/Mar/19 22:01,14/Nov/17 21:27,1.5.0,,,,,,,2.0.0,,,,,,,,,0,,,,,"The view code is all just done with StringBuilders which make the HTML near impossible to decipher in the .java files.  The controller and views should be broken apart with some framework. Many are around, .jsp would be better at this point.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2017-11-14 21:27:54.469,,,no_permission,,,,,,,,,,,,339194,,,Tue Nov 14 21:27:54 UTC 2017,,,,,,0|i1mi5b:,339514,,,,,,,,14/Nov/17 21:27;ctubbsii;I think that the work on ACCUMULO-3005 and related suite of issues satisfies this.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Return value from in.read() should be checked in NonCachingSecretKeyEncryptionStrategy#doKeyEncryptionOperation(),ACCUMULO-2278,12692121,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,,yuzhihong@gmail.com,yuzhihong@gmail.com,29/Jan/14 20:02,14/Oct/16 21:50,13/Mar/19 22:01,14/Oct/16 21:50,,,,,,,,1.7.3,1.8.1,2.0.0,,,,,,,0,newbie,,,,"Here is related code:
{code}
      byte[] keyEncryptionKey = new byte[keyEncryptionKeyLength];
      in.read(keyEncryptionKey);
{code}
The return value should be checked so that we don't need to call cipher.init() in case encryption key isn't read properly.",,"GitHub user mm376 opened a pull request:

    https://github.com/apache/accumulo/pull/163

    ACCUMULO-2278 Return value from in.read() should be checked in

    NonCachingSecretKeyEn.cryptionStrategy#doKeyEncryptionOperation()

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/mm376/accumulo ACCUMULO-2278

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/accumulo/pull/163.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #163
    
----
commit ca3b8f1414fc4536e9c42921e8b8271025874912
Author: mm376k <mm376k@mdcdtl02mm376k.itservices.sbc.com>
Date:   2016-10-11T23:29:03Z

    ACCUMULO-2278 Return value from in.read() should be checked in
    NonCachingSecretKeyEn.cryptionStrategy#doKeyEncryptionOperation()

----
;11/Oct/16 23:30;githubbot;600","Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/163#discussion_r82929101
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/security/crypto/NonCachingSecretKeyEncryptionStrategy.java ---
    @@ -81,7 +81,10 @@ private void doKeyEncryptionOperation(int encryptionMode, CryptoModuleParameters
           Cipher cipher = DefaultCryptoModuleUtils.getCipher(params.getAllOptions().get(Property.CRYPTO_DEFAULT_KEY_STRATEGY_CIPHER_SUITE.getKey()));
     
           try {
    -        cipher.init(encryptionMode, new SecretKeySpec(keyEncryptionKey, params.getAlgorithmName()));
    +    	if (keyEncryptionKey.length > 0)
    --- End diff --
    
    It looks like this change might actually change the code flow. When the keyEncryptionKey was of length `0`, would `cipher.init(...)` have thrown an `InvalidKeyException`? I would assume that when the key is empty, we would want to throw a `RuntimeException`.
;12/Oct/16 02:59;githubbot;600","Github user ctubbsii commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/163#discussion_r82935160
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/security/crypto/NonCachingSecretKeyEncryptionStrategy.java ---
    @@ -81,7 +81,10 @@ private void doKeyEncryptionOperation(int encryptionMode, CryptoModuleParameters
           Cipher cipher = DefaultCryptoModuleUtils.getCipher(params.getAllOptions().get(Property.CRYPTO_DEFAULT_KEY_STRATEGY_CIPHER_SUITE.getKey()));
     
           try {
    -        cipher.init(encryptionMode, new SecretKeySpec(keyEncryptionKey, params.getAlgorithmName()));
    +    	if (keyEncryptionKey.length > 0)
    --- End diff --
    
    This makes me wonder what the API contract is on `read()`. Will the return value from this always be equal to the length of the byte array? If it's not, should we explicitly throw an `InvalidKeyException`? Should we use some `readFully()` method to populate the read buffer instead of `read()`?
;12/Oct/16 04:38;githubbot;600","Github user ctubbsii commented on the issue:

    https://github.com/apache/accumulo/pull/163
  
    @mm376 If you comment on https://issues.apache.org/jira/browse/ACCUMULO-2278 , we can add your user name to the contributors in JIRA and assign the issue to you. (You'll also be able to self-assign issues, and other things in JIRA, if you make further contributions.)
;12/Oct/16 04:40;githubbot;600","Github user mstair commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/163#discussion_r83072327
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/security/crypto/NonCachingSecretKeyEncryptionStrategy.java ---
    @@ -81,7 +81,10 @@ private void doKeyEncryptionOperation(int encryptionMode, CryptoModuleParameters
           Cipher cipher = DefaultCryptoModuleUtils.getCipher(params.getAllOptions().get(Property.CRYPTO_DEFAULT_KEY_STRATEGY_CIPHER_SUITE.getKey()));
     
           try {
    -        cipher.init(encryptionMode, new SecretKeySpec(keyEncryptionKey, params.getAlgorithmName()));
    +    	if (keyEncryptionKey.length > 0)
    --- End diff --
    
    The SecretKeySpec constructor would throw IllegalArgumentException
    
    https://docs.oracle.com/javase/7/docs/api/javax/crypto/spec/SecretKeySpec.html 

;12/Oct/16 18:45;githubbot;600","Github user mm376 commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/163#discussion_r83072563
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/security/crypto/NonCachingSecretKeyEncryptionStrategy.java ---
    @@ -81,7 +81,10 @@ private void doKeyEncryptionOperation(int encryptionMode, CryptoModuleParameters
           Cipher cipher = DefaultCryptoModuleUtils.getCipher(params.getAllOptions().get(Property.CRYPTO_DEFAULT_KEY_STRATEGY_CIPHER_SUITE.getKey()));
     
           try {
    -        cipher.init(encryptionMode, new SecretKeySpec(keyEncryptionKey, params.getAlgorithmName()));
    +    	if (keyEncryptionKey.length > 0)
    --- End diff --
    
    Code was throwing an exception even before the if check was added, adding this check probably caused the rest of the code to be executed resulting in a null exception in another part of the code.
;12/Oct/16 18:46;githubbot;600","Github user joshelser commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/163#discussion_r83087033
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/security/crypto/NonCachingSecretKeyEncryptionStrategy.java ---
    @@ -81,7 +81,10 @@ private void doKeyEncryptionOperation(int encryptionMode, CryptoModuleParameters
           Cipher cipher = DefaultCryptoModuleUtils.getCipher(params.getAllOptions().get(Property.CRYPTO_DEFAULT_KEY_STRATEGY_CIPHER_SUITE.getKey()));
     
           try {
    -        cipher.init(encryptionMode, new SecretKeySpec(keyEncryptionKey, params.getAlgorithmName()));
    +    	if (keyEncryptionKey.length > 0)
    --- End diff --
    
    > The SecretKeySpec constructor would throw IllegalArgumentException
    
    > adding this check probably caused the rest of the code to be executed resulting in a null exception in another part of the code.
    
    Sounds to me like we would want to throw our own IllegalArgumentException (or some unchecked exception) in an `else` branch to the conditional you added. Care to update the pull request with that change?
;12/Oct/16 20:04;githubbot;600","Github user ctubbsii commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/163#discussion_r83102811
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/security/crypto/NonCachingSecretKeyEncryptionStrategy.java ---
    @@ -81,7 +81,10 @@ private void doKeyEncryptionOperation(int encryptionMode, CryptoModuleParameters
           Cipher cipher = DefaultCryptoModuleUtils.getCipher(params.getAllOptions().get(Property.CRYPTO_DEFAULT_KEY_STRATEGY_CIPHER_SUITE.getKey()));
     
           try {
    -        cipher.init(encryptionMode, new SecretKeySpec(keyEncryptionKey, params.getAlgorithmName()));
    +    	if (keyEncryptionKey.length > 0)
    --- End diff --
    
    The original reported issue is that the return value of the read is not captured or checked. The conditional being checked here only verifies that the allocated array was larger than an empty array. What it actually needs to check is that the number of bytes read into the array is the same as the value of the length field, regardless of what else we want to check. The conditional in this patch is sufficient only if we switch to using `readFully` instead of `read`, which throws an EOFException if the number of bytes read from the input stream isn't enough to fill the buffer (e.g. doesn't match the expected keyEncryptionKeyLength).
;12/Oct/16 21:29;githubbot;600","Github user mm376 commented on a diff in the pull request:

    https://github.com/apache/accumulo/pull/163#discussion_r83207379
  
    --- Diff: core/src/main/java/org/apache/accumulo/core/security/crypto/NonCachingSecretKeyEncryptionStrategy.java ---
    @@ -81,7 +81,10 @@ private void doKeyEncryptionOperation(int encryptionMode, CryptoModuleParameters
           Cipher cipher = DefaultCryptoModuleUtils.getCipher(params.getAllOptions().get(Property.CRYPTO_DEFAULT_KEY_STRATEGY_CIPHER_SUITE.getKey()));
     
           try {
    -        cipher.init(encryptionMode, new SecretKeySpec(keyEncryptionKey, params.getAlgorithmName()));
    +    	if (keyEncryptionKey.length > 0)
    --- End diff --
    
    Chris, Josh: I made the code change and pushed it into repository, take a look at it when you get a chance.
;13/Oct/16 12:47;githubbot;600","Github user ctubbsii commented on the issue:

    https://github.com/apache/accumulo/pull/163
  
    Going to merge this in, starting at 1.7 branch. @mm376 see note above, if you want to be added to contributors in JIRA. Also, let me know if you want to be added to https://accumulo.apache.org/people
;14/Oct/16 19:23;githubbot;600","Github user ctubbsii commented on the issue:

    https://github.com/apache/accumulo/pull/163
  
    Oh, I'm also going to squash and cherry-pick this commit so that it will apply to the 1.7 branch, since the current PR is against the master branch.
;14/Oct/16 19:26;githubbot;600","Commit 9e236f289679e950e181db7c14b7f54042d1bb14 in accumulo's branch refs/heads/1.7 from mm376k
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e236f2 ]

ACCUMULO-2278 Return value from in.read() should be checked

Return value from in.read() should be checked in
NonCachingSecretKeyEn.cryptionStrategy#doKeyEncryptionOperation()

Commits squashed and rebase'd onto 1.7 branch, formatted, and log
message reworded by ctubbsii. This closes #163

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
;14/Oct/16 21:49;jira-bot;600","Commit 9e236f289679e950e181db7c14b7f54042d1bb14 in accumulo's branch refs/heads/1.8 from mm376k
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e236f2 ]

ACCUMULO-2278 Return value from in.read() should be checked

Return value from in.read() should be checked in
NonCachingSecretKeyEn.cryptionStrategy#doKeyEncryptionOperation()

Commits squashed and rebase'd onto 1.7 branch, formatted, and log
message reworded by ctubbsii. This closes #163

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
;14/Oct/16 21:49;jira-bot;600","Commit 9e236f289679e950e181db7c14b7f54042d1bb14 in accumulo's branch refs/heads/master from mm376k
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e236f2 ]

ACCUMULO-2278 Return value from in.read() should be checked

Return value from in.read() should be checked in
NonCachingSecretKeyEn.cryptionStrategy#doKeyEncryptionOperation()

Commits squashed and rebase'd onto 1.7 branch, formatted, and log
message reworded by ctubbsii. This closes #163

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
;14/Oct/16 21:49;jira-bot;600","Github user asfgit closed the pull request at:

    https://github.com/apache/accumulo/pull/163
;14/Oct/16 21:49;githubbot;600",,,,,,,,,0,9000,,,0,9000,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,370712,,,2014-01-29 20:02:57.0,,,,,,0|i1rw4n:,371023,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
disk file usage off in the monitor,ACCUMULO-2282,12692189,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,sblack,afuchs,afuchs,30/Jan/14 00:08,02/Mar/15 22:29,13/Mar/19 22:01,02/Mar/15 22:29,1.6.1,,,,,,,1.7.0,,,monitor,,,,,,0,newbie,,,,"The monitor DefaultServelet uses ContentSummary.getSpaceConsumed(), which returns something like the sum of all the space that all of the allocated blocks could possibly consume. This includes replication and a bunch of unconsumed space for things like walogs. The monitor should use ContentSummary.getLength() instead, which is the total current size of bytes used on disk in the given directory, pre-replication.",,"Commit 293340ac64309d644a308e44d3a2c9219167ccfd in accumulo's branch refs/heads/master from [~afuchs]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=293340a ]

ACCUMULO-2282 applied patch
;02/Mar/15 22:27;jira-bot;600",,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,26/Jan/15 08:32;sblack;ACCUMULO-2282.patch;https://issues.apache.org/jira/secure/attachment/12694503/ACCUMULO-2282.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2015-01-24 15:15:12.962,,,no_permission,,,,,,,,,,,,370780,,,Mon Mar 02 22:29:00 UTC 2015,,,,,,0|i1rwiv:,371088,,,,,,,,"24/Jan/15 15:15;sonixbp;[~sblack], were you intending on attaching a patch to this ticket or on reviews.apache.org? If so, I can add you as a developer so you can assign this ticket to yourself.","24/Jan/15 15:24;sblack;Yes I am intending on adding a patch to this ticket, if you can add me as a devloper then that would be great.",25/Jan/15 00:11;elserj;Done -- happy developing!,02/Mar/15 22:29;afuchs;Patch pushed. Thanks for your contribution!,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooSession should be more robust to transient DNS issues,ACCUMULO-2224,12689840,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,busbey,busbey,busbey,20/Jan/14 17:30,01/Jul/14 15:46,13/Mar/19 22:01,23/Jan/14 13:19,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,,,1.4.5,1.5.1,1.6.0,client,,,,,,0,,,,,"While injecting network faults, I found that transient DNS problems caused us to bail out of ZooSessions rather than retrying as we do for all other IO problems. We should retry these failures just as we do for Connection Refused or other networking problems.

Since the addition of ACCUMULO-131, we can be sure that we won't retry actual invalid hosts for ever. Instead, after the time out period that holds for all other problems we'll properly exit.

The warn messages logged for IOExceptions should suffice to indicate improperly specified host names.",1.4.5-SNAP on CDH4 w/gremlins,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2967,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-21 14:58:19.212,,,no_permission,,,,,,,,,,,,368807,,,Wed Mar 26 17:13:47 UTC 2014,,,,,,0|i1rkfr:,369111,,,,,,,,"20/Jan/14 17:57;busbey;AFAICT, ZK will throw as soon as any of the specified hostnames in the connect string resolves as UnknownHostException.

The workaround for existing releases is to fix the underlying DNS problem and then restart roles.

Some stack traces of where this came up during testing (for those wishing to dedup errors they might see)

tserver compaction
{noformat}
Unexpected exception in Split/MajC initiator
	java.lang.RuntimeException: java.net.UnknownHostException: zookeeper1.example.com
		at org.apache.accumulo.core.zookeeper.ZooSession.connect(ZooSession.java:94)
		at org.apache.accumulo.core.zookeeper.ZooSession.getSession(ZooSession.java:142)
		at org.apache.accumulo.core.zookeeper.ZooReader.getSession(ZooReader.java:36)
		at org.apache.accumulo.core.zookeeper.ZooReader.getZooKeeper(ZooReader.java:40)
		at org.apache.accumulo.core.zookeeper.ZooCache.getZooKeeper(ZooCache.java:56)
		at org.apache.accumulo.core.zookeeper.ZooCache.retry(ZooCache.java:127)
		at org.apache.accumulo.core.zookeeper.ZooCache.get(ZooCache.java:233)
		at org.apache.accumulo.core.zookeeper.ZooCache.get(ZooCache.java:188)
		at org.apache.accumulo.server.conf.TableConfiguration.get(TableConfiguration.java:121)
		at org.apache.accumulo.server.conf.TableConfiguration.get(TableConfiguration.java:109)
		at org.apache.accumulo.core.conf.AccumuloConfiguration.getMemoryInBytes(AccumuloConfiguration.java:47)
		at org.apache.accumulo.server.tabletserver.Tablet.findSplitRow(Tablet.java:3028)
		at org.apache.accumulo.server.tabletserver.Tablet.needsSplit(Tablet.java:3122)
		at org.apache.accumulo.server.tabletserver.TabletServer$MajorCompactor.run(TabletServer.java:2117)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at java.lang.Thread.run(Thread.java:662)
	Caused by: java.net.UnknownHostException: zookeeper1.example.com
		at java.net.InetAddress.getAllByName0(InetAddress.java:1157)
		at java.net.InetAddress.getAllByName(InetAddress.java:1083)
		at java.net.InetAddress.getAllByName(InetAddress.java:1019)
		at org.apache.zookeeper.client.StaticHostProvider.<init>(StaticHostProvider.java:60)
		at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:445)
		at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:380)
		at org.apache.accumulo.core.zookeeper.ZooSession.connect(ZooSession.java:77)
		... 15 m
{noformat}

logger tracing
{noformat}
2014-01-16 00:00:12,772 [zookeeper.ZooSession] WARN : java.net.UnknownHostException : zookeeper2.example.com
2014-01-16 00:00:12,772 [trace.ZooTraceClient] ERROR: unable to get destination hosts in zookeeper
java.lang.RuntimeException: java.net.UnknownHostException: zookeeper2.example.com
        at org.apache.accumulo.core.zookeeper.ZooSession.connect(ZooSession.java:94)
        at org.apache.accumulo.core.zookeeper.ZooSession.getSession(ZooSession.java:142)
        at org.apache.accumulo.core.zookeeper.ZooReader.getSession(ZooReader.java:37)
        at org.apache.accumulo.server.zookeeper.ZooReaderWriter.getZooKeeper(ZooReaderWriter.java:57)
        at org.apache.accumulo.core.zookeeper.ZooReader.getChildren(ZooReader.java:66)
        at org.apache.accumulo.core.trace.ZooTraceClient.process(ZooTraceClient.java:64)
        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:519)
        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:495)
{noformat}

master startup (I think):
{noformat}
Caused by: java.lang.RuntimeException: java.net.UnknownHostException: zookeeper1.example.com
        at org.apache.accumulo.core.zookeeper.ZooSession.connect(ZooSession.java:94)
        at org.apache.accumulo.core.zookeeper.ZooSession.getSession(ZooSession.java:142)
        at org.apache.accumulo.core.zookeeper.ZooReader.getSession(ZooReader.java:37)
        at org.apache.accumulo.server.zookeeper.ZooReaderWriter.getZooKeeper(ZooReaderWriter.java:57)
        at org.apache.accumulo.core.zookeeper.ZooReader.getChildren(ZooReader.java:61)
        at org.apache.accumulo.server.Accumulo.waitForZookeeperAndHdfs(Accumulo.java:201)
        at org.apache.accumulo.server.master.state.SetGoalState.main(SetGoalState.java:40)

{noformat}

Continuous Ingest stats collector
{noformat}
1389860157417 Failed to collect stats : java.net.UnknownHostException: zookeeper1.example.com
java.lang.RuntimeException: java.net.UnknownHostException: zookeeper1.example.com
        at org.apache.accumulo.core.zookeeper.ZooSession.connect(ZooSession.java:94)
        at org.apache.accumulo.core.zookeeper.ZooSession.getSession(ZooSession.java:142)
        at org.apache.accumulo.core.zookeeper.ZooReader.getSession(ZooReader.java:37)
        at org.apache.accumulo.core.zookeeper.ZooReader.getZooKeeper(ZooReader.java:41)
        at org.apache.accumulo.core.zookeeper.ZooCache.getZooKeeper(ZooCache.java:56)
        at org.apache.accumulo.core.zookeeper.ZooCache.retry(ZooCache.java:127)
        at org.apache.accumulo.core.zookeeper.ZooCache.getChildren(ZooCache.java:178)
        at org.apache.accumulo.server.zookeeper.ZooLock.getLockData(ZooLock.java:414)
        at org.apache.accumulo.server.client.HdfsZooInstance.getMasterLocations(HdfsZooInstance.java:102)
        at org.apache.accumulo.core.client.impl.MasterClient.getConnection(MasterClient.java:52)
        at org.apache.accumulo.core.client.impl.MasterClient.getConnectionWithRetry(MasterClient.java:43)
        at org.apache.accumulo.server.test.continuous.ContinuousStatsCollector$StatsCollectionTask.getACUStats(ContinuousStatsCollector.java:128)
        at org.apache.accumulo.server.test.continuous.ContinuousStatsCollector$StatsCollectionTask.run(ContinuousStatsCollector.java:77)
        at java.util.TimerThread.mainLoop(Timer.java:512)
        at java.util.TimerThread.run(Timer.java:462)
{noformat}

Continuous Ingest scanner (probably all BatchScanners)
{noformat}
Caused by: java.lang.RuntimeException: java.net.UnknownHostException: zookeeper1.example.com
        at org.apache.accumulo.core.zookeeper.ZooSession.connect(ZooSession.java:94)
        at org.apache.accumulo.core.zookeeper.ZooSession.getSession(ZooSession.java:142)
        at org.apache.accumulo.core.zookeeper.ZooReader.getSession(ZooReader.java:37)
        at org.apache.accumulo.core.zookeeper.ZooReader.getZooKeeper(ZooReader.java:41)
        at org.apache.accumulo.core.zookeeper.ZooCache.getZooKeeper(ZooCache.java:56)
        at org.apache.accumulo.core.zookeeper.ZooCache.retry(ZooCache.java:127)
        at org.apache.accumulo.core.zookeeper.ZooCache.get(ZooCache.java:233)
        at org.apache.accumulo.core.zookeeper.ZooCache.get(ZooCache.java:188)
        at org.apache.accumulo.core.client.ZooKeeperInstance.getInstanceID(ZooKeeperInstance.java:148)
        at org.apache.accumulo.core.client.impl.TabletLocator.getInstance(TabletLocator.java:96)
        at org.apache.accumulo.core.client.impl.ThriftScanner.scan(ThriftScanner.java:245)
        at org.apache.accumulo.core.client.impl.ScannerIterator$Reader.run(ScannerIterator.java:94)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
{noformat}

Continous Ingest writer (probably all users of BatchWriter):
{noformat}
Caused by: java.lang.RuntimeException: java.net.UnknownHostException: zookeeper1.example.com
        at org.apache.accumulo.core.zookeeper.ZooSession.connect(ZooSession.java:94)
        at org.apache.accumulo.core.zookeeper.ZooSession.getSession(ZooSession.java:142)
        at org.apache.accumulo.core.zookeeper.ZooReader.getSession(ZooReader.java:37)
        at org.apache.accumulo.core.zookeeper.ZooReader.getZooKeeper(ZooReader.java:41)
        at org.apache.accumulo.core.zookeeper.ZooCache.getZooKeeper(ZooCache.java:56)
        at org.apache.accumulo.core.zookeeper.ZooCache.retry(ZooCache.java:127)
        at org.apache.accumulo.core.zookeeper.ZooCache.get(ZooCache.java:233)
        at org.apache.accumulo.core.zookeeper.ZooCache.get(ZooCache.java:188)
        at org.apache.accumulo.core.client.ZooKeeperInstance.getInstanceID(ZooKeeperInstance.java:148)
        at org.apache.accumulo.core.client.impl.TabletLocator.getInstance(TabletLocator.java:96)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter$SendTask.send(TabletServerBatchWriter.java:733)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter$SendTask.run(TabletServerBatchWriter.java:671)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
{noformat}",21/Jan/14 14:58;ecn;What are you using to inject these network faults?,21/Jan/14 15:02;busbey;iptables via [gremlins|https://github.com/busbey/gremlins],"23/Jan/14 14:23;jira-bot;Commit de7d198459ba745b0d2d5a3c60b2be7286742f39 in branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=de7d198 ]

ACCUMULO-2224 link TODOs to new JIRAs
","23/Jan/14 14:23;jira-bot;Commit de7d198459ba745b0d2d5a3c60b2be7286742f39 in branch refs/heads/1.5.1-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=de7d198 ]

ACCUMULO-2224 link TODOs to new JIRAs
","23/Jan/14 14:23;jira-bot;Commit de7d198459ba745b0d2d5a3c60b2be7286742f39 in branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=de7d198 ]

ACCUMULO-2224 link TODOs to new JIRAs
","23/Jan/14 17:15;jira-bot;Commit de7d198459ba745b0d2d5a3c60b2be7286742f39 in branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=de7d198 ]

ACCUMULO-2224 link TODOs to new JIRAs
","26/Mar/14 17:12;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
","26/Mar/14 17:13;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
","26/Mar/14 17:13;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
","26/Mar/14 17:13;jira-bot;Commit 4ee0f6494ea0d2265d930bce962ebcc3c7dbfe5c in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4ee0f64 ]

Fix recent warnings introduced by several tickets

ACCUMULO-2005
ACCUMULO-2182
ACCUMULO-2224
ACCUMULO-2234
ACCUMULO-2539
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TServerUtils no longer needs to catch NPE as a thrift bug workaround,ACCUMULO-2410,12697427,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,al.krinker,mdrob,mdrob,26/Feb/14 19:15,12/Jun/14 23:20,13/Mar/19 22:01,12/Jun/14 23:20,1.5.1,1.6.0,,,,,,1.5.2,1.6.1,1.7.0,tserver,,,,,,0,newbie,Summit2014,,,"Since we are using thrift 0.9.0 starting with Accumulo 1.6, we should be able to clean up the following code in {{TServerUtils}}.
{code:java}
        try {
          return other.process(in, out);
        } catch (NullPointerException ex) {
          // THRIFT-1447 - remove with thrift 0.9
          return true;
        }
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-822,THRIFT-1447,22/Apr/14 23:27;krinker;ACCUMULO-2410.patch.txt;https://issues.apache.org/jira/secure/attachment/12641372/ACCUMULO-2410.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-02-26 19:32:58.837,,,no_permission,,,,,,,,,,,,375901,,,Thu Jun 12 23:20:55 UTC 2014,,,,,,0|i1srxr:,376197,,,,,,,,26/Feb/14 19:32;elserj;Thrift-0.9.0 is used by both 1.5 and 1.6. 1.4 is the only version still on Thrift 0.6.x,"12/Jun/14 23:18;jira-bot;Commit c5aac49ed299b7c6eee534333cf080b638bcdecd in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~al.krinker]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c5aac49 ]

ACCUMULO-2410 TServerUtils no longer needs to catch NPE as a thrift bug workaround

Signed-off-by: John Vines <vines@apache.org>
","12/Jun/14 23:20;jira-bot;Commit c5aac49ed299b7c6eee534333cf080b638bcdecd in accumulo's branch refs/heads/1.6.1-SNAPSHOT from [~al.krinker]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c5aac49 ]

ACCUMULO-2410 TServerUtils no longer needs to catch NPE as a thrift bug workaround

Signed-off-by: John Vines <vines@apache.org>
","12/Jun/14 23:20;jira-bot;Commit c5aac49ed299b7c6eee534333cf080b638bcdecd in accumulo's branch refs/heads/master from [~al.krinker]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c5aac49 ]

ACCUMULO-2410 TServerUtils no longer needs to catch NPE as a thrift bug workaround

Signed-off-by: John Vines <vines@apache.org>
","12/Jun/14 23:20;vines;Patch applied, thanks Al!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cli.Help should return non-zero status on error parsing args,ACCUMULO-1899,12679473,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,mhaskel,busbey,busbey,15/Nov/13 19:45,28/Apr/14 19:04,13/Mar/19 22:01,25/Nov/13 04:14,1.5.0,,,,,,,1.5.1,1.6.0,,,,,,,,0,newbie,,,,"Right now org.apache.accumulo.core.cli.Help.parseArgs() uses System.exit(0) on parse error.

If the user gives invalid flags and triggers this code path, we should exit with non-zero status to indicate a problem.

Previously (in 1.4.x), not properly setting non-zero status for command line parse errors caused some integration tests to fail silently for some time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,25/Nov/13 03:52;mhaskel;ACCUMULO-1899.patch;https://issues.apache.org/jira/secure/attachment/12615526/ACCUMULO-1899.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-11-25 03:51:45.133,,,no_permission,,,,,,,,,,,,358833,,,Mon Nov 25 05:20:31 UTC 2013,,,,,,0|i1puvz:,359123,,,,,,,,25/Nov/13 03:51;mhaskel;The attached patch against 1.5.1-SNAPSHOT will make it exit with status 1 if there's an issue parsing the arguments.,"25/Nov/13 04:13;jira-bot;Commit 100e75bece15ad2d223070912854430d078e587a in branch refs/heads/1.6.0-SNAPSHOT from [~mhaskel]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=100e75b ]

ACCUMULO-1899 exit with non-zero exit code if there's an error parsing the arguments.

Signed-off-by: Josh Elser <elserj@apache.org>
","25/Nov/13 04:14;elserj;Applied. Thanks for the patch, [~mhaskel]!","25/Nov/13 04:18;jira-bot;Commit 100e75bece15ad2d223070912854430d078e587a in branch refs/heads/master from [~mhaskel]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=100e75b ]

ACCUMULO-1899 exit with non-zero exit code if there's an error parsing the arguments.

Signed-off-by: Josh Elser <elserj@apache.org>
","25/Nov/13 05:20;jira-bot;Commit 100e75bece15ad2d223070912854430d078e587a in branch refs/heads/1.5.1-SNAPSHOT from [~mhaskel]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=100e75b ]

ACCUMULO-1899 exit with non-zero exit code if there's an error parsing the arguments.

Signed-off-by: Josh Elser <elserj@apache.org>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The update() method on the ProxyServer should throw a MutationsRejectedException,ACCUMULO-1190,12637966,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,sonixbp,sonixbp,sonixbp,20/Mar/13 12:24,25/Apr/14 18:56,13/Mar/19 22:01,03/Apr/13 20:59,,,,,,,,1.5.0,,,proxy,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23/Mar/13 09:40;sonixbp;ACCUMULO-1190.patch;https://issues.apache.org/jira/secure/attachment/12575181/ACCUMULO-1190.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-03-20 16:16:41.129,,,no_permission,,,,,,,,,,,,318444,,,Thu Apr 04 01:43:18 UTC 2013,,,,,,0|i1iy3j:,318785,,,,,,,,"20/Mar/13 16:16;ecn;Corey, did you want to take this on?  If so, assign it to yourself.","20/Mar/13 17:05;sonixbp;Eric, I would love to take this on. I don't think I have permissions to assign things to myself- are you able to grant that to me?","20/Mar/13 17:23;ecn;It won't let me assign it to you, either. Do you have a jira account?
",20/Mar/13 17:38;billie.rinaldi;You have to add new contributors to the contributors role in JIRA.  (I've just done this for Corey.)  It's under Administration -> Accumulo -> Roles -> Contributors.,"20/Mar/13 18:36;sonixbp;Thanks guys. I'll work on this tonight. Eric, do you want me to make sure all methods that take tableNames throw a TableNotFoundException or would you rather follow the core API directly?","20/Mar/13 18:45;kturner;bq.   Eric, do you want me to make sure all methods that take tableNames throw a TableNotFoundException or would you rather follow the core API directly?

The core API is broken in some places, like the security stuff, in that some methods that take a table do not throw TableNotFound.  Since its new, I vote for making the proxy API do the right thing and throw TableNotFoundException.  You may have to see if the cause of an exception is TableNotFound in the proxy implementation for these methods.","21/Mar/13 03:54;sonixbp;Wow, trying to force a MutationsRejectedException using the MockBatchWriter is really non-trivial with the current design of the Mocks. ",21/Mar/13 03:58;sonixbp;I vote we utilize the table permissions to throw necessary exceptions in the MockConnector.,"21/Mar/13 04:16;sonixbp;Nevermind, it looks like MiniAccumuloCluster may solve this issue.",23/Mar/13 09:40;sonixbp;Added MutationsRejectedException to proxy.thrift & regenerated thrift java classes. Changed tableOperations() tests in SimpleTest.java to catch MutationsRejectedException during updateAndFlush(). Added batchWriter() tests to SimpleTest.java. ,23/Mar/13 09:41;sonixbp;Patch attached & appropriate tests created.,"25/Mar/13 14:30;kturner;The patch removes oneway from update().  This may have performance consequences.   

An alternative would be to leave update() as oneway.  When an exception occurs, in the proxy remember the exception and start throwing away subsequent updates.  When the user finally calls close() or flush(), then throw the exception.  This strategy makes error conditions suboptimal, but normal conditions more optimal.","26/Mar/13 14:47;sonixbp;Sure. I can do that. It seems like it may be a little weird for the user of the proxy, however, if they only see the first or the last exception that was thrown. Merging the constraint violation for many different mutations may be a little funky too.","26/Mar/13 15:20;kturner;bq. I can do that. It seems like it may be a little weird for the user of the proxy, however, if they only see the first or the last exception that was thrown. Merging the constraint violation for many different mutations may be a little funky too.

I think the best strategy to deal with this is to call close() on the batchwriter and use that exception as the final exception.  

{code:java}

void proxyUpdate(sessionID, mutations){

  if(sessionFailed(sessionID))
     return; 

  try{
     bw = getBatchWriter(sessionID);
     bw.addMutations(mutations);
  }catch(MRE e){
     MRE sessionException = e;
     try{
        //close should throw MRE again and release resources... the MRE thrown by close should contain all error info
        bw.close();
     }catch(MRE e2){
        sessionException = e2;
     }
 
     markSessionFailed(sessionID, sessionException);
  }
}
{code}","02/Apr/13 18:42;sonixbp;If I put in a bunch of mutations and one of them fails a constraint violation, I'll be closing the batch writer, even though it was just that one mutation that failed. ","03/Apr/13 04:09;sonixbp;Keith, I think I like your first idea better- maybe it's okay to just throw the first or last exception upon closing rather than force a close when there may still be more acceptable data to be written.","03/Apr/13 19:11;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #60 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/60/])
    ACCUMULO-1190 applying Corey's patch (Revision 1463980)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/MutationsRejectedException.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","03/Apr/13 19:12;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #172 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/172/])
    ACCUMULO-1190 applying Corey's patch (Revision 1463983)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/MutationsRejectedException.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","03/Apr/13 19:16;hudson;Integrated in Accumulo-Trunk #813 (See [https://builds.apache.org/job/Accumulo-Trunk/813/])
    ACCUMULO-1190 applying Corey's patch (Revision 1463983)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/MutationsRejectedException.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","03/Apr/13 19:18;hudson;Integrated in Accumulo-1.5 #62 (See [https://builds.apache.org/job/Accumulo-1.5/62/])
    ACCUMULO-1190 applying Corey's patch (Revision 1463980)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/MutationsRejectedException.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","03/Apr/13 19:37;kturner;bq. Keith, I think I like your first idea better- maybe it's okay to just throw the first or last exception upon closing rather than force a close when there may still be more acceptable data to be written.

The behavior of the  batch writer is that it stops working after a problem occurs.  So once it throws a MRE, it will continue to throw them.","03/Apr/13 19:55;sonixbp;Hey Keith, I see that now when I look @ the TabletServerBatchWriter. I had cancelled this patch because I was going to prepare another one with the strategy you had proposed. The 'oneway' was still removed from the patch that was just applied. If it's okay, I'll throw up another ticket to put the oneway back in and cache the exception until either close(), flush() or updateAndFlush() are called.","03/Apr/13 19:59;ecn;Hey Corey, I'm almost done with the change.  I would appreciate if you could review the check-in, though.",03/Apr/13 20:59;sonixbp;I see it should be throwing the MutationsRejectedException upon close() and flush() anyways because it's checking for failures in each of those methods. Looks good! Thanks Eric!,"03/Apr/13 22:34;ecn;Thanks Corey, you have made the Proxy a lot better!","04/Apr/13 01:18;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #61 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/61/])
    ACCUMULO-1190 make update a oneway call again (Revision 1464189)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","04/Apr/13 01:26;hudson;Integrated in Accumulo-1.5 #63 (See [https://builds.apache.org/job/Accumulo-1.5/63/])
    ACCUMULO-1190 make update a oneway call again (Revision 1464189)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","04/Apr/13 01:35;hudson;Integrated in Accumulo-Trunk #814 (See [https://builds.apache.org/job/Accumulo-Trunk/814/])
    ACCUMULO-1190 make update a oneway call again (Revision 1464192)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/resources/log4j.properties
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/TestAccumulo1235.java
","04/Apr/13 01:43;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #173 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/173/])
    ACCUMULO-1190 make update a oneway call again (Revision 1464192)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/resources/log4j.properties
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/TestAccumulo1235.java
",,,,,,,,,,,,,,,,,,,,,,,,,
Problem using accumulo artifacts from ivy,ACCUMULO-1876,12678495,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,mjwall,mjwall,mjwall,11/Nov/13 01:33,22/Apr/14 19:13,13/Mar/19 22:01,12/Nov/13 22:42,1.5.0,,,,,,,1.4.5,1.5.1,1.6.0,master,,,,,,0,,,,,"Defining an accumulo dependency in an ivy.xml file for any Accyumulo version greater than 1.4.4 results in the following error 

{noformat}
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 		::          UNRESOLVED DEPENDENCIES         ::
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 		:: org.slf4j#slf4j-api;${slf4j.version}: not found
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 

{noformat}

The issue appears to be that in the parent pom.xml, slf4j.version is only defined in profiles.  Ivy doesn't load profiles when pulling from a maven repo, so the ${slf4j.version} is never set.

One possible fix is to define a property earlier with the version, and allow the profiles to overwrite.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,12/Nov/13 02:38;mjwall;1876-1.5.1-SNAPSHOT.patch;https://issues.apache.org/jira/secure/attachment/12613300/1876-1.5.1-SNAPSHOT.patch,12/Nov/13 02:38;mjwall;1876-1.6.0-SNAPSHOT.patch;https://issues.apache.org/jira/secure/attachment/12613301/1876-1.6.0-SNAPSHOT.patch,11/Nov/13 13:32;mjwall;1876.patch;https://issues.apache.org/jira/secure/attachment/12613151/1876.patch,11/Nov/13 01:37;mjwall;accumulo-slf4j-bug.tar.gz;https://issues.apache.org/jira/secure/attachment/12613080/accumulo-slf4j-bug.tar.gz,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,2013-11-11 21:15:48.365,,,no_permission,,,,,,,,,,,,357862,,,Tue Nov 26 15:49:53 UTC 2013,,,,,,0|i1powf:,358152,,,,,,,,"11/Nov/13 01:37;mjwall;Demo ant/ivy project that demonstrates the problem.  This is also an issue with Scala's sbt, as it uses ivy.  Not sure if other build tools like gradle or lein will have the same issue.",11/Nov/13 13:32;mjwall;Patch attached for my proposed solution if that is the way you decide to go.  Thanks,"11/Nov/13 13:32;mjwall;Oh, that patch is for the 1.5.1-SNAPSHOT branch","11/Nov/13 21:15;elserj;Looks good to me. The only issue I see is changing the value for that property to account for hadoop-2 being the default in >=1.6.0-SNAPSHOT.

[~mjwall] -- a few things if you want to update this. 1) Fix the patch to use git-format-patch instead of git-diff (http://accumulo.apache.org/git.html) 2) Provide the update to 1.6.0-SNAPSHOT to account for the aforementioned default hadoop switch.","12/Nov/13 02:38;mjwall;[~elserj] patches attached, thanks man.  Let me know if I did it wrong.","12/Nov/13 04:30;elserj;Looks good to me! Thanks for the patches, [~mjwall]!","12/Nov/13 05:01;elserj;Actually, I take it back. I applied your patch locally, installed 1.5.1-SNAPSHOT and then tried out the above ant+ivy project with no success.

Am I missing something?

{noformat}
Buildfile: /Users/jelser/accumulo-slf4j-bug/build.xml

init:
    [mkdir] Created dir: /Users/jelser/accumulo-slf4j-bug/ivy-lib
      [get] Getting: http://repo1.maven.org/maven2/org/apache/ivy/ivy/2.3.0-rc1/ivy-2.3.0-rc1.jar
      [get] To: /Users/jelser/accumulo-slf4j-bug/ivy-lib/ivy-2.3.0-rc1.jar
[ivy:resolve] :: Apache Ivy 2.3.0-rc1 - 20120416000235 :: http://ant.apache.org/ivy/ ::
[ivy:resolve] :: loading settings :: file = /Users/jelser/accumulo-slf4j-bug/ivysettings.xml
[ivy:resolve] :: resolving dependencies :: com.mjwall#accumulo-slfj4-bug;working@hw10447
[ivy:resolve] 	confs: [compile]
[ivy:resolve] 	found org.apache.accumulo#accumulo-minicluster;1.5.1-SNAPSHOT in local-maven-2
[ivy:resolve] 	found com.beust#jcommander;1.30 in local-maven-2
[ivy:resolve] 	found org.apache.accumulo#accumulo-core;1.5.1-SNAPSHOT in local-maven-2
[ivy:resolve] 	found com.google.guava#guava;14.0.1 in local-maven-2
[ivy:resolve] 	found jline#jline;1.0 in local-maven-2
[ivy:resolve] 	found org.apache.accumulo#accumulo-fate;1.5.1-SNAPSHOT in local-maven-2
[ivy:resolve] 	found org.apache.accumulo#accumulo-start;1.5.1-SNAPSHOT in local-maven-2
[ivy:resolve] 	found org.apache.commons#commons-vfs2;2.0 in local-maven-2
[ivy:resolve] 	found commons-logging#commons-logging;1.1.1 in default
[ivy:resolve] 	found org.apache.maven.scm#maven-scm-api;1.4 in local-maven-2
[ivy:resolve] 	found org.codehaus.plexus#plexus-utils;1.5.6 in local-maven-2
[ivy:resolve] 	found org.apache.maven.scm#maven-scm-provider-svnexe;1.4 in local-maven-2
[ivy:resolve] 	found org.apache.maven.scm#maven-scm-provider-svn-commons;1.4 in local-maven-2
[ivy:resolve] 	found regexp#regexp;1.3 in local-maven-2
[ivy:resolve] 	found org.apache.accumulo#accumulo-trace;1.5.1-SNAPSHOT in local-maven-2
[ivy:resolve] 	found org.apache.thrift#libthrift;0.9.0 in local-maven-2
[ivy:resolve] 	found commons-lang#commons-lang;2.4 in default
[ivy:resolve] 	found org.apache.httpcomponents#httpclient;4.1.3 in local-maven-2
[ivy:resolve] 	found commons-codec#commons-codec;1.4 in default
[ivy:resolve] 	found org.apache.httpcomponents#httpcore;4.1.3 in local-maven-2
[ivy:resolve] 	found org.apache.accumulo#accumulo-server;1.5.1-SNAPSHOT in local-maven-2
[ivy:resolve] 	found com.google.code.gson#gson;2.2.2 in local-maven-2
[ivy:resolve] :: resolution report :: resolve 827ms :: artifacts dl 15ms
[ivy:resolve] 	:: evicted modules:
[ivy:resolve] 	org.apache.httpcomponents#httpcore;4.1.4 by [org.apache.httpcomponents#httpcore;4.1.3] in [compile]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      compile     |   24  |   3   |   0   |   1   ||   21  |   0   |
	---------------------------------------------------------------------
[ivy:resolve]
[ivy:resolve] :: problems summary ::
[ivy:resolve] :::: WARNINGS
[ivy:resolve] 		module not found: org.slf4j#slf4j-api;${slf4j.version}
[ivy:resolve] 	==== local-maven-2: tried
[ivy:resolve] 	  /Users/jelser/.m2/repository/org/slf4j/slf4j-api/${slf4j.version}/slf4j-api-${slf4j.version}.pom
[ivy:resolve] 	  -- artifact org.slf4j#slf4j-api;${slf4j.version}!slf4j-api.jar:
[ivy:resolve] 	  /Users/jelser/.m2/repository/org/slf4j/slf4j-api/${slf4j.version}/slf4j-api-${slf4j.version}.jar
[ivy:resolve] 	==== maven2: tried
[ivy:resolve] 	  http://repo1.maven.org/maven2/org/slf4j/slf4j-api/${slf4j.version}/slf4j-api-${slf4j.version}.pom
[ivy:resolve] 	  -- artifact org.slf4j#slf4j-api;${slf4j.version}!slf4j-api.jar:
[ivy:resolve] 	  http://repo1.maven.org/maven2/org/slf4j/slf4j-api/${slf4j.version}/slf4j-api-${slf4j.version}.jar
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 		::          UNRESOLVED DEPENDENCIES         ::
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 		:: org.slf4j#slf4j-api;${slf4j.version}: not found
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve]
[ivy:resolve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS

BUILD FAILED
/Users/jelser/accumulo-slf4j-bug/build.xml:23: impossible to resolve dependencies:
	resolve failed - see output for details

Total time: 3 seconds
{noformat}","12/Nov/13 11:56;mjwall;It looks like an old copy in your ivy cache. Either comment out the
dependency in ivy.XML and run ant clean-all to clear the cache. Or simply
rm -rf ~/.ivy2. Let me know if that doesn't work. Thanks Josh

","12/Nov/13 14:03;mjwall;Cool, replying to the email added the comment. Forgot to link you in [~elserj].  Thanks","12/Nov/13 21:25;elserj;Blarggg, throw the ""learn ivy"" book at the maven kid :). That fixed it. (obligatory -- why is ivy re-caching the files that maven is caching, though :D)

I'll pull these in.

","12/Nov/13 21:28;elserj;Oh, I also wanted to mention: if we had this problem with no default version for slf4j-api, I would imagine that we also want to do the same for hadoop.version and httpclient.version, no? I didn't dig through the dependencies to figure out why this didn't directly bite you already.","12/Nov/13 21:55;jira-bot;Commit c93872afd3e191ea81e353e609749128d3b5c417 in branch refs/heads/1.5.1-SNAPSHOT from [~mjwall]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c93872a ]

ACCUMULO-1876 default for slf4j.version

Sets default to 1.4.3 as hadoop-1.0 is default in parent pom for 1.5.1-SNAPSHOT

Signed-off-by: Josh Elser <elserj@apache.org>
","12/Nov/13 22:22;jira-bot;Commit 20cbf248e27069c0c05a595342de73e9ecc43743 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=20cbf24 ]

ACCUMULO-1876 Add default values for hadoop.version and httpclient.version to make ivy work.
","12/Nov/13 22:39;jira-bot;Commit 850bd3e7300425ae78f51d41f67912604f2bb914 in branch refs/heads/1.6.0-SNAPSHOT from [~mjwall]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=850bd3e ]

ACCUMULO-1876 default for slf4j.version

Sets default to 1.7.5 as hadoop-2.2 is default in parent pom for 1.6.0-SNAPSHOT

Signed-off-by: Josh Elser <elserj@apache.org>
","12/Nov/13 22:40;jira-bot;Commit 20cbf248e27069c0c05a595342de73e9ecc43743 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=20cbf24 ]

ACCUMULO-1876 Add default values for hadoop.version and httpclient.version to make ivy work.
","12/Nov/13 22:40;jira-bot;Commit ed11bd3d0125ebb3ea3f4e872ab0d0a52b5d8c5f in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ed11bd3 ]

ACCUMULO-1876 Update the default versions from hadoop1 to hadoop2 values.
","12/Nov/13 22:41;jira-bot;Commit 850bd3e7300425ae78f51d41f67912604f2bb914 in branch refs/heads/master from [~mjwall]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=850bd3e ]

ACCUMULO-1876 default for slf4j.version

Sets default to 1.7.5 as hadoop-2.2 is default in parent pom for 1.6.0-SNAPSHOT

Signed-off-by: Josh Elser <elserj@apache.org>
","12/Nov/13 22:42;jira-bot;Commit 20cbf248e27069c0c05a595342de73e9ecc43743 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=20cbf24 ]

ACCUMULO-1876 Add default values for hadoop.version and httpclient.version to make ivy work.
","12/Nov/13 22:42;jira-bot;Commit ed11bd3d0125ebb3ea3f4e872ab0d0a52b5d8c5f in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ed11bd3 ]

ACCUMULO-1876 Update the default versions from hadoop1 to hadoop2 values.
","13/Nov/13 00:37;mjwall;[~elserj] hmm, not sure why hadoop.version http.client version weren't causing issues.  I see you fixed them as well.  Thanks man.

Oh, and ivy was not caching the files maven already cached.  I had ivy reading from the local maven repo so we ""mvn install"" a fix and test it.  Normally, you wouldn't need that and could just pretend that maven didn't exist :)  ","13/Nov/13 00:46;elserj;bq. Oh, and ivy was not caching the files maven already cached. I had ivy reading from the local maven repo so we ""mvn install"" a fix and test it. Normally, you wouldn't need that and could just pretend that maven didn't exist 

That makes *much* more sense. I couldn't fathom why Ivy would be caching things that Maven was already caching :D","26/Nov/13 15:18;jira-bot;Commit c093974647a93f70320c5d62eeff00e27fa3149d in branch refs/heads/1.4.5-SNAPSHOT from [~mjwall]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c093974 ]

ACCUMULO-1876 default for slf4j.version

Sets default to 1.4.3 as hadoop-1.0 is default in parent pom for 1.5.1-SNAPSHOT
(cherry picked from commit c93872afd3e191ea81e353e609749128d3b5c417)

Reason: bugfix
Author: Michael Wall <mjwall@gmail.com>
Ref: ACCUMULO-1792

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","26/Nov/13 15:18;jira-bot;Commit 6446ad5c20fec4b4506a01ac259c26d08974faf4 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6446ad5 ]

ACCUMULO-1876 Add default values for hadoop.version and httpclient.version to make ivy work.

(cherry picked from commit 20cbf248e27069c0c05a595342de73e9ecc43743)

Differs from original by changing Hadoop version to match current pom and leaving out dependencies not yet declared in profiles.

Reason: bugfix
Author: Josh Elser <elserj@apache.org>
Ref: ACCUMULO-1792

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","26/Nov/13 15:47;jira-bot;Commit c093974647a93f70320c5d62eeff00e27fa3149d in branch refs/heads/1.5.1-SNAPSHOT from [~mjwall]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c093974 ]

ACCUMULO-1876 default for slf4j.version

Sets default to 1.4.3 as hadoop-1.0 is default in parent pom for 1.5.1-SNAPSHOT
(cherry picked from commit c93872afd3e191ea81e353e609749128d3b5c417)

Reason: bugfix
Author: Michael Wall <mjwall@gmail.com>
Ref: ACCUMULO-1792

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","26/Nov/13 15:47;jira-bot;Commit 6446ad5c20fec4b4506a01ac259c26d08974faf4 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6446ad5 ]

ACCUMULO-1876 Add default values for hadoop.version and httpclient.version to make ivy work.

(cherry picked from commit 20cbf248e27069c0c05a595342de73e9ecc43743)

Differs from original by changing Hadoop version to match current pom and leaving out dependencies not yet declared in profiles.

Reason: bugfix
Author: Josh Elser <elserj@apache.org>
Ref: ACCUMULO-1792

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","26/Nov/13 15:47;jira-bot;Commit c093974647a93f70320c5d62eeff00e27fa3149d in branch refs/heads/1.6.0-SNAPSHOT from [~mjwall]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c093974 ]

ACCUMULO-1876 default for slf4j.version

Sets default to 1.4.3 as hadoop-1.0 is default in parent pom for 1.5.1-SNAPSHOT
(cherry picked from commit c93872afd3e191ea81e353e609749128d3b5c417)

Reason: bugfix
Author: Michael Wall <mjwall@gmail.com>
Ref: ACCUMULO-1792

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","26/Nov/13 15:47;jira-bot;Commit 6446ad5c20fec4b4506a01ac259c26d08974faf4 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6446ad5 ]

ACCUMULO-1876 Add default values for hadoop.version and httpclient.version to make ivy work.

(cherry picked from commit 20cbf248e27069c0c05a595342de73e9ecc43743)

Differs from original by changing Hadoop version to match current pom and leaving out dependencies not yet declared in profiles.

Reason: bugfix
Author: Josh Elser <elserj@apache.org>
Ref: ACCUMULO-1792

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","26/Nov/13 15:49;jira-bot;Commit c093974647a93f70320c5d62eeff00e27fa3149d in branch refs/heads/master from [~mjwall]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c093974 ]

ACCUMULO-1876 default for slf4j.version

Sets default to 1.4.3 as hadoop-1.0 is default in parent pom for 1.5.1-SNAPSHOT
(cherry picked from commit c93872afd3e191ea81e353e609749128d3b5c417)

Reason: bugfix
Author: Michael Wall <mjwall@gmail.com>
Ref: ACCUMULO-1792

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","26/Nov/13 15:49;jira-bot;Commit 6446ad5c20fec4b4506a01ac259c26d08974faf4 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6446ad5 ]

ACCUMULO-1876 Add default values for hadoop.version and httpclient.version to make ivy work.

(cherry picked from commit 20cbf248e27069c0c05a595342de73e9ecc43743)

Differs from original by changing Hadoop version to match current pom and leaving out dependencies not yet declared in profiles.

Reason: bugfix
Author: Josh Elser <elserj@apache.org>
Ref: ACCUMULO-1792

Signed-off-by: Eric Newton <eric.newton@gmail.com>
",,,,,,,,,,,,,,,,,,,,,,,,,
ShellServerTest still fails occasionally,ACCUMULO-2433,12698938,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,05/Mar/14 18:42,04/Apr/14 23:14,13/Mar/19 22:01,04/Apr/14 23:14,1.5.1,,,,,,,1.5.2,,,,,,,,,0,,,,,"From a Jenkins run:

{{addauths}}

{noformat}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.accumulo.test.ShellServerTest.assertBadExit(ShellServerTest.java:138)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:124)
	at org.apache.accumulo.test.ShellServerTest.addauths(ShellServerTest.java:411)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}

{{deleterows}} too

{noformat}
Error Message

expected:<3> but was:<4>

Stacktrace

java.lang.AssertionError: expected:<3> but was:<4>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.deleterows(ShellServerTest.java:566)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}

And {{listscans}}, although I'm guessing this one is just subject to timing (uses the ""slow iterator"" to catch a scan in progress)

{noformat}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.accumulo.test.ShellServerTest.listscans(ShellServerTest.java:794)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-05 18:47:56.582,,,no_permission,,,,,,,,,,,,377285,,,Fri Apr 04 22:45:35 UTC 2014,,,,,,0|i1t0gn:,377580,,,,,,,,"05/Mar/14 18:47;mdrob;Did we fix the issue where if a single test fails then all tests in ShellServerTest will fail too? Because the second and third failures might be what you're seeing, if these are all from a single run.","05/Mar/14 18:52;elserj;bq. Did we fix the issue where if a single test fails then all tests in ShellServerTest will fail too?

Yes, I believe I resolved that. Failures in SST should now be isolated to a single test failure and not cascade (that was ACCUMULO-1908).

I had also tried to make the test cases a little more resilient in the previous ticket; however, I apparently haven't done so. All of the tests listed in the description were the *only* test that failed in the ShellServerTest class.","10/Mar/14 22:16;jira-bot;Commit 4cc25caa07ea5ca49e4d81f9e5a22908e45bba59 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cc25ca ]

ACCUMULO-2433 Add a way to still use the exec methods but provide a custom error message on failure.

Fix some tests that I've seen fail to provide better messages on failure to help future debugging
because I can't get them reproduced locally in any reasonable timeframe.
","10/Mar/14 22:16;jira-bot;Commit 4cc25caa07ea5ca49e4d81f9e5a22908e45bba59 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cc25ca ]

ACCUMULO-2433 Add a way to still use the exec methods but provide a custom error message on failure.

Fix some tests that I've seen fail to provide better messages on failure to help future debugging
because I can't get them reproduced locally in any reasonable timeframe.
","10/Mar/14 22:16;jira-bot;Commit 4cc25caa07ea5ca49e4d81f9e5a22908e45bba59 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cc25ca ]

ACCUMULO-2433 Add a way to still use the exec methods but provide a custom error message on failure.

Fix some tests that I've seen fail to provide better messages on failure to help future debugging
because I can't get them reproduced locally in any reasonable timeframe.
","10/Mar/14 22:22;elserj;I haven't been able to recreate these with much ease locally, so I made some changes which should help to debug it when I see it on my test server again.","11/Mar/14 18:57;jira-bot;Commit 43cebf8c0389ce178fc02c7a541671d335e8e45e in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=43cebf8 ]

ACCUMULO-2433 It would help to actually pass the error message to the assertion
","11/Mar/14 18:58;jira-bot;Commit 43cebf8c0389ce178fc02c7a541671d335e8e45e in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=43cebf8 ]

ACCUMULO-2433 It would help to actually pass the error message to the assertion
","11/Mar/14 18:58;jira-bot;Commit 43cebf8c0389ce178fc02c7a541671d335e8e45e in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=43cebf8 ]

ACCUMULO-2433 It would help to actually pass the error message to the assertion
","26/Mar/14 17:13;jira-bot;Commit d77cba39fc032b327c448931e3841e4aa34c90f2 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d77cba3 ]

Merge branch '1.4.5-SNAPSHOT' into 1.5.2-SNAPSHOT

Conflicts:
	fate/src/main/java/org/apache/accumulo/fate/util/AddressUtil.java
	test/src/main/java/org/apache/accumulo/test/functional/RunTests.java

Include warning from ACCUMULO-2433
","26/Mar/14 17:13;jira-bot;Commit d77cba39fc032b327c448931e3841e4aa34c90f2 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d77cba3 ]

Merge branch '1.4.5-SNAPSHOT' into 1.5.2-SNAPSHOT

Conflicts:
	fate/src/main/java/org/apache/accumulo/fate/util/AddressUtil.java
	test/src/main/java/org/apache/accumulo/test/functional/RunTests.java

Include warning from ACCUMULO-2433
","26/Mar/14 17:13;jira-bot;Commit d77cba39fc032b327c448931e3841e4aa34c90f2 in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d77cba3 ]

Merge branch '1.4.5-SNAPSHOT' into 1.5.2-SNAPSHOT

Conflicts:
	fate/src/main/java/org/apache/accumulo/fate/util/AddressUtil.java
	test/src/main/java/org/apache/accumulo/test/functional/RunTests.java

Include warning from ACCUMULO-2433
","27/Mar/14 19:39;elserj;Updated stacktrace for listscans

{noformat}
java.lang.AssertionError: Could not find any active scans over table listscans
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertFalse(Assert.java:64)
	at org.apache.accumulo.test.ShellServerTest.listscans(ShellServerTest.java:852)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}","27/Mar/14 20:27;jira-bot;Commit c1964b27fb7d9fed9b5f68f66ca7532f7964cdd6 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c1964b2 ]

ACCUMULO-2433 Try to stabilize listscans on ShellServerTest

Remove the ZKI and Connector timing from the 5s that we used to look
for the slow scan that was running. Increase the amount of time inbetween
calls to listscans.
","27/Mar/14 20:27;jira-bot;Commit c1964b27fb7d9fed9b5f68f66ca7532f7964cdd6 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c1964b2 ]

ACCUMULO-2433 Try to stabilize listscans on ShellServerTest

Remove the ZKI and Connector timing from the 5s that we used to look
for the slow scan that was running. Increase the amount of time inbetween
calls to listscans.
","27/Mar/14 20:27;jira-bot;Commit c1964b27fb7d9fed9b5f68f66ca7532f7964cdd6 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c1964b2 ]

ACCUMULO-2433 Try to stabilize listscans on ShellServerTest

Remove the ZKI and Connector timing from the 5s that we used to look
for the slow scan that was running. Increase the amount of time inbetween
calls to listscans.
","27/Mar/14 23:44;jira-bot;Commit 729e11adfe862d328d82b1df34fdd18493672c32 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=729e11a ]

ACCUMULO-2433 Can't reliably assume we won't get stale data with >1 tserver in test.

Add some retries to make sure we don't get stale data from ZooCache if we happen to talk
to the other MAC tserver.
","27/Mar/14 23:44;jira-bot;Commit dfbce9bcc361364c5a512406a1e4d9e2fd55ac56 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=dfbce9b ]

ACCUMULO-2433 More test retries if at first we don't succeed.
","27/Mar/14 23:44;jira-bot;Commit 729e11adfe862d328d82b1df34fdd18493672c32 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=729e11a ]

ACCUMULO-2433 Can't reliably assume we won't get stale data with >1 tserver in test.

Add some retries to make sure we don't get stale data from ZooCache if we happen to talk
to the other MAC tserver.
","27/Mar/14 23:44;jira-bot;Commit dfbce9bcc361364c5a512406a1e4d9e2fd55ac56 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=dfbce9b ]

ACCUMULO-2433 More test retries if at first we don't succeed.
","27/Mar/14 23:44;jira-bot;Commit 729e11adfe862d328d82b1df34fdd18493672c32 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=729e11a ]

ACCUMULO-2433 Can't reliably assume we won't get stale data with >1 tserver in test.

Add some retries to make sure we don't get stale data from ZooCache if we happen to talk
to the other MAC tserver.
","27/Mar/14 23:44;jira-bot;Commit dfbce9bcc361364c5a512406a1e4d9e2fd55ac56 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=dfbce9b ]

ACCUMULO-2433 More test retries if at first we don't succeed.
",27/Mar/14 23:45;elserj;Fixed cases where I could guess at a possible failure. Made tests a little more resilient to failure elsewhere.,04/Apr/14 18:54;elserj;Jenkins failure made me see that I screwed up some loop variable usage.,"04/Apr/14 18:58;elserj;Go figure, just got another jenkins failure:

{noformat}
Error Message

Current auths for root are: 

Stacktrace

java.lang.AssertionError: Current auths for root are: 
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.accumulo.test.ShellServerTest.assertBadExit(ShellServerTest.java:172)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:153)
	at org.apache.accumulo.test.ShellServerTest.addauths(ShellServerTest.java:448)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}","04/Apr/14 20:33;jira-bot;Commit 174c678236b6bc9ab17487e0d3ca150766887f7b in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=174c678 ]

ACCUMULO-2433 Use IteratorSetting instead of config to avoid ZK issues. Fix loop variable usage.
","04/Apr/14 20:33;jira-bot;Commit 2df0eb89e3802330eff5368aebc712cf3cbc882c in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2df0eb8 ]

ACCUMULO-2433 Ensure that we wait for teh constraint update to propagate to the tserver

This test has the potential to fail because of how `createtable -evc` is implemented.
It sets a zk property which the tserver hosting the tablet for the given table must
notice that the property changed so that it enforces the constraint.
","04/Apr/14 20:33;jira-bot;Commit 174c678236b6bc9ab17487e0d3ca150766887f7b in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=174c678 ]

ACCUMULO-2433 Use IteratorSetting instead of config to avoid ZK issues. Fix loop variable usage.
","04/Apr/14 20:33;jira-bot;Commit 2df0eb89e3802330eff5368aebc712cf3cbc882c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2df0eb8 ]

ACCUMULO-2433 Ensure that we wait for teh constraint update to propagate to the tserver

This test has the potential to fail because of how `createtable -evc` is implemented.
It sets a zk property which the tserver hosting the tablet for the given table must
notice that the property changed so that it enforces the constraint.
","04/Apr/14 20:33;jira-bot;Commit 174c678236b6bc9ab17487e0d3ca150766887f7b in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=174c678 ]

ACCUMULO-2433 Use IteratorSetting instead of config to avoid ZK issues. Fix loop variable usage.
","04/Apr/14 20:33;jira-bot;Commit 2df0eb89e3802330eff5368aebc712cf3cbc882c in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2df0eb8 ]

ACCUMULO-2433 Ensure that we wait for teh constraint update to propagate to the tserver

This test has the potential to fail because of how `createtable -evc` is implemented.
It sets a zk property which the tserver hosting the tablet for the given table must
notice that the property changed so that it enforces the constraint.
","04/Apr/14 22:45;elserj;Filed ACCUMULO-2453 after realizing how the {{addauths}} tests was failing. I (hopefully) made the test robust enough to work around the race condition, but fixing ACCUMULO-2453 will be a better long-term solution.",,,,,,,,,,,,,,,,,,,,,,
conflicting commons-logging imports in root pom,ACCUMULO-1724,12669436,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ctubbsii,stevel@apache.org,stevel@apache.org,19/Sep/13 11:40,04/Apr/14 19:45,13/Mar/19 22:01,09/Oct/13 23:47,,,,,,,,1.6.0,,,build,,,,,,0,,,,,"the root POM pulls in commons-logging and an older version of commons-logging-api
{code}
      <dependency>
        <groupId>commons-logging</groupId>
        <artifactId>commons-logging</artifactId>
        <version>1.1.1</version>
      </dependency>
      <dependency>
        <groupId>commons-logging</groupId>
        <artifactId>commons-logging-api</artifactId>
        <version>1.0.4</version>
      </dependency>
{code}
You should drop the the -api JAR as it is an out of date proper subset of the full JAR: [http://commons.apache.org/proper/commons-logging/guide.html#commons-logging-api.jar]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-09 23:45:05.133,,,no_permission,,,,,,,,,,,,349368,,,Wed Oct 09 23:46:47 UTC 2013,,,,,,0|i1o8on:,349666,,,,,,,,"09/Oct/13 23:45;ctubbsii;I don't think it is actually true that this is pulled in or that it is in conflict. This is declared in the {{<dependencyManagement />}} section, not a {{<dependencies />}} section, and it doesn't have any effect on anything, because it is never declared as a dependency in any module or actual dependency.

However, since it is a vestigial managed dependency, I will excise it promptly.","09/Oct/13 23:46;jira-bot;Commit 4bc0a85f990872e966dfd656b65c085d8bae7878 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4bc0a85 ]

ACCUMULO-1724 Excise vestigial managed commons-logging-api
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Spurious ShellServerTest failures,ACCUMULO-1908,12679855,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,19/Nov/13 01:29,03/Apr/14 14:56,13/Mar/19 22:01,20/Feb/14 01:04,1.5.0,,,,,,,1.5.1,1.6.0,,test,,,,,,0,,,,,"{noformat}
Tests run: 33, Failures: 21, Errors: 0, Skipped: 0, Time elapsed: 46.949 sec <<< FAILURE!
constraint(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.691 sec  <<< FAILURE!
java.lang.AssertionError: VisibilityConstraint=1 present in root@miniInstance c> constraint -l -t c
org.apache.accumulo.core.security.VisibilityConstraint=1
 was not false expected:<false> but was:<true>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:122)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.constraint(ShellServerTest.java:460)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

du(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 1.102 sec  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.accumulo.test.ShellServerTest.du(ShellServerTest.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

grep(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.002 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.grep(ShellServerTest.java:516)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

help(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.02 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.help(ShellServerTest.java:525)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

info(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.001 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.info(ShellServerTest.java:581)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

iter(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.064 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.iter(ShellServerTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

ping(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.066 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.ping(ShellServerTest.java:646)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

user(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.137 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.user(ShellServerTest.java:275)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

debug(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.005 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.debug(ShellServerTest.java:262)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

egrep(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.092 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.egrep(ShellServerTest.java:241)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

merge(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.428 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<4>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.merge(ShellServerTest.java:632)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

sleep(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.202 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<4>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.sleep(ShellServerTest.java:364)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

trace(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.007 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<4>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.trace(ShellServerTest.java:754)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

testPertableClasspath(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.043 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<4>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.testPertableClasspath(ShellServerTest.java:720)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

setscaniterDeletescaniter(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.1 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<5>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.setscaniterDeletescaniter(ShellServerTest.java:217)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

clearCls(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.002 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<5>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:105)
	at org.apache.accumulo.test.ShellServerTest.clearCls(ShellServerTest.java:404)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

deletemany(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.825 sec  <<< FAILURE!
java.lang.AssertionError: expected:<10> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.deletemany(ShellServerTest.java:469)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

deleterows(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 2.338 sec  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.accumulo.test.ShellServerTest.deleterows(ShellServerTest.java:499)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

execfile(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.022 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<8>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.execfile(ShellServerTest.java:232)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

clonetable(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.433 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<8>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.clonetable(ShellServerTest.java:412)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

notable(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.459 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<8>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.notable(ShellServerTest.java:351)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}

All of them appear to have the same STDOUT, but differing non-zero exit codes.

{noformat}
Standard Output

2013-11-18 19:05:35,940 [vfs.AccumuloVFSClassLoader] WARN : ignoring classpath entry file:///lib/ext/[^.].*.jar
Exception in thread ""Thread-79"" java.lang.NoClassDefFoundError: org/apache/commons/httpclient/HttpMethod
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:437)
Caused by: java.lang.ClassNotFoundException: org.apache.commons.httpclient.HttpMethod
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	... 1 more
With failures, global counters are inaccurate; consider running with -i
Copy failed: java.io.IOException: Job failed!
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1357)
	at org.apache.hadoop.tools.DistCp.copy(DistCp.java:667)
	at org.apache.hadoop.tools.DistCp.run(DistCp.java:881)
	at org.apache.accumulo.test.ShellServerTest.exporttableImporttable(ShellServerTest.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

2013-11-18 19:05:47,327 [client.ZooKeeperInstance] WARN : ZooKeeperInstance being cleaned up without being closed. Please remember to call close() before dereferencing to clean up threads.
{noformat}",openjdk 1.7.0_40,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-19 03:00:54.649,,,no_permission,,,,,,,,,,,,359213,,,Fri Feb 07 16:22:34 UTC 2014,,,,,,0|i1pxbj:,359512,,,,,,,,"19/Nov/13 03:00;ecn;Only the first of these is a failure. This test pukes all over the place when the first test fails.

Since it is a constraint, it is most certainly a zookeeper propagation delay.
","19/Nov/13 03:08;elserj;bq. Only the first of these is a failure. This test pukes all over the place when the first test fails.

Some of the other test cases in this class failed because that constraint error occurred? There were most definitely 21 test case failures.","19/Nov/13 04:19;ecn;So the first test fails. It sets a value in the shell to one (meaning ""bad"").

The second test runs to completion and we check the code.  It is 1 and that's bad.   It gets set to 2.  Something like that.

These tests are not stateless... the same shell instance is abused multiple times.

","19/Nov/13 04:52;elserj;I added two sleeps to the constraint test case and still got 20 failures. It appears to be the same assertion errors they threw previously.

Haha, ok. Found another that didn't fail on assertGoodExit. Instead, failed on the line

{noformat}
assertTrue(o.matches("".*26[0-9]B\\s\\[t\\]\\n"")); // for some reason, there's 1-2 bytes of fluctuation
{noformat}

Inspires confidence :)","20/Nov/13 02:07;jira-bot;Commit 316a84b54cf68cc8051d1971b3123e52c20338ef in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=316a84b ]

ACCUMULO-1908 Add in small sleeps to let ZK information propogate.
","20/Nov/13 04:33;jira-bot;Commit 2ad8a4f3eb2a3e3c8d00ebfba6a1218ed6ff824c in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2ad8a4f ]

ACCUMULO-1908 Make an odd du assertion a little more odd.
","20/Nov/13 04:33;jira-bot;Commit 054a89e4b03532262877d6e0f7c07ddd332a7406 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=054a89e ]

ACCUMULO-1908 Manually set filter on table and force deletetable.

It appears that testPertableClasspath could never pass as expected, but I didn't investigate how it did sometimes.
Because FooFilter extends Filter, it should always hang waiting for the option to be input. Additionally, the
deletetable should have also hung indefinitely because it wouldn't get the necessary user delete confirmation.
",20/Nov/13 05:34;elserj;org.apache.accumulo.start.classloader.vfs.providers.VfsClassLoaderTest.testFileMonitor also fails occasionally.,"20/Nov/13 05:40;jira-bot;Commit 054a89e4b03532262877d6e0f7c07ddd332a7406 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=054a89e ]

ACCUMULO-1908 Manually set filter on table and force deletetable.

It appears that testPertableClasspath could never pass as expected, but I didn't investigate how it did sometimes.
Because FooFilter extends Filter, it should always hang waiting for the option to be input. Additionally, the
deletetable should have also hung indefinitely because it wouldn't get the necessary user delete confirmation.
",26/Nov/13 22:36;elserj;I've stopped seeing failures from this test. I've opened tickets for the other tests which I've seen failures in.,"27/Nov/13 03:17;elserj;Just saw another failure

{noformat}
listscans(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.473 sec  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.accumulo.test.ShellServerTest.listscans(ShellServerTest.java:706)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

maxrow(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.maxrow(ShellServerTest.java:620)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

importDirectory(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.153 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.importDirectory(ShellServerTest.java:575)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

constraint(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.006 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.constraint(ShellServerTest.java:457)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

renametable(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.546 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.renametable(ShellServerTest.java:664)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

listcompactions(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.002 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.listcompactions(ShellServerTest.java:601)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

classpath(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.003 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<3>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.classpath(ShellServerTest.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

du(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.276 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<4>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.du(ShellServerTest.java:252)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

grep(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.002 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<5>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.grep(ShellServerTest.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

help(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.013 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<5>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.help(ShellServerTest.java:528)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

info(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.001 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<5>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.info(ShellServerTest.java:584)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

iter(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.044 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<6>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.iter(ShellServerTest.java:314)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

ping(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.033 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<6>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.ping(ShellServerTest.java:649)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

user(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.027 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<6>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.user(ShellServerTest.java:276)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

debug(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.001 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<6>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.debug(ShellServerTest.java:263)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

egrep(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.052 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<7>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.egrep(ShellServerTest.java:241)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

merge(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.18 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<8>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.merge(ShellServerTest.java:635)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

sleep(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.202 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<8>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.sleep(ShellServerTest.java:365)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

trace(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.003 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<8>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.trace(ShellServerTest.java:760)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

testPertableClasspath(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.036 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<8>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.testPertableClasspath(ShellServerTest.java:723)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

setscaniterDeletescaniter(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.02 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<9>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.setscaniterDeletescaniter(ShellServerTest.java:217)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

clearCls(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.001 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<9>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:105)
	at org.apache.accumulo.test.ShellServerTest.clearCls(ShellServerTest.java:405)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

deletemany(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.457 sec  <<< FAILURE!
java.lang.AssertionError: expected:<10> but was:<4>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.deletemany(ShellServerTest.java:472)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

deleterows(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.317 sec  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.accumulo.test.ShellServerTest.deleterows(ShellServerTest.java:502)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

execfile(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.013 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<11>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:111)
	at org.apache.accumulo.test.ShellServerTest.execfile(ShellServerTest.java:232)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

clonetable(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.227 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<11>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.clonetable(ShellServerTest.java:413)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

notable(org.apache.accumulo.test.ShellServerTest)  Time elapsed: 0.002 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<12>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.accumulo.test.ShellServerTest.assertGoodExit(ShellServerTest.java:119)
	at org.apache.accumulo.test.ShellServerTest.exec(ShellServerTest.java:98)
	at org.apache.accumulo.test.ShellServerTest.notable(ShellServerTest.java:352)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

{noformat}","15/Jan/14 03:37;ctubbsii;Are these failures applicable to 1.6.x? That test is called ShellServerIT in 1.6.0-SNAPSHOT, not ShellServerTest. And, that test has been updated a lot. It's not clear to me that these errors apply to both 1.5.x and 1.6.x. Can you perhaps create separate tickets for unrelated failures? Or, at least, narrow the applicable versions to only 1.5.x if it does not apply to 1.6.x?",15/Jan/14 03:54;elserj;Previously they did. I haven't been regularly running the ITs as I don't have the resources to do it reguarly.,"06/Feb/14 03:37;jira-bot;Commit d6bbbd6ab39eab99b272ee931183ce7fc91ee3ae in branch refs/heads/1908-shellservertest from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d6bbbd6 ]

ACCUMULO-1908 Lots of small fixes that make ShellServerTest a little more stable.

Try to isolate each test using new tables each test. Increase timings, account
for caching, better use of JUnit asserts for meaningful failures, and better
helper methods (countFiles).
","07/Feb/14 16:22;jira-bot;Commit 2c4b38c7759dd88da095e9e8618c7a6f702538d8 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2c4b38c ]

ACCUMULO-1908 Lots of small fixes that make ShellServerTest a little more stable.

Try to isolate each test using new tables each test. Increase timings, account
for caching, better use of JUnit asserts for meaningful failures, and better
helper methods (countFiles).
","07/Feb/14 16:22;jira-bot;Commit 2c4b38c7759dd88da095e9e8618c7a6f702538d8 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2c4b38c ]

ACCUMULO-1908 Lots of small fixes that make ShellServerTest a little more stable.

Try to isolate each test using new tables each test. Increase timings, account
for caching, better use of JUnit asserts for meaningful failures, and better
helper methods (countFiles).
","07/Feb/14 16:22;jira-bot;Commit 2c4b38c7759dd88da095e9e8618c7a6f702538d8 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2c4b38c ]

ACCUMULO-1908 Lots of small fixes that make ShellServerTest a little more stable.

Try to isolate each test using new tables each test. Increase timings, account
for caching, better use of JUnit asserts for meaningful failures, and better
helper methods (countFiles).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ContinuousMoru does not run under hadoop 2.0,ACCUMULO-1809,12675334,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,23/Oct/13 20:50,28/Mar/14 21:26,13/Mar/19 22:01,23/Oct/13 20:53,1.5.0,,,,,,,1.5.1,1.6.0,,test,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-23 20:51:54.129,,,no_permission,,,,,,,,,,,,354954,,,Fri Mar 28 21:26:16 UTC 2014,,,,,,0|i1p6zj:,355243,,,,,,,,"23/Oct/13 20:51;jira-bot;Commit a7e159219a29ca6f127616fd965aa857900e3f9c in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a7e1592 ]

ACCUMULO-1809 parse short args and use reflection tricks to update counters
","23/Oct/13 20:52;jira-bot;Commit a7e159219a29ca6f127616fd965aa857900e3f9c in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a7e1592 ]

ACCUMULO-1809 parse short args and use reflection tricks to update counters
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
","28/Mar/14 21:26;jira-bot;Commit 9e5854fb3ff90c0e80523394401f4103eb4212a2 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9e5854f ]

ACCUMULO-2564 Backport changes to unify Hadoop 1/2

This is a backport of the changes made for Accumulo 1.5.0 and 1.5.1 to
establish binary compatibility with both Hadoop 1 and 2 branches. This
work was originally done under several commits and issues, as outlined
below. Additionally, there was some new work that needed to be done,
but is not applicable to later branches.

ACCUMULO-1421, commit c9c0d45 by Adam Fuchs
ACCUMULO-1421, commit d7ba6ca by Christopher Tubbs
ACCUMULO-1421, commit 261cf36 by Eric Newton
ACCUMULO-1421, commit cc3c2d8 by Eric Newton

Issue: ACCUMULO-1809
Author: Eric Newton
Reason: use reflection tricks to update counters
Commit: a7e159219a29ca6f127616fd965aa857900e3f9c

Issue: n/a
Reason: Delegate reflection to ContextFactory

The InsertWithOutputFormat functional test uses ContextFactory, so we
have to update that to use the reflection hack as well. And while we're
there, might as well keep the code in one place.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NoClassDefFound building against Hadoop1 in ShellServerTest,ACCUMULO-2453,12700743,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,11/Mar/14 16:27,27/Mar/14 20:33,13/Mar/19 22:01,27/Mar/14 20:27,1.5.1,,,,,,,1.5.2,1.6.0,,test,,,,,,0,,,,,"Looks like we don't have the profile dependencies correctly set up. I see this building against hadoop1 but not hadoop2.

{noformat}
Exception in thread ""Thread-126"" java.lang.NoClassDefFoundError: org/apache/commons/httpclient/HttpMethod
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:437)
Caused by: java.lang.ClassNotFoundException: org.apache.commons.httpclient.HttpMethod
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 1 more
With failures, global counters are inaccurate; consider running with -i
Copy failed: java.io.IOException: Job failed!
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1357)
	at org.apache.hadoop.tools.DistCp.copy(DistCp.java:667)
	at org.apache.hadoop.tools.DistCp.run(DistCp.java:881)
	at org.apache.accumulo.test.ShellServerTest.exporttableImporttable(ShellServerTest.java:228)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-25 15:26:46.013,,,no_permission,,,,,,,,,,,,379086,,,Thu Mar 27 20:33:04 UTC 2014,,,,,,0|i1tbiv:,379378,,,,,,,,"25/Mar/14 15:26;ecn;I can't reproduce this error.  I did this:

{noformat}
$ git checkout 1.5.1
$ mvn package -Dtest=ShellServerTest -DfailIfNoTests=false -Phadoop-1 -Dhadoop.version=1.0.4
{noformat}
","25/Mar/14 16:31;elserj;[~ecn], did you look at the logs? I must have responded to Mike via IRC on this same subject and forgot to post here. The exception gets printed to the logs but doesn't fail the test. I marked this as minor since it's not causing us failure ATM.","27/Mar/14 20:27;jira-bot;Commit 4a05a17deb36924a126c3e04894fb34b65910565 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4a05a17 ]

ACCUMULO-2453 Add in commons-httpclient test dependency
","27/Mar/14 20:27;jira-bot;Commit 4a05a17deb36924a126c3e04894fb34b65910565 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4a05a17 ]

ACCUMULO-2453 Add in commons-httpclient test dependency
","27/Mar/14 20:27;jira-bot;Commit 4a05a17deb36924a126c3e04894fb34b65910565 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4a05a17 ]

ACCUMULO-2453 Add in commons-httpclient test dependency
","27/Mar/14 20:33;jira-bot;Commit 3ce0bfda3475f6a0e320b1af3e52c545b699d636 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3ce0bfd ]

ACCUMULO-2453 Forgot to remove dependency from the default
","27/Mar/14 20:33;jira-bot;Commit 3ce0bfda3475f6a0e320b1af3e52c545b699d636 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3ce0bfd ]

ACCUMULO-2453 Forgot to remove dependency from the default
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Scanner is left unclosed in AddSplitsCommand#execute(),ACCUMULO-2187,12688669,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,vickyuec,yuzhihong@gmail.com,yuzhihong@gmail.com,14/Jan/14 03:22,18/Mar/14 05:11,13/Mar/19 22:01,07/Mar/14 16:11,,,,,,,,1.7.0,,,,,,,,,0,newbie,,,,"Here is related code:
{code}
      java.util.Scanner file = new java.util.Scanner(new File(f));
      while (file.hasNextLine()) {
        line = file.nextLine();
        if (!line.isEmpty()) {
          splits.add(decode ? new Text(Base64.decodeBase64(line.getBytes())) : new Text(line));
        }
      }
{code}
file should be closed upon return.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29/Jan/14 08:47;vickyuec;ACCUMULO-2187.v1.patch.txt;https://issues.apache.org/jira/secure/attachment/12625823/ACCUMULO-2187.v1.patch.txt,06/Mar/14 21:32;vickyuec;ACCUMULO-2187.v2.patch.txt;https://issues.apache.org/jira/secure/attachment/12633227/ACCUMULO-2187.v2.patch.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2014-01-29 08:47:15.545,,,no_permission,,,,,,,,,,,,367688,,,Tue Mar 18 05:11:35 UTC 2014,,,,,,0|i1rdlr:,367995,,,,,,,,29/Jan/14 08:47;vickyuec;Attached patch. Refactored file reading into a method.,"03/Mar/14 15:55;bhavanki;Can you add a unit test for the refactored method, and also add @param and @return to the Javadoc?",06/Mar/14 21:32;vickyuec;Added unit tests. Had to also make a change in ShellUtil to use UTF8 due to the new changes in AddSplitsCommand and CreateTableCommand.,"07/Mar/14 16:10;jira-bot;Commit 2d68f5772cce9ef995d97730f4c9f95f203d72b1 in accumulo's branch refs/heads/master from [~vickyuec]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=2d68f57 ]

ACCUMULO-2187 Refactor method to read file in AddSplitsCommand and CreateTableCommand

Signed-off-by: Bill Havanki <bhavanki@cloudera.com>
","07/Mar/14 16:10;jira-bot;Commit ff605865d1388a07687a924b064e3dd3495d3102 in accumulo's branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ff60586 ]

ACCUMULO-2187 Clean whitespace, format ShellUtilTest
",07/Mar/14 16:11;bhavanki;Thanks Vikram!,"18/Mar/14 05:11;jira-bot;Commit 18fee706ba213b2cd6b0aaa587f5da1bfe5aa118 in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=18fee70 ]

ACCUMULO-2477, ACCUMULO-2187 Fix introduced warnings/formatting
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TableConfiguration should override invalidateCache,ACCUMULO-2331,12693478,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,06/Feb/14 01:37,17/Mar/14 22:04,13/Mar/19 22:01,07/Feb/14 16:24,1.5.0,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,"In trying to get ACCUMULO-1908 resolved, I noticed that I had a new test failure in which the test appeared to not see updates to a table's properties.

Upon further investigation, I noticed that the server-side impl in ClientServiceHandler was calling invalidateCache on the AccumuloConfiguration it was passed (which is actually a TableConfiguration). However, since this method isn't implemented in TableConfiguration, the cache wasn't cleared and the client saw stale data.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2489,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-06 04:09:11.949,,,no_permission,,,,,,,,,,,,372063,,,Mon Mar 17 22:04:46 UTC 2014,,,,,,0|i1s4db:,372367,,,,,,,,"06/Feb/14 04:09;jira-bot;Commit 07384da27a9997824f56230d30a52fd17e0aef39 in branch refs/heads/2331-tableconfig from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=07384da ]

ACCUMULO-2331 Actually invalidate the cache when requested.
",06/Feb/14 15:41;elserj;This also just caused a failure for me in o.a.a.p.SimpleTest.,"06/Feb/14 15:52;jira-bot;Commit 050ff39e67204dfd1959d1a31efb34fefec124e2 in branch refs/heads/2331-tableconfig from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=050ff39 ]

ACCUMULO-2331 Remove unnecessary attempt at polling for configuration updates.

getTableProperties should flush the ZooCache before pulling the configuration
values from it and thus force communication to ZooKeeper. As such, there should
be no need to try to code around this.
","07/Feb/14 16:22;jira-bot;Commit 510140ad0cae2d54bc4c097c94cf4b024f3655bf in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=510140a ]

ACCUMULO-2331 Actually invalidate the cache in TableConfiguration when requested.

TableConfiguration previously didn't override invalidateCache, which means that
the implementations that used it and the invalidateCache method, were not providing
the semantics that were intended. Fix the case in SimpleTest that outlined this issue,
removing the additional poll/check loop as it was both broken and unnecessary with
proper API implementation.
","07/Feb/14 16:22;jira-bot;Commit 510140ad0cae2d54bc4c097c94cf4b024f3655bf in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=510140a ]

ACCUMULO-2331 Actually invalidate the cache in TableConfiguration when requested.

TableConfiguration previously didn't override invalidateCache, which means that
the implementations that used it and the invalidateCache method, were not providing
the semantics that were intended. Fix the case in SimpleTest that outlined this issue,
removing the additional poll/check loop as it was both broken and unnecessary with
proper API implementation.
","07/Feb/14 16:22;jira-bot;Commit 510140ad0cae2d54bc4c097c94cf4b024f3655bf in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=510140a ]

ACCUMULO-2331 Actually invalidate the cache in TableConfiguration when requested.

TableConfiguration previously didn't override invalidateCache, which means that
the implementations that used it and the invalidateCache method, were not providing
the semantics that were intended. Fix the case in SimpleTest that outlined this issue,
removing the additional poll/check loop as it was both broken and unnecessary with
proper API implementation.
",17/Mar/14 21:42;vines;[~elserj] thinks this may be related,"17/Mar/14 22:04;elserj;bq. thinks this may be related

At the very least, it's a change that happened between 1.5.0 and 1.5.1. Certainly suspect. Giving a quick glance, I don't think the current synchronization is sufficient to guarantee that an NPE isn't hit.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SimpleTest test cases occasionally fail,ACCUMULO-1936,12681427,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,26/Nov/13 22:14,10/Mar/14 22:20,13/Mar/19 22:01,10/Mar/14 22:20,1.5.0,1.5.1,,,,,,1.5.2,1.6.0,,test,,,,,,0,,,,,"Have seen testTableOperations fail.

Recently saw testInstanceOperations fail:

{noformat}
expected:<[c]> but was:<[!0]>

Stacktrace

org.junit.ComparisonFailure: expected:<[c]> but was:<[!0]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.accumulo.proxy.SimpleTest.testInstanceOperations(SimpleTest.java:821)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-20 06:51:20.397,,,no_permission,,,,,,,,,,,,360692,,,Mon Mar 10 22:20:52 UTC 2014,,,,,,0|i1q6ef:,360991,,,,,,,,"20/Feb/14 06:51;vickyuec;Is the stacktrace correct? It says 
{noformat}
at  org.apache.accumulo.start.classloader.vfs.providers.VfsClassLoaderTest.testFileMonitor(VfsClassLoaderTest.java:93)
{noformat}","10/Mar/14 14:46;elserj;Ok, this one isn't too bad in the end. The unit test is looking for a compaction on the table it made but the METADATA table occasionally has a compaction running too which fails the test.","10/Mar/14 22:16;jira-bot;Commit 72395e010d3f495507d03664057a63c3d690a206 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=72395e0 ]

ACCUMULO-1936 Make testInstanceOperations a more reliable test.

Avoid pulling scans for users other than root and compactions for
compactions over tables other than the one we're looking at. Slow down
the slow iterator even more.
","10/Mar/14 22:16;jira-bot;Commit 72395e010d3f495507d03664057a63c3d690a206 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=72395e0 ]

ACCUMULO-1936 Make testInstanceOperations a more reliable test.

Avoid pulling scans for users other than root and compactions for
compactions over tables other than the one we're looking at. Slow down
the slow iterator even more.
","10/Mar/14 22:16;jira-bot;Commit 72395e010d3f495507d03664057a63c3d690a206 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=72395e0 ]

ACCUMULO-1936 Make testInstanceOperations a more reliable test.

Avoid pulling scans for users other than root and compactions for
compactions over tables other than the one we're looking at. Slow down
the slow iterator even more.
",10/Mar/14 22:20;elserj;Accounted for other scans and/or compactions happening and look for exactly what we want to make the assertions more reliable.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shell#printHelp should use the ConsoleReader to print,ACCUMULO-2447,12699808,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,10/Mar/14 17:37,10/Mar/14 22:18,13/Mar/19 22:01,10/Mar/14 22:18,1.5.1,,,,,,,1.5.2,1.6.0,,shell,test,,,,,0,,,,,"In debugging ShellServerTest, there was a ton of garbage on the console from the Help command. In tracking this down, there's a method on Shell that always makes its own PrintWriter to System.err.

Then, optionally, it will print the same message to the OutputStream that the ConsoleReader has. I'm not sure if there's a reason that we always need to print to System.err

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-10 22:15:59.867,,,no_permission,,,,,,,,,,,,378154,,,Mon Mar 10 22:16:05 UTC 2014,,,,,,0|i1t5rz:,378446,,,,,,,,"10/Mar/14 22:15;jira-bot;Commit e13c27331a42d55408427f18d97b285372f92a47 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e13c273 ]

ACCUMULO-2447 Always set PrintWriter on Shell and don't print to stderr.

While we don't have access to the printwriter/outputstream from the jline
ConsoleReader, we can force the user to pass in one (or just make one for
stdout). This will allow unit tests to correctly squash all output into
a bytearray (or similar) instead of having to redirect stderr too (which
would have other repercussions).
","10/Mar/14 22:16;jira-bot;Commit e13c27331a42d55408427f18d97b285372f92a47 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e13c273 ]

ACCUMULO-2447 Always set PrintWriter on Shell and don't print to stderr.

While we don't have access to the printwriter/outputstream from the jline
ConsoleReader, we can force the user to pass in one (or just make one for
stdout). This will allow unit tests to correctly squash all output into
a bytearray (or similar) instead of having to redirect stderr too (which
would have other repercussions).
","10/Mar/14 22:16;jira-bot;Commit e13c27331a42d55408427f18d97b285372f92a47 in accumulo's branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e13c273 ]

ACCUMULO-2447 Always set PrintWriter on Shell and don't print to stderr.

While we don't have access to the printwriter/outputstream from the jline
ConsoleReader, we can force the user to pass in one (or just make one for
stdout). This will allow unit tests to correctly squash all output into
a bytearray (or similar) instead of having to redirect stderr too (which
would have other repercussions).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MergeIT fails,ACCUMULO-2412,12697441,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,26/Feb/14 19:55,05/Mar/14 21:17,13/Mar/19 22:01,05/Mar/14 21:17,1.4.0,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,1.5.1,1.6.0,,,,,,,,,0,16_qa_bug,,,,"Running nightly integration tests:

{noformat}
java.lang.Exception: split inconsistency mergeTest5_2 [m, b, r] != [m, r]
	at org.apache.accumulo.test.functional.MergeIT.runMergeTest(MergeIT.java:182)
	at org.apache.accumulo.test.functional.MergeIT.runMergeTest(MergeIT.java:132)
	at org.apache.accumulo.test.functional.MergeIT.mergeTest(MergeIT.java:114)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-05 21:12:48.172,,,no_permission,,,,,,,,,,,,375915,,,Wed Mar 05 21:13:25 UTC 2014,,,,,,0|i1ss0v:,376211,,,,,,,,"26/Feb/14 21:20;ecn;The master didn't see the splits (was using stale metadata table information) while performing the merge.  It identified the merge as trivial and didn't do anything.

Need to grab all merge information prior to pulling the metadata table information.
","05/Mar/14 21:12;jira-bot;Commit 4cd12c4251a7a6ac4d04b23cf7c736d81acd33de in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cd12c4 ]

ACCUMULO-2412 use only pre-existing merge requests before processing the metadata table
","05/Mar/14 21:13;jira-bot;Commit 8e7a8a2ccfd8f124f532fed747852c87f8b05cdd in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8e7a8a2 ]

ACCUMULO-2412 use only pre-existing merge requests before processing the metadata table
","05/Mar/14 21:13;jira-bot;Commit 4cd12c4251a7a6ac4d04b23cf7c736d81acd33de in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cd12c4 ]

ACCUMULO-2412 use only pre-existing merge requests before processing the metadata table
","05/Mar/14 21:13;jira-bot;Commit 8e7a8a2ccfd8f124f532fed747852c87f8b05cdd in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8e7a8a2 ]

ACCUMULO-2412 use only pre-existing merge requests before processing the metadata table
","05/Mar/14 21:13;jira-bot;Commit 4cd12c4251a7a6ac4d04b23cf7c736d81acd33de in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cd12c4 ]

ACCUMULO-2412 use only pre-existing merge requests before processing the metadata table
","05/Mar/14 21:13;jira-bot;Commit 1392e07fb5a4d5efe803810bcd888568cc57d9b9 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1392e07 ]

ACCUMULO-2412 use only pre-existing merge requests before processing the metadata table
","05/Mar/14 21:13;jira-bot;Commit 8e7a8a2ccfd8f124f532fed747852c87f8b05cdd in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8e7a8a2 ]

ACCUMULO-2412 use only pre-existing merge requests before processing the metadata table
","05/Mar/14 21:13;jira-bot;Commit 4cd12c4251a7a6ac4d04b23cf7c736d81acd33de in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cd12c4 ]

ACCUMULO-2412 use only pre-existing merge requests before processing the metadata table
","05/Mar/14 21:13;jira-bot;Commit 1392e07fb5a4d5efe803810bcd888568cc57d9b9 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1392e07 ]

ACCUMULO-2412 use only pre-existing merge requests before processing the metadata table
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BatchWalkers die when started before Ingesters,ACCUMULO-2399,12696993,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,mdrob,mdrob,mdrob,24/Feb/14 20:09,04/Mar/14 14:18,13/Mar/19 22:01,04/Mar/14 14:18,,,,,,,,1.4.5,1.5.2,1.6.0,test,,,,,,0,16_qa_bug,,,,"When starting up ingest and batchwalk at the same time for the continuous ingest test, if the walkers come up first then they might die due to {{TableNotFound}}.

{noformat}
Thread ""org.apache.accumulo.test.continuous.ContinuousBatchWalker"" died java.lang.reflect.InvocationTargetException
java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:137)
        at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.accumulo.core.client.TableNotFoundException: Table ci does not exist
        at org.apache.accumulo.core.client.impl.Tables._getTableId(Tables.java:181)
        at org.apache.accumulo.core.client.impl.Tables.getTableId(Tables.java:166)
        at org.apache.accumulo.core.client.impl.ConnectorImpl.getTableId(ConnectorImpl.java:84)
        at org.apache.accumulo.core.client.impl.ConnectorImpl.createScanner(ConnectorImpl.java:151)
        at org.apache.accumulo.test.continuous.ContinuousBatchWalker.main(ContinuousBatchWalker.java:61)
        ... 6 more
{noformat}

A workaround is to make sure you start ingest first, or to manually create the table before the test.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-04 14:17:28.562,,,no_permission,,,,,,,,,,,,375468,,,Tue Mar 04 14:17:30 UTC 2014,,,,,,0|i1sp9r:,375764,,,,,,,,24/Feb/14 23:03;mdrob;ContinuousScanner and ContinuousWalker both suffer from the same problem.,24/Feb/14 23:36;mdrob;Review up on RB at https://reviews.apache.org/r/18444/,"04/Mar/14 14:17;jira-bot;Commit 759582b78d5d72870a4a8c359ef6134c4dd97993 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=759582b ]

ACCUMULO-2399 Alert user CI table should exist

Extract common table checking functionality for continuous clients and
fail fast when the table does not exist. No longer create the table in
ingest to make the requirement explicit.
","04/Mar/14 14:17;jira-bot;Commit 759582b78d5d72870a4a8c359ef6134c4dd97993 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=759582b ]

ACCUMULO-2399 Alert user CI table should exist

Extract common table checking functionality for continuous clients and
fail fast when the table does not exist. No longer create the table in
ingest to make the requirement explicit.
","04/Mar/14 14:17;jira-bot;Commit 759582b78d5d72870a4a8c359ef6134c4dd97993 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=759582b ]

ACCUMULO-2399 Alert user CI table should exist

Extract common table checking functionality for continuous clients and
fail fast when the table does not exist. No longer create the table in
ingest to make the requirement explicit.
","04/Mar/14 14:17;jira-bot;Commit 759582b78d5d72870a4a8c359ef6134c4dd97993 in accumulo's branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=759582b ]

ACCUMULO-2399 Alert user CI table should exist

Extract common table checking functionality for continuous clients and
fail fast when the table does not exist. No longer create the table in
ingest to make the requirement explicit.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MetadataIT has a race condition,ACCUMULO-2397,12696979,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,24/Feb/14 18:34,25/Feb/14 17:19,13/Mar/19 22:01,25/Feb/14 17:19,,,,,,,,1.6.0,,,test,,,,,,0,16_qa_bug,,,,"in {{testFlushAndCompact}} the metadata table is dirtied, then flushed.  However, the root table could flush on its own before the manual flush, which would cause subsequent examination of files to compare as equal.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-24 18:40:14.12,,,no_permission,,,,,,,,,,,,375454,,,Mon Feb 24 18:40:22 UTC 2014,,,,,,0|i1sp6n:,375750,,,,,,,,"24/Feb/14 18:40;jira-bot;Commit 5a39a03341209d20c67a1fbd25876a2fca9bd83b in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5a39a03 ]

ACCUMULO-2397 dirty the !METADATA table a second time to ensure the file list changes
","24/Feb/14 18:40;jira-bot;Commit 5a39a03341209d20c67a1fbd25876a2fca9bd83b in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5a39a03 ]

ACCUMULO-2397 dirty the !METADATA table a second time to ensure the file list changes
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DynamicThreadPoolsIT sometimes fails,ACCUMULO-2398,12696982,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,24/Feb/14 18:55,24/Feb/14 19:02,13/Mar/19 22:01,24/Feb/14 19:00,,,,,,,,1.6.0,,,test,,,,,,0,16_qa_bug,,,,"Sometimes the test code does not catch the major compactions running.  They could be completing too quickly.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-24 19:00:16.854,,,no_permission,,,,,,,,,,,,375457,,,Mon Feb 24 19:02:30 UTC 2014,,,,,,0|i1sp7b:,375753,,,,,,,,"24/Feb/14 19:00;jira-bot;Commit 739082d757c6a0b58380508e92b79ef518030735 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=739082d ]

ACCUMULO-2398 write more data, wait less between checks
","24/Feb/14 19:00;jira-bot;Commit 739082d757c6a0b58380508e92b79ef518030735 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=739082d ]

ACCUMULO-2398 write more data, wait less between checks
","24/Feb/14 19:02;mdrob;Maybe instead of depending on a race condition, we can use {{SlowIterator}}?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
switching WALogs can cause scary traceback message,ACCUMULO-2391,12696619,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,21/Feb/14 19:49,24/Feb/14 17:01,13/Mar/19 22:01,24/Feb/14 17:01,,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"I'm seeing this ugly message in the monitor.

{noformat}

Unexpected error writing to log, retrying attempt 1
	java.io.IOException: java.lang.reflect.InvocationTargetException
		at org.apache.accumulo.tserver.log.DfsLogger.defineTablet(DfsLogger.java:463)
		at org.apache.accumulo.tserver.log.TabletServerLogger$4.write(TabletServerLogger.java:335)
		at org.apache.accumulo.tserver.log.TabletServerLogger.write(TabletServerLogger.java:275)
		at org.apache.accumulo.tserver.log.TabletServerLogger.write(TabletServerLogger.java:231)
		at org.apache.accumulo.tserver.log.TabletServerLogger.defineTablet(TabletServerLogger.java:332)
		at org.apache.accumulo.tserver.log.TabletServerLogger.write(TabletServerLogger.java:256)
		at org.apache.accumulo.tserver.log.TabletServerLogger.write(TabletServerLogger.java:231)
		at org.apache.accumulo.tserver.log.TabletServerLogger.log(TabletServerLogger.java:344)
		at org.apache.accumulo.tserver.TabletServer$ThriftClientHandler.update(TabletServer.java:1778)
		at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
		at java.lang.reflect.Method.invoke(Method.java:597)
		at org.apache.accumulo.trace.instrument.thrift.TraceWrap$1.invoke(TraceWrap.java:63)
		at $Proxy15.update(Unknown Source)
		at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$update.getResult(TabletClientService.java:2392)
		at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor$update.getResult(TabletClientService.java:2376)
		at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
		at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
		at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:171)
		at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
		at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:231)
		at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at java.lang.Thread.run(Thread.java:662)
	Caused by: java.lang.reflect.InvocationTargetException
		at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
		at java.lang.reflect.Method.invoke(Method.java:597)
		at org.apache.accumulo.tserver.log.DfsLogger.defineTablet(DfsLogger.java:460)
		... 25 more
	Caused by: java.nio.channels.ClosedChannelException
		at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:1317)
		at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:1630)
		at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1612)
		at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1595)
		at org.apache.hadoop.fs.FSDataOutputStream.hsync(FSDataOutputStream.java:137)
		... 29 more
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-24 16:41:14.688,,,no_permission,,,,,,,,,,,,375095,,,Mon Feb 24 16:41:20 UTC 2014,,,,,,0|i1smzb:,375393,,,,,,,,"24/Feb/14 16:41;jira-bot;Commit ec3a160425a8c307e5b4dbe859d29f45377c680c in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ec3a160 ]

ACCUMULO-2391 hide warning if it takes just one retry
","24/Feb/14 16:41;jira-bot;Commit ec3a160425a8c307e5b4dbe859d29f45377c680c in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ec3a160 ]

ACCUMULO-2391 hide warning if it takes just one retry
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Native library compiling fails on OS X 10.7 (Lion),ACCUMULO-682,12598194,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,,jklucar,jklucar,10/Jul/12 14:43,20/Feb/14 23:23,13/Mar/19 22:01,13/Jul/12 11:34,1.4.1,,,,,,,1.4.2,1.5.0,,scripts,,,,,,0,build,,,,"The makefiles for building the native libraries require the Java headers (jni.h, etc) The Makefile in src/server/src/main/c++/nativeMap points to 

/Developer/SDKs/MacOSX10.6.sdk/System/Library/Frameworks/JavaVM.framework/Versions/A/Headers

The correct directory to include that works for both 10.6 and 10.7 is

/System/Library/Frameworks/JavaVM.framework/Headers

the Makefile in the mlock directory is including this directory correctly.

",OS X 10.7.x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246386,,,2012-07-10 14:43:42.0,,,,,,0|i07lpb:,42282,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cachedDataIndex.close() should be enclosed in finally block in BCFile#Reader(),ACCUMULO-2371,12695266,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,yuzhihong@gmail.com,yuzhihong@gmail.com,14/Feb/14 19:27,20/Feb/14 15:11,13/Mar/19 22:01,20/Feb/14 15:11,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Here is related code:
{code}
        try {
          dataIndex = new DataIndex(cachedDataIndex);
        } catch (IOException e) {
          LOG.error(""Got IOException when trying to create DataIndex block"");
          throw e;
        }
        cachedDataIndex.close();
{code}
If there is IOE, cachedDataIndex.close() would be skipped.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-20 15:10:40.678,,,no_permission,,,,,,,,,,,,373774,,,Thu Feb 20 15:10:50 UTC 2014,,,,,,0|i1seun:,374074,,,,,,,,"20/Feb/14 15:10;jira-bot;Commit 8220905264ca8856aa383bbbc438bbabb67c0c5b in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8220905 ]

ACCUMULO-2371 add finally clause
","20/Feb/14 15:10;jira-bot;Commit 8220905264ca8856aa383bbbc438bbabb67c0c5b in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8220905 ]

ACCUMULO-2371 add finally clause
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
classload problem running functional tests,ACCUMULO-2385,12696092,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,19/Feb/14 22:20,19/Feb/14 22:25,13/Mar/19 22:01,19/Feb/14 22:25,,,,,,,,1.5.1,,,test,,,,,,0,,,,,"{noformat}
======================================================================
FAIL: runTest (simple.mapreduce.MapReduceTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/user/workspace/accumulo-1.5.1/test/system/auto/simple/mapreduce.py"", line 101, in runTest
    self.fail(""Test did not finish"")
AssertionError: Test did not finish
{noformat}

Running the test with debug finds:

{noformat}
Error: java.lang.ClassNotFoundException: com.google.common.cache.CacheLoader
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
{noformat}
","hadoop 1.0.4, zookeeper 3.3.5, rhel6.3",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-19 22:24:28.766,,,no_permission,,,,,,,,,,,,374569,,,Wed Feb 19 22:24:59 UTC 2014,,,,,,0|i1sjqv:,374869,,,,,,,,"19/Feb/14 22:24;jira-bot;Commit 4dd2d662cabb8372acaba36d58820c804ecd53ed in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4dd2d66 ]

ACCUMULO-2385 fix error running test against hadoop 1.0
","19/Feb/14 22:24;jira-bot;Commit 4dd2d662cabb8372acaba36d58820c804ecd53ed in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4dd2d66 ]

ACCUMULO-2385 fix error running test against hadoop 1.0
","19/Feb/14 22:24;jira-bot;Commit 4dd2d662cabb8372acaba36d58820c804ecd53ed in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4dd2d66 ]

ACCUMULO-2385 fix error running test against hadoop 1.0
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tablet constructor leaks this,ACCUMULO-1948,12682182,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,bhavanki,kturner,kturner,02/Dec/13 17:50,19/Feb/14 20:09,13/Mar/19 22:01,04/Feb/14 20:05,,,,,,,,1.7.0,,,,,,,,,0,,,,,"The tablet constructor leaks this when it calls {{tabletResources.setTablet(this, acuTableConf);}}  AFAIK this is completey innocuous because nothing is really done (in 1.4 code) w/ the reference.  Howerver, it is possible the code could be changed in the future to use the ref.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-27 19:34:26.25,,,no_permission,,,,,,,,,,,,361439,,,Wed Feb 19 20:09:52 UTC 2014,,,,,,0|i1qazz:,361738,,,,,,,,27/Jan/14 19:34;bhavanki;I'll try this one. I've been meaning to get into the {{Tablet}} code.,"27/Jan/14 19:37;elserj;bq. I've been meaning to get into the Tablet code.

Famous last words ;) 

(just kidding, of course)",27/Jan/14 19:53;bhavanki;Where is the Like button on JIRA? (y),"27/Jan/14 20:05;vines;you can vote on tickets, that's close!",27/Jan/14 22:16;bhavanki;First shot at this up for review. I still plan to test this out on an actual cluster.,"28/Jan/14 20:12;bhavanki;Third attempt up for review. After testing I found an issue with the simpler second attempt. Notably, this latest attempt changes the memory management framework for tablets slightly, so that minor compaction is not attempted on an offline tablet. This makes sense in my limited understanding of things, so others' opinions are definitely needed. See the review for more details.","31/Jan/14 19:26;bhavanki;Attempt #4 up for review. This avoids the online check from the third attempt and also tries to handle the scenario when analysis of a later-unloaded tablet leads to minor compaction of a new, reloaded instance of the same tablet.","04/Feb/14 00:01;kturner;I noticed there is another place in the tablet constructor that leaks this, the call to {{{tabletServer.recover(...,this,...)}}}.  I took a quick look at how its used, it seems to just use the extent and table config.","04/Feb/14 20:02;jira-bot;Commit eade3b59ddd95732cbfc635eadf6447c6b3108d2 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=eade3b5 ]

ACCUMULO-1948 Tablet constructor no longer leaks this

The core Tablet constructor no longer sets this on the TabletResourceManager passed to it.
The TabletResourceManager instance is created now without a Tablet reference, but only
with its key extent and configuration, and so it can be constructed first and safely passed
to the Tablet constructor. This alteration in TabletResourceManager drove changes to several
other locations which had been expecting a tablet reference to be available. In most of those
places, the key extent takes its place.

However, Keith Turner pointed out that, without a tablet reference in the TabletStateImpl
class (memory report) used to guide minor compaction, it's possible that a report logged
against a tablet that was since unloaded could cause compaction to start on a new instance
of that tablet that had just been reloaded. In order to ensure that cannot happen, the
tablet reference remains, so that the same object is used to decide on compaction and
potentially perform compaction.

In addition, the method of working with the memory reports was changed so that the same
snapshot of them used to decide on compactions is used to find the tablet to compact later.
This change was necessary regardless of this ticket.

Finally, the unused tabletResources field was removed from TabletServerResourceManager,
and that class also now avoids erroneously removing the memory report for a reloaded tablet
if its prior incarnation is unloaded in the scenario described above.
","04/Feb/14 20:05;bhavanki;Thanks again for the reviews, Keith. I will open a new JIRA for the additional this leakage you located yesterday, since this one got complicated.","19/Feb/14 20:09;jira-bot;Commit dcc19ccbada8c2f0a206ec797455294015e8ca6d in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=dcc19cc ]

ACCUMULO-1961 Re-apply inadvertently dropped 4abb3f1 to master branch

  Fixes trivial warnings and broken javadocs which have been recently
  introduced. Specifically, removes references to private and
  package-private (default) classes in public javadoc comments (internal
  details aren't relevant to the API and subject to change). Another
  common warning was unused imports and javadoc param tags that refer to
  non-existent parameters.

  Commits against the following JIRA issues introduced these:
  ACCUMULO-1948, ACCUMULO-1974, ACCUMULO-2021, ACCUMULO-2136,
  ACCUMULO-2322, ACCUMULO-2334, ACCUMULO-2350
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
VfsClassLoaderTest.testFileMonitor occasionally fails,ACCUMULO-1935,12681426,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,26/Nov/13 22:13,14/Feb/14 04:57,13/Mar/19 22:01,14/Feb/14 04:57,1.5.0,,,,,,,1.5.1,,,test,,,,,,0,,,,,"{noformat}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.accumulo.start.classloader.vfs.providers.VfsClassLoaderTest.testFileMonitor(VfsClassLoaderTest.java:93)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{noformat}

or

{noformat}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.accumulo.start.classloader.vfs.providers.VfsClassLoaderTest.testFileMonitor(VfsClassLoaderTest.java:97)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-06 03:53:00.951,,,no_permission,,,,,,,,,,,,360691,,,Fri Feb 14 04:57:33 UTC 2014,,,,,,0|i1q6e7:,360990,,,,,,,,"04/Feb/14 16:11;elserj;So I don't forget it later, I believe that [~vines] told me that this was actually a commons-vfs bug, VFS-487 I believe.","06/Feb/14 03:53;jira-bot;Commit a37ca7fc292c45ba9957e1d328d507033be2fe93 in branch refs/heads/1935-vfstests from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a37ca7f ]

ACCUMULO-1935 Sufficiently increase timeouts in attempt to avoid missed notifications.
","07/Feb/14 16:22;jira-bot;Commit a37ca7fc292c45ba9957e1d328d507033be2fe93 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a37ca7f ]

ACCUMULO-1935 Sufficiently increase timeouts in attempt to avoid missed notifications.
","07/Feb/14 16:22;jira-bot;Commit a37ca7fc292c45ba9957e1d328d507033be2fe93 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a37ca7f ]

ACCUMULO-1935 Sufficiently increase timeouts in attempt to avoid missed notifications.
","07/Feb/14 16:22;jira-bot;Commit a37ca7fc292c45ba9957e1d328d507033be2fe93 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a37ca7f ]

ACCUMULO-1935 Sufficiently increase timeouts in attempt to avoid missed notifications.
",14/Feb/14 04:57;elserj;Will reopen if continues to fail after adjustments,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Additional unnecessary member on InputFormatBase,ACCUMULO-2297,12692404,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,30/Jan/14 23:01,14/Feb/14 02:19,13/Mar/19 22:01,14/Feb/14 02:19,1.4.4,1.5.0,,,,,,1.6.0,,,client,,,,,,0,,,,,"Noticed in 1.4.5 and 1.5.1 that there's an extra currentValue member defined in the RecordReaderBase that is never actually used (there's a currentV member that's used instead), conversely to the currentK and the currentKey members which are returned to the client and used for progress reporting, respectively.

We probably shouldn't change these for the current versions (as we could break compilation across minor releases), but it likely makes sense to remove this extra, unnecessary variable before 1.6 goes out.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-03 17:51:52.041,,,no_permission,,,,,,,,,,,,370999,,,Fri Feb 14 02:18:30 UTC 2014,,,,,,0|i1rxuv:,371304,,,,,,,,"03/Feb/14 17:51;vines;A. That's a protected value, so I don't see how removing it can affect users
B. It doesn't exist in 1.6.0",03/Feb/14 17:52;vines;And then I see that it moved to AbstractInputFormat,"03/Feb/14 17:55;billie.rinaldi;bq. A. That's a protected value, so I don't see how removing it can affect users

If people have implemented their own InputFormats, they might have used it.","03/Feb/14 18:25;vines;That makes sense, then. But if that's the case, shouldn't we deprecate it? And in the same thought, shouldn't we make all the protected Key, K, and Vs in that class private?","03/Feb/14 18:35;elserj;bq. shouldn't we make all the protected Key, K, and Vs in that class private?

Potentially, but that would also cause you to have to write more code with the mapreduce API. We'd also have to fix our implementations or write some getters (which may be cleaner?).","03/Feb/14 18:43;billie.rinaldi;Subclasses need to be able to set the Key, K, and V (they may not actually need to get them).","14/Feb/14 02:18;jira-bot;Commit ec4d4d858ae2ad6aca01f73f2f30a09abd5f0f81 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ec4d4d8 ]

ACCUMULO-2297 Remove unnecessary currentValue and add javadoc for purpose of other members
","14/Feb/14 02:18;jira-bot;Commit ec4d4d858ae2ad6aca01f73f2f30a09abd5f0f81 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ec4d4d8 ]

ACCUMULO-2297 Remove unnecessary currentValue and add javadoc for purpose of other members
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AccumuloReloadingVFSClassLoaderTest failure,ACCUMULO-2369,12695099,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,13/Feb/14 23:13,14/Feb/14 00:14,13/Mar/19 22:01,14/Feb/14 00:14,1.5.0,,,,,,,1.5.1,1.6.0,,start,test,,,,,0,,,,,"{code}
testModifiedClass(org.apache.accumulo.start.classloader.vfs.AccumuloReloadingVFSClassLoaderTest)  Time elapsed: 3.512 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<H[allo Welt]> but was:<H[ello World!]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.accumulo.start.classloader.vfs.AccumuloReloadingVFSClassLoaderTest.testModifiedClass(AccumuloReloadingVFSClassLoaderTest.java:213)
{code}

Probably related to ACCUMULO-1935",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-14 00:14:03.933,,,no_permission,,,,,,,,,,,,373607,,,Fri Feb 14 00:14:06 UTC 2014,,,,,,0|i1sdtj:,373907,,,,,,,,"14/Feb/14 00:14;jira-bot;Commit a9cd5d14e5675a6346bdce79bc5c670af88f784b in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a9cd5d1 ]

ACCUMULO-2369 Increase the sleep time and add some comments as to why
","14/Feb/14 00:14;jira-bot;Commit a9cd5d14e5675a6346bdce79bc5c670af88f784b in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a9cd5d1 ]

ACCUMULO-2369 Increase the sleep time and add some comments as to why
","14/Feb/14 00:14;jira-bot;Commit a9cd5d14e5675a6346bdce79bc5c670af88f784b in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a9cd5d1 ]

ACCUMULO-2369 Increase the sleep time and add some comments as to why
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
classpath example is not in the examples integration test,ACCUMULO-1930,12681122,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,vines,ecn,ecn,25/Nov/13 20:32,04/Feb/14 19:02,13/Mar/19 22:01,04/Feb/14 19:02,1.5.0,,,,,,,1.6.0,,,test,,,,,,0,,,,,ExampleIT is supposed to run through all the examples.  At least the classpath example is missing.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-04 19:00:28.02,,,no_permission,,,,,,,,,,,,360387,,,Tue Feb 04 19:01:54 UTC 2014,,,,,,0|i1q4iv:,360686,,,,,,,,25/Nov/13 20:34;ecn;StatsCombiner is also missing.,"04/Feb/14 19:00;jira-bot;Commit 482f570ca1cf98108a7b939a8211821c6feed0e4 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=482f570 ]

ACCUMULO-1930 Adding StatsCombiner and Classpath test
","04/Feb/14 19:01;jira-bot;Commit 482f570ca1cf98108a7b939a8211821c6feed0e4 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=482f570 ]

ACCUMULO-1930 Adding StatsCombiner and Classpath test
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RegExFilter Erroneously Reconstructs RowId Containing Null Character,ACCUMULO-2083,12686191,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,vines,lbschan,lbschan,23/Dec/13 18:56,30/Jan/14 18:51,13/Mar/19 22:01,29/Jan/14 20:16,1.5.0,,,,,,,,,,,,,,,,0,,,,,"I applied a core.iterators.user.RegExFilter iterator to a BatchScanner iterating over Key,Value pairs where the row id of the Keys are formatted as ""<source>\0\<sink>"". RegExFilter reconstructed the row id as ""<source>"", dropping the sink half. This appears to be due to the usage of the String(byte bytes[], int offset, int length, Charset charset) constructor to reset the values of the Matcher objects in the both of the matches() functions. The String constructor only reconstructs a String up to the ""\0"" character.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29/Jan/14 16:38;vines;RegexWithNullByte.java;https://issues.apache.org/jira/secure/attachment/12625893/RegexWithNullByte.java,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-01-29 16:38:30.533,,,no_permission,,,,,,,,,,,,365164,,,Thu Jan 30 18:51:27 UTC 2014,,,,,,0|i1qxx3:,365469,,,,,,,,"29/Jan/14 16:38;vines;I cannot reproduce the bug at hand. Attached is test code which has a row key with a 0 byte in the middle and I am able to successfully match against the latter half of it. Additionally, I saw no alterations of my Key from the iterator. I tried using both attached iterators and scan time iterators with no divergence of behavior.","29/Jan/14 16:50;mdrob;[~vines], can you commit your code as a unit test?",29/Jan/14 16:56;vines;Sure,"29/Jan/14 20:14;jira-bot;Commit cabdbe829b9b901a292e1bc17bd02a9c54d9f8c9 in branch refs/heads/1.5.1-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cabdbe8 ]

ACCUMULO-2083 - adding test for 0 byte in Key with regexes
","29/Jan/14 20:16;jira-bot;Commit cabdbe829b9b901a292e1bc17bd02a9c54d9f8c9 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cabdbe8 ]

ACCUMULO-2083 - adding test for 0 byte in Key with regexes
","29/Jan/14 20:16;jira-bot;Commit cabdbe829b9b901a292e1bc17bd02a9c54d9f8c9 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cabdbe8 ]

ACCUMULO-2083 - adding test for 0 byte in Key with regexes
",30/Jan/14 18:51;elserj;[~lbschan] please feel free to reopen this issue if you have a test case or some code that shows the issue you originally described.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stop-all.sh in 1.4.x requires tracers and gc files,ACCUMULO-2285,12692289,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,bhavanki,bhavanki,bhavanki,30/Jan/14 14:31,30/Jan/14 16:25,13/Mar/19 22:01,30/Jan/14 16:25,1.4.4,,,,,,,1.4.5,,,scripts,,,,,,0,,,,,"In 1.4.x, start-all.sh script defaults to starting single gc and tracer processes on the (first) master if the files $ACCUMULO_CONF_DIR/gc and $ACCUMULO_CONF_DIR/tracers are absent. However, stop-all.sh lacks the corresponding behavior, and so it cannot stop those default processes.

The start/stop mechanism for tracers and gc in 1.5.x changed significantly, so work here is just for 1.4.x. See ACCUMULO-2153 for 1.5.x and higher.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-30 16:22:47.042,,,no_permission,,,,,,,,,,,,370884,,,Thu Jan 30 16:25:45 UTC 2014,,,,,,0|i1rx5b:,371189,,,,,,,,30/Jan/14 14:51;bhavanki;Review posted.,"30/Jan/14 16:22;jira-bot;Commit 9bff89fc29b728607aaf1b6f8dcb2cc8ef171313 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9bff89f ]

ACCUMULO-2285 Default to MASTER1 if tracers or gc file is missing (1.4.x)

The start-all.sh script defaults to starting tracer and gc processes on the first
master if the tracers and gc files are missing from ACCUMULO_CONF_DIR. This change
adds that default behavior to stop-all.sh, which otherwise does not stop the
processes.
","30/Jan/14 16:22;jira-bot;Commit 9bff89fc29b728607aaf1b6f8dcb2cc8ef171313 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9bff89f ]

ACCUMULO-2285 Default to MASTER1 if tracers or gc file is missing (1.4.x)

The start-all.sh script defaults to starting tracer and gc processes on the first
master if the tracers and gc files are missing from ACCUMULO_CONF_DIR. This change
adds that default behavior to stop-all.sh, which otherwise does not stop the
processes.
","30/Jan/14 16:22;jira-bot;Commit 9bff89fc29b728607aaf1b6f8dcb2cc8ef171313 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9bff89f ]

ACCUMULO-2285 Default to MASTER1 if tracers or gc file is missing (1.4.x)

The start-all.sh script defaults to starting tracer and gc processes on the first
master if the tracers and gc files are missing from ACCUMULO_CONF_DIR. This change
adds that default behavior to stop-all.sh, which otherwise does not stop the
processes.
","30/Jan/14 16:22;jira-bot;Commit 9bff89fc29b728607aaf1b6f8dcb2cc8ef171313 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9bff89f ]

ACCUMULO-2285 Default to MASTER1 if tracers or gc file is missing (1.4.x)

The start-all.sh script defaults to starting tracer and gc processes on the first
master if the tracers and gc files are missing from ACCUMULO_CONF_DIR. This change
adds that default behavior to stop-all.sh, which otherwise does not stop the
processes.
","30/Jan/14 16:25;bhavanki;Fix is 1.4.x only, merged -sours to 1.5.1-SNAPSHOT.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Auto tests use wrong options,ACCUMULO-2275,12692080,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,29/Jan/14 17:18,29/Jan/14 21:48,13/Mar/19 22:01,29/Jan/14 21:48,1.5.0,,,,,,,1.5.1,,,test,,,,,,0,,,,,"Test uses the wrong option names:

FateStarvationTest
MaxOpenTest
LotsOfTablets",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-29 20:36:45.047,,,no_permission,,,,,,,,,,,,370670,,,Wed Jan 29 21:47:18 UTC 2014,,,,,,0|i1rvvb:,370980,,,,,,,,29/Jan/14 17:29;elserj;Default required args used to be: <rows> <start_row> <num_columns>,"29/Jan/14 20:36;jira-bot;Commit 265a99b8e23e3a18fdc28dfdb46f02bc0f6a6849 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=265a99b ]

ACCUMULO-2275 Fix up the options provided to work with TestIngest.
","29/Jan/14 20:36;jira-bot;Commit 265a99b8e23e3a18fdc28dfdb46f02bc0f6a6849 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=265a99b ]

ACCUMULO-2275 Fix up the options provided to work with TestIngest.
","29/Jan/14 20:36;jira-bot;Commit 265a99b8e23e3a18fdc28dfdb46f02bc0f6a6849 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=265a99b ]

ACCUMULO-2275 Fix up the options provided to work with TestIngest.
","29/Jan/14 21:47;jira-bot;Commit 613da730acebe19dc6d278a1a4ef0bd010683078 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=613da73 ]

ACCUMULO-2275 Fix options for LotsOfTablets
","29/Jan/14 21:47;jira-bot;Commit 613da730acebe19dc6d278a1a4ef0bd010683078 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=613da73 ]

ACCUMULO-2275 Fix options for LotsOfTablets
","29/Jan/14 21:47;jira-bot;Commit 613da730acebe19dc6d278a1a4ef0bd010683078 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=613da73 ]

ACCUMULO-2275 Fix options for LotsOfTablets
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooCacheTest uses wrong package names for classes,ACCUMULO-2276,12692113,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,29/Jan/14 19:30,29/Jan/14 20:37,13/Mar/19 22:01,29/Jan/14 20:37,,,,,,,,1.5.1,,,test,,,,,,0,,,,,The merge of ACCUMULO-1829 from 1.4 into 1.5 screwed up the package names.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-29 20:36:46.002,,,no_permission,,,,,,,,,,,,370704,,,Wed Jan 29 20:36:51 UTC 2014,,,,,,0|i1rw2v:,371015,,,,,,,,"29/Jan/14 20:36;jira-bot;Commit 25a0493e3bf61ad8f6b2fef5a6bf269e52d13911 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=25a0493 ]

ACCUMULO-2276 Re-fix the package names to the correct ones.
","29/Jan/14 20:36;jira-bot;Commit 25a0493e3bf61ad8f6b2fef5a6bf269e52d13911 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=25a0493 ]

ACCUMULO-2276 Re-fix the package names to the correct ones.
","29/Jan/14 20:36;jira-bot;Commit 25a0493e3bf61ad8f6b2fef5a6bf269e52d13911 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=25a0493 ]

ACCUMULO-2276 Re-fix the package names to the correct ones.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
socket should be closed in MiniAccumuloClusterImpl#start(),ACCUMULO-2210,12689384,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,vines,yuzhihong@gmail.com,yuzhihong@gmail.com,16/Jan/14 22:34,28/Jan/14 23:03,13/Mar/19 22:01,28/Jan/14 23:03,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Here is related code:
{code}
      while (true) {
        try {
          Socket s = new Socket(""localhost"", config.getZooKeeperPort());
          s.getOutputStream().write(""ruok\n"".getBytes());
          s.getOutputStream().flush();
          byte buffer[] = new byte[100];
          int n = s.getInputStream().read(buffer);
          if (n == 4 && new String(buffer, 0, n).equals(""imok""))
            break;
{code}
Socket s should be closed coming out of the loop.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-28 23:03:33.61,,,no_permission,,,,,,,,,,,,368351,,,Tue Jan 28 23:03:33 UTC 2014,,,,,,0|i1rhmn:,368656,,,,,,,,"28/Jan/14 23:03;jira-bot;Commit 21f09f42a32059befd715f904047971daecd2c47 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=21f09f4 ]

ACCUMULO-2210 Closing socket after checking on on Zookeeper
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KilledTabletServerSplitTest fails on Hadoop2,ACCUMULO-2264,12691550,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,28/Jan/14 02:07,28/Jan/14 17:39,13/Mar/19 22:01,28/Jan/14 16:16,1.5.0,,,,,,,1.5.1,,,test,,,,,,0,,,,,KilledTabletServerSplitTest tries to set tserver.walog.max.size to 50K which will cause infinite loop as Hadoop won't create files with a blocksize less than 1M by default in 2.2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-28 04:04:30.971,,,no_permission,,,,,,,,,,,,370295,,,Tue Jan 28 16:16:40 UTC 2014,,,,,,0|i1rtjb:,370596,,,,,,,,"28/Jan/14 04:04;jira-bot;Commit ffd72325e5dd4ed3a6a46ba6ef47f95f87c7c40a in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ffd7232 ]

ACCUMULO-2264 Up the walog max size so it doesn't break by default on hadoop2
","28/Jan/14 04:04;jira-bot;Commit ffd72325e5dd4ed3a6a46ba6ef47f95f87c7c40a in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ffd7232 ]

ACCUMULO-2264 Up the walog max size so it doesn't break by default on hadoop2
","28/Jan/14 04:04;jira-bot;Commit ffd72325e5dd4ed3a6a46ba6ef47f95f87c7c40a in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ffd7232 ]

ACCUMULO-2264 Up the walog max size so it doesn't break by default on hadoop2
","28/Jan/14 06:31;busbey;I think this points to an underlying problem with the tserver wal configuration. Hadoop can be configured to set an arbitrary minimum blocksize (the property is dfs.namenode.fs-limits.min-block-size).

The tserver should probably be checking for this and then either issuing a WARN/ERROR to the client and using the minimum or failing loudly and refusing to start.","28/Jan/14 15:31;elserj;[~busbey], this was about a 3 character change to a test class that is only necessary in the 1.5 branch. It sounds like what you're suggesting is an improvement to the tserver class to do better startup diagnostics. I think it would be better for you to open a new ticket for the changes you're suggesting and not confuse this very simple ticket for something larger.",28/Jan/14 16:16;busbey;filed as ACCUMULO-2266,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tracer reports: IllegalStateException: Closed,ACCUMULO-2213,12689505,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,busbey,ecn,ecn,17/Jan/14 15:17,24/Jan/14 21:37,13/Mar/19 22:01,24/Jan/14 21:37,,,,,,,,1.4.5,1.5.1,1.6.0,trace,,,,,,0,,,,,"During a 24 hour continuous ingest test with agitation, the following was reported 42k times:

{noformat}
Timer task failed org.apache.accumulo.tracer.TraceServer$1 Closed
	java.lang.IllegalStateException: Closed
		at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.flush(TabletServerBatchWriter.java:302)
		at org.apache.accumulo.core.client.impl.BatchWriterImpl.flush(BatchWriterImpl.java:59)
		at org.apache.accumulo.tracer.TraceServer.flush(TraceServer.java:225)
		at org.apache.accumulo.tracer.TraceServer.access$400(TraceServer.java:75)
		at org.apache.accumulo.tracer.TraceServer$1.run(TraceServer.java:217)
		at org.apache.accumulo.server.util.time.SimpleTimer$LoggingTimerTask.run(SimpleTimer.java:42)
		at java.util.TimerThread.mainLoop(Timer.java:512)
		at java.util.TimerThread.run(Timer.java:462)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-17 15:23:07.215,,,no_permission,,,,,,,,,,,,368472,,,Fri Jan 24 21:37:08 UTC 2014,,,,,,0|i1ridb:,368776,,,,,,,,"17/Jan/14 15:23;busbey;I can make this happen reliably on 1.4.5 while using gremlins to disrupt the node the tracer is on.

I also get exceptions in the main loop, which blows up the log for the service:

{noformat}
2014-01-15 23:41:10,533 [trace.TraceServer] ERROR: Unable to write mutation to table: org.apache.accumulo.core.data.Mutation@0
java.lang.IllegalStateException: Closed
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.addMutation(TabletServerBatchWriter.java:192)
        at org.apache.accumulo.core.client.impl.BatchWriterImpl.addMutation(BatchWriterImpl.java:40)
        at org.apache.accumulo.server.trace.TraceServer$Receiver.span(TraceServer.java:136)
        at org.apache.accumulo.cloudtrace.thrift.SpanReceiver$Processor$span.process(SpanReceiver.java:205)
        at org.apache.accumulo.cloudtrace.thrift.SpanReceiver$Processor.process(SpanReceiver.java:185)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:176)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
2014-01-15 23:41:10,533 [trace.TraceServer] ERROR: Unable to write mutation to table: org.apache.accumulo.core.data.Mutation@0
java.lang.IllegalStateException: Closed
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.addMutation(TabletServerBatchWriter.java:192)
        at org.apache.accumulo.core.client.impl.BatchWriterImpl.addMutation(BatchWriterImpl.java:40)
        at org.apache.accumulo.server.trace.TraceServer$Receiver.span(TraceServer.java:137)
        at org.apache.accumulo.cloudtrace.thrift.SpanReceiver$Processor$span.process(SpanReceiver.java:205)
        at org.apache.accumulo.cloudtrace.thrift.SpanReceiver$Processor.process(SpanReceiver.java:185)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:176)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
{noformat}

I think there are two issues here: that the writer gets closed and that our error handling to reset doesn't properly account for enough error conditions (right now it's just Mutations Rejected).

I've been talking in IRC as I try to figure out how the tracer's writer could get closed. Can we coordinate there?",17/Jan/14 15:40;ecn;Ugh... I checked in the fix for this under ACCUMULO-2209.  I'm still investigating how the writer gets closed.,"17/Jan/14 15:48;busbey;I was worried about causing deadlock if the recovery was expanded, because the only way I could think of at first is for the thread doing the reset to block after the close but before the reset to null.","20/Jan/14 19:24;busbey;Attaching a follow up patch for consideration.

Unfortunately, I can no longer get this particular failure case to show up. 

Proposed patch :
* isolates reset to the flush() thread; we don't need to queue up a bunch of resets in failure
* adds explanatory comments
* avoids catching Exception when adding mutations or flushing
* adjusts logging to reflect retrying
* makes it easier for to leave a test cluster configured to watch for the source of the closing (by setting TSBW's log level to trace in tracer_logger.xml)

[~ecn], let me know if this looks reasonable","23/Jan/14 13:20;busbey;[~ecn], do you want the source of the close call that triggered this error chased down before closing this ticket?","23/Jan/14 13:42;ecn;If you have it, great.  If not, I'm not worried about it.","24/Jan/14 21:37;busbey;I couldn't reproduce the failure condition upon rerunning a 24hr version of the test.

I did, however, see our new code handle some failures in the network. So I think we're good to close.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Thread ""tablet assignment 1"" died overlaps assigned (tablet) true [] [] []",ACCUMULO-1937,12681454,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,26/Nov/13 23:40,24/Jan/14 16:52,13/Mar/19 22:01,27/Nov/13 14:49,1.4.0,1.5.0,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,"Running a single node random walk test with two walkers.  I got this error message several times.

The way I read this: an assignment was not found in the unopened tablets list.  But unopened, opening and online tablets are all empty.

Need to figure out if this condition warrants an error message and squash it if it does not.

{noformat}
Thread ""tablet assignment 1"" died overlaps assigned 2a;38bf6abbb983dc21;11d3511c75529bcd true [] [] []
	java.lang.IllegalStateException: overlaps assigned 2a;38bf6abbb983dc21;11d3511c75529bcd true [] [] []
		at org.apache.accumulo.tserver.TabletServer$AssignmentHandler.run(TabletServer.java:2824)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at java.lang.Thread.run(Thread.java:662)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-27 14:47:57.78,,,no_permission,,,,,,,,,,,,360719,,,Fri Jan 24 16:52:45 UTC 2014,,,,,,0|i1q6kf:,361018,,,,,,,,"27/Nov/13 14:44;ecn;If the master assigns a tablet, but then comes back and unassigns it, there's a race in which the assignment handler can start the assignment, but the tablet is no longer in the unopened list.","27/Nov/13 14:47;jira-bot;Commit edae90f593da385e3a6d58063a2d41fbdbb543aa in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=edae90f ]

ACCUMULO-1937 decrease log severity for expected case of a tablet no longer being in the unopened set at the moment it is being loaded
","27/Nov/13 14:48;jira-bot;Commit edae90f593da385e3a6d58063a2d41fbdbb543aa in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=edae90f ]

ACCUMULO-1937 decrease log severity for expected case of a tablet no longer being in the unopened set at the moment it is being loaded
","02/Dec/13 14:51;kturner;[~ecn] looked at 1.4 this issue exist there ( I did not check 1.5).   Looking at the code it seems like this issue generates spurious error messages, but does not cause problems (does not kill the assignment thread because the exception is caught and logged).  Is this what you saw?  ","02/Dec/13 16:13;ecn;[~kturner] Yes, it's just a big scary message; everything works as expected.",24/Jan/14 16:07;elserj;[~ecn] just ran across this myself in 1.5.1. Any qualms against me pulling this back (despite it just being a logging change),"24/Jan/14 16:18;ecn;[~elserj] sure, go ahead.","24/Jan/14 16:52;jira-bot;Commit 4e89c614533b730dc41ff437d2451b5c93fe243b in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4e89c61 ]

ACCUMULO-1937 decrease log severity for expected case of a tablet no longer being in the unopened set at the moment it is being loaded

Conflicts:
	server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
","24/Jan/14 16:52;jira-bot;Commit 4e89c614533b730dc41ff437d2451b5c93fe243b in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4e89c61 ]

ACCUMULO-1937 decrease log severity for expected case of a tablet no longer being in the unopened set at the moment it is being loaded

Conflicts:
	server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
","24/Jan/14 16:52;jira-bot;Commit 4e89c614533b730dc41ff437d2451b5c93fe243b in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4e89c61 ]

ACCUMULO-1937 decrease log severity for expected case of a tablet no longer being in the unopened set at the moment it is being loaded

Conflicts:
	server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in tablet assignment,ACCUMULO-1921,12680804,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,22/Nov/13 20:05,24/Jan/14 16:39,13/Mar/19 22:01,22/Nov/13 21:28,1.5.0,,,,,,,1.5.1,1.6.0,,tserver,,,,,,0,,,,,"Running randomwalk tests:

{noformat}
Thread ""tablet assignment 1"" died java.lang.NullPointerException
	java.lang.RuntimeException: java.lang.NullPointerException
		at org.apache.accumulo.tserver.TabletServer$AssignmentHandler.run(TabletServer.java:2863)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
		at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
		at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
		at java.lang.Thread.run(Thread.java:662)
	Caused by: java.lang.NullPointerException
		at org.apache.accumulo.tserver.TabletServer$AssignmentHandler.run(TabletServer.java:2841)
		... 7 more
{noformat}
","single development system, 1.6.0-SNAPSHOT, 2f585a7b1bb97e50af243d756e5b7bd2b642d0bb",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-22 21:28:20.14,,,no_permission,,,,,,,,,,,,360069,,,Fri Jan 24 16:39:09 UTC 2014,,,,,,0|i1q2kn:,360368,,,,,,,,"22/Nov/13 21:28;jira-bot;Commit 7dd3592cdcc333d221477d6b97584e1f1c514e3b in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7dd3592 ]

ACCUMULO-1921 check for null
","22/Nov/13 21:28;jira-bot;Commit 7dd3592cdcc333d221477d6b97584e1f1c514e3b in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7dd3592 ]

ACCUMULO-1921 check for null
","25/Nov/13 13:26;jira-bot;Commit 855593862bec796035eb5dfd07100485c9965b80 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8555938 ]

ACCUMULO-1921 fixed formatting
","25/Nov/13 14:04;jira-bot;Commit 855593862bec796035eb5dfd07100485c9965b80 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8555938 ]

ACCUMULO-1921 fixed formatting
",24/Jan/14 16:08;elserj;Just saw this with 1.5.1 as well. I'll pull back the changes.,"24/Jan/14 16:39;jira-bot;Commit 4cac84ecd70bce51f12791194d1ab721f29b2d57 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cac84e ]

ACCUMULO-1921 check for null
","24/Jan/14 16:39;jira-bot;Commit 4cac84ecd70bce51f12791194d1ab721f29b2d57 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cac84e ]

ACCUMULO-1921 check for null
","24/Jan/14 16:39;jira-bot;Commit 4cac84ecd70bce51f12791194d1ab721f29b2d57 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cac84e ]

ACCUMULO-1921 check for null
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
'du' shell command doesn't work when not in a table,ACCUMULO-2235,12690166,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,22/Jan/14 01:41,24/Jan/14 15:58,13/Mar/19 22:01,23/Jan/14 04:34,1.5.0,,,,,,,1.5.1,1.6.0,,shell,,,,,,0,,,,,"Open the shell, type `du trace`, and receive an error.

The help on the du command says that it can take one to many tables to print, but it forces you to always have a table selected, and always includes that table (even if not provided as an argument).

A workaround is to select a table first.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-23 04:34:05.788,,,no_permission,,,,,,,,,,,,369123,,,Fri Jan 24 15:58:09 UTC 2014,,,,,,0|i1rmdz:,369428,,,,,,,,"23/Jan/14 04:34;jira-bot;Commit 707e74e057bc449aced48147544153d0571801d0 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=707e74e ]

ACCUMULO-2235 Make the du shell command successful when not in a table context.
","23/Jan/14 04:34;jira-bot;Commit 707e74e057bc449aced48147544153d0571801d0 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=707e74e ]

ACCUMULO-2235 Make the du shell command successful when not in a table context.
","23/Jan/14 04:34;jira-bot;Commit 707e74e057bc449aced48147544153d0571801d0 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=707e74e ]

ACCUMULO-2235 Make the du shell command successful when not in a table context.
","23/Jan/14 18:05;jira-bot;Commit 00bd820ef9ff016305241504eb83e3c6e90dd873 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=00bd820 ]

ACCUMULO-2235 Fix up formatter for madrob and make the du test a little less sensitive to other tests
","23/Jan/14 18:05;jira-bot;Commit 00bd820ef9ff016305241504eb83e3c6e90dd873 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=00bd820 ]

ACCUMULO-2235 Fix up formatter for madrob and make the du test a little less sensitive to other tests
","23/Jan/14 18:05;jira-bot;Commit 00bd820ef9ff016305241504eb83e3c6e90dd873 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=00bd820 ]

ACCUMULO-2235 Fix up formatter for madrob and make the du test a little less sensitive to other tests
","24/Jan/14 14:39;mdrob;{quote}
    // create and delete a table so we get out of a table context in the shell
    exec(""createtable du_test_table"", true);
    exec(""deletetable -f du_test_table"", true);
{quote}

IIRC, there's also a ""notable"" command to do just that.","24/Jan/14 15:58;jira-bot;Commit 6989d99f193ded70f7f5c7443d7fed2d08b2572b in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6989d99 ]

ACCUMULO-2235 Replace the create/delete table calls with the notable ""notable"" command.
","24/Jan/14 15:58;jira-bot;Commit 6989d99f193ded70f7f5c7443d7fed2d08b2572b in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6989d99 ]

ACCUMULO-2235 Replace the create/delete table calls with the notable ""notable"" command.
","24/Jan/14 15:58;jira-bot;Commit 6989d99f193ded70f7f5c7443d7fed2d08b2572b in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6989d99 ]

ACCUMULO-2235 Replace the create/delete table calls with the notable ""notable"" command.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need to better handle DNS failure propagation from Hadoop,ACCUMULO-2225,12689843,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,busbey,busbey,busbey,20/Jan/14 17:39,23/Jan/14 13:19,13/Mar/19 22:01,23/Jan/14 13:19,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"Injecting network failures to cause dns failures can cause odd failures within our underlying Hadoop calls such that IllegalArgumentExceptions come out (rather than IOException or UnknownHostException).

There are several places where we do not adequately account for this, causing role failure.",1.4.5-SNAP on CDH4 w/gremlins,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,368810,,,2014-01-20 17:39:14.0,,,,,,0|i1rkgf:,369114,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CloudStone Benchmarks should accept ZKs as parameter,ACCUMULO-2221,12689572,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,mdrob,mdrob,mdrob,17/Jan/14 21:46,21/Jan/14 15:33,13/Mar/19 22:01,21/Jan/14 15:32,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,docs,test,,,,,0,newbie,,,,"When running CloudStone tests, I am prompted for ZKs, instead of being given the opportunity to specify them as a parameter, similar to user/password/instance.

Actually, looking at the code, there might be an option to specify them, but it is not enumerated in the README.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-21 15:32:05.233,,,no_permission,,,,,,,,,,,,368539,,,Tue Jan 21 15:32:33 UTC 2014,,,,,,0|i1ris7:,368843,,,,,,,,"21/Jan/14 15:32;jira-bot;Commit e887f376a2fc5a3b1b5a29e182175afc6a7077bf in branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e887f37 ]

ACCUMULO-2221 Add -z flag to bench README
","21/Jan/14 15:32;jira-bot;Commit e887f376a2fc5a3b1b5a29e182175afc6a7077bf in branch refs/heads/1.5.1-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e887f37 ]

ACCUMULO-2221 Add -z flag to bench README
","21/Jan/14 15:32;jira-bot;Commit e887f376a2fc5a3b1b5a29e182175afc6a7077bf in branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e887f37 ]

ACCUMULO-2221 Add -z flag to bench README
","21/Jan/14 15:32;jira-bot;Commit e887f376a2fc5a3b1b5a29e182175afc6a7077bf in branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e887f37 ]

ACCUMULO-2221 Add -z flag to bench README
",21/Jan/14 15:32;mdrob;Updated the README.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Wrong property name in user manual, section 11.5.4",ACCUMULO-2226,12689856,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,20/Jan/14 18:45,20/Jan/14 18:54,13/Mar/19 22:01,20/Jan/14 18:54,1.5.0,,,,,,,1.5.1,1.6.0,,docs,,,,,,0,,,,,"Noticed that section 11.5.4 uses a property name of ""zookeeper"" instead of ""instance.zookeeper.host"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-20 18:54:14.417,,,no_permission,,,,,,,,,,,,368823,,,Mon Jan 20 18:54:16 UTC 2014,,,,,,0|i1rkjb:,369127,,,,,,,,"20/Jan/14 18:54;jira-bot;Commit 0328838f339d4e27ac417c5a27e6a43b0ee5ed66 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0328838 ]

ACCUMULO-2226 Fix incorrect zookeeper hosts property name
","20/Jan/14 18:54;jira-bot;Commit 0328838f339d4e27ac417c5a27e6a43b0ee5ed66 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0328838 ]

ACCUMULO-2226 Fix incorrect zookeeper hosts property name
","20/Jan/14 18:54;jira-bot;Commit 0328838f339d4e27ac417c5a27e6a43b0ee5ed66 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0328838 ]

ACCUMULO-2226 Fix incorrect zookeeper hosts property name
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Security randomwalk fails ""User doesn't exist and they SHOULD""",ACCUMULO-2211,12689425,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,bhavanki,bhavanki,bhavanki,17/Jan/14 03:26,17/Jan/14 14:21,13/Mar/19 22:01,17/Jan/14 14:21,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,test,,,,,,0,randomwalk,test,,,"The CreateUser node in the Security randomwalk test can create the ""table"" user even in the face of an expected PERMISSION_DENIED error. When that happens, and the next node happens to want to change the new table user's password, you can get:

{noformat}
org.apache.accumulo.core.client.AccumuloException: User table_server_domain_com_29780_1389915181300 doesn't exist and they SHOULD.
{noformat}

This happens because there is no delay between the user creation and the password change, as there are for other user creations, added in ACCUMULO-1123.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-17 03:59:55.457,,,no_permission,,,,,,,,,,,,368392,,,Fri Jan 17 14:21:39 UTC 2014,,,,,,0|i1rhvj:,368696,,,,,,,,"17/Jan/14 03:59;jira-bot;Commit 0ffb01a5600c4133f502a4b2a5befa2d0c70d8f4 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0ffb01a ]

ACCUMULO-2211 Add missing delay in Security randomwalk CreateUser

This commit adds a one second delay after creating the ""table"" user in the Security
randomwalk test, in the case where the creation fails with a permission denied error,
but the user needs to be created anyway to continue the test. The delay accompanies
those added in ACCUMULO-1123.
","17/Jan/14 03:59;jira-bot;Commit 0ffb01a5600c4133f502a4b2a5befa2d0c70d8f4 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0ffb01a ]

ACCUMULO-2211 Add missing delay in Security randomwalk CreateUser

This commit adds a one second delay after creating the ""table"" user in the Security
randomwalk test, in the case where the creation fails with a permission denied error,
but the user needs to be created anyway to continue the test. The delay accompanies
those added in ACCUMULO-1123.
","17/Jan/14 03:59;jira-bot;Commit 0ffb01a5600c4133f502a4b2a5befa2d0c70d8f4 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0ffb01a ]

ACCUMULO-2211 Add missing delay in Security randomwalk CreateUser

This commit adds a one second delay after creating the ""table"" user in the Security
randomwalk test, in the case where the creation fails with a permission denied error,
but the user needs to be created anyway to continue the test. The delay accompanies
those added in ACCUMULO-1123.
","17/Jan/14 04:00;jira-bot;Commit 0ffb01a5600c4133f502a4b2a5befa2d0c70d8f4 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0ffb01a ]

ACCUMULO-2211 Add missing delay in Security randomwalk CreateUser

This commit adds a one second delay after creating the ""table"" user in the Security
randomwalk test, in the case where the creation fails with a permission denied error,
but the user needs to be created anyway to continue the test. The delay accompanies
those added in ACCUMULO-1123.
","17/Jan/14 04:02;bhavanki;The commit just now is a one-liner. I'm confident enough in it that I'm throwing caution to the wind and just committing it without review. I know, what's gotten into me.

I observed the additional delay in effect in a run of the Security test. I also identified a traversal of the same nodes that produced the error condition, which this time succeeded.",17/Jan/14 14:21;bhavanki;Security randomwalk has run for 10 hours so far without trouble.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CheckBalance is ending random walk tests,ACCUMULO-1239,12640791,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,04/Apr/13 15:38,16/Jan/14 20:25,13/Mar/19 22:01,05/Apr/13 17:46,,,,,,,,1.5.0,,,test,,,,,,0,15_qa_bug,,,,"CheckBalance ensures that accumulo is maintaining balance during the test.  However, balance is always out-of-date when tservers are restarted for some period of time.  The check attempts to compensate for this, but its still ending the test too soon when nothing is wrong.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-05 22:03:37.092,,,no_permission,,,,,,,,,,,,321250,,,Sat Apr 06 00:07:32 UTC 2013,,,,,,0|i1jffz:,321595,,,,,,,,"05/Apr/13 22:03;hudson;Integrated in Accumulo-Trunk #818 (See [https://builds.apache.org/job/Accumulo-Trunk/818/])
    ACCUMULO-1239 make balance checker triple-check (Revision 1465066)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/CheckBalance.java
","05/Apr/13 22:07;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #65 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/65/])
    ACCUMULO-1239 make balance checker triple-check (Revision 1465065)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/CheckBalance.java
","06/Apr/13 00:07;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #178 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/178/])
    ACCUMULO-1239 make balance checker triple-check (Revision 1465066)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/CheckBalance.java
","06/Apr/13 00:07;hudson;Integrated in Accumulo-1.5 #67 (See [https://builds.apache.org/job/Accumulo-1.5/67/])
    ACCUMULO-1239 make balance checker triple-check (Revision 1465065)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/CheckBalance.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bloom loader missleading ERROR,ACCUMULO-2202,12689230,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,mjwall,mjwall,16/Jan/14 13:26,16/Jan/14 15:43,13/Mar/19 22:01,16/Jan/14 15:43,1.4.4,,,,,,,1.4.5,1.5.1,1.6.0,tserver,,,,,,0,,,,,"After talking with [~ecn], the following hand typed stacktrace can be ignored and should be cleaned up in the code.  

{noformat}
   Thread ""bloom-loader-20"" died File /accumulo/tables/2h/default_tablet/F0yuuuiof.rf is closed
     java.lang.IllegalStateException: File /accumulo/tables/2h/default_tablet/F0yuuuiof.rf is closed
       at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getBCFile(CachableBlockFile:244)
       at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.access$000(CachableBlockFile:142)
       at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader$MetaBlockLoader.get(CachableBlockFile:211)
       at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getBlock(CachableBlockFile:307)
       at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getMetaBlock(CachableBlockFile:357)
       at org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile$Reader.getMetaBlock(CachableBlockFile:142)
       at org.apache.accumulo.core.file.rfile.RFile$Reader.getMetaStore(RFile.java:927)
       at org.apache.accumulo.core.file.BloomFilterLayer$BloomFilterLoader$1.run(BloomFilterLayer.java:210)
       at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
       at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExectutor.java:866)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
       at java.lang.Thread.run(Thread.java:662)
{noformat}

The line right before this in the tserver debug log shows starting a MajC which included the closed rfile.  That file was closed by the garbage collected and deleted shortly thereafter.  The table was getting lots of writes.  Eric, please correct anything I missed.  Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-16 15:41:52.341,,,no_permission,,,,,,,,,,,,368197,,,Thu Jan 16 15:42:25 UTC 2014,,,,,,0|i1rgof:,368502,,,,,,,,"16/Jan/14 15:41;jira-bot;Commit 91be551f655bf0a1d80493c95eafadd0025cfe40 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=91be551 ]

ACCUMULO-2202 catch all runtime exceptions, not just NPE
","16/Jan/14 15:42;jira-bot;Commit 91be551f655bf0a1d80493c95eafadd0025cfe40 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=91be551 ]

ACCUMULO-2202 catch all runtime exceptions, not just NPE
","16/Jan/14 15:42;jira-bot;Commit 47ca312c950042c4b277a98cbb4eed8a37bf9afd in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=47ca312 ]

ACCUMULO-2202 catch all runtime exceptions, not just NPE
","16/Jan/14 15:42;jira-bot;Commit 91be551f655bf0a1d80493c95eafadd0025cfe40 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=91be551 ]

ACCUMULO-2202 catch all runtime exceptions, not just NPE
","16/Jan/14 15:42;jira-bot;Commit 47ca312c950042c4b277a98cbb4eed8a37bf9afd in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=47ca312 ]

ACCUMULO-2202 catch all runtime exceptions, not just NPE
","16/Jan/14 15:42;jira-bot;Commit 91be551f655bf0a1d80493c95eafadd0025cfe40 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=91be551 ]

ACCUMULO-2202 catch all runtime exceptions, not just NPE
","16/Jan/14 15:42;jira-bot;Commit 47ca312c950042c4b277a98cbb4eed8a37bf9afd in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=47ca312 ]

ACCUMULO-2202 catch all runtime exceptions, not just NPE
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Unknown"" HDFS usage on monitor",ACCUMULO-2184,12688579,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,13/Jan/14 17:33,15/Jan/14 21:10,13/Mar/19 22:01,13/Jan/14 17:59,1.4.0,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,,1.4.5,1.5.1,1.6.0,monitor,,,,,,0,,,,,"When running Accumulo as *not* a member of the HDFS superuser group (or the superuser, itself), the monitor cannot get a ContentSummary for all of HDFS.

It can, however, get a ContentSummary for just {{instance.dfs.dir}} and show the disk usage of Accumulo, even if not relative to HDFS total used/available.

The code currently gets that ContentSummary for {{instance.dfs.dir}} but doesn't assign it to the local variable until after it tries to do the same for {{/}}, which it fails on.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2201,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-13 17:59:06.231,,,no_permission,,,,,,,,,,,,367598,,,Mon Jan 13 20:53:11 UTC 2014,,,,,,0|i1rd1z:,367906,,,,,,,,"13/Jan/14 17:59;jira-bot;Commit 8e0e0e1f5b64a0c9ca2010796c7cff5d368da3cf in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8e0e0e1 ]

ACCUMULO-2184 Fix ""Unknown"" HDFS usage entry in ""Accumulo Master"" table on overview monitor page
","13/Jan/14 17:59;jira-bot;Commit 8e0e0e1f5b64a0c9ca2010796c7cff5d368da3cf in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8e0e0e1 ]

ACCUMULO-2184 Fix ""Unknown"" HDFS usage entry in ""Accumulo Master"" table on overview monitor page
",13/Jan/14 17:59;elserj;Fails gracefully when the user running the Accumulo monitor cannot get disk usage across all of HDFS.,"13/Jan/14 18:00;jira-bot;Commit 8e0e0e1f5b64a0c9ca2010796c7cff5d368da3cf in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8e0e0e1 ]

ACCUMULO-2184 Fix ""Unknown"" HDFS usage entry in ""Accumulo Master"" table on overview monitor page
","13/Jan/14 18:01;jira-bot;Commit 8e0e0e1f5b64a0c9ca2010796c7cff5d368da3cf in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8e0e0e1 ]

ACCUMULO-2184 Fix ""Unknown"" HDFS usage entry in ""Accumulo Master"" table on overview monitor page
",13/Jan/14 19:10;mdrob;I thought we were getting rid of that box?,13/Jan/14 20:05;busbey;I think you're thinking of ACCUMULO-873,"13/Jan/14 20:53;elserj;bq. I thought we were getting rid of that box?

Nope

bq. I think you're thinking of ACCUMULO-873

Yup

Namenode/Jobtracker boxes are gone -- Master box is not. Master box calls out to HDFS to get FS usage amounts which is what this issue was fixing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
start-stats.sh isn't using the script boilerplate properly,ACCUMULO-2192,12688831,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,14/Jan/14 20:13,14/Jan/14 20:23,13/Mar/19 22:01,14/Jan/14 20:23,,,,,,,,1.6.0,,,test,,,,,,0,16_qa_bug,,,,running continuous ingest... and the start-stats.sh script didn't work.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-14 20:21:27.958,,,no_permission,,,,,,,,,,,,367798,,,Tue Jan 14 20:21:37 UTC 2014,,,,,,0|i1re9j:,368105,,,,,,,,"14/Jan/14 20:21;jira-bot;Commit 9747cc76799cfdbb8be2e30448ff738c0d0a31ce in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9747cc7 ]

ACCUMULO-2192 make the script boilerplate the first thing in the script
","14/Jan/14 20:21;jira-bot;Commit 9747cc76799cfdbb8be2e30448ff738c0d0a31ce in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9747cc7 ]

ACCUMULO-2192 make the script boilerplate the first thing in the script
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ExecfileCommand#execute() should close scanner,ACCUMULO-2176,12688350,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,yuzhihong@gmail.com,yuzhihong@gmail.com,10/Jan/14 22:50,13/Jan/14 15:29,13/Mar/19 22:01,10/Jan/14 23:35,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,,,,,"{code}
    Scanner scanner = new Scanner(new File(cl.getArgs()[0]));
    while (scanner.hasNextLine()) {
      shellState.execCommand(scanner.nextLine(), true, cl.hasOption(verboseOption.getOpt()));
    }
{code}
scanner should be closed upon return.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-10 23:24:39.442,,,no_permission,,,,,,,,,,,,367369,,,Fri Jan 10 23:35:49 UTC 2014,,,,,,0|i1rbnj:,367678,,,,,,,,"10/Jan/14 23:24;jira-bot;Commit 826dc4880ca1ed916d073dc101fe39d12f5c2fdb in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=826dc48 ]

ACCUMULO-2176 Ensure scanner is closed.
","10/Jan/14 23:34;jira-bot;Commit 826dc4880ca1ed916d073dc101fe39d12f5c2fdb in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=826dc48 ]

ACCUMULO-2176 Ensure scanner is closed.
","10/Jan/14 23:35;jira-bot;Commit 826dc4880ca1ed916d073dc101fe39d12f5c2fdb in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=826dc48 ]

ACCUMULO-2176 Ensure scanner is closed.
","10/Jan/14 23:35;jira-bot;Commit 826dc4880ca1ed916d073dc101fe39d12f5c2fdb in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=826dc48 ]

ACCUMULO-2176 Ensure scanner is closed.
","10/Jan/14 23:35;elserj;Thanks for the catch, [~yuzhihong@gmail.com]!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fresh installs report a lot of VFS warnings from scripts,ACCUMULO-2162,12688102,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,vines,vines,09/Jan/14 17:14,10/Jan/14 21:06,13/Mar/19 22:01,10/Jan/14 21:06,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Fresh start, run start-all, start-here, stop-all, etc. and I see one to several {code}2014-01-09 12:13:11,656 [vfs.UniqueFileReplicator] WARN : Directory does not exists: /tmp/accumulo-vfs-cache-john
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-10 19:49:55.687,,,no_permission,,,,,,,,,,,,367108,,,Fri Jan 10 21:04:39 UTC 2014,,,,,,0|i1ra1z:,367418,,,,,,,,10/Jan/14 19:49;elserj;Introduced in 5bd4e27cbc4dd800d88188c4b39f59447e02e44a according to git-bisect,"10/Jan/14 21:04;jira-bot;Commit deae04f670986ce7e465a89f61dd844d2d416903 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=deae04f ]

ACCUMULO-2162 Make better checks before warning the user.

Currently, multiple processes share one temp directory, which
means that the tempDir being unable to be deleted is expected,
and thus shouldn't be WARN'ed.
","10/Jan/14 21:04;jira-bot;Commit deae04f670986ce7e465a89f61dd844d2d416903 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=deae04f ]

ACCUMULO-2162 Make better checks before warning the user.

Currently, multiple processes share one temp directory, which
means that the tempDir being unable to be deleted is expected,
and thus shouldn't be WARN'ed.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ExamplesIT fails with Hadoop 1.2.1,ACCUMULO-2009,12684369,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,12/Dec/13 22:55,10/Jan/14 17:00,13/Mar/19 22:01,10/Jan/14 17:00,,,,,,,,1.6.0,,,,,,,,,0,,,,,"{noformat}
$ time mvn -Dhadoop.profile=1.2 -Dhadoop.version=1.2.1 -Daccumulo.it.forkCount=3 -Dtest=xyzzy -DfailIfNoTests=false -Dit.test=ExamplesIT clean verify

{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-12 22:57:25.252,,,no_permission,,,,,,,,,,,,363441,,,Fri Jan 10 17:00:48 UTC 2014,,,,,,0|i1qnbr:,363747,,,,,,,,"12/Dec/13 22:57;jira-bot;Commit 7f37d96c33df2a0a13aa868c55c32444920f6a90 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7f37d96 ]

ACCUMULO-2009 add commons-httpclient as a test dependency
","12/Dec/13 22:57;jira-bot;Commit 7f37d96c33df2a0a13aa868c55c32444920f6a90 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7f37d96 ]

ACCUMULO-2009 add commons-httpclient as a test dependency
",10/Jan/14 17:00;elserj;This works for me now. Please reopen if there's something that still needs to be done.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
example accumulo-site.xmls put Hadoop 2 jars ahead of Accumulo jars on classpath,ACCUMULO-2127,12687061,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,benpopp,benpopp,02/Jan/14 22:16,07/Jan/14 18:49,13/Mar/19 22:01,03/Jan/14 23:48,,,,,,,,1.4.5,1.5.1,1.6.0,,,,,,,0,newbie,,,,"conf/examples/1GB/native-standalone/accumulo-site.xml currently reads 

{noformat}
  <property>
    <name>general.classpaths</name>
    <value>
      <!-- Comment the following for hadoop-1.2 -->
      $HADOOP_PREFIX/share/hadoop/common/.*.jar,
      $HADOOP_PREFIX/share/hadoop/common/lib/.*.jar,
      $HADOOP_PREFIX/share/hadoop/hdfs/.*.jar,
      $HADOOP_PREFIX/share/hadoop/mapreduce/.*.jar,
      $HADOOP_PREFIX/share/hadoop/yarn/.*.jar,
      /usr/lib/hadoop/.*.jar,
      /usr/lib/hadoop/lib/.*.jar,
      /usr/lib/hadoop-hdfs/.*.jar,
      /usr/lib/hadoop-mapreduce/.*.jar,
      /usr/lib/hadoop-yarn/.*.jar,

      $ACCUMULO_HOME/lib/accumulo-server.jar,
      $ACCUMULO_HOME/lib/accumulo-core.jar,
      $ACCUMULO_HOME/lib/accumulo-start.jar,
      $ACCUMULO_HOME/lib/accumulo-fate.jar,
      $ACCUMULO_HOME/lib/accumulo-proxy.jar,
      $ACCUMULO_HOME/lib/[^.].*.jar,
      $ZOOKEEPER_HOME/zookeeper[^.].*.jar,
      $HADOOP_CONF_DIR,
      $HADOOP_PREFIX/[^.].*.jar,
      $HADOOP_PREFIX/lib/[^.].*.jar,
    </value>
    <description>Classpaths that accumulo checks for updates and class files.</description>
  </property>
{noformat}

this has the unusual property of sticking Hadoop jars before Accumulo jars on the classpath when using Hadoop 2.  

we discovered this issue when one of our custom iterators loaded up the wrong version of guava (Hadoop 2.2.0's guava 11.0.2 instead of Accumulo 1.6.0-SNAPSHOT's guava 14) due to this ordering.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-02 22:25:12.785,,,no_permission,,,,,,,,,,,,366056,,,Fri Jan 03 23:48:44 UTC 2014,,,,,,0|i1r3kn:,366367,,,,,,,,"02/Jan/14 22:25;mdrob;[~benpopp], thanks for the bug report! Would you be interested in submitting a patch for this, as well?","03/Jan/14 23:09;jira-bot;Commit a561152c8dc5216be00dc0dcea526668ea8f1177 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a561152 ]

ACCUMULO-2127 Add note to append hadoop2 classpath entries in example configs
","03/Jan/14 23:12;jira-bot;Commit a561152c8dc5216be00dc0dcea526668ea8f1177 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a561152 ]

ACCUMULO-2127 Add note to append hadoop2 classpath entries in example configs
","03/Jan/14 23:31;jira-bot;Commit a561152c8dc5216be00dc0dcea526668ea8f1177 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a561152 ]

ACCUMULO-2127 Add note to append hadoop2 classpath entries in example configs
","03/Jan/14 23:31;jira-bot;Commit a561152c8dc5216be00dc0dcea526668ea8f1177 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a561152 ]

ACCUMULO-2127 Add note to append hadoop2 classpath entries in example configs
","03/Jan/14 23:48;elserj;Thanks for reporting, [~benpopp].",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
typo in continuous-env.sh.example,ACCUMULO-2146,12687684,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,busbey,busbey,busbey,07/Jan/14 16:56,07/Jan/14 17:57,13/Mar/19 22:01,07/Jan/14 17:57,1.4.5,1.5.1,,,,,,1.4.5,1.5.1,1.6.0,docs,test,,,,,0,,,,,"The AGITATE_HDFS_COMMAND given is missing part of defaulting to /usr/lib/hadoop.

As is, attempting to use it will result in a bash warning about not parsing it. (but continuous still runs AFAICT)

Workaround: edit it to be something else (e.g. `which hdfs` )",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,07/Jan/14 16:58;busbey;ACCUMULO-2146.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12621813/ACCUMULO-2146.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-01-07 17:56:12.823,,,no_permission,,,,,,,,,,,,366684,,,Tue Jan 07 17:57:54 UTC 2014,,,,,,0|i1r7fz:,366995,,,,,,,,"07/Jan/14 17:56;jira-bot;Commit d2a1fe7a236a099170805c76dc862648bb7fb087 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d2a1fe7 ]

ACCUMULO-2146 correctly default the hdfs command for hadoop 2.
","07/Jan/14 17:56;jira-bot;Commit d2a1fe7a236a099170805c76dc862648bb7fb087 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d2a1fe7 ]

ACCUMULO-2146 correctly default the hdfs command for hadoop 2.
","07/Jan/14 17:56;jira-bot;Commit d2a1fe7a236a099170805c76dc862648bb7fb087 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d2a1fe7 ]

ACCUMULO-2146 correctly default the hdfs command for hadoop 2.
","07/Jan/14 17:57;jira-bot;Commit d2a1fe7a236a099170805c76dc862648bb7fb087 in branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d2a1fe7 ]

ACCUMULO-2146 correctly default the hdfs command for hadoop 2.
","07/Jan/14 17:57;mdrob;Thanks for the patch, Sean!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Backport fix for Accumulo-1379 PermGen Leak to 1.4 and 1.5,ACCUMULO-1858,12677874,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,busbey,acordova,acordova,06/Nov/13 22:02,06/Jan/14 22:44,13/Mar/19 22:01,19/Nov/13 18:00,1.4.3,1.5.0,,,,,,1.4.5,1.5.1,,,,,,,,0,,,,,Apply bug fix for the way zookeeper client is handled in ACCUMULO-1379 to Accumulo versions 1.4 and 1.5.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2027,,,,,,,,,,,15/Nov/13 05:41;jaredwinick;ACCUMULO-1858-no-patch.png;https://issues.apache.org/jira/secure/attachment/12614016/ACCUMULO-1858-no-patch.png,15/Nov/13 05:41;jaredwinick;ACCUMULO-1858-patch-close.png;https://issues.apache.org/jira/secure/attachment/12614017/ACCUMULO-1858-patch-close.png,13/Nov/13 20:41;busbey;ACCUMULO-1858.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12613680/ACCUMULO-1858.1.patch.txt,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2013-11-13 16:11:20.697,,,no_permission,,,,,,,,,,,,357249,,,Mon Jan 06 22:44:30 UTC 2014,,,,,,0|i1pl4f:,357539,,,,,,,,"13/Nov/13 16:11;busbey;attaching review board for backport of patches related to ACCUMULO-1379 to 1.4.

I'm inclined to squash these into a single commit when submitting the patch. People wanting to trace history will have to use the ""cherry picked from commit..."" links to follow it manually either way. Please let me know if leaving them as two commits is preferable.

Once the 1.4 version is fine by reviewboard, I'll attach it here and work out what's still needed after merging forward to 1.5.
",13/Nov/13 20:37;ctubbsii;We should not be backporting this until its behavior is actually finalized in a release.,13/Nov/13 20:40;busbey;It was a bugfix originally reported against 1.4 and 1.5. Shouldn't we be targeting the fix of said bug against all supported versions as we go?,13/Nov/13 20:41;busbey;Attaching patch that provides ACCUMULO-1379 against 1.4 as single commit.,"13/Nov/13 21:08;ctubbsii;Targeting the bugfix for an older version is fine. No objections here. However, ACCUMULO-1379 is only marked as fixed for 1.6.0, so it is not clear that the fix is appropriate or applicable for the older versions.

The bugfix probably should have been applied to 1.4 and merged forward to 1.6. The important thing is that we need to be consistent. I'd hate to have only a partially complete fix in 1.4 and 1.5, and the implementation we really want only in the latest branch.","13/Nov/13 21:16;busbey;Right exactly. I think originally the work on ACCUMULO-1379 was going to be some retooling of our ZooKeeper stuff, so it targetted 1.6.0. That ended up not happening. Instead it's a much more straightforward bugfix that probably should have targetted 1.4 and been merged forward to 1.6.

I think treating that omission as a bug and then applying future fixes (like ACCUMULO-1889) properly is the easiest way to make sure we remain consistent.","13/Nov/13 21:25;busbey;Patch updated per Chris' suggestion. Review board also updated, restarting functional tests.",13/Nov/13 21:26;busbey;(patch removed. wrong ticket. :/ ),"14/Nov/13 16:33;acordova;The ticket is marked as fixed for 1.6, but also as affecting 1.4 and 1.5. The same fix that has been applied to 1.6 may not apply to 1.4/5, but 1.4/5 still have the issue, and so will need _a_ fix, if not the one in 1.6.","14/Nov/13 17:13;bills;So, what's the actual hold up? It seems more appropriate that this is a bug fix overlapping with work done in another ticket. [~ctubbsii] are you concerned about clean history and ticket management, or the efficacy of this fix?","14/Nov/13 17:45;elserj;IMO, if we're backporting & improving, just change the ticket name.. If we're splitting up the backport and then improvement, make a new ticket for the improvement portion.","15/Nov/13 01:35;ctubbsii;[~bills], I have no outstanding concerns. I was just confused about what was applied when and on which branch, and which ticket was trying to do what.","15/Nov/13 05:52;jaredwinick;I have successfully tested Sean's patch today using the simple web application found at https://github.com/jaredwinick/accumulo-1858-test/. The testing applied the patch to the 1.4.3 tag as that is the version currently being used by a customer. I was using Zookeeper 3.3.6 and JBoss 7.1.1. 

The attached ACCUMULO-1858-no-patch.png shows the behavior, prior to the patch being applied, of successive redeploys (https://github.com/jaredwinick/accumulo-1858-test/blob/master/redeploy.sh) until JBoss finally dies with the OOM error. ACCUMULO-1858-patch-close.png shows the behavior with the patch applied. You can see the thread count holding steady over time and GC cleaning up space/classes when needed.

The one caveat we found is that the close() method doesn't block until the ZK threads have actually been shutdown (nor does this look possible with the ZK API). If close() is called and the SevletContextListener.contextDestoryed() method returns immediately, the container starts to clean up resources. There appears to be a race condition between the container cleaning up resources and the ZK SendThread actually shutting down and we have thus repeatedly seen ""java.lang.NoClassDefFoundError: org/apache/zookeeper/server/ZooTrace"" errors when the ZK thread tries to log a message after the container has already unloaded the ZooTrace class. It appears this situation can be avoided by sleeping for a few seconds after calling close() as seen in https://github.com/jaredwinick/accumulo-1858-test/blob/master/src/main/java/com/koverse/ApplicationServletContextListener.java 
",15/Nov/13 06:02;jaredwinick;Forgot to mention that this testing was done with the patch for ACCUMULO-1889 applied as well.,15/Nov/13 16:51;kturner;[~jaredwinick] sleeping is a solution for the short term.  Do you have any thoughts on a more long term solution?  Do you think a zookeeper ticket needs to be opened?,"15/Nov/13 19:04;busbey;If there's no way for us to ensure the threads have exited before we return, then we should file a ZooKeeper ticket.

Is the sleep really necessary? [~jaredwinick] does the NoClassDefFoundError cause an error in undeploying? Could the work-around for now involve a sleep on the part of the person calling close() if they want to avoid the log message?","15/Nov/13 20:05;jaredwinick;No, the NoClassDefFoundError doesn't seem to cause a problem besides the log message. I definitely agree the sleep should be the responsibility of the user and not the ZooKeeperInstance.

I think this would be a reasonable Zookeeper ticket which I am happy to write up. Without intimate knowledge of their code, it seems like a sendThread.join() and eventThread.join() after line 1304 http://svn.apache.org/viewvc/zookeeper/tags/release-3.3.6/src/java/main/org/apache/zookeeper/ClientCnxn.java?revision=1368082&view=markup would do the trick, right? Either way, the fix I think we would want is to make the ZooKeeper.close() (and internally the ClientCnxn.close()) block until the threads have stopped.

BTW, someone brought this up on the ZK mailing list this summer but didn't get a response http://mail-archives.apache.org/mod_mbox/zookeeper-user/201306.mbox/%3CBAY174-W21494DF40247669DA7B719A89B0@phx.gbl%3E

If you guys think this sounds right, I can write up a ZooKeeper issue referencing the testing done here. I will also verify the behavior on v3.4.5. ",15/Nov/13 20:18;busbey;That all sounds correct.,"15/Nov/13 21:39;jaredwinick;Until this issue is fixed in ZooKeeper, users running an Accumulo client inside a container such as JBoss or Tomcat will need to sleep momentarily after closing the ZooKeeperInstance and before letting the container finishing undeploying the application to avoid potentially seeing a ""java.lang.NoClassDefFoundError: org/apache/zookeeper/server/ZooTrace""",15/Nov/13 21:41;jaredwinick;Previous comment was referring to the link to ZOOKEEPER-1816,"18/Nov/13 18:18;jira-bot;Commit 79d686faa1e477b9cbd80c6f833ece402050b490 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=79d686f ]

ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.

Fix cherry picks two commits:

ACCUMULO-1379 - Adding close() to Instance to assist in freeing up resources

(cherry picked from commit 7da1164d87227960d3e0cfc841f753067e2c0304)

Reason: bugfix
Author: John Vines <jvines@gmail.com>

Differs from original by path changes and leaving out ConditionalWriterTest, which is only in 1.6.0+

----

ACCUMULO-1379 Fix edge cases if error in closing ZooKeeperInstance

(cherry picked from commit 3f6c66ede52cb1fb5a122d7bad06d7978ff0a671)

Reason: bugfix
Author: Christopher Tubbs <ctubbsii@apache.org>

Signed-off-by: Bill Slacum <ujustgotbilld@apache.org>
","18/Nov/13 19:38;jira-bot;Commit 79d686faa1e477b9cbd80c6f833ece402050b490 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=79d686f ]

ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.

Fix cherry picks two commits:

ACCUMULO-1379 - Adding close() to Instance to assist in freeing up resources

(cherry picked from commit 7da1164d87227960d3e0cfc841f753067e2c0304)

Reason: bugfix
Author: John Vines <jvines@gmail.com>

Differs from original by path changes and leaving out ConditionalWriterTest, which is only in 1.6.0+

----

ACCUMULO-1379 Fix edge cases if error in closing ZooKeeperInstance

(cherry picked from commit 3f6c66ede52cb1fb5a122d7bad06d7978ff0a671)

Reason: bugfix
Author: Christopher Tubbs <ctubbsii@apache.org>

Signed-off-by: Bill Slacum <ujustgotbilld@apache.org>
","18/Nov/13 19:46;jira-bot;Commit a7c5b72d3b5b28775106adf87dab2f76f5c1430e in branch refs/heads/1.5.1-SNAPSHOT from Bill Slacum
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a7c5b72 ]

ACCUMULO-1858 Fixed compilation error from bad merge.

The old merge&push bit me as I was missing a '}'.
","18/Nov/13 23:32;jira-bot;Commit a7c5b72d3b5b28775106adf87dab2f76f5c1430e in branch refs/heads/1.6.0-SNAPSHOT from Bill Slacum
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a7c5b72 ]

ACCUMULO-1858 Fixed compilation error from bad merge.

The old merge&push bit me as I was missing a '}'.
","18/Nov/13 23:33;jira-bot;Commit c10ccf375b97c1882d5b89decd701bbdae7f71ef in branch refs/heads/1.6.0-SNAPSHOT from Bill Slacum
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c10ccf3 ]

Merge remote-tracking branch 'apache-committers/1.5.1-SNAPSHOT' into 1.6.0-SNAPSHOT

Did a merge for ACCUMULO-1858 and picked some ""Elser"" slack.

Conflicts:
	core/src/main/java/org/apache/accumulo/core/client/ZooKeeperInstance.java
	server/base/src/main/java/org/apache/accumulo/server/client/HdfsZooInstance.java
","18/Nov/13 23:42;jira-bot;Commit c10ccf375b97c1882d5b89decd701bbdae7f71ef in branch refs/heads/master from Bill Slacum
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c10ccf3 ]

Merge remote-tracking branch 'apache-committers/1.5.1-SNAPSHOT' into 1.6.0-SNAPSHOT

Did a merge for ACCUMULO-1858 and picked some ""Elser"" slack.

Conflicts:
	core/src/main/java/org/apache/accumulo/core/client/ZooKeeperInstance.java
	server/base/src/main/java/org/apache/accumulo/server/client/HdfsZooInstance.java
",19/Nov/13 17:44;busbey;I believe this can be marked closed now?,19/Nov/13 18:00;acordova;Marking resolved.,"06/Jan/14 22:35;jira-bot;Commit e946ba052c3fcce8d07815b9daf51bcdc3febbd3 in branch refs/heads/1.4.5-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e946ba0 ]

ACCUMULO-1858 revert commits that added ZooKeeperInstance.close()

Revert ""ACCUMULO-2027 Synchronized access to ZooKeeperInstance methods that mutated state""

This reverts commit 975e8c05e8d11f3848e6c800f4d2772026f6c3a3.

Revert ""ACCUMULO-1984 Rework interruption for instance implementations.""

This reverts commit 0d0bc4643a8680593e2cf5f828b7566c30fcb345.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java

Revert ""ACCUMULO-1889 mark ZKI as closed once close() is called.""

This reverts commit ada4180379d46297c1531cf8065de5030d12953d.

Revert ""ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.""

This reverts commit 79d686faa1e477b9cbd80c6f833ece402050b490.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
","06/Jan/14 22:38;jira-bot;Commit e946ba052c3fcce8d07815b9daf51bcdc3febbd3 in branch refs/heads/1.4.5-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e946ba0 ]

ACCUMULO-1858 revert commits that added ZooKeeperInstance.close()

Revert ""ACCUMULO-2027 Synchronized access to ZooKeeperInstance methods that mutated state""

This reverts commit 975e8c05e8d11f3848e6c800f4d2772026f6c3a3.

Revert ""ACCUMULO-1984 Rework interruption for instance implementations.""

This reverts commit 0d0bc4643a8680593e2cf5f828b7566c30fcb345.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java

Revert ""ACCUMULO-1889 mark ZKI as closed once close() is called.""

This reverts commit ada4180379d46297c1531cf8065de5030d12953d.

Revert ""ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.""

This reverts commit 79d686faa1e477b9cbd80c6f833ece402050b490.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
","06/Jan/14 22:38;jira-bot;Commit e946ba052c3fcce8d07815b9daf51bcdc3febbd3 in branch refs/heads/1.5.1-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e946ba0 ]

ACCUMULO-1858 revert commits that added ZooKeeperInstance.close()

Revert ""ACCUMULO-2027 Synchronized access to ZooKeeperInstance methods that mutated state""

This reverts commit 975e8c05e8d11f3848e6c800f4d2772026f6c3a3.

Revert ""ACCUMULO-1984 Rework interruption for instance implementations.""

This reverts commit 0d0bc4643a8680593e2cf5f828b7566c30fcb345.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java

Revert ""ACCUMULO-1889 mark ZKI as closed once close() is called.""

This reverts commit ada4180379d46297c1531cf8065de5030d12953d.

Revert ""ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.""

This reverts commit 79d686faa1e477b9cbd80c6f833ece402050b490.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
","06/Jan/14 22:41;jira-bot;Commit e946ba052c3fcce8d07815b9daf51bcdc3febbd3 in branch refs/heads/1.5.1-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e946ba0 ]

ACCUMULO-1858 revert commits that added ZooKeeperInstance.close()

Revert ""ACCUMULO-2027 Synchronized access to ZooKeeperInstance methods that mutated state""

This reverts commit 975e8c05e8d11f3848e6c800f4d2772026f6c3a3.

Revert ""ACCUMULO-1984 Rework interruption for instance implementations.""

This reverts commit 0d0bc4643a8680593e2cf5f828b7566c30fcb345.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java

Revert ""ACCUMULO-1889 mark ZKI as closed once close() is called.""

This reverts commit ada4180379d46297c1531cf8065de5030d12953d.

Revert ""ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.""

This reverts commit 79d686faa1e477b9cbd80c6f833ece402050b490.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
","06/Jan/14 22:41;jira-bot;Commit e946ba052c3fcce8d07815b9daf51bcdc3febbd3 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e946ba0 ]

ACCUMULO-1858 revert commits that added ZooKeeperInstance.close()

Revert ""ACCUMULO-2027 Synchronized access to ZooKeeperInstance methods that mutated state""

This reverts commit 975e8c05e8d11f3848e6c800f4d2772026f6c3a3.

Revert ""ACCUMULO-1984 Rework interruption for instance implementations.""

This reverts commit 0d0bc4643a8680593e2cf5f828b7566c30fcb345.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java

Revert ""ACCUMULO-1889 mark ZKI as closed once close() is called.""

This reverts commit ada4180379d46297c1531cf8065de5030d12953d.

Revert ""ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.""

This reverts commit 79d686faa1e477b9cbd80c6f833ece402050b490.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
","06/Jan/14 22:44;jira-bot;Commit e946ba052c3fcce8d07815b9daf51bcdc3febbd3 in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e946ba0 ]

ACCUMULO-1858 revert commits that added ZooKeeperInstance.close()

Revert ""ACCUMULO-2027 Synchronized access to ZooKeeperInstance methods that mutated state""

This reverts commit 975e8c05e8d11f3848e6c800f4d2772026f6c3a3.

Revert ""ACCUMULO-1984 Rework interruption for instance implementations.""

This reverts commit 0d0bc4643a8680593e2cf5f828b7566c30fcb345.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooReader.java

Revert ""ACCUMULO-1889 mark ZKI as closed once close() is called.""

This reverts commit ada4180379d46297c1531cf8065de5030d12953d.

Revert ""ACCUMULO-1858 Backport ZooKeeper clean up to 1.4 and 1.5.""

This reverts commit 79d686faa1e477b9cbd80c6f833ece402050b490.

Conflicts:
	src/core/src/main/java/org/apache/accumulo/core/client/Instance.java
	src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java
",,,,,,,,,,,,,,,,,,,,
Concurrent random walk test fails,ACCUMULO-2054,12685412,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,18/Dec/13 16:50,02/Jan/14 14:12,13/Mar/19 22:01,19/Dec/13 21:32,,,,,,,,1.6.0,,,test,,,,,,0,16_qa_bug,,,,"Random walk testing, the namespace test sometimes fails:

{noformat}
18 16:21:54,810 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Concurrent.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.accumulo.start.Main$1.run(Main.java:137)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.Exception: Error running node ct.CreateTable
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloSecurityException: Error NAMESPACE_DOESNT_EXIST for user root on table nspc_001.ctt_002(?) - Unknown security exception
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:316)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:296)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.create(TableOperationsImpl.java:224)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.create(TableOperationsImpl.java:193)
        at org.apache.accumulo.test.randomwalk.concurrent.CreateTable.visit(CreateTable.java:42)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 9 more
Caused by: ThriftSecurityException(user:root, code:NAMESPACE_DOESNT_EXIST)
        at org.apache.accumulo.core.master.thrift.MasterClientService$executeTableOperation_result$executeTableOperation_resultStandardScheme.read(MasterClientService.java:19067)
        at org.apache.accumulo.core.master.thrift.MasterClientService$executeTableOperation_result$executeTableOperation_resultStandardScheme.read(MasterClientService.java:19053)
        at org.apache.accumulo.core.master.thrift.MasterClientService$executeTableOperation_result.read(MasterClientService.java:18995)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Client.recv_executeTableOperation(MasterClientService.java:582)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Client.executeTableOperation(MasterClientService.java:563)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.executeTableOperation(TableOperationsImpl.java:252)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:305)
        ... 14 more
{noformat}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1965,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-31 00:35:50.162,,,no_permission,,,,,,,,,,,,364489,,,Tue Dec 31 14:19:19 UTC 2013,,,,,,0|i1qtqf:,364789,,,,,,,,31/Dec/13 00:35;ctubbsii;This is marked as fixed. What fixed it?,"31/Dec/13 14:19;ecn;ACCUMULO-1965
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Examples functional test only works when run from ACCUMULO_HOME,ACCUMULO-2116,12686877,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,busbey,busbey,busbey,31/Dec/13 21:28,31/Dec/13 22:46,13/Mar/19 22:01,31/Dec/13 22:46,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,,test,,,,,,0,,,,,one of the example functional tests refers to directories in ACCUMULO_HOME via relative paths that presume the working directory is ACCUMULO_HOME.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31/Dec/13 21:39;busbey;ACCUMULO-2116.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12620986/ACCUMULO-2116.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-12-31 22:30:21.294,,,no_permission,,,,,,,,,,,,365872,,,Tue Dec 31 22:44:20 UTC 2013,,,,,,0|i1r2ev:,366178,,,,,,,,31/Dec/13 21:39;busbey;simple patch to add explicit references to ACCUMULO_HOME,"31/Dec/13 22:30;jira-bot;Commit 1ad1151ab0ae2c57ff998cf563cbe6a019994724 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1ad1151 ]

ACCUMULO-2116 Examples functional test should run from outside of ACCUMULO_HOME.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
","31/Dec/13 22:42;jira-bot;Commit 1ad1151ab0ae2c57ff998cf563cbe6a019994724 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1ad1151 ]

ACCUMULO-2116 Examples functional test should run from outside of ACCUMULO_HOME.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
","31/Dec/13 22:44;jira-bot;Commit 1ad1151ab0ae2c57ff998cf563cbe6a019994724 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1ad1151 ]

ACCUMULO-2116 Examples functional test should run from outside of ACCUMULO_HOME.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
functional tests do not clean up generated test site.xml files,ACCUMULO-2109,12686603,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,busbey,busbey,busbey,28/Dec/13 07:28,31/Dec/13 21:40,13/Mar/19 22:01,31/Dec/13 21:39,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,,test,,,,,,0,,,,,"the tearDown code for the functional tests tries to delete the generated accumulo-site.xml file from $ACCUMULO_HOME/conf, even though they are generated in $ACCUMULO_CONF_DIR.

When these are not pointing to the same place, the files are left behind.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,28/Dec/13 07:52;busbey;ACCUMULO-2109.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12620725/ACCUMULO-2109.1.patch.txt,31/Dec/13 21:06;busbey;ACCUMULO-2109.2.patch.txt;https://issues.apache.org/jira/secure/attachment/12620983/ACCUMULO-2109.2.patch.txt,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-12-30 13:33:15.508,,,no_permission,,,,,,,,,,,,365594,,,Tue Dec 31 21:39:36 UTC 2013,,,,,,0|i1r0pb:,365901,,,,,,,,"30/Dec/13 13:33;mdrob;Why not use the existing path created at line 83?

Edit: Because it refers to a different file.

Revised query: Why not refactor the references on 264 and 458 out into a single variable?","30/Dec/13 14:00;busbey;I try to minimize change sizes, especially when we have to merge through 2 branches.",31/Dec/13 21:06;busbey;Updated patch for Mike's feedback. also turned up related issue with config file use in a few tests.,"31/Dec/13 21:39;jira-bot;Commit d605ebb52a14d4d1964b01dcb5bb5ccad4fa6fb9 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d605ebb ]

ACCUMULO-2109 make sure functional tests clean up generate accumulo-site file.

Signed-off-by: Mike Drob <mdrob@cloudera.com>
","31/Dec/13 21:39;jira-bot;Commit d605ebb52a14d4d1964b01dcb5bb5ccad4fa6fb9 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d605ebb ]

ACCUMULO-2109 make sure functional tests clean up generate accumulo-site file.

Signed-off-by: Mike Drob <mdrob@cloudera.com>
","31/Dec/13 21:39;jira-bot;Commit d605ebb52a14d4d1964b01dcb5bb5ccad4fa6fb9 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d605ebb ]

ACCUMULO-2109 make sure functional tests clean up generate accumulo-site file.

Signed-off-by: Mike Drob <mdrob@cloudera.com>
","31/Dec/13 21:39;jira-bot;Commit d605ebb52a14d4d1964b01dcb5bb5ccad4fa6fb9 in branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d605ebb ]

ACCUMULO-2109 make sure functional tests clean up generate accumulo-site file.

Signed-off-by: Mike Drob <mdrob@cloudera.com>
","31/Dec/13 21:39;mdrob;Patch applied. Thanks, Sean!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
start-here.sh starts only one GC process even if more are defined,ACCUMULO-1901,12679497,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,texpilot,texpilot,texpilot,15/Nov/13 21:42,19/Dec/13 20:19,13/Mar/19 22:01,19/Dec/13 20:19,1.4.2,1.4.3,1.4.4,1.5.0,,,,1.4.5,1.5.1,1.6.0,gc,scripts,,,,,0,gc,newbie,,,"Even when a second host is listed in the gc file, the gc process is only ever started on the first host listed in the gc file.  The issue lies in lines 48-55 in start-here.sh as shown below:

{code}
for host in $HOSTS
do
    if [ ${host} = ${GC} ]
    then
        ${bin}/start-server.sh $GC gc ""garbage collector""
        break
    fi
done
{code}

Simple fix:

{code}
for host in $HOSTS
do
    if grep -q ""^${host}\$"" $ACCUMULO_HOME/conf/gc
    then
        ${bin}/start-server.sh ${host} gc ""garbage collector""
        break
    fi
done
{code}

This fix works in my 1.4.2 environment.  stop-here.sh already sweeps all possible processes to kill them, so I assumed no fix was needed there, but on my last cluster shutdown I found the stop-all.sh script only stopped the GC on the Master host. That fix is still outstanding.",Red Hat Enterprise Linux 6.3 64-bit,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,ACCUMULO-1967,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-15 22:07:25.624,,,no_permission,,,,,,,,,,,,358857,,,Thu Dec 19 20:19:57 UTC 2013,,,,,,0|i1pv1b:,359147,,,,,,,,15/Nov/13 21:44;texpilot;Clearly I don't know how to format code here on JIRA ... sorry about that.,"15/Nov/13 22:07;busbey;Formatting fixed.

Is the GC role expecting there to be multiple instances? the manual doesn't really shed any light.","16/Nov/13 00:10;texpilot;Per this thread:
http://mail-archives.apache.org/mod_mbox/accumulo-user/201311.mbox/%3cCAPnhrdvhgKL+vSK1s-Sq9V+14YZ1cP5kh=kX1+BhO9OKH1t2Mg@mail.gmail.com%3e

Josh Elser looked at the code and stated multiple GC processes can run and they will use Zookeeper to perform failover (like the master process).  I haven't tested failover part yet but hope to do so next week. I did configure gc to run on my standby master / secondary namenode and during cluster startup the gc process started as it should.",16/Nov/13 04:07;busbey;Excellent. Please reach out if you need any help with [putting together your patch|http://accumulo.apache.org/git.html#contributors].,"17/Nov/13 20:15;texpilot;Thanks Sean. I'm a newbie with git, so I want to ensure I do the commit step properly. My questions are:

1. 'git help commit' says ""even modified files must be 'added'"" but the Accumulo Contributor instructions don't mention doing a 'git add' at all.  Do I need to first to a 'git add' for the filename I'm changing / going to change?

2. Step 5 ""Make commits"" mentions ""referencing the issue name in the commit message"", but the syntax shown doesn't include the -m switch that I see in the git commit help.  I assume a more complete syntax example for my case would be:

git commit -av -m ""ACCUMULO-1901"" bin/start-here.sh

Or if I do it from the directory where my code change was done, do I even need to include the filename? Or ever? (meaning does git commit everything in its index automatically?)  Again, I'm brand new to git and want to do this right the first time.

Thanks for the help!","18/Nov/13 00:05;busbey;Happy to help Terry. I was going to recommend we take this to the dev@accumulo list. Since you posted things over there, I'll respond in kind. :)","19/Nov/13 04:59;texpilot;Thanks for your excellent reply Sean, I appreciate all the time you took and learned a lot from it. I've prepared the patch for 1.4.5 and will submit it in a second. I'd appreciate if you could take a look and see how I did.

If it looks right, do I repeat against the 1.5.1 and 1.6.0 Snapshots, or will you guys merge this patch into those branches?","19/Nov/13 05:00;texpilot;Corrects start-here.sh to spin up multiple GCs if defined. Still need to resolve shutdown issue, as stop-all.sh seems to only stop the GC on the master host.","19/Nov/13 05:02;texpilot;(the above comment was included in my ""Submit Patch"" action; didn't know it would show up here or I would have been a tad more descriptive)","19/Nov/13 05:02;elserj;[~texpilot], we'll merge it through. If there are excessive conflicts between versions, we might ask for a new patch for a given version.","19/Nov/13 17:15;jira-bot;Commit 4976a935f2566ee648d20c3bc5381bc22edc51ec in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4976a93 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:15;jira-bot;Commit ffb26a25ffc94d28a9e1de93054ed5a8590cb943 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ffb26a2 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:15;jira-bot;Commit d8b4ba9424d5cb7b2f1260f63386b2c7f478b306 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d8b4ba9 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:15;jira-bot;Commit 6f07d7aaacaa93ce8dbcb1747bc1bccdfade008b in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6f07d7a ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:15;jira-bot;Commit 6f07d7aaacaa93ce8dbcb1747bc1bccdfade008b in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6f07d7a ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:16;jira-bot;Commit 6f07d7aaacaa93ce8dbcb1747bc1bccdfade008b in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6f07d7a ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:37;jira-bot;Commit d8b4ba9424d5cb7b2f1260f63386b2c7f478b306 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d8b4ba9 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:37;jira-bot;Commit 487eec38f41429c61aca2699b44c349c1836bc7d in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=487eec3 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:43;jira-bot;Commit 4976a935f2566ee648d20c3bc5381bc22edc51ec in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4976a93 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:44;jira-bot;Commit ffb26a25ffc94d28a9e1de93054ed5a8590cb943 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ffb26a2 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:44;jira-bot;Commit d8b4ba9424d5cb7b2f1260f63386b2c7f478b306 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d8b4ba9 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:44;jira-bot;Commit 487eec38f41429c61aca2699b44c349c1836bc7d in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=487eec3 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:45;jira-bot;Commit ffb26a25ffc94d28a9e1de93054ed5a8590cb943 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=ffb26a2 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:45;jira-bot;Commit d8b4ba9424d5cb7b2f1260f63386b2c7f478b306 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d8b4ba9 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
","19/Nov/13 17:45;jira-bot;Commit 487eec38f41429c61aca2699b44c349c1836bc7d in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=487eec3 ]

ACCUMULO-1901 treat the gc start/stop like the redundant masters
",04/Dec/13 19:07;kturner;I was looking into merging the patch in ACCUMULO-1785 and it conflicted with this change.  While looking at this change for 1.4.5 I noticed it changes the conf/gc file from optional to required.   I do not think this should be done in a bug fix release.,04/Dec/13 19:15;billie.rinaldi;I think we should keep the gc file optional.,"04/Dec/13 19:19;elserj;What happens when you have no gc file? No gc process? Use the master instead?

To be honest, I never realized that the gc file was optional.","04/Dec/13 19:37;billie.rinaldi;I think it just doesn't start a gc process.  Actually, I guess keeping the file optional isn't that important to me since we have the example configurations to copy.  Prior to that, I recall it being nice to be able to get started with a minimal configuration.","04/Dec/13 19:40;ecn;It used to use the masters file.  Specifically, just the first entry in the masters file.","04/Dec/13 22:42;texpilot;I think it's good that this was reopened -- I just found that the secondary gc doesn't get started when start-all.sh is used. It works if a service script is used, which I use and that's why I missed it.  The issue is on line 55 of start-all.sh; that bit needs to look more like lines 50-53 for multiple masters.

With respect to the gc file being mandatory or optional: in bin/config.sh, the GC variable is set to the value of the MASTER1 variable. So I think the gc file can remain optional if the master file is mandatory.  To avoid any runtime script errors from being reported, start-here.sh and start-all.sh should check to see if the gc file exists; if it does, process it; if not, run the traditional command to start the GC on the server found in variables $GC.

Tonight I'll change the start-here.sh script to check for the existence of the gc file as described above, and make similar changes to the start-all.sh entry on line 55, and see if I missed any changes needed in any of the stop-* scripts.","05/Dec/13 18:21;busbey;Part of the change in behavior on 1.4.5-SNAPSHOT is that, as is, when starting in stand-alone mode there won't be a GC process.

[~texpilot], falling back to the GC variable won't work ATM because the variable just doesn't exit. Rather than reinstate that variable, I'd recommend you look to make the gc file optional by following the same approach used with the tracer file. Namely, in bin/config.sh if ACCUMULO_VERIFY_ONLY isn't set then you write out a gc file that contains just the first master from the masters file.","13/Dec/13 22:01;mdrob;[~texpilot], are you still working on this? I can pick it up if other priorities have gotten in the way.","14/Dec/13 00:01;mdrob;Working on cleaning up the code paths here, I'm seeking some confirmation - running all any of tracers, gc, and monitor should be completely optional, right?","14/Dec/13 01:58;texpilot;Mike Drob, if you have the bandwidth, that would be great. It's crunch time for project delivery and I've had no spare time at home. You're far more knowledgeable than I am on Accumulo, but if there's anything I can help with, let me know. Thanks!","14/Dec/13 05:27;busbey;[~mdrob], the original behavior of the start scripts in 1.4.x was that *specifying* a host for tracers, gc, and monitor was all optional. In the case of not specifying a config file for any of these, the first host listed in the masters file was used instead.

If you don't use ""start-all.sh"" (or ""start-here.sh"" on the first host in the masters file) then running said processes would be optional.
",19/Dec/13 20:19;mdrob;I believe this was re-resolved with ACCUMULO-2015,,,,,,,,,,,,,,,,,
Cannot bind monitor on remote host to all interfaces,ACCUMULO-1985,12683316,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,08/Dec/13 04:57,19/Dec/13 16:55,13/Mar/19 22:01,09/Dec/13 03:11,1.5.0,,,,,,,1.5.1,1.6.0,,scripts,,,,,,0,,,,,"To get the monitor to bind on all interfaces (typically, localhost and the public address), you can specify 0.0.0.0 in conf/monitor.

However, because 0.0.0.0 is also used in the ssh command to start the monitor on a remote host, you can't get the monitor to start on all interfaces and on another host.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2065,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-09 02:45:56.722,,,no_permission,,,,,,,,,,,,362568,,,Mon Dec 09 03:11:28 UTC 2013,,,,,,0|i1qhxb:,362862,,,,,,,,08/Dec/13 05:00;elserj;I think the easiest approach (without re-working the scripts) is to add a configuration variable to accumulo-env.sh that will substitute '0.0.0.0' for the --address argument when starting the monitor.,08/Dec/13 06:08;elserj;Surprised to find that this doesn't affect 1.4. I guess things must have changed in 1.5.,"08/Dec/13 18:46;elserj;It looks like ACCUMULO-259 (specifically [b5c31dff|https://git-wip-us.apache.org/repos/asf?p=accumulo.git;a=commit;h=b5c31dff6d46eb419ea37db33d3f67dbb912a10c]) broke this way back in the day.

Previously, the static ""create"" method was used instead of the actual constructor to EmbeddedWebServer ([changes|https://git-wip-us.apache.org/repos/asf?p=accumulo.git;a=blobdiff;f=server/src/main/java/org/apache/accumulo/server/util/EmbeddedWebServer.java;h=b44788cbd01ab2a11ef2707b525d10fbee0329ba;hp=2d883ac423c02a3192f56ebbe51c7ff31335efb0;hb=b5c31dff6d46eb419ea37db33d3f67dbb912a10c;hpb=3131a518ec3d7acfaac3a58cdac349139a66a6b7]). What it looks like is that in <1.5, the Monitor was always bound to all ports and >=1.5.0 actually ""broke"" this. Given that the changes were applied under a ticket that has nothing to do with such a change, this makes me wonder if this was even desirable? [~vines], do you remember at all?

I can see benefit in having the ability to not bind to all interfaces, but I wonder if we should be changing *back* to bind to all by default and provide the means to bind to a specific interface for that ""new"" case.","09/Dec/13 01:21;elserj;I've been thinking about this. I actually checked out the 1.3.5 tag and it appears that Accumulo, up until 1.5.0, bound the monitor to all interfaces which makes me think this is a bug that no one has noticed yet (somehow).","09/Dec/13 01:25;elserj;Ok -- this was intentional. Sadly, when ACCUMULO-746 was done, we lost the ability to bind to everything to a single address with the scripts. I'm guessing the changes just got merged without the correct ticket reference (or the Git-svn conversion wasn't 100%)","09/Dec/13 02:45;jira-bot;Commit 7655de68fa94a379afe3ed4eb65c16c060b7e475 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7655de6 ]

ACCUMULO-1985 Allow the monitor to bind to all network interfaces.

Create a new configuration parameter that users can defined in accumulo-env.sh
that will, when starting the monitor process, override the value provided to the
--address option from the hostname to ""0.0.0.0"". We can't just put ""0.0.0.0"" in
conf/monitor as the scripts use each line in conf/monitor as the host to SSH to
and this would break starting the monitor on a remote host.
","09/Dec/13 02:51;jira-bot;Commit 7655de68fa94a379afe3ed4eb65c16c060b7e475 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7655de6 ]

ACCUMULO-1985 Allow the monitor to bind to all network interfaces.

Create a new configuration parameter that users can defined in accumulo-env.sh
that will, when starting the monitor process, override the value provided to the
--address option from the hostname to ""0.0.0.0"". We can't just put ""0.0.0.0"" in
conf/monitor as the scripts use each line in conf/monitor as the host to SSH to
and this would break starting the monitor on a remote host.
","09/Dec/13 02:52;jira-bot;Commit 7655de68fa94a379afe3ed4eb65c16c060b7e475 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7655de6 ]

ACCUMULO-1985 Allow the monitor to bind to all network interfaces.

Create a new configuration parameter that users can defined in accumulo-env.sh
that will, when starting the monitor process, override the value provided to the
--address option from the hostname to ""0.0.0.0"". We can't just put ""0.0.0.0"" in
conf/monitor as the scripts use each line in conf/monitor as the host to SSH to
and this would break starting the monitor on a remote host.
","09/Dec/13 03:11;elserj;Introduced new variable: {{ACCUMULO_MONITOR_BIND_ALL}.

When ""true"", the monitor will be started with an address of ""0.0.0.0"" instead of the host entry from $ACCUMULO_CONF_DIR/monitor.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE seen balancing tablets,ACCUMULO-2028,12685032,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,16/Dec/13 19:38,16/Dec/13 19:46,13/Mar/19 22:01,16/Dec/13 19:46,,,,,,,,1.6.0,,,master,,,,,,0,,,,,"{noformat}
Error balancing tablets
	java.lang.NullPointerException
		at org.apache.accumulo.server.master.balancer.TableLoadBalancer.getLoadBalancerClassNameForTable(TableLoadBalancer.java:55)
		at org.apache.accumulo.server.master.balancer.TableLoadBalancer.getBalancerForTable(TableLoadBalancer.java:63)
		at org.apache.accumulo.server.master.balancer.TableLoadBalancer.balance(TableLoadBalancer.java:144)
		at org.apache.accumulo.master.Master$StatusThread.balanceTablets(Master.java:1620)
		at org.apache.accumulo.master.Master$StatusThread.updateStatus(Master.java:1582)
		at org.apache.accumulo.master.Master$StatusThread.run(Master.java:1560)
{noformat}

Was deleting tables at the time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-16 19:44:41.047,,,no_permission,,,,,,,,,,,,364109,,,Mon Dec 16 19:45:00 UTC 2013,,,,,,0|i1qre7:,364409,,,,,,,,"16/Dec/13 19:44;jira-bot;Commit 0e3fd3b3cc26496f5a3e898c52f8fded16a5f203 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0e3fd3b ]

ACCUMULO-2028 avoid NPE during a table delete when balancing
","16/Dec/13 19:45;jira-bot;Commit 0e3fd3b3cc26496f5a3e898c52f8fded16a5f203 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0e3fd3b ]

ACCUMULO-2028 avoid NPE during a table delete when balancing
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Value constructors taking ByteBuffers need refinement,ACCUMULO-1959,12682443,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,bhavanki,bhavanki,bhavanki,03/Dec/13 17:53,16/Dec/13 19:01,13/Mar/19 22:01,16/Dec/13 18:42,1.4.0,,,,,,,1.6.0,,,,,,,,,0,,,,,"This ticket pertains to the following Value constructors.

{noformat}
public Value(ByteBuffer bytes)
public Value(ByteBuffer bytes, boolean copy)
{noformat}

Their appearance suggests that the second one can either copy bytes from the buffer or reference them directly, and the first one works similarly but has some default copying behavior.

However, both constructors use {{ByteBufferUtil.toBytes()}} on the ByteBuffer object, which always performs a copy. Therefore, it doesn't make sense (to me at least) to support a copy flag in the second constructor. In the current implementation, the bytes are copied twice if the copy flag is true.

The implementation should be reworked to avoid unnecessary copies, and perhaps simplify the API.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,05/Dec/13 20:53;bhavanki;ACCUMULO-1959.patch;https://issues.apache.org/jira/secure/attachment/12617235/ACCUMULO-1959.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-12-16 18:42:03.824,,,no_permission,,,,,,,,,,,,361700,,,Mon Dec 16 19:01:55 UTC 2013,,,,,,0|i1qclj:,361998,,,,,,,,05/Dec/13 19:56;bhavanki;Posted quick review. I opted to deprecate the constructor causing the double copy. I'd like this change to go into 1.6.0 if possible.,"05/Dec/13 20:55;bhavanki;This patch works against 1.6.0-SNAPSHOT. Keith had set the fix version on this ticket to 1.7.0, but since it's only a deprecation can it go against 1.6.0?","16/Dec/13 18:42;jira-bot;Commit f06b067063c92c1ae46f0c02dc24ff40564741b6 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f06b067 ]

ACCUMULO-1959 Deprecate Value(ByteBuffer,boolean)

The Value constructor that takes a ByteBuffer and a copy flag does
an unnecessary double copy when the flag is true. This change
deprecates the constructor in favor of the one without the flag
(which always performs a copy).

Signed-off-by: Josh Elser <elserj@apache.org>
","16/Dec/13 18:42;elserj;Applied. Thanks, [~bhavanki].","16/Dec/13 18:51;jira-bot;Commit f06b067063c92c1ae46f0c02dc24ff40564741b6 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f06b067 ]

ACCUMULO-1959 Deprecate Value(ByteBuffer,boolean)

The Value constructor that takes a ByteBuffer and a copy flag does
an unnecessary double copy when the flag is true. This change
deprecates the constructor in favor of the one without the flag
(which always performs a copy).

Signed-off-by: Josh Elser <elserj@apache.org>
","16/Dec/13 18:52;jira-bot;Commit 37c9a76017eac42577fbbc4c217f2af76ea84779 in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=37c9a76 ]

ACCUMULO-1959 - supressing deprecation warning
","16/Dec/13 18:52;jira-bot;Commit 37c9a76017eac42577fbbc4c217f2af76ea84779 in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=37c9a76 ]

ACCUMULO-1959 - supressing deprecation warning
","16/Dec/13 19:01;bhavanki;Awesome, thanks Josh.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Distro built from clean checkout misses several directories,ACCUMULO-1868,12678281,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,mdrob,busbey,busbey,08/Nov/13 18:22,12/Dec/13 19:17,13/Mar/19 22:01,12/Dec/13 19:17,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,,build,,,,,,0,newbie,,,,"Steps to reproduce :

* checkout 1.5.x
* clean up filesystem (git clean -xdf)
* mvn package -P assemble
* explode tarball
* look for lib/ext

the assembly includes a section to include ""../lib/ext"" in the generated tarball, but since nothing creates the directory it doesn't show up.

the directory missing causes a WARN for anything using Accumulo start. that warn (with a confluence of other things) causes functional tests to fail out of the box for 1.5.x.

for lib/ext works fine in 1.6 and (with different mvn call) in 1.4.x.

also missing is logs for 1.5 and 1.4, and walogs for 1.4.

Solution for all of these is to implement the same change as is in the component descriptor in 1.6, e.g. make them match this general form

{code:xml}
    <fileSet>
      <directory>./</directory>
      <outputDirectory>/lib/ext</outputDirectory>
      <directoryMode>0755</directoryMode>
      <excludes>
        <exclude>*/**</exclude>
      </excludes>
    </fileSet>
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-12 17:51:54.419,,,no_permission,,,,,,,,,,,,357656,,,Thu Dec 12 19:15:12 UTC 2013,,,,,,0|i1pnmv:,357946,,,,,,,,"12/Dec/13 17:51;mdrob;[~busbey], does fixing this issue for the sake of functional tests end up making more work for cluster administrators by including logs and walogs directories in the installation? Common practices are to symlink them out to /var/log or wherever, no? Maybe there is a better way to fix it from the test side of things.

Agree on lib/ext, however.",12/Dec/13 18:25;mdrob;Patch available at https://reviews.apache.org/r/16217/,"12/Dec/13 19:15;mdrob;Committed, but with a message that mistakenly referenced ACCUMULO-1896, so the ASF bot messages live over there now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
magitator should respect presence or lack of gc file,ACCUMULO-1967,12682818,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,05/Dec/13 02:29,05/Dec/13 04:54,13/Mar/19 22:01,05/Dec/13 04:54,,,,,,,,1.4.5,1.5.1,1.6.0,test,,,,,,0,,,,,"Noticed this yesterday when I was poking with the agitator again.

The magitator uses the same ""masters"" files with pssh to kill the garbage collector. It needs to us the gc file first, and, when not present, fall back to the first entry in masters.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-05 04:49:47.026,,,no_permission,,,,,,,,,,,,362075,,,Thu Dec 05 04:54:40 UTC 2013,,,,,,0|i1qevz:,362370,,,,,,,,"05/Dec/13 04:49;jira-bot;Commit 6175d7a51838b471b96ffbdee17f4b327bf3de0e in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6175d7a ]

ACCUMULO-1967 Magitator should respect presence (or lack) of a 'gc' file
","05/Dec/13 04:51;jira-bot;Commit 6175d7a51838b471b96ffbdee17f4b327bf3de0e in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6175d7a ]

ACCUMULO-1967 Magitator should respect presence (or lack) of a 'gc' file
","05/Dec/13 04:52;jira-bot;Commit 6175d7a51838b471b96ffbdee17f4b327bf3de0e in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6175d7a ]

ACCUMULO-1967 Magitator should respect presence (or lack) of a 'gc' file
","05/Dec/13 04:53;jira-bot;Commit 6175d7a51838b471b96ffbdee17f4b327bf3de0e in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6175d7a ]

ACCUMULO-1967 Magitator should respect presence (or lack) of a 'gc' file
","05/Dec/13 04:54;elserj;Fix magitator to respect gc file when present, falling back to masters.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MultiTableBatchWriterTest.testOfflineTable failed,ACCUMULO-1953,12682247,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,mberman,elserj,elserj,02/Dec/13 22:47,04/Dec/13 19:23,13/Mar/19 22:01,04/Dec/13 19:07,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Noticed this building 1.6.0-SNAPSHOT, but likely that it could also fail in 1.5.1-SNAPSHOT.

{noformat}
testOfflineTable(org.apache.accumulo.test.MultiTableBatchWriterTest)  Time elapsed: 0.427 sec  <<< FAILURE!
java.lang.AssertionError: Expected mutations to be rejected.
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.accumulo.test.MultiTableBatchWriterTest.testOfflineTable(MultiTableBatchWriterTest.java:444)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Dec/13 18:53;mberman;0001-ACCUMULO-1953-fix-intermittent-failure-due-to-race-i.patch;https://issues.apache.org/jira/secure/attachment/12617044/0001-ACCUMULO-1953-fix-intermittent-failure-due-to-race-i.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-12-04 18:42:32.131,,,no_permission,,,,,,,,,,,,361504,,,Wed Dec 04 19:23:53 UTC 2013,,,,,,0|i1qbef:,361802,,,,,,,,"04/Dec/13 18:42;mberman;[~elserj], are you actively working on this?  I have a patch that I believe fixes it (adding wait=true to the tableops.offline())",04/Dec/13 18:43;elserj;do it :),04/Dec/13 18:53;mberman;Attaching patch against 1.6.0-SNAPSHOT.  Doesn't look like the bug exists in 1.5.1-SNAPSHOT because TableOperations.offline() was always synchronous back then.,"04/Dec/13 18:56;elserj;bq.  Doesn't look like the bug exists in 1.5.1-SNAPSHOT because TableOperations.offline() was always synchronous back then.

Good call. I think I saw the failure in passing and just assumed that it was in both versions. I didn't consider the API changes.

Thanks for the patch.","04/Dec/13 19:03;jira-bot;Commit b07d12976274876dfeb250ad0c2fe1e5a98e74cd in branch refs/heads/1.6.0-SNAPSHOT from [~mberman]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b07d129 ]

ACCUMULO-1953: fix intermittent failure due to race in MultiTableBatchWriterTest.testOfflineTable

Signed-off-by: Josh Elser <elserj@apache.org>
","04/Dec/13 19:07;jira-bot;Commit b07d12976274876dfeb250ad0c2fe1e5a98e74cd in branch refs/heads/master from [~mberman]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b07d129 ]

ACCUMULO-1953: fix intermittent failure due to race in MultiTableBatchWriterTest.testOfflineTable

Signed-off-by: Josh Elser <elserj@apache.org>
","04/Dec/13 19:09;vines;Wait, API change? Perhaps this is a behavior we want to reconsider?","04/Dec/13 19:14;elserj;The default action on TableOperations being synchronous previously, while now being asynchronous. Personally, I feel like having the API potentially tank my client by blocking for a long time was bad.","04/Dec/13 19:20;vines;Not disagreeing with adding a flag, but we're changing the behavior of a command. That's where I'm not comfortable.","04/Dec/13 19:23;elserj;My point was that the previous action was kind of crappy (and thus, I'm not too worried about it changing across a major version). This ticket probably isn't the right place to discuss this. Mailing list or new ticket?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Initialize could use a better warning when HDFS dir is already populated,ACCUMULO-1556,12656619,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,bhavanki,blueraiu,blueraiu,08/Jul/13 15:07,02/Dec/13 20:48,13/Mar/19 22:01,02/Dec/13 20:47,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,client,,,,,,0,,,,,"When attempting to initialize Accumulo and the instance.dfs.dir is pointing at a directory in HDFS which has already been initialized, you get a very undescriptive warning message which doesn't actually say refer to the fact that this is an HDFS directory.

{noformat}
[util.Initialize] FATAL: It appears this location was previously initialized, exiting ... 
{noformat}

It would be better to be explicit and tell the user that their $instance.dfs.dir value already has been initialized in HDFS instead of leaving that up to the user to discern.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,07/Nov/13 21:05;bhavanki;ACCUMULO-1556-1.5.patch;https://issues.apache.org/jira/secure/attachment/12612697/ACCUMULO-1556-1.5.patch,02/Dec/13 19:03;bhavanki;ACCUMULO-1556-master.patch;https://issues.apache.org/jira/secure/attachment/12616597/ACCUMULO-1556-master.patch,07/Nov/13 19:33;bhavanki;ACCUMULO-1556.patch;https://issues.apache.org/jira/secure/attachment/12612679/ACCUMULO-1556.patch,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2013-11-06 19:02:42.305,,,no_permission,,,,,,,,,,,,336842,,,Mon Dec 02 20:48:50 UTC 2013,,,,,,0|i1m3nz:,337165,,,,,,,,06/Nov/13 19:02;bhavanki;Review available: https://reviews.apache.org/r/15279/,07/Nov/13 19:34;bhavanki;Patch based on 1.4.5-SNAPSHOT.,"07/Nov/13 19:58;ecn;[~havankijrw] the merge from 1.4 to 1.5 isn't going trivially for me.  Can you post a 1.5-based patch, too?","07/Nov/13 20:02;bhavanki;Sure, I'll get to work on that.","07/Nov/13 21:07;bhavanki;ACCUMULO-1556-1.5.patch is the patch for 1.5.1-SNAPSHOT.

Differences:
- easymock is already in dependency management for 1.5.x
- IZooReaderWriter moved from server to fate, needed to fix unit test","11/Nov/13 17:55;mdrob;Is this impacted by ACCUMULO-1747?

Edit: And ACCUMULO-118?","29/Nov/13 20:04;vines;Sorry [~bhavanki], I also need a revised patch for master, as it was also non trivial. I got the compile warnings resolved, but can't quite get the test passing, most likely to my lack of understanding of easymock.","02/Dec/13 14:03;bhavanki;No worries, I'll get on that.",02/Dec/13 15:42;bhavanki;Created patch for master branch by [~vines]'s request. Posted for review to double-check myself.,"02/Dec/13 19:03;bhavanki;Patch for master, reviewed.","02/Dec/13 20:46;jira-bot;Commit 1b3d071a8b46617245a39d039a2fe9e31600fc2e in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1b3d071 ]

ACCUMULO-1556 Clarify initialization error for used fs

The Initialize class now generates clearer and more informative
error messages if an initialized instance is discovered. The
messages vary depending on whether instance.dfs.uri is used. The
values of instance.dfs.uri and instance.dfs.dir are also logged.
","02/Dec/13 20:46;jira-bot;Commit 1b3d071a8b46617245a39d039a2fe9e31600fc2e in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1b3d071 ]

ACCUMULO-1556 Clarify initialization error for used fs

The Initialize class now generates clearer and more informative
error messages if an initialized instance is discovered. The
messages vary depending on whether instance.dfs.uri is used. The
values of instance.dfs.uri and instance.dfs.dir are also logged.
","02/Dec/13 20:46;jira-bot;Commit 07fa748e0f25acc59c76ca04fc37f84d84d3b12e in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=07fa748 ]

ACCUMULO-1556 Clarify initialization error for used fs

The Initialize class now generates clearer and more informative
error messages if an initialized instance is discovered. The
messages vary depending on whether instance.dfs.uri is used. The
values of instance.dfs.uri and instance.dfs.dir are also logged.
","02/Dec/13 20:46;jira-bot;Commit 1b3d071a8b46617245a39d039a2fe9e31600fc2e in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1b3d071 ]

ACCUMULO-1556 Clarify initialization error for used fs

The Initialize class now generates clearer and more informative
error messages if an initialized instance is discovered. The
messages vary depending on whether instance.dfs.uri is used. The
values of instance.dfs.uri and instance.dfs.dir are also logged.
","02/Dec/13 20:46;jira-bot;Commit 07fa748e0f25acc59c76ca04fc37f84d84d3b12e in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=07fa748 ]

ACCUMULO-1556 Clarify initialization error for used fs

The Initialize class now generates clearer and more informative
error messages if an initialized instance is discovered. The
messages vary depending on whether instance.dfs.uri is used. The
values of instance.dfs.uri and instance.dfs.dir are also logged.
","02/Dec/13 20:46;jira-bot;Commit 31b58c473d4abd4c7a9f51c558bdc89b61a92bfe in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=31b58c4 ]

ACCUMULO-1556 Clarify initialization error for used fs

The Initialize class now generates clearer and more informative
error messages if an initialized instance is discovered. The
messages vary depending on whether instance.dfs.uri is used. The
values of instance.dfs.uri and instance.dfs.dir are also logged.
","02/Dec/13 20:46;jira-bot;Commit 07fa748e0f25acc59c76ca04fc37f84d84d3b12e in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=07fa748 ]

ACCUMULO-1556 Clarify initialization error for used fs

The Initialize class now generates clearer and more informative
error messages if an initialized instance is discovered. The
messages vary depending on whether instance.dfs.uri is used. The
values of instance.dfs.uri and instance.dfs.dir are also logged.
","02/Dec/13 20:46;jira-bot;Commit 31b58c473d4abd4c7a9f51c558bdc89b61a92bfe in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=31b58c4 ]

ACCUMULO-1556 Clarify initialization error for used fs

The Initialize class now generates clearer and more informative
error messages if an initialized instance is discovered. The
messages vary depending on whether instance.dfs.uri is used. The
values of instance.dfs.uri and instance.dfs.dir are also logged.
",02/Dec/13 20:48;vines;Thanks for the patch(es)!,02/Dec/13 20:48;vines;Please close the review board entry when you get a chance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
examples.simple.RandomBatchWriter might not write the specified number of rowids,ACCUMULO-1892,12679238,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,busbey,busbey,busbey,14/Nov/13 16:23,19/Nov/13 18:18,13/Mar/19 22:01,19/Nov/13 18:18,1.4.0,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,,1.4.5,1.5.1,1.6.0,docs,test,,,,,0,,,,,"examples.simple.RandomBatchWriter takes a command line arg for how many rowids to write.

In the functional tests, this arg is used to coordinate a number of expected reads with the examples.simple.RandomBatchReader example.

the reader implementation ensures that it generates the passed number of query rows, but the write just makes num attempts at creating random rowids.

For a small number of goal rows and a large range (like the examples used for testing bloom filter speeds early in the examples integration test), this works fine.

For a larger number of goal rows (like the examples used to just write/read 10k rows later in the examples integration test), collisions in the selected row ids will cause the writer to actually generate fewer than the expected number. That, in turn, will  cause the attempted read integration test to fail.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1878,,,,,,,,,,,,,,,,,,,,14/Nov/13 16:31;busbey;ACCUMULO-1892.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12613867/ACCUMULO-1892.1.patch.txt,14/Nov/13 22:24;busbey;ACCUMULO-1892.2.patch.txt;https://issues.apache.org/jira/secure/attachment/12613955/ACCUMULO-1892.2.patch.txt,15/Nov/13 18:29;busbey;ACCUMULO-1892.3.patch.txt;https://issues.apache.org/jira/secure/attachment/12614100/ACCUMULO-1892.3.patch.txt,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2013-11-15 18:39:51.367,,,no_permission,,,,,,,,,,,,358603,,,Tue Nov 19 18:18:25 UTC 2013,,,,,,0|i1ptgv:,358893,,,,,,,,14/Nov/13 16:30;busbey;attaching review board of fix to make RandomBatchWriter use an approach to getting sufficient row ids similar to that used by RandomBatchReader.,"14/Nov/13 16:31;busbey;Attaching preliminary patch, in case review board misbehaves.",14/Nov/13 22:24;busbey;patch update based on review board.,15/Nov/13 18:29;busbey;attaching final patch based on all review feedback.,"15/Nov/13 18:39;jira-bot;Commit 4119611eea4bc5780761ec17691483dac3e95f47 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4119611 ]

ACCUMULO-1892 changes RandomBatchWriter to ensure it writes the specified number of rowids.

Signed-off-by: Keith Turner <kturner@apache.org>
","15/Nov/13 19:20;kturner;I am working on merging this in to 1.5.1-SNAP, one case that differs is that it will not System.exit(1) when it fails to parse args.  In 1.5.1 org.apache.accumulo.core.cli.Help.parseArgs() is used which will System.exit(0) when it does not parse args.","15/Nov/13 19:22;busbey;That's probably an error. If the user asks for ""--help"", then I think System.exit(0) is correct. But if there's a parsing error, the exit code should be non-zero.","15/Nov/13 19:22;busbey;I could file a ticket against 1.5.+ and fix it after, if you prefer?","15/Nov/13 19:26;kturner;yeah, I think it would be best to fix that in a separate ticket","15/Nov/13 19:43;jira-bot;Commit 4119611eea4bc5780761ec17691483dac3e95f47 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4119611 ]

ACCUMULO-1892 changes RandomBatchWriter to ensure it writes the specified number of rowids.

Signed-off-by: Keith Turner <kturner@apache.org>
","15/Nov/13 19:46;busbey;filed ACCUMULO-1899. I don't believe the same parsing problem actually existed in 1.5.x, so should be fine to wait on.","15/Nov/13 19:48;jira-bot;Commit 4119611eea4bc5780761ec17691483dac3e95f47 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4119611 ]

ACCUMULO-1892 changes RandomBatchWriter to ensure it writes the specified number of rowids.

Signed-off-by: Keith Turner <kturner@apache.org>
",15/Nov/13 20:59;kturner;The merge from 1.4 to 1.5 did not correctly resolve conflicts.  The new loop and sanity check for num < (max - min) were not carried forward.  Trying to undertstand what happened on the dev list.  In the meantime this ticket should not be closed.,"18/Nov/13 20:35;jira-bot;Commit 60dd8bd732ce0596150e49ae06fa7605aa0a15fd in branch refs/heads/1.5.1-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=60dd8bd ]

ACCUMULO-1892 redo resolving conflict resolution from 1.4 merge
","18/Nov/13 23:33;jira-bot;Commit 60dd8bd732ce0596150e49ae06fa7605aa0a15fd in branch refs/heads/1.6.0-SNAPSHOT from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=60dd8bd ]

ACCUMULO-1892 redo resolving conflict resolution from 1.4 merge
","18/Nov/13 23:41;jira-bot;Commit 60dd8bd732ce0596150e49ae06fa7605aa0a15fd in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=60dd8bd ]

ACCUMULO-1892 redo resolving conflict resolution from 1.4 merge
",19/Nov/13 17:18;ecn;Is this resolved?,19/Nov/13 17:52;kturner;[~busbey] do the merges to 1.5 and 1.6 look good?,"19/Nov/13 18:18;busbey;Yeah, 1.5.1-SNAPSHOT, 1.6.0-SNAPSHOT, and master all look correct now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
start-all.sh's zookeeper version check is lacking,ACCUMULO-1873,12678418,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,bhavanki,elserj,elserj,09/Nov/13 21:09,19/Nov/13 18:00,13/Mar/19 22:01,19/Nov/13 17:59,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,scripts,,,,,,0,,,,,"If ZOOKEEPER_HOME is defined (in the current env or in accumul-env.sh) but it's pointing at somewhere that doesn't contain a zookeeper-x.y.z.jar (e.g. ZOOKEEPER_HOME isn't actually pointing to a ZooKeeper installation), the zookeeper version check will end up returning an empty string which will cause an inaccurate warning to be printed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15/Nov/13 15:36;bhavanki;ACCUMULO-1873.patch;https://issues.apache.org/jira/secure/attachment/12614074/ACCUMULO-1873.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-11-15 15:36:58.179,,,no_permission,,,,,,,,,,,,357793,,,Tue Nov 19 18:00:50 UTC 2013,,,,,,0|i1pohb:,358083,,,,,,,,15/Nov/13 15:36;bhavanki;Try this patch (based on 1.4.5-SNAPSHOT).,"19/Nov/13 17:59;jira-bot;Commit e326641039942a25114490c0291c3386c4354d73 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e326641 ]

ACCUMULO-1873 follow symlinks
","19/Nov/13 17:59;jira-bot;Commit 0927eb83067ad2f209f67ab25a7c5b9009b18000 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0927eb8 ]

ACCUMULO-1873 Better ZOOKEEPER_HOME check in start-all.sh

The script now checks that ZOOKEEPER_HOME is a directory and detects
when the search for a ZK JAR comes up empty.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","19/Nov/13 17:59;jira-bot;Commit e326641039942a25114490c0291c3386c4354d73 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e326641 ]

ACCUMULO-1873 follow symlinks
","19/Nov/13 17:59;jira-bot;Commit 0927eb83067ad2f209f67ab25a7c5b9009b18000 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=0927eb8 ]

ACCUMULO-1873 Better ZOOKEEPER_HOME check in start-all.sh

The script now checks that ZOOKEEPER_HOME is a directory and detects
when the search for a ZK JAR comes up empty.

Signed-off-by: Eric Newton <eric.newton@gmail.com>
","19/Nov/13 18:00;jira-bot;Commit f2950ab52968ebdb405556aa544f55b79f2b7281 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f2950ab ]

ACCUMULO-1873 merging patch
","19/Nov/13 18:00;jira-bot;Commit e326641039942a25114490c0291c3386c4354d73 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e326641 ]

ACCUMULO-1873 follow symlinks
","19/Nov/13 18:00;jira-bot;Commit f2950ab52968ebdb405556aa544f55b79f2b7281 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=f2950ab ]

ACCUMULO-1873 merging patch
","19/Nov/13 18:00;jira-bot;Commit e326641039942a25114490c0291c3386c4354d73 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e326641 ]

ACCUMULO-1873 follow symlinks
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AccumuloSecurityException doesn't properly handle null error codes.,ACCUMULO-1891,12679120,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,busbey,busbey,busbey,13/Nov/13 22:13,15/Nov/13 02:59,13/Mar/19 22:01,15/Nov/13 02:59,1.4.0,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,,1.4.5,1.5.1,1.6.0,client,,,,,,0,,,,,"As a part of fixing ACCUMULO-1878 I hit an error condition in examples.simple.isolation.InterferenceTest$Writer where a security exception hits a path that doesn't properly handle a null coming out of thrift.

{code}
Caused by: java.lang.NullPointerException
        at org.apache.accumulo.core.client.AccumuloSecurityException.getDefaultErrorMessage(AccumuloSecurityException.java:30)
        at org.apache.accumulo.core.client.AccumuloSecurityException.<init>(AccumuloSecurityException.java:70)
        at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.doLookup(TabletServerBatchReaderIterator.java:579)
        at org.apache.accumulo.core.client.impl.MetadataLocationObtainer.lookupTablets(MetadataLocationObtainer.java:150)
        at org.apache.accumulo.core.client.impl.TabletLocatorImpl.processInvalidated(TabletLocatorImpl.java:591)
        at org.apache.accumulo.core.client.impl.TabletLocatorImpl.binRanges(TabletLocatorImpl.java:272)
        at org.apache.accumulo.core.client.impl.TabletLocatorImpl.processInvalidated(TabletLocatorImpl.java:584)
        at org.apache.accumulo.core.client.impl.TabletLocatorImpl.binMutations(TabletLocatorImpl.java:126)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.binMutations(TabletServerBatchWriter.java:560)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.addMutations(TabletServerBatchWriter.java:600)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.startProcessing(TabletServerBatchWriter.java:180)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.addFailedMutations(TabletServerBatchWriter.java:471)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.access$700(TabletServerBatchWriter.java:94)
        at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$FailedMutations.run(TabletServerBatchWriter.java:523)
{code} 

Looking at the code for AccumuloSecurityException, everything except for getDefaultErrorMessage accounts for the error code being null.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14/Nov/13 05:40;busbey;ACCUMULO-1891.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12613789/ACCUMULO-1891.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-11-15 02:56:36.395,,,no_permission,,,,,,,,,,,,358485,,,Fri Nov 15 02:58:03 UTC 2013,,,,,,0|i1psqn:,358775,,,,,,,,"14/Nov/13 05:40;busbey;Attached a patch that treats a null error code as the default in getdefaulterrormessage, since it looks like that's what is intended.",14/Nov/13 05:52;busbey;Looks like this issue carries through to master. Fix is simple enough that I'm skipping a review board for the patch.,"15/Nov/13 02:56;jira-bot;Commit 268028f8c17118208d45119ec26fc3e929a7f179 in branch refs/heads/1.4.5-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=268028f ]

ACCUMULO-1891 sets errorcode to default if it is null during message lookup.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
","15/Nov/13 02:56;jira-bot;Commit 268028f8c17118208d45119ec26fc3e929a7f179 in branch refs/heads/1.5.1-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=268028f ]

ACCUMULO-1891 sets errorcode to default if it is null during message lookup.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
","15/Nov/13 02:57;jira-bot;Commit 268028f8c17118208d45119ec26fc3e929a7f179 in branch refs/heads/1.6.0-SNAPSHOT from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=268028f ]

ACCUMULO-1891 sets errorcode to default if it is null during message lookup.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
","15/Nov/13 02:58;jira-bot;Commit 268028f8c17118208d45119ec26fc3e929a7f179 in branch refs/heads/master from [~busbey]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=268028f ]

ACCUMULO-1891 sets errorcode to default if it is null during message lookup.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SortedMapIterator.seek() doesn't respect columnFamilies,ACCUMULO-1471,12650002,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,mberman,mberman,mberman,29/May/13 20:21,31/Oct/13 16:02,13/Mar/19 22:01,31/Oct/13 16:02,1.4.3,1.5.0,,,,,,1.5.1,1.6.0,,client,,,,,,0,Documentation,,,,"If you specify columnFamilies in a seek() on a SortedMapIterator, it will happily return results from other column families.  The arguments are never even read.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31/Oct/13 15:34;mberman;ACCUMULO-1471.patch;https://issues.apache.org/jira/secure/attachment/12611403/ACCUMULO-1471.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-05-29 20:54:59.918,,,no_permission,,,,,,,,,,,,330329,,,Thu Oct 31 16:02:11 UTC 2013,,,,,,0|i1kzmn:,330663,,,,,,,,"29/May/13 20:54;kturner;There is actually a reason you would not want to filter in SortedMapIterator.   If you want to read from multiple SortedMapIterator, then you will provide them as inputs to a MultiIterator.  Column fam filtering should be done after the multi-iterator, like the following.

ColumnFamilySkippingIterator(MultiIterator(SortedMapIterator(map1),SortedMapIterator(map2)))

If every data source below the MultiIterator does column fam fitlering, then its possible that multiple data sources could unnecessarily read and filter alot of data for each seek.  They could do this even though another data source has visible key that sorts before the data they are filtering.  This could lead to O(N^2) seek performance.

The reason ColumnFamilySkippingIterator passes columns through is so that lower level data sources like rfile can possibly optimize what locality groups are read.   

So one possible fix for this is via javadocs.


","29/May/13 21:08;mberman;So this iterator shouldn't respect the interface's contract because there's a particular consumer that might want it to behave differently?  It seems like the scenario you describe would be better handled by having MultiIterator not pass its CFs through into the inner seek (perhaps optionally), so it can do the filter in one pass higher up in cases where that would be more efficient.","29/May/13 21:30;vines;But I think SortedMapIterator should be treated just like an RFileReader. It is the MockAccumulo equivalent after all. Sure, there currently are no optimizations for it (but there could be by implementing locality groups via multimaps).

I mean, the fundamental problem I think, is that there are portions of the iterator arguments that are not part of each iterator's contract, but rather an option that is known to be used SOMEWHERE in the stack. We are not clear on this behavior, but it's something that had been brought up in the work for ACCUMULO-652 because that brings in further options. I just remember the column families between strange because they get used in multiple places in the stack.","29/May/13 21:41;kturner;I do not think MultiIterator should optionally suppress column families, because this option would not be used in production.  The column families are always passed through MultiIterator in production as a hint to RFile.

I suppose we could say that SortedMapIterator is only used for unit test, do column family filtering there, and not care if someone gets O(N^2) performance in some unit test.  I am not in favor of doing that.  I would rather update the javadoc.

","30/May/13 15:03;mberman;Ahh ok, so I guess my misunderstanding was the assumption that seek() actually specifies the range of possible results from the iterator, rather than it just being a hint that different iterators will respect to different degrees (and generally, you might get back results that are outside the range specified).  So if you actually want your range to be enforced, you need to specifically ensure there's an iterator in your stack that is known to be strict.  Definitely seems like this could use some more doc.","30/May/13 15:49;kturner;bq.  it just being a hint that different iterators will respect to different degrees (and generally, you might get back results that are outside the range specified)

The basic stack built by Mock and Accumulo does not treat the range and col fams as a hint.   When iterators are independently pulled out of this system stack, the behavior may be different.  

I should have outlined the history.  A long time ago Accumulo actually built the system stack as follows.

MultiIterator(RFile(ColumnFamilySkippingIterator(LGroup())), RFile(ColumnFamilySkippingIterator(LGroup())), ColumnFamilySkippingIterator(InMemMap()))

With this use case, ColumnFamilySkippingIterator() would not pass column fams to data source iterators like Rfile.LGroup(), InMemMap(), and SortedMapIter.  Also the data source iterators used to throw an exception if column fams were passed.  Howerver this led to severe performance problems in some cases.  ColumnFamilySkippingIterator was moved above MultiIterator and modified to pass columns as a hint to data sources.  Data sources were modified to accept column fams, with the understanding that filtering would always be done above.  Currently rfile is only data source that uses this hint, in the future the in memory map will support locality groups and use this hint also.     

The javadoc I am thinking of is specifically for SortedMapIterator, encouraging wrapping it w/ ColumnFamilySkippingIterator if using it directly.",25/Oct/13 20:41;vines;I can't figure out if this is a Won't Fix or if we need to document/change mock to add in a ColumnFamilySkippingIterator automatically.,"25/Oct/13 22:47;mberman;When I filed this bug, I wasn't in a mock stack, I was just unit testing my iterators and using SortedMapIterator as a source, so, now that I understand the design, it seems like documentation is the best we can do.  At least a javadoc on SortedMapIterator (which is where I would have seen it before filing this bug), although it would also be nice to have some overview docs about what the built in iterator stack looks like and how responsibilities are distributed.",31/Oct/13 15:16;mberman;Attaching patch with more doc on SortedMapIterator explaining what you want if you're just looking for a simple Map-backed Iterator.,31/Oct/13 15:34;mberman;Fresh patch formatted per [~vines]'s advice,"31/Oct/13 16:01;jira-bot;Commit e328eab6e25f3d3bbcb7e4ed2690c1373e8d2a26 in branch refs/heads/1.5.1-SNAPSHOT from [~mberman]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e328eab ]

ACCUMULO-1471: more doc on SortedMapIterator explaining what you want if you're just looking for a simple Map-backed Iterator

Signed-off-by: John Vines <jvines@gmail.com>
","31/Oct/13 16:02;jira-bot;Commit e328eab6e25f3d3bbcb7e4ed2690c1373e8d2a26 in branch refs/heads/master from [~mberman]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=e328eab ]

ACCUMULO-1471: more doc on SortedMapIterator explaining what you want if you're just looking for a simple Map-backed Iterator

Signed-off-by: John Vines <jvines@gmail.com>
","31/Oct/13 16:02;vines;Applied, thanks [~mberman]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ctrl-C in shell terminates the process,ACCUMULO-1042,12630766,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,mdrob,mdrob,mdrob,04/Feb/13 22:35,28/Oct/13 15:02,13/Mar/19 22:01,28/Oct/13 15:02,,,,,,,,1.6.0,,,shell,,,,,,0,,,,,"When performing a scan in the shell, Ctrl-C will terminate both the scan and the entire shell. Seems bad.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-04 22:44:24.622,,,no_permission,,,,,,,,,,,,311262,,,Mon Oct 28 15:01:35 UTC 2013,,,,,,0|i1hpt3:,311608,,,,,,,,"04/Feb/13 22:44;elserj;Last I remember looking at this it was a limitation of JLine. That being said, it was over 12mos that I looked into it. ","06/Feb/13 01:48;ctubbsii;I made a rough attempt at this, and it's definitely much harder to fix in a reasonable way than I had thought as well. This ticket may be obviated by ACCUMULO-1045.","28/Oct/13 15:01;jira-bot;Commit 8fb6c860709419e95b16d18af3d4101ae035abd2 in branch refs/heads/master from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8fb6c86 ]

ACCUMULO-1042 use jline 2.11 for ctrl-c
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zooCacheTest fails due to missing /tmp/zcTest-42,ACCUMULO-1775,12673467,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,Jessica Seastrom,Jessica Seastrom,Jessica Seastrom,11/Oct/13 17:44,27/Oct/13 05:59,13/Mar/19 22:01,15/Oct/13 18:33,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,test,,,,,,0,,,,,Accumulo-1557 fixes an issue with re-running tests but fails on first run as /tmp/zcTest-42 does not exist yet. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11/Oct/13 17:49;Jessica Seastrom;accumulo-1775.patch;https://issues.apache.org/jira/secure/attachment/12608041/accumulo-1775.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-10-14 21:12:40.926,,,no_permission,,,,,,,,,,,,353090,,,Tue Oct 15 18:33:18 UTC 2013,,,,,,0|i1ovj3:,353377,,,,,,,,"11/Oct/13 17:47;Jessica Seastrom;Patch adds parameters to shutil.rmtree('/tmp/zcTest-42', ignore_errors=True, onerror=None)

in runTest and adds the call to tearDown.
In this way, on first run, the error will be ignored and the test will clean up in tearDown.","14/Oct/13 21:12;busbey;Verified pre-patch:

* Current 1.4.5-SNAPSHOT on clean VM fails simple.zooCacheTest.ZooCacheTest with directory not found.
* manually creating /tmp/zcTest-42 and running passes, but leaves an empty /tmp/zcTest-42

After applying patch:

* running simple.zooCacheTest.ZooCacheTest against clean VM succeeds
* no /tmp/zcTest-42 left behind.

Nit:

Jessica, could you reformat the patch using [git format-patch (instructions in the contributor section of the git workflow page)|http://accumulo.apache.org/git.html#contributors] so that a committer can easily apply the change with credit to you?

+1 (non-binding)","15/Oct/13 18:23;jira-bot;Commit 3705acd8e4cb3ce994893df3ee8a7f5f9e5e86b4 in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3705acd ]

ACCUMULO-1775 Applying patch from Jessica Seastrom to ignore errors when trying to remove a test directory
","15/Oct/13 18:26;jira-bot;Commit 3705acd8e4cb3ce994893df3ee8a7f5f9e5e86b4 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3705acd ]

ACCUMULO-1775 Applying patch from Jessica Seastrom to ignore errors when trying to remove a test directory
","15/Oct/13 18:26;jira-bot;Commit 1b05bd8c790b7c24ad4067fa160924f2f84c61eb in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1b05bd8 ]

Merge branch '1.4.5-SNAPSHOT' into 1.5.1-SNAPSHOT

Conflicts:
	test/system/auto/simple/zooCacheTest.py

ACCUMULO-1775
","15/Oct/13 18:28;jira-bot;Commit 3705acd8e4cb3ce994893df3ee8a7f5f9e5e86b4 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3705acd ]

ACCUMULO-1775 Applying patch from Jessica Seastrom to ignore errors when trying to remove a test directory
","15/Oct/13 18:28;jira-bot;Commit 1b05bd8c790b7c24ad4067fa160924f2f84c61eb in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1b05bd8 ]

Merge branch '1.4.5-SNAPSHOT' into 1.5.1-SNAPSHOT

Conflicts:
	test/system/auto/simple/zooCacheTest.py

ACCUMULO-1775
","15/Oct/13 18:33;elserj;Applied to 1.4.5 and 1.5.1. Moot for 1.6.0 as the python was removed and replaced with a Java test equivalent.

Thanks for the patch, Jessica. Echo'ing what [~busbey] said, please use git-format-patch next time. I also can't seem to find a username for you on Jira. Let me know what it is and I can add you as an Accumulo contributor and add you as the assignee for this ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
status command for init.d script doesn't work with service command,ACCUMULO-1791,12674590,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,jfield,jfield,jfield,18/Oct/13 21:32,25/Oct/13 23:40,13/Mar/19 22:01,25/Oct/13 23:20,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,scripts,,,,,,0,,,,,"The current version of the init.d script uses the returned result of pwd -P to get the physical path of the init.d script. This works when directly executing:

[root@localhost tmp]# /etc/init.d/accumulo status
There are 3 accumulo processes on this machine

But when executing it with the /sbin/service command on RHEL/CentOS, the value returned by the `pwd -P` command is no longer the directory the script is expecting, and instead returns '/', resulting in incorrect output:

[root@localhost tmp]# service accumulo status
There are 0 accumulo processes on this machine",CentOS release 6.4 (Final),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,18/Oct/13 21:38;jfield;ACCUMULO-1791.1.patch.txt;https://issues.apache.org/jira/secure/attachment/12609217/ACCUMULO-1791.1.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-10-18 21:50:07.402,,,no_permission,,,,,,,,,,,,354212,,,Fri Oct 25 23:40:28 UTC 2013,,,,,,0|i1p2fr:,354504,,,,,,,,18/Oct/13 21:38;jfield;Patches the init.d script to use $0 and readlink/dirname to establish the distro root folder. Tested on original environment.,"18/Oct/13 21:50;mdrob;{{readlink -f}} will not work on a Mac. For other ideas, check out http://stackoverflow.com/questions/1055671/how-can-i-get-the-behavior-of-gnus-readlink-f-on-a-mac
","18/Oct/13 22:01;jfield;Happy to go about it another way, but I assumed since this is an init script and Macs do not use init scripts, that wouldn't be a requirement.","18/Oct/13 22:03;vines;Actually, OSX can use init.d scripts","18/Oct/13 22:25;busbey;Back when similar issues came up over finding IP addresses, the [consensus I heard was that init.d scripts aren't expected to work on OS X, because it's only expected to be a dev platform|http://mail-archives.apache.org/mod_mbox/accumulo-user/201308.mbox/%3CCAF1jEfAJnojnMCD%2BLa5zF-SwEUWrARFZyySFk1Zmyye8LsmMSA%40mail.gmail.com%3E].

Is that no longer the case? maybe we should have a discussion on dev@ about what we're going to require from the host OS/shells for our scripts?","18/Oct/13 22:37;vines;It is considered a dev platform (FTR, I don't dev on OSX),  but there is a basic usability requirement required for OSX for other devs as well as first time users. Whether or not init.d falls into that space, I really can't say.","18/Oct/13 22:57;mdrob;Mea culpa, I remembered that discussion but didn't put two and two together for thinking that it applies here. Consider my concerns addressed.","19/Oct/13 03:46;mdrob;[~jfield], I assigned you the issue and added you as a contributor to JIRA and our people page. Let me know if you want time zone, company, etc.. included.",21/Oct/13 20:28;fwiffo;+1 to commit (non-binding),25/Oct/13 23:20;vines;Looks like this has already been rolled in?,"25/Oct/13 23:40;busbey;yep, it's [commit 7bf6148f|https://git-wip-us.apache.org/repos/asf?p=accumulo.git;a=commit;h=7bf6148f2f19266ea3194be15d6ebb1f8a7d98a8]. The commit message fails to mention the ticket number, so it's hard to see.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Resolve table name to table id once in Accumulo input format,ACCUMULO-1732,12670196,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,sonixbp,kturner,kturner,24/Sep/13 02:22,23/Oct/13 03:15,13/Mar/19 22:01,16/Oct/13 02:49,1.4.0,,,,,,,1.6.0,,,,,,,,,0,,,,,"AccumuloInputFormat (and I suspect AccumuloOutputFormat) sends the table name to each mapper.  The mapper uses this table name to create a scanner.  In the case of the following events a map reduce job could read from two different table ids.   

 # start M/R job reading table A
 # rename table A (tableId=1) to table C
 # rename table B (tableId=2) to table A

If the input format passed table id 1 to the mappers, then the renames would not cause a problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-26 17:08:16.529,,,no_permission,,,,,,,,,,,,350026,,,Wed Oct 23 03:15:46 UTC 2013,,,,,,0|i1ocqf:,350322,,,,,,,,"26/Sep/13 17:08;ctubbsii;The same issue applies to renames in general for any arbitrary application that scans tables. If we make the M/R API robust against this, should we also make it available for other applications? Or is the M/R API a special case (because it's implementation details that it creates a separate scanner per mapper).

Also, maybe that's the behavior you want? Maybe you're trying to rename a table and replace it with a backup clone, to limit the impact of some problematic or corrupt data?","26/Sep/13 18:07;kturner;bq. The same issue applies to renames in general for any arbitrary application that scans tables.

Alot of the client side code already resolves a table id early and uses the table id.   But I am not sure this happens everywhere.

bq. Also, maybe that's the behavior you want? Maybe you're trying to rename a table and replace it with a backup clone, to limit the impact of some problematic or corrupt data?

I think this system should be designed such that when its working correctly it does not behave in surprising ways.  I do not think we should design the system to have surprising behavior that can be leveraged when the system is working incorrectly.","26/Sep/13 18:27;kturner;Unpredictable is probably a better word to use than surprising to describe what I was thinking in my previous comment.  We want to define behaviors that lead to users being able to predict what will happen. 

I misunderstood your first question. 

bq. should we also make it available for other applications? 

You are basically asking if we should make the table id available through the client API.  Possibly.  I think we can make map reduce jobs behave in a predictable way w/o doing this.   For the more general point of making the table id a first class citizen in the API, what are the use cases?  Probably other systems like M/R that access Accumulo in a distributed manner.   

","30/Sep/13 00:38;jira-bot;Commit 686257d40a37acb31fee7636bf6c295f6234cc04 in branch refs/heads/ACCUMULO-391 from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=686257d ]

ACCUMULO-1732 Using table id in RangeInputSplit so that it can be resolved back to ""working"" table name in mappers. Scanner uses the ""working"" table name while everything else can still safely use the original configured table name.
",01/Oct/13 01:21;sonixbp;It would be nice to have an integration test suit to verify behavior like this. I'm not seeing a good spot for putting an AccumuloInputFormatIT. Any ideas? I'm thinking either a new package or an addition to the functional tests but maybe I'm overlooking something.,01/Oct/13 01:31;ecn;Put it anywhere you like... the functional group can be a dumping ground for IT tests.  It's not unmanageable; having a test in the wrong location beats not having a test.,"02/Oct/13 03:22;jira-bot;Commit 10b4eb8206ab4395ef2d4df375b52a7ffe77d655 in branch refs/heads/ACCUMULO-391 from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=10b4eb8 ]

ACCUMULO-1732 Using table id in RangeInputSplit so that it can be resolved back to ""working"" table name in mappers. Scanner uses the ""working"" table name while everything else can still safely use the original configured table name.
","05/Oct/13 02:28;jira-bot;Commit b96701f220ecb3e891a71741179b867429fa1d39 in branch refs/heads/master from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b96701f ]

Squashed commit of the following:

commit 3227a822379718d6c1297f11d7af37a716f78a60
Author: Corey J. Nolet <cjnolet@gmail.com>
Date:   Tue Oct 1 23:20:34 2013 -0400

    Adding the following:
    - Deprecation to InputConfigurator, mapred.InputFormatBase, mapreduce.InputFormatBase
    - Comments to TableQueryConfig
    - Multi-table support to mapred.InputFormatBase

    ACCUMULO-391

commit 6648e8a1c97939f740b24f9368ecda9f7072cbd2
Author: Corey J. Nolet <cjnolet@gmail.com>
Date:   Tue Oct 1 21:45:37 2013 -0400

    Fixing some more formatting. Adding license headers. ACCUMULO-391

commit 53bcc85689510fc988c9e9f6aff0da0cb7091c6c
Author: Corey J. Nolet <cjnolet@gmail.com>
Date:   Mon Sep 30 21:01:55 2013 -0400

    Cleaning up tests. Adding test for legacy input for base + new multi-table methods. ACCUMULO-391

commit e4e05c804ea7f486290181f0246cf6b2880f5d1a
Author: Corey J. Nolet <cjnolet@gmail.com>
Date:   Sun Sep 29 21:05:55 2013 -0400

    Fixing some formatting. Adding some comments. ACCUMULO-391

commit 10b4eb8206ab4395ef2d4df375b52a7ffe77d655
Author: Corey J. Nolet <cjnolet@gmail.com>
Date:   Sun Sep 29 20:37:07 2013 -0400

    ACCUMULO-1732 Using table id in RangeInputSplit so that it can be resolved back to ""working"" table name in mappers. Scanner uses the ""working"" table name while everything else can still safely use the original configured table name.

commit 7b8585f0333c09674f7612b4dc24887f684413fe
Author: Corey J. Nolet <cjnolet@gmail.com>
Date:   Sat Sep 28 23:23:48 2013 -0400

    Removing deprecation for now until we have some discussions. Updating/adding comments. ACCUMULO-391

commit 273ee49530de28c2c5dfe39c80ab0c90c3c3a95f
Author: Corey J. Nolet <cjnolet@gmail.com>
Date:   Sat Sep 28 23:01:04 2013 -0400

    The legacy mapred InputFormatBase now verifies (and fixes the scanner for) a possible change in table name that could happen between the configuration of the map/reduce job and the actual processing of the scanner for a specific split. In that case, the most recent table name associated with the id is always used for the scanner (though the table name that was expected during job setup is still used in the RangeInputSplit). ACCUMULO-391

commit e6a7c962f707487d832ba4b16c1f9066d13ff8f1
Author: Corey J. Nolet <cjnolet@gmail.com>
Date:   Sat Sep 28 22:53:42 2013 -0400

    The original single-table setters/getters now populate a ""default"" TableQueryConfig object under the hood. This should make the switch over much easier. Deprecated single table methods in light of the API changes for the new configuration object. ACCUMULO-391

commit fdf4cadb16c29fc03a610cf83399ee26d7f83bc9
Author: Corey J. Nolet <cjnolet@gmail.com>
Date:   Sat Sep 28 21:58:40 2013 -0400

    Adding new TableQueryConfig object for setting multiple table info in the InputFormatBase
","18/Oct/13 21:47;jira-bot;Commit 3e74ee6654b879ca4eccf7b6f5469d4fa92b4b66 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3e74ee6 ]

ACCUMULO-1732 fix AccumuloInputFormatIT
","23/Oct/13 02:42;jira-bot;Commit 7f6e512278a365c9bbb525c8d8fee57e5d573d24 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7f6e512 ]

ACCUMULO-1732 Input format changes : used table id exclusively, fixed issues with table propagation, removed some duplicated code
","23/Oct/13 03:15;jira-bot;Commit 941e3cb1acbdb3ad2047e512d5fe3c95e595496b in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=941e3cb ]

ACCUMULO-1732 fixed input format w/ mock
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
du <tablename> command throws NullPointerException,ACCUMULO-1662,12665162,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,matt_d,matt_d,23/Aug/13 00:42,22/Oct/13 17:22,13/Mar/19 22:01,22/Oct/13 17:22,1.5.0,,,,,,,,,,shell,,,,,,0,,,,,When running 'du <tablename>' in the shell I receive the NullPointerException outlined in the attached stacktrace.  Command was run while in a table context.  ,RHEL6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23/Aug/13 00:45;matt_d;Accumulo-du-exception.pdf;https://issues.apache.org/jira/secure/attachment/12599552/Accumulo-du-exception.pdf,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-08-23 15:36:16.176,,,no_permission,,,,,,,,,,,,345103,,,Tue Oct 22 17:22:30 UTC 2013,,,,,,0|i1nifr:,345404,,,,,,,,23/Aug/13 00:45;matt_d;Stack trace,"23/Aug/13 15:36;ecn;Is it possible that a file referenced by your table has been deleted?

You can search for missing files with:

$ ./bin/accumulo org.apache.accumulo.server.util.RemoveEntriesForMissingFiles -u root --password

","25/Aug/13 23:10;matt_d;UNOFFICIAL


When running this command I get ClassNotFoundException for org.apache.mapreduce.Job.   The accumulo-env has the correct path set to the hadoop directory, HADOOP_PREFIX, that contains all the necessary jars, is there an additional environment setup required for this command to work? I've tried adding the hadoop jars to the classpath with no success.


","26/Aug/13 23:53;ecn;This could be a hadoop 2.0 vs 1.0 problem. What version of hadoop are you running?  Have you recompiled accumulo for your environment?
","28/Aug/13 23:26;matt_d;UNOFFICIAL

Apologies, it's a 1.5.1-SNAPSHOT.  There was an AUDIT branch made earlier this year in approximately March which we cloned.  We required the audit functionality to go to PROD therefore the clone of this branch.

",29/Aug/13 00:54;sonixbp;Is this issue resolved then?,22/Oct/13 17:22;ecn;Marking this closed.  Please re-open if you can reproduce the problem.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MiniAccumuloRunner to support miniDFS in property file,ACCUMULO-1781,12674220,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,sonixbp,sonixbp,sonixbp,16/Oct/13 23:21,17/Oct/13 02:58,13/Mar/19 22:01,17/Oct/13 02:07,,,,,,,,1.6.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-17 02:07:15.584,,,no_permission,,,,,,,,,,,,353842,,,Thu Oct 17 02:58:46 UTC 2013,,,,,,0|i1p067:,354134,,,,,,,,"17/Oct/13 02:07;jira-bot;Commit 45559c862425462cfc3a786237608756181dd6df in branch refs/heads/master from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=45559c8 ]

ACCUMULO-1781 Adding miniDFS support to MACRunner. Adding sample property file
","17/Oct/13 02:58;jira-bot;Commit a65fe6a2b0b66b28c232da8025966cdafc4159fb in branch refs/heads/master from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a65fe6a ]

ACCUMULO-1781 Adding license header to minicluster.properties
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mutation is hard to check in unit tests,ACCUMULO-1734,12670308,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,,ecn,ecn,24/Sep/13 16:30,14/Oct/13 11:45,13/Mar/19 22:01,14/Oct/13 11:45,1.4.4,,,,,,,1.4.4,1.5.1,1.6.0,client,,,,,,0,,,,,"[~treardon] writes:

{quote}
The problem is that Mutation.equals() calls a private serialize() method that modifies the data about to be checked. I have successfully worked around this in the past by wrapping the Mutation in a new Mutation, which calls serialize under the hood:

 assertEquals(expectedMutation, new Mutation(actualMutation));

This applies to 1.4.x, I don't know if Mutation.equals() has changed since then.
{quote}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-27 13:38:14.393,,,no_permission,,,,,,,,,,,,350137,,,Mon Oct 14 11:43:42 UTC 2013,,,,,,0|i1oden:,350431,,,,,,,,"27/Sep/13 13:38;bhavanki;I've been looking at {{Mutation.equals()}} (trunk version) while working ACCUMULO-1627. The implementation is problematic for doing a close-to-correct subclass implementation of {{equals()}}, and I was planning of reworking it (a scary thing for a n00b like me, so I'll be seeking lots of feedback). I was thinking of protecting and renaming {{Mutation.equals(Mutation)}} - that's the one with the serialize calls - so that it doesn't get called instead of {{Mutation.equals(Object)}} when the parameter is a {{Mutation}} instance. That would make the implementation more typical.

Maybe such a change would help? Regardless, I wanted to mention it since it's related.","27/Sep/13 16:20;kturner;bq.  I was thinking of protecting and renaming Mutation.equals(Mutation)

D you know if this would this maintain ABI compatibility?  ","27/Sep/13 17:04;bhavanki;I'm not sure that it would. I could write a quick test case to find out.

I would rather find some solution that doesn't change the API at all, so I'm still working on it. I can provide more details under ACCUMULO-1627 when I have something that I think is decent.",11/Oct/13 13:15;bhavanki;Just noting here that ACCUMULO-1627 is complete and the API did not change.,14/Oct/13 11:43;treardon;The behavior described in this ticket was fixed by ACCUMULO-1626. Mutatation.equals() now serializes both Mutations prior to checking.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accumulo ignores HDFS max replication configuration,ACCUMULO-683,12598197,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,,jklucar,jklucar,10/Jul/12 15:00,09/Oct/13 19:51,13/Mar/19 22:01,19/Jul/12 18:14,1.4.1,,,,,,,1.4.2,1.5.0,,tserver,,,,,,0,,,,,"I setup a new 1.4.1 instance that was running on top of a Hadoop installation that had the maximum block replications set to 3 and the following error showed up on the monitor page.

java.io.IOException: failed to create file /accumulo/tables/!0/table_info/F0000001.rf_tmp on client 127.0.0.1. Requested replication 5 exceeds maximum 3 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1123) at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:551) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:523) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1383) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1379) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1377)

Tablet server error is:

10 10:56:25,408 [tabletserver.MinorCompactor] WARN : MinC failed (java.io.IOException: failed to create file /accumulo/tables/!0/
table_info/F0000001.rf_tmp on client 127.0.0.1.
Requested replication 5 exceeds maximum 3
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1123)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:551)
        at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:523)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1383)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1379)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1377)
) to create /accumulo/tables/!0/table_info/F0000001.rf_tmp retrying ...
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-07-10 15:26:57.712,,,no_permission,,,,,,,,,,,,246385,,,Wed Oct 09 19:51:32 UTC 2013,,,,,,0|i07lp3:,42281,,,,,,,,"10/Jul/12 15:03;jklucar;Here's the hdfs-site.xml property entry

<property>
  <name>dfs.replication.max</name>
  <value>3</value>
  <description>Maximal block replication. 
  </description>
</property>
","10/Jul/12 15:14;jklucar;I didn't have table.file.replication set, and the documentation says a value of 0 will use HDFS defaults. I will explicitly set this property to zero and try again. 

However, looks like the offending line could be here:

./server/src/main/java/org/apache/accumulo/server/util/Initialize.java:    initialMetadataConf.put(Property.TABLE_FILE_REPLICATION.getKey(), ""5"");","10/Jul/12 15:26;billie.rinaldi;That looks like something we should figure out how to handle better.  The !METADATA table has a larger number of replicas (5 by default) because it is really important not to lose those files.  To make 1.4.1 run with a max replication of 3, you could manually change the parameter table.file.replication for the !METADATA table to equal the max replication of HDFS.  However, I would strongly urge against making this lower than 5.

We should decide if we want Accumulo to automatically set the !METADATA replication to the HDFS max if it is less than five, or if we want it to throw an informative error saying that the user should lower the !METADATA replication at a greater risk of losing critical data.","10/Jul/12 15:32;afuchs;A workaround should be to set table.file.replication to 3 for the !METADATA table. This can be done in the shell via
$ config -t !METADATA -s table.file.replication=3

There's another debate about whether we should fix this automatically. This is a prickly issue -- on the one hand we could just ignore the table.file.replication if it is set to more than the hadoop dfs.replication.max, and on the other hand we could enforce the table.file.replication and make an administrator resolve the conflict. I would argue the later is better because of the following:
# Automatically defaulting to the lower replication setting would constitute a subtle decrease in durability, which may not be obvious to the administrator when they are modifying a dependent system. We should make the the administrator fully aware of the consequences by forcing the administrator to resolve the conflict.
# There is already an administrator involved in creating the conflict (by setting the HDFS parameter), so adding another human-in-the-loop step here should not be overly costly.
# Accumulo shouldn't have to keep track of all the HDFS configuration parameters that might affect it. These parameters change relatively frequently, so we could introduce future incompatibilities by trying to avoid current incompatibilities.

That said, I think we should catch this exception and suggest the fix in the error message that we log.","11/Jul/12 16:26;jvines;Perhaps there's a middle ground where we can handle this. I think when we init we should do a check and alert the user if they have an issue. We can prompt them to set the replication there, so if they want to keep the 5 and mess with their HDFS configuration they can. Or they can set their !METADATA replication to 3 and be done with it.","11/Jul/12 16:33;jvines;Actually, this points out a bug. Our initial root tablet doesn't have it's replication set to 5, it's the system default.","11/Jul/12 17:24;kturner;One concern I have about issues like this is for indirect users of Accumulo.  An indirect user of Accumulo is someone who is using something like OpenTSDB[1] or Jaccson[2].   These users  want to know as little about Accumuo as possible, they just want OpenTSDB or Jaccson to work.  For these users, the assumption that setting a config option on the metadata table is a trivial operation does not hold.  It could take them a while to figure out what they need to do to fix this issue.  

This issue is somewhat similar to the java policy file that could keep Accumulo from running and make users spend a lot of time figuring it out.  The issue differs in that its much less likely and increases the probability of loss of critical data.  It changes probabilities, but it does not make data loss certain.

Also I think if a user sets max replication, they mean it.  I think Accumulo should just work (automatically take the min setting) and log a warning.

Basically I am in favor of Accumulo just working in as many situations as possible.

Also, setting the metadata table replication to 5 instead of 3 was something I did w/o much thought when adding per table replication setting.  The basic premise what that 5 is better than 3.  I certainly did not analyze the probabilities of how it affects your odds under different datanode loss situations.  For example instead of being 5, should it be some function of the cluster size? I dunno know.

We will probably also run into a similar issue if someone sets the min hdfs replication > 5.  We should handle that issue in this ticket also.


[1] : https://github.com/ericnewton/opentsdb
[2] : https://github.com/acordova/jaccson

John, I like your suggestion about checking in when the user runs init and prompting.  The prompt should suggest a default that will work.

","16/Jul/12 21:12;jvines;Unless there are any objections, I'm going to implement this as an initialization time prompt which will check both max and mins and ask for what setting the user wants IFF the default of 5 is not within bounds.","09/Oct/13 18:55;charlescva;I am still seeing the replication factor for !METADATA table as having override value of 5 upon a fresh installation of 1.4.4.

It took a while to find this thread and resolve the issue.  This should either be in the install guide or should be something I am prompted to choose during the init process.

",09/Oct/13 19:02;vines;Did you have the max replication set below 5?,"09/Oct/13 19:07;charlescva;Yes, using Cloud Manager 4.7, the 'hdfs-site.xml' defaults to a factor of 3 for cdh3u6 installation.  ","09/Oct/13 19:24;vines;Not default replication, max replication.","09/Oct/13 19:30;charlescva;ah.  ""Max"" Replication is not specified.  In HDFS the property looks like this:

<property>
    <name>dfs.replication</name>
    <value>3</value>
</property>

Looks like the Hadoop default Max Replication is 512 for cdh3u6.  
So I guess the replica of 5 will almost always be used by accumulo when deployed on cdh3u6.

Sorry about the confusion.

","09/Oct/13 19:51;vines;Correct, you can override this by setting the table replication for the !METADATA table after you init. However, it is not advised because you really want to have that extra reliability for the !METADATA.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"false error message ""tablet overlaps previously assigned tablet""",ACCUMULO-1567,12657469,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kturner,ecn,ecn,12/Jul/13 15:02,08/Oct/13 19:14,13/Mar/19 22:01,08/Oct/13 19:14,1.4.0,1.5.0,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"In the presence of recent splits, the tablet server will complain 
{noformat}
tablet X overlaps previously assigned tablets X;y< X<;y
{noformat}

this is a transient condition, and should not be an error.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-12 15:29:45.788,,,no_permission,,,,,,,,,,,,337690,,,Tue Oct 08 19:02:43 UTC 2013,,,,,,0|i1m8vz:,338013,,,,,,,,"12/Jul/13 15:29;jira-bot;Commit 1502587 from [~ecn]
[ https://svn.apache.org/r1502587 ]

ACCUMULO-1567 ignore recently split tablets when complaining about overlapping assignments","08/Oct/13 16:15;kturner;While testing changes to making offline and online table wait I ran into a bug where a tablet was never being assigned.  I think it was caused by changes against this issue, I am going to try to fix it.

The change caused an extent to be left in the unopened tablet set forever preventing future assignments.

{noformat}
2013-10-08 10:34:27,597 [tabletserver.Tablet] TABLET_HIST: 1;1f6;1f4 opened 
2013-10-08 10:34:27,610 [tabletserver.Tablet] DEBUG: initiateClose(saveState=true queueMinC=false disableWrites=false) 1;1f6;1f4
2013-10-08 10:34:27,611 [tabletserver.Tablet] DEBUG: completeClose(saveState=true completeClose=false) 1;1f6;1f4
2013-10-08 10:34:27,634 [tabletserver.Tablet] TABLET_HIST: 1;1f6;1f4 closed
2013-10-08 10:34:27,635 [tabletserver.Tablet] DEBUG: Files for high split 1;1f6;1f5  []
2013-10-08 10:34:27,642 [tabletserver.Tablet] TABLET_HIST: 1;1f6;1f4 split 1;1f5;1f4 1;1f6;1f5
2013-10-08 10:34:27,642 [tabletserver.TabletServer] INFO : Starting split: 1;1f6;1f4
2013-10-08 10:34:27,658 [tabletserver.Tablet] TABLET_HIST: 1;1f6;1f5 opened 
2013-10-08 10:34:27,658 [tabletserver.TabletServer] INFO : Tablet split: 1;1f6;1f4 size0 0 size1 0 time 48ms
2013-10-08 10:34:27,659 [tabletserver.TabletServer] INFO : Loading tablet 1;1f6;1f4
2013-10-08 10:34:27,725 [tabletserver.TabletServer] INFO : node1:59921: got assignment from master: 1;1f6;1f4
2013-10-08 10:34:27,728 [tabletserver.TabletServer] ERROR: Thread ""tablet assignment 1"" died overlaps assigned 1;1f6;1f4 false [1;1f6;1f4] [] [1;1f5;1f4, 1;1f6;1f5]
java.lang.IllegalStateException: overlaps assigned 1;1f6;1f4 false [1;1f6;1f4] [] [1;1f5;1f4, 1;1f6;1f5]
2013-10-08 10:34:32,348 [tabletserver.Tablet] DEBUG: initiateClose(saveState=true queueMinC=false disableWrites=false) 1;1f6;1f5
2013-10-08 10:34:32,348 [tabletserver.Tablet] DEBUG: completeClose(saveState=true completeClose=true) 1;1f6;1f5
2013-10-08 10:34:32,379 [tabletserver.Tablet] TABLET_HIST: 1;1f6;1f5 closed
2013-10-08 10:34:32,379 [tabletserver.TabletServer] DEBUG: Unassigning 1;1f6;1f5@(null,node1:59921[141987d48cc0005],null)
2013-10-08 10:34:32,381 [tabletserver.TabletServer] INFO : unloaded 1;1f6;1f5
2013-10-08 10:35:43,118 [tabletserver.TabletServer] ERROR: Tablet 1;1f6;1f5 overlaps previously assigned [1;1f6;1f4] [] []
2013-10-08 10:35:43,340 [tabletserver.TabletServer] ERROR: Tablet 1;1f6;1f5 overlaps previously assigned [1;1f6;1f4] [] []

{noformat}","08/Oct/13 19:02;jira-bot;Commit 53fb6c7635f41c4376649e85f3ec9226aa6a56b0 in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=53fb6c7 ]

ACCUMULO-1567 fixed issue with recently split tablets not being assigned
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Examples functional test fails when sources are not in the run directory,ACCUMULO-1435,12648463,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,20/May/13 17:28,13/Sep/13 18:54,13/Mar/19 22:01,13/Sep/13 18:54,1.5.0,,,,,,,1.5.1,1.6.0,,test,,,,,,0,,,,,Running the functional tests without source code breaks the Examples functional test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-21 17:13:33.501,,,no_permission,,,,,,,,,,,,328818,,,Tue May 21 17:35:10 UTC 2013,,,,,,0|i1kqdb:,329160,,,,,,,,21/May/13 17:13;ctubbsii;Which test is affected. Have you been able to discern the cause?,"21/May/13 17:35;ecn;Yes, the test runs the dirlist example.  It ingests source files and then looks for them.  No source files are ingested because they are not there.  I'll just change the test to ingest documentation instead.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
deep copy in the compaction scope iterators can throw off the stats,ACCUMULO-1696,12667369,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kturner,afuchs,afuchs,06/Sep/13 17:56,06/Sep/13 22:40,13/Mar/19 22:01,06/Sep/13 22:40,1.5.0,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"When application-level iterators deep copy the source iterator in a major compaction, the stats can be significantly off. We count two things in a major compaction:
1. Entries read. This is done using a counting iterator sitting just above the system iterators.
2. Entries written. This is done by counting the entries that are written to the RFile.
Here's an example of what we see in the Accumulo logs:
{code}
2013-09-06 11:53:31,371 [tabletserver.Compactor] DEBUG: Compaction k;row11;row10 20 read | 382,629 written |      3 entries/sec |  5.337 secs
{code}
In this case, we're only counting 20 entries read, presumably because the iterators have been deep copied and the counting iterator that is being polled does not get a complete view of how many entries were read. Instead of 3 entries/sec we should have registered close to 72k entries/sec.

To fix this, should we be counting all reads coming from any of the deep copies of the source iterators? This could be done by using a CountingIterator that keeps one counter for all deep copies. Thread-level counters could be used for lock-free counts in case multiple threads are ever used.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-06 22:37:28.666,,,no_permission,,,,,,,,,,,,347306,,,Fri Sep 06 22:37:28 UTC 2013,,,,,,0|i1nvzr:,347605,,,,,,,,"06/Sep/13 22:37;jira-bot;Commit de24f8322f1ef2d4817b335ae90b131f0a7b2c1c in branch refs/heads/master from [~keith_turner]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=de24f83 ]

ACCUMULO-1696 fixed compaction debug counts for deep copies
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
user manual refers to deprecated calls,ACCUMULO-1687,12667140,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,05/Sep/13 16:49,06/Sep/13 21:32,13/Mar/19 22:01,06/Sep/13 21:32,1.5.0,,,,,,,1.5.1,,,docs,,,,,,0,,,,,"In particular, AccumuloInputFormat.setRegex.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-06 21:32:40.264,,,no_permission,,,,,,,,,,,,347077,,,Fri Sep 06 21:32:40 UTC 2013,,,,,,0|i1nukv:,347376,,,,,,,,"06/Sep/13 21:32;jira-bot;Commit 76ae0c6b6f727566004c5c95e0afdbfe7fbe8089 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=76ae0c6 ]

ACCUMULO-1687 update RegEx example; fix some other typos and hard-to-understand instructions
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Monitor requires jumping through hadoop permissions hoops (and granting accumulo broad permissions),ACCUMULO-1282,12642814,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,mberman,mberman,16/Apr/13 20:59,16/Aug/13 18:05,13/Mar/19 22:01,17/Apr/13 16:56,1.4.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"The monitor's master status box requires getContentSummary(new Path(""/"")) on HDFS (otherwise see stack trace below).  There doesn't seem to be any way to grant this permission to a particular user or change the permissions on /, so for this to work, you either need to run accumulo and hdfs as the same user or add accumulo's user to hadoop's supergroup.  Either way, this seems like it's granting unnecessarily broad permissions to accumulo.  Is there some other way to get the disk usage information out of hadoop with normal user-level permissions?


Stack trace running as separate users without special permissions:
{code}
2013-04-16 20:34:57,770 [servlets.BasicServlet] DEBUG:  org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=accumulo, ac
cess=READ_EXECUTE, inode=""system"":hadoop:supergroup:rwx------
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=accumulo, access=READ_EXECUTE, inode=""system"":hadoop:supergroup:rwx-
-----
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:532)
        at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
        at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
        at org.apache.hadoop.hdfs.DFSClient.getContentSummary(DFSClient.java:1438)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getContentSummary(DistributedFileSystem.java:251)
        at org.apache.accumulo.server.trace.TraceFileSystem.getContentSummary(TraceFileSystem.java:312)
        at org.apache.accumulo.server.monitor.servlets.DefaultServlet.doAccumuloTable(DefaultServlet.java:317)
        at org.apache.accumulo.server.monitor.servlets.DefaultServlet.pageBody(DefaultServlet.java:256)
        at org.apache.accumulo.server.monitor.servlets.BasicServlet.doGet(BasicServlet.java:61)
        at org.apache.accumulo.server.monitor.servlets.DefaultServlet.doGet(DefaultServlet.java:157)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Permission denied: user=accumulo, access=READ_EXECUTE, inode=""system"":hadoop:supergroup:rwx--
----
        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:199)
        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkSubAccess(FSPermissionChecker.java:168)
        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:137)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5468)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getContentSummary(FSNamesystem.java:2225)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.getContentSummary(NameNode.java:986)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:578)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1393)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1389)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:416)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1149)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1387)

        at org.apache.hadoop.ipc.Client.call(Client.java:1107)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
        at sun.proxy.$Proxy1.getContentSummary(Unknown Source)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
        at sun.proxy.$Proxy1.getContentSummary(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient.getContentSummary(DFSClient.java:1436)
        ... 22 more
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-17 14:00:15.796,,,no_permission,,,,,,,,,,,,323228,,,Fri Aug 16 18:05:49 UTC 2013,,,,,,0|i1jrmv:,323573,,,,,,,,"16/Apr/13 21:04;mberman;Hadoop 1.1.2, btw","17/Apr/13 14:00;kturner;Does this prevent the monitor page from displaying?  If so maybe for 1.5 we can fix that, make it display something like N/A when it can not get the info.",17/Apr/13 14:10;vines;It does prevent the Accumulo Master window in the Overview page from displaying.,"17/Apr/13 16:56;ecn;If there's a problem fetching this info from hdfs, the table will just say ""Unknown"".","17/Apr/13 19:37;hudson;Integrated in Accumulo-1.5 #82 (See [https://builds.apache.org/job/Accumulo-1.5/82/])
    ACCUMULO-1282 ignore permission problems getting disk usage information (Revision 1468995)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
","17/Apr/13 19:51;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #81 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/81/])
    ACCUMULO-1282 ignore permission problems getting disk usage information (Revision 1468995)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
","17/Apr/13 20:44;hudson;Integrated in Accumulo-Trunk #835 (See [https://builds.apache.org/job/Accumulo-Trunk/835/])
    ACCUMULO-1282 ignore permission problems getting disk usage information (Revision 1468997)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
* /accumulo/trunk/src
","17/Apr/13 20:50;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #193 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/193/])
    ACCUMULO-1282 ignore permission problems getting disk usage information (Revision 1468997)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java
* /accumulo/trunk/src
",16/Aug/13 18:05;busbey;[start of thread discussing manually fixing permissions on 1.4.x|http://mail-archives.apache.org/mod_mbox/accumulo-user/201306.mbox/%3CCAPnhrdv1uOYNRSfdZFtC0yu687DEdozoMpErRjqi_fFehSqHXA@mail.gmail.com%3E] and [suggested workaround|http://mail-archives.apache.org/mod_mbox/accumulo-user/201306.mbox/%3CB9CB2B2BF27F0F46B8ECF781831E00E70F5D4088@0015-its-exmb10.us.saic.com%3E],,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
'service accumulo-tserver stop' does not work,ACCUMULO-1615,12659883,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,rmutyala,rmutyala,rmutyala,25/Jul/13 20:15,15/Aug/13 13:36,13/Mar/19 22:01,25/Jul/13 20:50,1.5.0,,,,,,,1.5.1,,,scripts,tserver,,,,,0,,,,,"Started accumulo with 'service accumulo-tserver start'

Tried to stop accumulo with 'service accumulo-tserver stop'

Fails with org.apache.hadoop.security.AccessControlException as it tries to 
stop with user 'root' and not 'ACCUMULO_USER'. 
",RHEL6.4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,25/Jul/13 20:19;rmutyala;ACCUMULO-1615.patch;https://issues.apache.org/jira/secure/attachment/12594258/ACCUMULO-1615.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-07-25 20:38:43.535,,,no_permission,,,,,,,,,,,,340075,,,Thu Jul 25 22:43:04 UTC 2013,,,,,,0|i1mnkf:,340393,,,,,,,,25/Jul/13 20:18;rmutyala;Made change so do_stop() has same logic of setting the user as do_start() logic,25/Jul/13 20:19;rmutyala;Patch,"25/Jul/13 20:38;jira-bot;Commit 260b4318802401e82bb0c737e604ab641b57a6cc in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=260b431 ]

ACCUMULO-1615 applying Ravi Mutyala's patch
",25/Jul/13 20:50;ecn;Patched. Thanks!,"25/Jul/13 20:51;jira-bot;Commit d8e5de664d12440df3ac629d53fb67e67b14db89 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d8e5de6 ]

ACCUMULO-1615 applying Ravi Mutyala's patch to 1.5 branch
","25/Jul/13 22:35;rmutyala;Patched against the wip repo? I thought people already started working on git://git@apache.org/accumulo.git. I tried a pull on that and didn't get the update. 
",25/Jul/13 22:43;kturner;Theres a ticket INFRA-6560,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Port CloudStone fixes to 1.4.x branch,ACCUMULO-897,12623416,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,dlyle,dlyle,11/Dec/12 17:32,07/Aug/13 23:10,13/Mar/19 22:01,20/Dec/12 19:08,1.4.1,1.4.2,,,,,,1.4.3,,,test,,,,,,0,,,,,"CloudStone fixes in 1.5 will not work in 1.4 due to the addition of the -f flag in the deletetable calls.
This fix ports all code from test/system/batch/lib, removes the -f flags, uses ACCUMULO_HOME to get location of accumulo and updates README file.",Multi Linux Hosts,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1519,,,,,,,,,,,11/Dec/12 17:36;dlyle;ACCUMULO-897.patch;https://issues.apache.org/jira/secure/attachment/12560411/ACCUMULO-897.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-12-20 19:13:57.535,,,no_permission,,,,,,,,,,,,297113,,,Thu Dec 20 20:26:22 UTC 2012,,,,,,0|i14lgn:,234941,,,,,,,,11/Dec/12 17:34;dlyle;Change was in 1.5 but I need it in 1.4.x.,"20/Dec/12 19:13;hudson;Integrated in Accumulo-Trunk #590 (See [https://builds.apache.org/job/Accumulo-Trunk/590/])
    ACCUMULO-897 get the benchmarks to run again (Revision 1424615)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/test/system/bench/README
* /accumulo/trunk/test/system/bench/lib/IngestBenchmark.py
* /accumulo/trunk/test/system/bench/lib/RowHashBenchmark.py
* /accumulo/trunk/test/system/bench/lib/path.py
* /accumulo/trunk/test/system/bench/run.py
","20/Dec/12 20:26;hudson;Integrated in Accumulo-1.4.x #257 (See [https://builds.apache.org/job/Accumulo-1.4.x/257/])
    ACCUMULO-897 get the benchmarks to run again (Revision 1424638)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/test/system/bench/README
* /accumulo/branches/1.4/test/system/bench/cloudstone1/cloudstone1.py
* /accumulo/branches/1.4/test/system/bench/lib/Benchmark.py
* /accumulo/branches/1.4/test/system/bench/lib/CreateTablesBenchmark.py
* /accumulo/branches/1.4/test/system/bench/lib/IngestBenchmark.py
* /accumulo/branches/1.4/test/system/bench/lib/RowHashBenchmark.py
* /accumulo/branches/1.4/test/system/bench/lib/TableSplitsBenchmark.py
* /accumulo/branches/1.4/test/system/bench/lib/TeraSortBenchmark.py
* /accumulo/branches/1.4/test/system/bench/lib/cloudshell.py
* /accumulo/branches/1.4/test/system/bench/lib/path.py
* /accumulo/branches/1.4/test/system/bench/run.py
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Dump/Restore Zookeeper command line parsing is broken,ACCUMULO-1573,12658023,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,16/Jul/13 14:48,07/Aug/13 13:41,13/Mar/19 22:01,07/Aug/13 13:41,1.5.0,,,,,,,1.5.1,,,,,,,,,0,,,,," * dump of / does not restore
 * argument parsing for dump is wrong (reads args[0])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-17 15:31:47.757,,,no_permission,,,,,,,,,,,,338217,,,Wed Jul 17 15:34:09 UTC 2013,,,,,,0|i1mc4n:,338538,,,,,,,,"17/Jul/13 15:31;jira-bot;Commit 122b1b13f0433c0b69693ad57713de048467dad3 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=122b1b1 ]

ACCUMULO-1573
","17/Jul/13 15:31;jira-bot;Commit 44532948ed4ddca0034a17d993106f0a8a42f274 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4453294 ]

ACCUMULO-1573
","17/Jul/13 15:34;jira-bot;Commit 122b1b13f0433c0b69693ad57713de048467dad3 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=122b1b1 ]

ACCUMULO-1573
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ListInstances utility doesn't work,ACCUMULO-1575,12658063,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,16/Jul/13 17:52,07/Aug/13 13:40,13/Mar/19 22:01,07/Aug/13 13:40,1.5.0,,,,,,,1.5.1,,,,,,,,,0,,,,,"Takes zookeeper argument, but doesn't use it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-17 15:31:46.465,,,no_permission,,,,,,,,,,,,338257,,,Wed Jul 17 15:34:07 UTC 2013,,,,,,0|i1mcdb:,338577,,,,,,,,"17/Jul/13 15:31;jira-bot;Commit 8ef040122228a459a16243e6456ebb03f27d0047 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8ef0401 ]

ACCUMULO-1575
","17/Jul/13 15:34;jira-bot;Commit 8ef040122228a459a16243e6456ebb03f27d0047 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8ef0401 ]

ACCUMULO-1575
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
utility class TabletServerLocks doesn't work,ACCUMULO-1574,12658057,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,16/Jul/13 17:32,07/Aug/13 13:36,13/Mar/19 22:01,07/Aug/13 13:36,1.5.0,,,,,,,1.5.1,,,,,,,,,0,,,,,"{noformat}
./bin/accumulo org.apache.accumulo.server.util.TabletServerLocks -list
Thread ""org.apache.accumulo.server.util.TabletServerLocks"" died null
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.accumulo.start.Main$1.run(Main.java:101)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.NullPointerException
	at org.apache.accumulo.fate.zookeeper.ZooLock.getLockData(ZooLock.java:416)
	at org.apache.accumulo.fate.zookeeper.ZooLock.getLockData(ZooLock.java:441)
	at org.apache.accumulo.fate.zookeeper.ZooLock.getLockData(ZooLock.java:437)
	at org.apache.accumulo.server.util.TabletServerLocks.main(TabletServerLocks.java:54)
	... 6 more
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-17 15:31:47.128,,,no_permission,,,,,,,,,,,,338251,,,Wed Jul 17 15:34:08 UTC 2013,,,,,,0|i1mcbz:,338571,,,,,,,,"17/Jul/13 15:31;jira-bot;Commit a1fda97fe788be4cceb9bb10a0d2247ac0ac145c in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a1fda97 ]

ACCUMULO-1574
","17/Jul/13 15:34;jira-bot;Commit a1fda97fe788be4cceb9bb10a0d2247ac0ac145c in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a1fda97 ]

ACCUMULO-1574
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Generated RPMs are not compatible with yum on 64-bit architectures,ACCUMULO-1560,12656747,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,mdrob,mdrob,mdrob,08/Jul/13 23:34,10/Jul/13 05:26,13/Mar/19 22:01,10/Jul/13 01:00,1.4.3,,,,,,,1.4.4,,,build,,,,,,0,,,,,"RPMs build with the maven-rpm-plugin on 64-bit systems are created with the ""amd64"" arch, which is not recognized on some (all?) RedHat x86_64 systems.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-09 04:05:45.388,,,no_permission,,,,,,,,,,,,336970,,,Wed Jul 10 05:26:48 UTC 2013,,,,,,0|i1m4gf:,337293,,,,,,,,"08/Jul/13 23:56;mdrob;[~ctubbsii] - Did we give up on building 32-bit RPMs? I noticed that the 1.5 branch and trunk both explicitly use ""x86_64"" and am wondering if there are mitigations to use for running on 32-bit systems. Or do we not even try, given that those systems are limited to 4G of RAM?","09/Jul/13 04:05;ctubbsii;In 1.5, the primary RPM is noarch. The only arch-dependent RPM in 1.5 is the RPM with native maps. That is x86_64, but there's nothing to stop users from editing the POM and making a 32-bit version. However, I was primarily focused on a POM that would generate artifacts to provide, rather than make separate profiles for end users to generate their own. In hindsight, I could have done something with a system property that one could override on the command-line at build time. It just wasn't my focus to support 32-bit artifacts, and the main artifact is noarch, so it doesn't matter much.

I don't really want to focus too much on these RPMs, though, given the anticipated packaging improvements of ACCUMULO-210.","10/Jul/13 00:59;jira-bot;Commit 1501624 from [~mdrob]
[ https://svn.apache.org/r1501624 ]

ACCUMULO-1560 updating pom to produce x86_64 arch rpm",10/Jul/13 05:26;ctubbsii;Might be better to make it a property with a default value of x86_64.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LateLastContact test needs to use a real entry in zookeeper,ACCUMULO-526,12550519,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,11/Apr/12 12:38,20/Jun/13 20:43,13/Mar/19 22:01,11/Apr/12 17:24,,,,,,,,,,,test,,,,,,0,,,,,"The LateLastContact attempts to find troubled tservers by noticing that they are failing to respond to status requests.  If a server does not report status, the master attempts to kill it by removing the zookeeper lock.

The way the current test works, is that it creates a fake lock using zkCli.sh, which is not always present.  It isn't really creating a proper entry in zookeeper anyhow.  It should be re-written to use java code to create a proper entry.

Reported by Keys Botzum:

MapR does not normally install a full zookeeper install on each node. Instead we install a zookeeper ""client"" on each node which is basically the zookeeper JAR file - /opt/mapr/lib/zookeeper-3.3.2.jar. If I set ZOOKEEPER_HOME to /opt/mapr/lib almost everything works fine since Accumulo seems to only need the JAR file at that location. The one exception is the stress.weird.LateLastContact which directly references zkClient.sh (in stress/weird.py) which isn't part of the MapR install. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-20 20:43:56.069,,,no_permission,,,,,,,,,,,,235383,,,Thu Jun 20 20:43:56 UTC 2013,,,,,,0|i07mnr:,42437,,,,,,,,20/Jun/13 20:43;jmhsieh;fixed in 1.4.1.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooCacheTest timing is too tight,ACCUMULO-525,12550512,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,11/Apr/12 12:30,20/Jun/13 20:43,13/Mar/19 22:01,16/Oct/12 14:11,,,,,,,,,,,test,,,,,,0,,,,,"Reported by Keys Botzum

simple.zooCacheTest.ZooCacheTest has one minor issue. The issue is that the test times out on my system after 60 seconds. I changed the timeout to 120 seconds and the test completes successfully in 95 seconds.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-20 20:43:32.947,,,no_permission,,,,,,,,,,,,235376,,,Thu Jun 20 20:43:32 UTC 2013,,,,,,0|i07mnz:,42438,,,,,,,,20/Jun/13 20:43;jmhsieh;fixed in 1.4.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DeleteRowsSplitTest timing is too tight,ACCUMULO-524,12550511,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,11/Apr/12 12:29,20/Jun/13 20:43,13/Mar/19 22:01,11/Apr/12 17:23,,,,,,,,,,,test,,,,,,0,,,,,"reported by Keys Botzum

simple.deleterows.DeleteRowsSplitTest fails with a timeout. The test is coded to wait 120 seconds which wasn't' quite long enough on my system. I changed it to 180 seconds and it finishes cleanly after 138 seconds.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-20 20:43:13.914,,,no_permission,,,,,,,,,,,,235375,,,Thu Jun 20 20:43:13 UTC 2013,,,,,,0|i07mo7:,42439,,,,,,,,20/Jun/13 20:43;jmhsieh;fixed in 1.4.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FirstEntryInRowIterator is broken and has no test,ACCUMULO-633,12560533,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,13/Jun/12 17:04,07/Jun/13 16:58,13/Mar/19 22:01,22/Jun/12 20:22,1.3.5-incubating,1.4.0,,,,,,1.4.1,1.5.0,,client,,,,,,0,,,,,"In 1.4 and trunk, the iterator throws a NullPointerException when seeked.

In 1.3 the iterator runs, but there is a question as to what it should do when it is seeked to the middle of a row.  Currently, it returns the first key found within the range.  I believe this should be changed to ignore the remaining portion of that row and return the first key of the next row.  Should this change be made in 1.3, or should I leave it as is and just change it in 1.4 and greater?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-06-13 22:07:24.56,,,no_permission,,,,,,,,,,,,246433,,,Fri Jun 07 16:58:50 UTC 2013,,,,,,0|i07lzz:,42330,,,,,,,,"13/Jun/12 22:07;jvines;So the middle row behavior can have some interesting edge cases. If we take the literal name, then the attempting to return only the first Key is the proper thing to do. And I like that. But you need to be careful there, as someone could seek to a specific Key, which could actually be the first entry in the row. So this iterator will require seeking to the row and then checking the top key to see if the Key specified is teh first entry before seeking to the next possible row.","07/Jun/13 16:55;ctubbsii;This is the only issue that has been addressed in the 1.3 line since the release of 1.3.6. Given that 1.3 is old, and that this is a change in behavior, I don't think it warrants a release of 1.3.7. I'm removing 1.3.7 from the fixVersion on this ticket.",07/Jun/13 16:58;billie.rinaldi;+1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RestoreZookeeper does not work,ACCUMULO-1418,12647797,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,,ecn,ecn,15/May/13 18:20,04/Jun/13 14:24,13/Mar/19 22:01,04/Jun/13 14:24,1.4.0,,,,,,,1.4.4,,,,,,,,,0,,,,,get InvalideACLs error,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-16 01:42:48.87,,,no_permission,,,,,,,,,,,,328153,,,Mon Jun 03 22:42:01 UTC 2013,,,,,,0|i1km9z:,328497,,,,,,,,"16/May/13 01:42;hudson;Integrated in Accumulo-1.4.x #304 (See [https://builds.apache.org/job/Accumulo-1.4.x/304/])
    ACCUMULO-1418 use ZooReaderWriter, and not raw ZooKeeper (Revision 1482989)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/util/RestoreZookeeper.java
","16/May/13 03:37;hudson;Integrated in Accumulo-1.5 #117 (See [https://builds.apache.org/job/Accumulo-1.5/117/])
    ACCUMULO-1418 use ZooReaderWriter, and not raw ZooKeeper (Revision 1483023)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/proxy/README
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/RestoreZookeeper.java
* /accumulo/branches/1.5/src
","16/May/13 03:42;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #231 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/231/])
    ACCUMULO-1418 use ZooReaderWriter, and not raw ZooKeeper (Revision 1483047)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/RestoreZookeeper.java
* /accumulo/trunk/src
","16/May/13 03:46;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #119 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/119/])
    ACCUMULO-1418 use ZooReaderWriter, and not raw ZooKeeper (Revision 1483023)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/proxy/README
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/RestoreZookeeper.java
* /accumulo/branches/1.5/src
","16/May/13 03:50;hudson;Integrated in Accumulo-Trunk #873 (See [https://builds.apache.org/job/Accumulo-Trunk/873/])
    ACCUMULO-1418 use ZooReaderWriter, and not raw ZooKeeper (Revision 1483047)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/RestoreZookeeper.java
* /accumulo/trunk/src
",03/Jun/13 22:42;mdrob;Is this issue resolved?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
gc is warning about files not existing,ACCUMULO-1153,12635423,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,05/Mar/13 20:10,25/May/13 00:21,13/Mar/19 22:01,20/Mar/13 17:47,,,,,,,,1.5.0,,,gc,,,,,,0,,,,,"Might be related to using the Trash.

File doesn't exist: /accumulo/tables/id/c-00000003",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-20 20:04:22.673,,,no_permission,,,,,,,,,,,,315916,,,Sat May 25 00:21:39 UTC 2013,,,,,,0|i1iiif:,316259,,,,,,,,"20/Mar/13 20:04;hudson;Integrated in Accumulo-Trunk #789 (See [https://builds.apache.org/job/Accumulo-Trunk/789/])
    ACCUMULO-1153 guard against an index-out-of-bounds exception (Revision 1458979)
ACCUMULO-1153 do not bother warning about directories we know may not exist (Revision 1458977)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/src
","20/Mar/13 20:12;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #148 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/148/])
    ACCUMULO-1153 guard against an index-out-of-bounds exception (Revision 1458979)
ACCUMULO-1153 do not bother warning about directories we know may not exist (Revision 1458977)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/src
","20/Mar/13 21:05;hudson;Integrated in Accumulo-1.5 #44 (See [https://builds.apache.org/job/Accumulo-1.5/44/])
    ACCUMULO-1153 guard against an index-out-of-bounds exception (Revision 1458978)
ACCUMULO-1153 do not bother warning about directories we know may not exist (Revision 1458976)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java

ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
","20/Mar/13 22:16;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #42 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/42/])
    ACCUMULO-1153 guard against an index-out-of-bounds exception (Revision 1458978)
ACCUMULO-1153 do not bother warning about directories we know may not exist (Revision 1458976)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java

ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
",23/May/13 21:35;mdrob;I'm seeing this warning on a 1.4 cluster. It looks like the culprit is that the gc deletes the parent directory and then can't find the files that were supposed to be in it. Any chance of a backport?,"24/May/13 18:20;ctubbsii;{quote}Any chance of a backport?{quote} - Personal opinion: not worth the effort, and possibly disruptive to modify logging behavior in a bugfix.","25/May/13 00:21;mdrob;The bugfix, from an administrator's perspective, _is_ the logging behaviour. Seeing unnecessary messages in the logs on the monitor can hide relevant messages, and leading to other serious problems down the line.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
isInSafeMode ignores passed in FileSystem,ACCUMULO-1456,12649104,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,23/May/13 12:29,23/May/13 15:38,13/Mar/19 22:01,23/May/13 14:12,1.5.0,,,,,,,1.5.1,1.6.0,,gc,master,tserver,,,,0,,,,,"I noticed that Accumulo.isInSafeMode gets the file system from the HDFS config, and does not use the one passed in.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-23 15:23:19.219,,,no_permission,,,,,,,,,,,,329431,,,Thu May 23 15:38:48 UTC 2013,,,,,,0|i1ku3b:,329766,,,,,,,,"23/May/13 15:23;hudson;Integrated in Accumulo-Trunk #886 (See [https://builds.apache.org/job/Accumulo-Trunk/886/])
    ACCUMULO-1456 use provided FileSystem object (Revision 1485664)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/src
","23/May/13 15:26;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #135 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/135/])
    ACCUMULO-1456 use provided FileSystem object (Revision 1485662)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/Accumulo.java
","23/May/13 15:37;hudson;Integrated in Accumulo-1.5 #133 (See [https://builds.apache.org/job/Accumulo-1.5/133/])
    ACCUMULO-1456 use provided FileSystem object (Revision 1485662)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/Accumulo.java
","23/May/13 15:38;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #245 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/245/])
    ACCUMULO-1456 use provided FileSystem object (Revision 1485664)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add include for **/*.jnilib in the binary-release.xml for tar.gz artifact,ACCUMULO-1423,12648109,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ctubbsii,sonixbp,sonixbp,17/May/13 04:17,19/May/13 02:18,13/Mar/19 22:01,19/May/13 01:15,,,,,,,,1.5.0,,,,,,,,,0,,,,,Building a tarball on Mac with the native profile does not include the actual map lib.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-17 16:15:27.362,,,no_permission,,,,,,,,,,,,328465,,,Sun May 19 02:18:52 UTC 2013,,,,,,0|i1ko7b:,328809,,,,,,,,"17/May/13 16:15;ctubbsii;Yes, the binary assembly is platform-specific. It needs to be made more general.",17/May/13 16:18;sonixbp;So are you thinking maybe instead of **/*.so it should be something that would include any possible compiled c++ artifacts?,"19/May/13 02:11;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #238 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/238/])
    ACCUMULO-1404,ACCUMULO-1423 merge to trunk (Revision 1484205)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","19/May/13 02:14;hudson;Integrated in Accumulo-Trunk #880 (See [https://builds.apache.org/job/Accumulo-Trunk/880/])
    ACCUMULO-1404,ACCUMULO-1423 merge to trunk (Revision 1484205)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/src
","19/May/13 02:15;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #127 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/127/])
    ACCUMULO-1404,ACCUMULO-1423 include missing files in binary tarball; fix some permissions (Revision 1484204)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
","19/May/13 02:18;hudson;Integrated in Accumulo-1.5 #125 (See [https://builds.apache.org/job/Accumulo-1.5/125/])
    ACCUMULO-1404,ACCUMULO-1423 include missing files in binary tarball; fix some permissions (Revision 1484204)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Binary packages should not have the -assemble component in their filename,ACCUMULO-1413,12647240,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ctubbsii,ctubbsii,ctubbsii,13/May/13 03:39,18/May/13 05:18,13/Mar/19 22:01,18/May/13 02:57,,,,,,,,1.5.0,,,build,,,,,,0,bad,,,,"The binary packacking (tar.gz, rpm, deb, etc.) all have this ""-assemble"" part of their filename, because they are built in the assemble child module in our maven build. They should not have this part of their filename.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15/May/13 18:07;ctubbsii;ACCUMULO-1413.v1.patch;https://issues.apache.org/jira/secure/attachment/12583347/ACCUMULO-1413.v1.patch,16/May/13 15:45;ctubbsii;ACCUMULO-1413.v2.patch;https://issues.apache.org/jira/secure/attachment/12583494/ACCUMULO-1413.v2.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2013-05-15 18:59:15.313,,,no_permission,,,,,,,,,,,,327596,,,Sat May 18 05:18:04 UTC 2013,,,,,,0|i1kiu7:,327940,,,,,,,,"13/May/13 03:42;ctubbsii;This is going to require some maven trickery. However, it may not be all that important, as the filenames are only those that are published to Maven. The filenames we put on the website and in the mirrors when we release can be anything we want... we don't even need to re-sign them.

Also, any maven trickery to get this to happen in 1.5.0 for the rpms/debs is going to be superceded by ACCUMULO-210 in 1.6.0 and later (though it may still be applicable to the binary tarball).","15/May/13 18:12;ctubbsii;I've worked out an ugly patch [^ACCUMULO-1413.v1.patch] to split the aggregator parent from the inheritance parent, to satisfy this. I do not like this patch, though, and think it should be abandoned. I think we're trying to do something that isn't really that important.

Essentially, this patch makes the inherited ""parent"" a sibling of the other modules, and moves the assemble artifacts to the root.

Another option might be to rename the parent artifactId to ""accumulo-parent"", and rename the ""assemble"" module artifactId to simply ""accumulo"". This would have the side-effect, though, of renaming the source-release tarball to ""accumulo-parent-<version>-source-release.tar.gz"".","15/May/13 18:59;medined;-1 for accumulo-parent references. I'm happy to accept something with
'assemble' in the name if we briefly explain why it is there.


On Wed, May 15, 2013 at 2:13 PM, Christopher Tubbs (JIRA)

","15/May/13 20:06;ctubbsii;The thing is, this is only the ""filename"" (really a filename representation of attributes in the Maven2 artifact store), when it is in Maven. When we put it on the download page, and in the mirrors, we can call it whatever we want. I suppose technically, we don't even need to deploy these to Maven at all (but I find it easier to use it for staging all the build artifacts, and at that point, we might as well deploy it in case somebody finds it useful).","16/May/13 15:45;ctubbsii;Attached a better patch [^ACCUMULO-1413.v2.patch] for resolving the confusing names of components. I'm going to commit this one, as I think it gets us 99% towards what we want (1% remaining, only because it changes the name of our parent POM to ""accumulo-project"" and the assemble artifact name is now simply ""accumulo"").","16/May/13 19:13;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #120 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/120/])
    ACCUMULO-1413 applied v2 patch, which renames the parent POM and assemble module artifactIds, to provide artifacts with more suitable names (getting rid of the unnecessary zip version of the source release assembly in the process), and updating documentation to reflect tarball filenames (Revision 1483421)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/README
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/docs/src/main/latex/accumulo_user_manual/chapters/administration.tex
* /accumulo/branches/1.5/examples/pom.xml
* /accumulo/branches/1.5/fate/pom.xml
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/proxy/pom.xml
* /accumulo/branches/1.5/server/pom.xml
* /accumulo/branches/1.5/start/pom.xml
* /accumulo/branches/1.5/test/pom.xml
* /accumulo/branches/1.5/trace/pom.xml
","16/May/13 19:18;hudson;Integrated in Accumulo-1.5 #118 (See [https://builds.apache.org/job/Accumulo-1.5/118/])
    ACCUMULO-1413 applied v2 patch, which renames the parent POM and assemble module artifactIds, to provide artifacts with more suitable names (getting rid of the unnecessary zip version of the source release assembly in the process), and updating documentation to reflect tarball filenames (Revision 1483421)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/README
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/assemble/src/main/assemblies/binary-release.xml
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/docs/src/main/latex/accumulo_user_manual/chapters/administration.tex
* /accumulo/branches/1.5/examples/pom.xml
* /accumulo/branches/1.5/fate/pom.xml
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/proxy/pom.xml
* /accumulo/branches/1.5/server/pom.xml
* /accumulo/branches/1.5/start/pom.xml
* /accumulo/branches/1.5/test/pom.xml
* /accumulo/branches/1.5/trace/pom.xml
","16/May/13 20:47;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #232 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/232/])
    ACCUMULO-1413,ACCUMULO-1421 merge to trunk (Revision 1483431)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/TTimeoutTransport.java
* /accumulo/trunk/docs/src/main/latex/accumulo_user_manual/chapters/administration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
","16/May/13 20:53;hudson;Integrated in Accumulo-Trunk #874 (See [https://builds.apache.org/job/Accumulo-Trunk/874/])
    ACCUMULO-1413,ACCUMULO-1421 merge to trunk (Revision 1483431)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/TTimeoutTransport.java
* /accumulo/trunk/docs/src/main/latex/accumulo_user_manual/chapters/administration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
","17/May/13 17:12;ctubbsii;The previous solution did not make everybody happy. We need to try to get the ""-project"" part of the source-release assembly out of the name.","17/May/13 17:15;sonixbp;Would using a ""finalName"" in the assembly help this?


On Fri, May 17, 2013 at 1:13 PM, Christopher Tubbs (JIRA)

","17/May/13 17:37;ctubbsii;{quote}Would using a ""finalName"" in the assembly help this?{quote}

I'm experimenting using finalName to change the baseDirectory for the source-release tarball, and attaching the resulting artifact to the child module to change the filename.","17/May/13 20:24;hudson;Integrated in Accumulo-1.5 #121 (See [https://builds.apache.org/job/Accumulo-1.5/121/])
    ACCUMULO-1413 properly built the source-release tarball with the preferred naming convention (Revision 1483966)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/server/src/main/c++/nativeMap/Makefile
","17/May/13 20:27;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #123 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/123/])
    ACCUMULO-1413 properly built the source-release tarball with the preferred naming convention (Revision 1483966)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/server/src/main/c++/nativeMap/Makefile
","18/May/13 05:11;hudson;Integrated in Accumulo-Trunk #878 (See [https://builds.apache.org/job/Accumulo-Trunk/878/])
    ACCUMULO-1413 merge to trunk (Revision 1484047)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/.gitignore
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/c++/nativeMap/Makefile
* /accumulo/trunk/src
","18/May/13 05:18;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #236 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/236/])
    ACCUMULO-1413 merge to trunk (Revision 1484047)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/.gitignore
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/assemble/src/main/assemblies/binary-release.xml
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/c++/nativeMap/Makefile
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cannot use iterators in MockAccumulo running in a secondary classloader,ACCUMULO-1411,12647104,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,vines,vines,vines,10/May/13 21:10,14/May/13 18:56,13/Mar/19 22:01,14/May/13 16:30,,,,,,,,1.5.0,,,start,,,,,,0,,,,,"We have a situation where there is a test client which spins off a Thread running a MockAccumulo, and then we try to use iterators that are on the classpath for that Thread. Unfortunately, they CNFE. We've traced it back, since the ReloadingClassLoader just uses the parent classloader (AccumuloClassLoader) in absence of configurations. The AccumuloClassLoader.getClassLoader uses ClassLoader.getSystemClassLoader() as it's parent, not AccumuloClassLoader.class.getClassLoader(). I believe that should preserve the way the classloaders work in the standard use cases while not breaking in any other cases.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-14 00:42:42.014,,,no_permission,,,,,,,,,,,,327461,,,Tue May 14 18:56:51 UTC 2013,,,,,,0|i1ki07:,327805,,,,,,,,14/May/13 00:30;vines;This isn't as simple as changing the getClassLoader() method to using the classloader used to load AccumuloClassLoader as the shell seems to break (all the tests fail). ,14/May/13 00:42;dlmarion;Does Thread.setContextClassloader() apply here?,14/May/13 14:43;vines;Apply to Accumulo or to client code? It doesn't work for client code because Mock explicitly uses AccumuloVFSClassLoader.loadClass();,14/May/13 15:04;vines;Hmm... and now it builds fine for me... I guess something else in my workspace was broken,"14/May/13 18:42;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #226 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/226/])
    ACCUMULO-1411 - Classloader now inherits propertly (Revision 1482434)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java
","14/May/13 18:46;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #116 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/116/])
    ACCUMULO-1411 - Classloader now inherits propertly (Revision 1482431)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java
","14/May/13 18:51;hudson;Integrated in Accumulo-1.5 #114 (See [https://builds.apache.org/job/Accumulo-1.5/114/])
    ACCUMULO-1411 - Classloader now inherits propertly (Revision 1482431)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java
","14/May/13 18:56;hudson;Integrated in Accumulo-Trunk #868 (See [https://builds.apache.org/job/Accumulo-Trunk/868/])
    ACCUMULO-1411 - Classloader now inherits propertly (Revision 1482434)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"RPM has dependency on ""jdk"", it should be ""jre""",ACCUMULO-1389,12646465,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ctubbsii,ctubbsii,ctubbsii,07/May/13 18:09,08/May/13 22:56,13/Mar/19 22:01,08/May/13 22:15,,,,,,,,1.5.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-07 18:13:14.674,,,no_permission,,,,,,,,,,,,326823,,,Wed May 08 22:56:45 UTC 2013,,,,,,0|i1kdsn:,327168,,,,,,,,"07/May/13 18:13;vines;Does the rpm not build the native libraries? That would require jdk

Sent from my phone, please pardon the typos and brevity.

","07/May/13 19:22;ctubbsii;No, the RPM native package provides the pre-built native libraries. I decided to go with a arch-dependent RPM targetted towards x86_64, rather than a noarch RPM that builds locally. It was the easiest to do, and matches RPM conventions best.","08/May/13 22:31;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #104 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/104/])
    ACCUMULO-1389 change rpm dependency to jre instead of jdk (Revision 1480475)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
","08/May/13 22:34;hudson;Integrated in Accumulo-1.5 #102 (See [https://builds.apache.org/job/Accumulo-1.5/102/])
    ACCUMULO-1389 change rpm dependency to jre instead of jdk (Revision 1480475)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/branches/1.5/assemble/pom.xml
","08/May/13 22:52;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #214 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/214/])
    ACCUMULO-1384, ACCUMULO-1389 merged to trunk (Revision 1480486)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/bin/stop-all.sh
* /accumulo/trunk/bin/stop-here.sh
* /accumulo/trunk/bin/tdown.sh
* /accumulo/trunk/bin/tool.sh
* /accumulo/trunk/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/vfs-classloader/accumulo-site.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/resources/org/apache/accumulo/core/conf/config.html
* /accumulo/trunk/core/src/test/resources/disabled/conf/accumulo-site.xml
* /accumulo/trunk/docs/combiners.html
* /accumulo/trunk/docs/examples/README.bloom
* /accumulo/trunk/docs/examples/README.combiner
* /accumulo/trunk/docs/examples/README.constraints
* /accumulo/trunk/docs/examples/README.mapred
* /accumulo/trunk/docs/examples/README.maxmutation
* /accumulo/trunk/docs/examples/README.regex
* /accumulo/trunk/docs/examples/README.rowhash
* /accumulo/trunk/docs/examples/README.tabletofile
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/c++/nativeMap/Makefile
* /accumulo/trunk/src
* /accumulo/trunk/test/compat/japi-compliance/japi-accumulo-1.5.xml
* /accumulo/trunk/test/src/test/resources/conf/accumulo-site.xml
* /accumulo/trunk/test/system/auto/TestUtils.py
* /accumulo/trunk/test/system/auto/simple/mapreduce.py
* /accumulo/trunk/test/system/bench/lib/Benchmark.py
* /accumulo/trunk/test/system/continuous/agitator.pl
* /accumulo/trunk/test/system/continuous/mapred-setup.sh
","08/May/13 22:56;hudson;Integrated in Accumulo-Trunk #856 (See [https://builds.apache.org/job/Accumulo-Trunk/856/])
    ACCUMULO-1384, ACCUMULO-1389 merged to trunk (Revision 1480486)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/README
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/bin/stop-all.sh
* /accumulo/trunk/bin/stop-here.sh
* /accumulo/trunk/bin/tdown.sh
* /accumulo/trunk/bin/tool.sh
* /accumulo/trunk/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/vfs-classloader/accumulo-site.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/resources/org/apache/accumulo/core/conf/config.html
* /accumulo/trunk/core/src/test/resources/disabled/conf/accumulo-site.xml
* /accumulo/trunk/docs/combiners.html
* /accumulo/trunk/docs/examples/README.bloom
* /accumulo/trunk/docs/examples/README.combiner
* /accumulo/trunk/docs/examples/README.constraints
* /accumulo/trunk/docs/examples/README.mapred
* /accumulo/trunk/docs/examples/README.maxmutation
* /accumulo/trunk/docs/examples/README.regex
* /accumulo/trunk/docs/examples/README.rowhash
* /accumulo/trunk/docs/examples/README.tabletofile
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/README
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/c++/nativeMap/Makefile
* /accumulo/trunk/src
* /accumulo/trunk/test/compat/japi-compliance/japi-accumulo-1.5.xml
* /accumulo/trunk/test/src/test/resources/conf/accumulo-site.xml
* /accumulo/trunk/test/system/auto/TestUtils.py
* /accumulo/trunk/test/system/auto/simple/mapreduce.py
* /accumulo/trunk/test/system/bench/lib/Benchmark.py
* /accumulo/trunk/test/system/continuous/agitator.pl
* /accumulo/trunk/test/system/continuous/mapred-setup.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
simple.gc.GCTest sometimes fails,ACCUMULO-1332,12644161,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,23/Apr/13 17:29,23/Apr/13 20:12,13/Mar/19 22:01,23/Apr/13 17:33,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"In about 1 in 10 attempts, the simple.gc.GCTest fails to see files collected properly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-23 19:54:26.287,,,no_permission,,,,,,,,,,,,324528,,,Tue Apr 23 20:12:43 UTC 2013,,,,,,0|i1jznb:,324873,,,,,,,,"23/Apr/13 19:54;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #87 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/87/])
    ACCUMULO-1332 ensure the collector is run after the flush (Revision 1471061)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/test/system/auto/simple/gc.py
","23/Apr/13 19:56;hudson;Integrated in Accumulo-Trunk #841 (See [https://builds.apache.org/job/Accumulo-Trunk/841/])
    ACCUMULO-1332 ensure the collector is run after the flush (Revision 1471062)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/auto/simple/gc.py
","23/Apr/13 20:03;hudson;Integrated in Accumulo-1.5 #88 (See [https://builds.apache.org/job/Accumulo-1.5/88/])
    ACCUMULO-1332 ensure the collector is run after the flush (Revision 1471061)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/system/auto/simple/gc.py
","23/Apr/13 20:12;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #199 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/199/])
    ACCUMULO-1332 ensure the collector is run after the flush (Revision 1471062)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/auto/simple/gc.py
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
simple.wal.WriteAheadLog test sometimes fails,ACCUMULO-1331,12644159,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,23/Apr/13 17:23,23/Apr/13 20:12,13/Mar/19 22:01,23/Apr/13 17:34,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"In about 1 of 5 runs, the WriteAheadLog test fails to shutdown the master in the expected 10 seconds.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-23 19:54:26.496,,,no_permission,,,,,,,,,,,,324526,,,Tue Apr 23 20:12:43 UTC 2013,,,,,,0|i1jzmv:,324871,,,,,,,,"23/Apr/13 19:54;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #87 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/87/])
    ACCUMULO-1331 fixed (Revision 1471059)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
* /accumulo/branches/1.5/test/system/auto/simple/wal.py
","23/Apr/13 19:56;hudson;Integrated in Accumulo-Trunk #841 (See [https://builds.apache.org/job/Accumulo-Trunk/841/])
    ACCUMULO-1331 fixed (Revision 1471065)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
* /accumulo/trunk/src
* /accumulo/trunk/test/system/auto/simple/wal.py
","23/Apr/13 20:03;hudson;Integrated in Accumulo-1.5 #88 (See [https://builds.apache.org/job/Accumulo-1.5/88/])
    ACCUMULO-1331 fixed (Revision 1471059)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
* /accumulo/branches/1.5/test/system/auto/simple/wal.py
","23/Apr/13 20:12;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #199 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/199/])
    ACCUMULO-1331 fixed (Revision 1471065)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
* /accumulo/trunk/src
* /accumulo/trunk/test/system/auto/simple/wal.py
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Finding ACCUMULO_HOME and programs in scripts is broken for symbolic links,ACCUMULO-1071,12632627,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,dab5879,dab5879,dab5879,15/Feb/13 17:59,23/Apr/13 17:03,13/Mar/19 22:01,20/Mar/13 22:49,1.4.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"Finding the home $bin location for the accumulo/bin scripts needs to be iterative to traverse symbolic links.  Also, using 'locationByProgram' within bin/accumulo doesn't work for symbolic links.",bash,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15/Feb/13 18:04;dab5879;AccumuloBinScripts-1.patch;https://issues.apache.org/jira/secure/attachment/12569573/AccumuloBinScripts-1.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-02-25 01:36:36.16,,,no_permission,,,,,,,,,,,,313123,,,Thu Mar 21 04:15:23 UTC 2013,,,,,,0|i1i1an:,313469,,,,,,,,"15/Feb/13 18:04;dab5879;AccumuloBinScripts-1.patch properly locates ACCUMULO_HOME for all scripts.  Also updated locationByProgram to properly resolve linked binaries for java and hadoop.  Normalized usage of HADOOP_PREFIX and HADOOP_HOME within accumulo.

Added new feature: bootstrap_config.sh - if bin/config.sh cannot find conf/accumulo-env.sh, it will attempt to prompt the user for the example configuration to use.","15/Feb/13 18:08;dab5879;Also normalized all blocks, whitespace:
 - uses 3-space indentation
 - control structure initial statement all on one line: if ...; then, while ...; do
 - fixed matching logic for slaves and masters file to skip blank lines: egrep -v '(^#|^\s*$)' $FILE
 - normalized use of quotes
 - used $() for shell execution as appropriate","25/Feb/13 01:36;elserj;Damon, I noticed that you removed the checks for HADOOP_PREFIX in bin/config.sh. Am I overlooking something? I happened to only have HADOOP_HOME set, and starting up Accumulo failed with your patch applied where I expect to have been warned.","01/Mar/13 16:40;hudson;Integrated in Accumulo-1.5 #9 (See [https://builds.apache.org/job/Accumulo-1.5/9/])
    ACCUMULO-1071 committing Damon Brown's patch to clean-up the shell scripts (Revision 1451640)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/bin/LogForwarder.sh
* /accumulo/branches/1.5/bin/accumulo
* /accumulo/branches/1.5/bin/bootstrap_config.sh
* /accumulo/branches/1.5/bin/bootstrap_hdfs.sh
* /accumulo/branches/1.5/bin/config.sh
* /accumulo/branches/1.5/bin/etc_initd_accumulo
* /accumulo/branches/1.5/bin/generate_monitor_certificate.sh
* /accumulo/branches/1.5/bin/start-all.sh
* /accumulo/branches/1.5/bin/start-here.sh
* /accumulo/branches/1.5/bin/start-server.sh
* /accumulo/branches/1.5/bin/stop-all.sh
* /accumulo/branches/1.5/bin/stop-here.sh
* /accumulo/branches/1.5/bin/stop-server.sh
* /accumulo/branches/1.5/bin/tdown.sh
* /accumulo/branches/1.5/bin/tool.sh
* /accumulo/branches/1.5/bin/tup.sh
","01/Mar/13 16:44;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #8 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/8/])
    ACCUMULO-1071 committing Damon Brown's patch to clean-up the shell scripts (Revision 1451640)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/bin/LogForwarder.sh
* /accumulo/branches/1.5/bin/accumulo
* /accumulo/branches/1.5/bin/bootstrap_config.sh
* /accumulo/branches/1.5/bin/bootstrap_hdfs.sh
* /accumulo/branches/1.5/bin/config.sh
* /accumulo/branches/1.5/bin/etc_initd_accumulo
* /accumulo/branches/1.5/bin/generate_monitor_certificate.sh
* /accumulo/branches/1.5/bin/start-all.sh
* /accumulo/branches/1.5/bin/start-here.sh
* /accumulo/branches/1.5/bin/start-server.sh
* /accumulo/branches/1.5/bin/stop-all.sh
* /accumulo/branches/1.5/bin/stop-here.sh
* /accumulo/branches/1.5/bin/stop-server.sh
* /accumulo/branches/1.5/bin/tdown.sh
* /accumulo/branches/1.5/bin/tool.sh
* /accumulo/branches/1.5/bin/tup.sh
","01/Mar/13 16:55;ecn;Damon, can you please verify the scripts now work as expected?","01/Mar/13 19:31;vines;I'm not fond of the line

Choose the hadoop library type:

Should be something along the lines of choose the Accumulo in memory map type, etc.?","02/Mar/13 04:16;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #114 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/114/])
    ACCUMULO-1071 - needs to be executable (Revision 1451693)
ACCUMULO-1071 committing Damon Brown's patch to clean-up the shell scripts (Revision 1451647)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/bin/bootstrap_config.sh

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/LogForwarder.sh
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_config.sh
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/bin/etc_initd_accumulo
* /accumulo/trunk/bin/generate_monitor_certificate.sh
* /accumulo/trunk/bin/start-all.sh
* /accumulo/trunk/bin/start-here.sh
* /accumulo/trunk/bin/start-server.sh
* /accumulo/trunk/bin/stop-all.sh
* /accumulo/trunk/bin/stop-here.sh
* /accumulo/trunk/bin/stop-server.sh
* /accumulo/trunk/bin/tdown.sh
* /accumulo/trunk/bin/tool.sh
* /accumulo/trunk/bin/tup.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","02/Mar/13 04:20;hudson;Integrated in Accumulo-Trunk #755 (See [https://builds.apache.org/job/Accumulo-Trunk/755/])
    ACCUMULO-1071 - needs to be executable (Revision 1451693)
ACCUMULO-1071 committing Damon Brown's patch to clean-up the shell scripts (Revision 1451647)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/bin/bootstrap_config.sh

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/LogForwarder.sh
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_config.sh
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/bin/etc_initd_accumulo
* /accumulo/trunk/bin/generate_monitor_certificate.sh
* /accumulo/trunk/bin/start-all.sh
* /accumulo/trunk/bin/start-here.sh
* /accumulo/trunk/bin/start-server.sh
* /accumulo/trunk/bin/stop-all.sh
* /accumulo/trunk/bin/stop-here.sh
* /accumulo/trunk/bin/stop-server.sh
* /accumulo/trunk/bin/tdown.sh
* /accumulo/trunk/bin/tool.sh
* /accumulo/trunk/bin/tup.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","02/Mar/13 09:20;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #9 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/9/])
    ACCUMULO-1071 - needs to be executable (Revision 1451692)
ACCUMULO-1071 fixing syntax error (Revision 1451667)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/bin/bootstrap_config.sh

ecn : 
Files : 
* /accumulo/branches/1.5/bin/start-server.sh
","02/Mar/13 09:24;hudson;Integrated in Accumulo-1.5 #10 (See [https://builds.apache.org/job/Accumulo-1.5/10/])
    ACCUMULO-1071 - needs to be executable (Revision 1451692)
ACCUMULO-1071 fixing syntax error (Revision 1451667)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/bin/bootstrap_config.sh

ecn : 
Files : 
* /accumulo/branches/1.5/bin/start-server.sh
","03/Mar/13 06:54;elserj;{quote}
I'm not fond of the line

Choose the hadoop library type:

Should be something along the lines of choose the Accumulo in memory map type, etc.?
{quote}

Agreed and done, [~vines].","03/Mar/13 08:04;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #10 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/10/])
    ACCUMULO-1071 Changing wording from ""hadoop library type"" to ""Accumulo memory-map type"" (Revision 1452006)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/branches/1.5/bin/bootstrap_config.sh
","03/Mar/13 08:08;hudson;Integrated in Accumulo-1.5 #11 (See [https://builds.apache.org/job/Accumulo-1.5/11/])
    ACCUMULO-1071 Changing wording from ""hadoop library type"" to ""Accumulo memory-map type"" (Revision 1452006)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/branches/1.5/bin/bootstrap_config.sh
","04/Mar/13 18:16;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #115 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/115/])
    merged changes from 1.5
ACCUMULO-1142 Enable redirectTestOutputToFile in surefire plugin to nuke test output
ACCUMULO-1002 Apply override annotation to the close method on the BatchScanner implementation to be explicit
ACCUMULO-1002 Add a close method to ScannerBase and a no-op impl to ScannerOptions.
ACCUMULO-1104 Another update to account for 1.5 changes in the user manual
ACCUMULO-1071 Changing wording from ""hadoop library type"" to ""Accumulo memory-map type""
ACCUMULO-1104 ACCUMULO-1136 Applying additional wording for using config as opposed to setiter. Fix various other documentation which are now incorrect in 1.5.
ACCUMULO-1104 Correcting documented option to show timestamps in shell in user manual. (Revision 1452342)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/bootstrap_config.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/ScannerBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ScannerOptions.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReader.java
* /accumulo/trunk/docs/src/user_manual/accumulo_user_manual.tex
* /accumulo/trunk/docs/src/user_manual/chapters/administration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/NullScanner.java
* /accumulo/trunk/src
","04/Mar/13 18:23;hudson;Integrated in Accumulo-Trunk #756 (See [https://builds.apache.org/job/Accumulo-Trunk/756/])
    merged changes from 1.5
ACCUMULO-1142 Enable redirectTestOutputToFile in surefire plugin to nuke test output
ACCUMULO-1002 Apply override annotation to the close method on the BatchScanner implementation to be explicit
ACCUMULO-1002 Add a close method to ScannerBase and a no-op impl to ScannerOptions.
ACCUMULO-1104 Another update to account for 1.5 changes in the user manual
ACCUMULO-1071 Changing wording from ""hadoop library type"" to ""Accumulo memory-map type""
ACCUMULO-1104 ACCUMULO-1136 Applying additional wording for using config as opposed to setiter. Fix various other documentation which are now incorrect in 1.5.
ACCUMULO-1104 Correcting documented option to show timestamps in shell in user manual. (Revision 1452342)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/bootstrap_config.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/ScannerBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ScannerOptions.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReader.java
* /accumulo/trunk/docs/src/user_manual/accumulo_user_manual.tex
* /accumulo/trunk/docs/src/user_manual/chapters/administration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/NullScanner.java
* /accumulo/trunk/src
","08/Mar/13 21:39;billie.rinaldi;bootstrap_config.sh errors out on Mac OS X in the following way:
{noformat}
cp: illegal option -- u
usage: cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file target_file
       cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file ... target_directory
Bootstrap canceled, exiting...
{noformat}

Also, bootstrap_config.sh is used even when ""accumulo shell --fake"" is specified, which is unnecessary.  Accumulo doesn't need to be configured to use the fake shell.","20/Mar/13 15:51;kturner;Whats the behavior of bootstrap_config executing on a cluster?  If a lot nodes are not configured, what will start-all do? Maybe it should be execute when someone initializes Accumulo, instead of when the accumulo script runs.  But this behavior may confuse new users as it would only copy the config for the master node.   Should we have this, does it hurt more than it helps?

","20/Mar/13 23:29;hudson;Integrated in Accumulo-Trunk #790 (See [https://builds.apache.org/job/Accumulo-Trunk/790/])
    ACCUMULO-1071 stopped automatically populating conf dir in bin/config.sh (Revision 1459090)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/bootstrap_config.sh
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","20/Mar/13 23:50;hudson;Integrated in Accumulo-1.5 #45 (See [https://builds.apache.org/job/Accumulo-1.5/45/])
    ACCUMULO-1071 stopped automatically populating conf dir in bin/config.sh (Revision 1459088)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/bin/bootstrap_config.sh
* /accumulo/branches/1.5/bin/config.sh
","21/Mar/13 00:11;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #43 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/43/])
    ACCUMULO-1071 stopped automatically populating conf dir in bin/config.sh (Revision 1459088)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/bin/bootstrap_config.sh
* /accumulo/branches/1.5/bin/config.sh
","21/Mar/13 04:15;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #149 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/149/])
    ACCUMULO-1071 stopped automatically populating conf dir in bin/config.sh (Revision 1459090)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/bin/bootstrap_config.sh
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stats output not consistent,ACCUMULO-1211,12639166,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,mdrob,mdrob,26/Mar/13 19:19,23/Apr/13 01:21,13/Mar/19 22:01,28/Mar/13 18:57,1.4.2,,,,,,,1.5.0,,,master,,,,,,0,,,,,"The output of o.a.a.server.test.GetMasterStats is inconsistent. Examples include:

* Key value pairs have inconsistent separators. Some use a space, some use a colon, some use both.
** Records in Memory: 0
** Tablets 123
** Name 10.224.8.15:9997

Some indentation is a bit confusing. ""Unassigned tablets"" likely should not be indented under ""Goal State""?

There might be more that's not listed here, but manually parsing and verifying the output is a laborious process.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-28 18:57:17.458,,,no_permission,,,,,,,,,,,,319636,,,Tue Apr 23 01:21:52 UTC 2013,,,,,,0|i1j5gf:,319977,,,,,,,,"28/Mar/13 18:57;ecn;I removed the indentation for ""Unassigned tablets""
Everything with a value on the line has a colon after the label.
Header lines without a value have no colon.
","29/Mar/13 04:22;hudson;Integrated in Accumulo-1.5 #59 (See [https://builds.apache.org/job/Accumulo-1.5/59/])
    ACCUMULO-1211 made formatting more consistent (Revision 1462259)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/GetMasterStats.java
","29/Mar/13 04:26;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #57 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/57/])
    ACCUMULO-1211 made formatting more consistent (Revision 1462259)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/GetMasterStats.java
","23/Apr/13 00:59;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #86 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/86/])
    ACCUMULO-1211 new format breaks functional test (Revision 1470684)
ACCUMULO-1211 new format breaks functional test (Revision 1470671)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/test/system/auto/simple/simpleBalancer.py

ecn : 
Files : 
* /accumulo/branches/1.5/test/system/auto/stress/metadataMaxFiles.py
","23/Apr/13 01:08;hudson;Integrated in Accumulo-1.5 #87 (See [https://builds.apache.org/job/Accumulo-1.5/87/])
    ACCUMULO-1211 new format breaks functional test (Revision 1470684)
ACCUMULO-1211 new format breaks functional test (Revision 1470671)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/system/auto/simple/simpleBalancer.py

ecn : 
Files : 
* /accumulo/branches/1.5/test/system/auto/stress/metadataMaxFiles.py
","23/Apr/13 01:13;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #198 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/198/])
    ACCUMULO-1211 new format breaks functional test (Revision 1470685)
ACCUMULO-1211 new format breaks functional test (Revision 1470673)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/auto/simple/simpleBalancer.py

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/auto/stress/metadataMaxFiles.py
","23/Apr/13 01:21;hudson;Integrated in Accumulo-Trunk #840 (See [https://builds.apache.org/job/Accumulo-Trunk/840/])
    ACCUMULO-1211 new format breaks functional test (Revision 1470685)
ACCUMULO-1211 new format breaks functional test (Revision 1470673)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/auto/simple/simpleBalancer.py

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/auto/stress/metadataMaxFiles.py
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verify all methods in the ProxyService that take table names actually throw TableNotFoundException when the table is missing.,ACCUMULO-1199,12638661,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,sonixbp,sonixbp,sonixbp,23/Mar/13 14:37,19/Apr/13 04:21,13/Mar/19 22:01,12/Apr/13 19:49,,,,,,,,1.5.0,,,proxy,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-09 20:37:51.955,,,no_permission,,,,,,,,,,,,319136,,,Fri Apr 19 04:21:43 UTC 2013,,,,,,0|i1j2db:,319477,,,,,,,,23/Mar/13 14:38;sonixbp;Going to verify in unit tests and fix any violations in the proxy service itself.,"09/Apr/13 20:37;ecn;I've written the tests.   There are three methods that don't throw TableNotFound.  They throw security exceptions instead.

","10/Apr/13 01:10;hudson;Integrated in Accumulo-Trunk #824 (See [https://builds.apache.org/job/Accumulo-Trunk/824/])
    ACCUMULO-1199 add another check for table not found (Revision 1466202)
ACCUMULO-1199 added a lot of table not found checks (Revision 1466186)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/server
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/PrincipalToken.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","10/Apr/13 01:14;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #182 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/182/])
    ACCUMULO-1199 add another check for table not found (Revision 1466202)
ACCUMULO-1199 added a lot of table not found checks (Revision 1466186)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/server
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/PrincipalToken.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","10/Apr/13 01:23;hudson;Integrated in Accumulo-1.5 #71 (See [https://builds.apache.org/job/Accumulo-1.5/71/])
    ACCUMULO-1199 add another check for table not found (Revision 1466201)
ACCUMULO-1199 added a lot of table not found checks (Revision 1466177)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java

ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/PrincipalToken.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","10/Apr/13 01:38;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #70 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/70/])
    ACCUMULO-1199 add another check for table not found (Revision 1466201)
ACCUMULO-1199 added a lot of table not found checks (Revision 1466177)

     Result = ABORTED
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java

ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/PrincipalToken.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","17/Apr/13 16:01;hudson;Integrated in Accumulo-Trunk #834 (See [https://builds.apache.org/job/Accumulo-Trunk/834/])
    ACCUMULO-1199 translate security exceptions for a missing table into TableNotFound exceptions (Revision 1468933)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","19/Apr/13 03:27;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #84 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/84/])
    ACCUMULO-1199 mode some more methods in proxy throw table not found exception.  cleaned up proxy formatting.  made proxy throw more specific exceptions. (Revision 1469503)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","19/Apr/13 03:31;hudson;Integrated in Accumulo-1.5 #85 (See [https://builds.apache.org/job/Accumulo-1.5/85/])
    ACCUMULO-1199 mode some more methods in proxy throw table not found exception.  cleaned up proxy formatting.  made proxy throw more specific exceptions. (Revision 1469503)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","19/Apr/13 04:17;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #195 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/195/])
    ACCUMULO-1199 mode some more methods in proxy throw table not found exception.  cleaned up proxy formatting.  made proxy throw more specific exceptions. (Revision 1469516)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","19/Apr/13 04:21;hudson;Integrated in Accumulo-Trunk #837 (See [https://builds.apache.org/job/Accumulo-Trunk/837/])
    ACCUMULO-1199 mode some more methods in proxy throw table not found exception.  cleaned up proxy formatting.  made proxy throw more specific exceptions. (Revision 1469516)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FindOfflineTablets uses a batch scanner over the ROOT and META tablet types,ACCUMULO-1284,12642943,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,17/Apr/13 14:33,17/Apr/13 16:01,13/Mar/19 22:01,17/Apr/13 14:36,,,,,,,,1.5.0,,,tserver,,,,,,0,15_qa_bug,,,,"You have to use separate scanners for the ROOT and META sections of the METADATA table.  Also, there's no reason to read the ~del range.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-17 16:01:44.314,,,no_permission,,,,,,,,,,,,323353,,,Wed Apr 17 16:01:44 UTC 2013,,,,,,0|i1jsen:,323698,,,,,,,,"17/Apr/13 16:01;hudson;Integrated in Accumulo-Trunk #834 (See [https://builds.apache.org/job/Accumulo-Trunk/834/])
    ACCUMULO-1284 use different scanners for root/meta sections, limit scan to the tablet info range (Revision 1468935)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/FindOfflineTablets.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
build on ubuntu hangs without required dependencies,ACCUMULO-702,12600106,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,medined,dlmarion,dlmarion,25/Jul/12 01:45,16/Apr/13 21:24,13/Mar/19 22:01,26/Jul/12 01:07,,,,,,,,1.5.0,,,docs,,,,,,0,,,,,"build hangs when correct packages are not installed.


[INFO] --- exec-maven-plugin:1.2.1:exec (user-manual) @ accumulo ---
This is pdfTeX, Version 3.1415926-1.40.10 (TeX Live 2009/Debian)
entering extended mode
(./accumulo_user_manual.tex
LaTeX2e <2009/09/24>
Babel <v3.8l> and hyphenation patterns for english, usenglishmax, dumylang, noh
yphenation, loaded.
(/usr/share/texmf-texlive/tex/latex/base/report.cls
Document Class: report 2007/10/19 v1.4h Standard LaTeX document class
(/usr/share/texmf-texlive/tex/latex/base/size11.clo))
(/usr/share/texmf-texlive/tex/latex/base/alltt.sty)

! LaTeX Error: File `multirow.sty' not found.

Type X to quit or <RETURN> to proceed,
or enter new name. (Default extension: sty)

Enter file name: 
",Ubuntu 12.04 LTS,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,25/Jul/12 02:15;dlmarion;build.sh.patch;https://issues.apache.org/jira/secure/attachment/12537792/build.sh.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-07-25 03:02:30.587,,,no_permission,,,,,,,,,,,,246367,,,Thu Jul 26 16:35:04 UTC 2012,,,,,,0|i07ll3:,42263,,,,,,,,"25/Jul/12 01:47;dlmarion;Error occurs in docs/src/user_manual/build.sh, user needs to install the texlive-latex-extra package",25/Jul/12 02:15;dlmarion;check for required os dependencies in user manual build script so that the build does not hang.,"25/Jul/12 03:02;elserj;Dave, 

I can't say I'm a big fan of hard-coding Linux distro-specific logic into the script. Given my (brief) understanding of TeX distributions across Linux distributions, there isn't a good way to determine if multirow.sty is actually included on the user's system. Since this is about the third time this has come up on the dev list, I thought I'd suggest some alternatives:

# Bundle a pre-compiled PDF and the tex file and leave the dependencies up to the user if they want to modify/rebuild the PDF
# Bundle the multirow.sty (and other necessary dependencies) with the other stuff in docs/src/user_manual

Personally, I think the first alternative makes the most sense. If someone really wants to recompile the PDF, it's up to them to have a correct TeX installation.","25/Jul/12 03:08;elserj;Also, excuse my rudeness. Thank you for the patch :)","25/Jul/12 03:13;medined;First, thanks for the patch. It does seem to work from my limited testing on my Ubuntu server. However, I agree with Josh that adding OS-dependent checks can become complex; especially when different OS versions are considered. Perhaps we can have an README-UBUNTU file to list this dependency?","25/Jul/12 18:36;billie.rinaldi;Dave, thanks for the patch.  I've added you to our contributors list in JIRA.

At some point I'd like to move away from having the latex manual, perhaps making markdown the canonical format and then generating a pdf from that.  We might just end up with a different pdf generator dependency, though.","25/Jul/12 23:50;dlmarion;Do you want to accept this patch, or do you want a different one that updates the README?",26/Jul/12 00:45;medined;I am writing a README_UBUNTU now.,26/Jul/12 01:07;medined;SVN#1365861. I added an README_UBUNTU file to cover operating-specific issues. Please remember that I am not a system admin so let me know if I missed anything.,"26/Jul/12 01:22;elserj;David,

I took a look at your readme. Is there a reason you needed to install thrift? Boost, bison, and flex also seem odd to me.

Maven should be able to download all necessary jars, and, aside from the native C++ code (of which I would only think you'd need to install g++ and *maybe* build-essential). Are you sure those extra dependencies are necessary?","26/Jul/12 02:09;medined;I am not sure. However, the 'thrift' command was not on my Ubuntu Linode server. Therefore, the thrift-generated Java files could not be generated. The core/src/main/thrift/thrift.sh shell script runs 'thrift -version'. My understand is that Maven only downloads jar files and does not install Unix command-line tools.","26/Jul/12 02:12;bills;I'd prefer it if things that make external calls were turned on by user flag or possibly a build profile. The Thrift code, in the past, was already generated and I don't really see a need to build the documentation when all I want to do is get a running environment set up. ","26/Jul/12 03:04;medined;No arguments from me, William. But it seems like we're veering off topic for this ticket?","26/Jul/12 12:07;elserj;Yes/no. I'm worried that because you included installing thrift in a general readme, people will think that they have to install thrift before they can install Accumulo, which is not true.

I believe the general practice that is followed is that when the thrift auto-gen'd code needs to be changed, the developer making the change, commits the auto-gen'd java files, and does not force other developers/users to have to generate the java classes themselves. Assuming I'm not completely off base, there is no need for any user (who wants to use/build Accumulo) to install thrift. For the good majority of developers, they probably don't need to install thrift either.

Overall, I think we've identified a couple of changes outside the scope of this ticket (for which I'll be making a new ticket(s)), but I believe the changes you added to the Ubuntu readme are misleading to someone who is new to the project. Could you better clarify when you would actually need to install thrift (and boost, flex, bison, etc if they are indeed necessary)?","26/Jul/12 16:35;kturner;Instead of having a README_UBUNTU file, I would prefer adding a secion to the existing README called ""Compiling and Building Accumulo on Ubuntu""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update pom.xml to reference Commons IO v2.4 (or change Instamo to remove dependency),ACCUMULO-1063,12632137,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ctubbsii,medined,medined,13/Feb/13 03:04,11/Apr/13 21:12,13/Mar/19 22:01,05/Apr/13 03:24,,,,,,,,1.5.0,,,,,,,,,0,,,,,The MapReduceExample (for MiniAccumuloCluster) seems to depend on Commons IO v2.4 but the current compilation places Commons IO v1.2 in the lib directory.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-924,ACCUMULO-762,,,,,,,,,,,,,05/Mar/13 02:03;elserj;ACCUMULO-1063.patch;https://issues.apache.org/jira/secure/attachment/12572010/ACCUMULO-1063.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-02-13 21:50:25.07,,,no_permission,,,,,,,,,,,,312633,,,Thu Apr 11 21:12:56 UTC 2013,,,,,,0|i1hy9j:,312979,,,,,,,,"13/Feb/13 21:50;kturner;The instamo pom is supposed to represent a self contained example pom for Accumulo.  I think it should not matter what was in the accumulo/lib dir, but maybe this depends on how its run.  When I do the following it works fine.  The example also works fine for me when I run it from Eclipse.

{noformat}
  $ cd <accumulo-trunk-dir>
  $ mvn install -DskipTests
  $ cd examples/instamo/
  $ mvn exec:exec
  $ rm -rf <maven local repo>/org/apache/accumulo   #do not like to leave snapshots in local repo, eventually instamo will depend on a released version
{noformat}

How are you running the example?




","13/Feb/13 21:59;medined;I am sure the series of commands that you provided above work. However, I am loading the MapReduceExample.java file into a new Eclipse project and executing it directly. Since the MapReduceExample is part of the Accumulo release, naturally I first looked in the Accumulo directories for the commons-io jar file.","13/Feb/13 22:13;kturner;bq. Since the MapReduceExample is part of the Accumulo release, naturally I first looked in the Accumulo directories for the commons-io jar file.

Makes sense, I have done the same for other projects.  I will look into making its dependencies align with Accumulo deps.  I was not sure if I should put instamo in examples or contrib.  For some reason I decided on examples, still unsure about this.   ","27/Feb/13 05:53;ctubbsii;Was planning on looking for these things for ACCUMULO-924, but it can be fixed at any time. These things can be prevented with ACCUMULO-762, also.","05/Mar/13 02:02;elserj;[~kturner] You said that you meant for Instamo to be a stand-alone project, but I think I'd rather see it bundled as part of Accumulo. The capability that Instamo provides is very useful for testing and I think we could benefit from it.

To that end, I'll attach a patch which reworks the Instamo pom to reference the Examples parent pom, take advantage of the dependencyManagement and the already configured plugins.

I also bumped the managed version of commons-io to 2.4 as Instamo does use a method that doesn't exist in 1.4. I believe two non-test package classes actually reference commons-io classes, so I'm not too concerned about the upgrade.","05/Mar/13 02:12;mdrob;One potential issue is with diverging from whatever versions of commons the underlying Hadoop distribution uses. If users need to run MR jobs against Accumulo, I'm worried about classpath conflicts between hadoop libs and accumulo libs.","05/Mar/13 15:20;kturner;bq. To that end, I'll attach a patch which reworks the Instamo pom to reference the Examples parent pom, take advantage of the dependencyManagement and the already configured plugins.

In my mind Instamo has a few goals.

 # Provide a way for users to quickly get up an running writing an Accumulo program.
 # Provide an example pom that a user could reference when starting an Accumulo project.

I think making instamo have the example pom conflicts with goal 2, unless we would expect end users to do this for their own projects.   Also I think making the example be its parent makes the instamo pom harder to understand.  I think the instamo pom would be much easier for a new user to understand if it were self contained. 

Do you think I should move it to contrib?  I just wanted to park it somewhere in svn so that after 1.5 is release I could reference it from the Accumulo web page.  At first I was thinking of putting it in contrib.   Eventually i decided not to, I thought it would also be nice if it were included with the distribution in addition to being linked from the web page. ","05/Mar/13 17:06;elserj;If you want it to be stand-alone, yes, I think it should be moved to contrib.

I'm also a little fuzzy on how a user would use Instamo. If I try to think like a new user, I would think that I would add Instamo as a dependency to my maven project and then write some code which starts Instamo and runs my code against Instamo.

Would something like a Maven archetype be more along the lines of how you expect people to use this? They could generate a project using the Instamo archetype and add whatever user-specific dependencies they have. They would then presumably be able to run the `mvn exec:exec` with a parameter for their custom class. Thoughts?","05/Mar/13 17:53;kturner;bq. I'm also a little fuzzy on how a user would use Instamo.

What I am thinking Instamo should be is example pom + example code that runs against MiniAccumuloCluster.

I am thinking of providing a developer quick start web page on accumulo.apache.org. This page would have instructions like the following that would allow a new developer to write and run code against Accumulo in minutes.

 # svn co http://svn.apache.org/accumulo/.../instamo
 # cd instamo
 # vim src/main/java/AccumuloApp.java
 # mvn package

Not too familiar with maven archetypes.  Can an archetype generate an example pom and example code?  If this was done with an archetype, what would the steps be for a user to be up and running some example code against MiniAccumulo?  I do not know how a user would install a new archetype for maven.  If this has less steps, I am all for it.","03/Apr/13 19:15;ctubbsii;I think the example pom case is satisfied by an archetype, and the ability to get up quickly writing an Accumulo program and running code against it can be satisfied by putting MiniAccumuloCluster in a maven plugin much like the [jetty-maven-plugin|http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.eclipse.jetty%22%20a%3A%22jetty-maven-plugin%22].","03/Apr/13 19:16;ctubbsii;{quote}Can an archetype generate an example pom and example code?{quote} As far as I understand, that's its sole purpose.","05/Apr/13 03:23;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #64 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/64/])
    ACCUMULO-924 Updated plugin versions for build,
  applied latest apache parent pom,
  applied dependency pedantics based on dependency:analyze,
  add sorting/style standards to POM,
  simplified checking for licenses,
  fix brokenness with sealed jars,
  eliminated snapshot dependencies,
  used properties to support release plugin better
ACCUMULO-1063 verified previous fix on dependency conflicts
ACCUMULO-1122 incorporated Benson's changes to trunk for site
  plugin (to make it easier to merge back to trunk... site
  isn't currently being published anyway)
ACCUMULO-1201 incorporate David's changes to trunk to make merge
  back to trunk easier
ACCUMULO-1191 incorporate David's changes to trunk to make merge
  back to trunk easier (Revision 1464817)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/CHANGES
* /accumulo/branches/1.5/assemble/deb/accumulo/conffile
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/1GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/1GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/1GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/1GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/1GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/2GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/2GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/2GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/2GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/2GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/3GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/3GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/3GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/3GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/3GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/512MB/standalone/gc
* /accumulo/branches/1.5/conf/examples/512MB/standalone/masters
* /accumulo/branches/1.5/conf/examples/512MB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/512MB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/512MB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/vfs-classloader/accumulo-site.xml
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/core/src/test/resources/log4j.properties
* /accumulo/branches/1.5/docs/README_UBUNTU
* /accumulo/branches/1.5/examples/pom.xml
* /accumulo/branches/1.5/examples/simple/pom.xml
* /accumulo/branches/1.5/examples/simple/src/test/resources/log4j.properties
* /accumulo/branches/1.5/fate/pom.xml
* /accumulo/branches/1.5/fate/src/test/resources/log4j.properties
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/proxy/pom.xml
* /accumulo/branches/1.5/proxy/proxy.properties
* /accumulo/branches/1.5/proxy/src/test/resources/log4j.properties
* /accumulo/branches/1.5/server/pom.xml
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
* /accumulo/branches/1.5/server/src/test/resources/log4j.properties
* /accumulo/branches/1.5/start/pom.xml
* /accumulo/branches/1.5/start/src/test/resources/log4j.properties
* /accumulo/branches/1.5/test/compat/japi-compliance/japi-accumulo-1.4.xml
* /accumulo/branches/1.5/test/compat/japi-compliance/japi-accumulo-1.5.xml
* /accumulo/branches/1.5/test/pom.xml
* /accumulo/branches/1.5/test/src/main/resources/log4j.properties
* /accumulo/branches/1.5/test/src/test/resources/log4j.properties
* /accumulo/branches/1.5/test/system/auto/simple/__init__.py
* /accumulo/branches/1.5/test/system/auto/stress/__init__.py
* /accumulo/branches/1.5/test/system/continuous/batch_walkers.txt.example
* /accumulo/branches/1.5/test/system/continuous/ingesters.txt.example
* /accumulo/branches/1.5/test/system/continuous/scanners.txt.example
* /accumulo/branches/1.5/test/system/continuous/walkers.txt.example
* /accumulo/branches/1.5/test/system/randomwalk/conf/walkers.example
* /accumulo/branches/1.5/trace/pom.xml
","05/Apr/13 03:25;hudson;Integrated in Accumulo-1.5 #66 (See [https://builds.apache.org/job/Accumulo-1.5/66/])
    ACCUMULO-924 Updated plugin versions for build,
  applied latest apache parent pom,
  applied dependency pedantics based on dependency:analyze,
  add sorting/style standards to POM,
  simplified checking for licenses,
  fix brokenness with sealed jars,
  eliminated snapshot dependencies,
  used properties to support release plugin better
ACCUMULO-1063 verified previous fix on dependency conflicts
ACCUMULO-1122 incorporated Benson's changes to trunk for site
  plugin (to make it easier to merge back to trunk... site
  isn't currently being published anyway)
ACCUMULO-1201 incorporate David's changes to trunk to make merge
  back to trunk easier
ACCUMULO-1191 incorporate David's changes to trunk to make merge
  back to trunk easier (Revision 1464817)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/CHANGES
* /accumulo/branches/1.5/assemble/deb/accumulo/conffile
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/1GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/1GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/1GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/1GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/1GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/2GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/2GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/2GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/2GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/2GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/3GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/3GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/3GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/3GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/3GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/512MB/standalone/gc
* /accumulo/branches/1.5/conf/examples/512MB/standalone/masters
* /accumulo/branches/1.5/conf/examples/512MB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/512MB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/512MB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/vfs-classloader/accumulo-site.xml
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/core/src/test/resources/log4j.properties
* /accumulo/branches/1.5/docs/README_UBUNTU
* /accumulo/branches/1.5/examples/pom.xml
* /accumulo/branches/1.5/examples/simple/pom.xml
* /accumulo/branches/1.5/examples/simple/src/test/resources/log4j.properties
* /accumulo/branches/1.5/fate/pom.xml
* /accumulo/branches/1.5/fate/src/test/resources/log4j.properties
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/proxy/pom.xml
* /accumulo/branches/1.5/proxy/proxy.properties
* /accumulo/branches/1.5/proxy/src/test/resources/log4j.properties
* /accumulo/branches/1.5/server/pom.xml
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
* /accumulo/branches/1.5/server/src/test/resources/log4j.properties
* /accumulo/branches/1.5/start/pom.xml
* /accumulo/branches/1.5/start/src/test/resources/log4j.properties
* /accumulo/branches/1.5/test/compat/japi-compliance/japi-accumulo-1.4.xml
* /accumulo/branches/1.5/test/compat/japi-compliance/japi-accumulo-1.5.xml
* /accumulo/branches/1.5/test/pom.xml
* /accumulo/branches/1.5/test/src/main/resources/log4j.properties
* /accumulo/branches/1.5/test/src/test/resources/log4j.properties
* /accumulo/branches/1.5/test/system/auto/simple/__init__.py
* /accumulo/branches/1.5/test/system/auto/stress/__init__.py
* /accumulo/branches/1.5/test/system/continuous/batch_walkers.txt.example
* /accumulo/branches/1.5/test/system/continuous/ingesters.txt.example
* /accumulo/branches/1.5/test/system/continuous/scanners.txt.example
* /accumulo/branches/1.5/test/system/continuous/walkers.txt.example
* /accumulo/branches/1.5/test/system/randomwalk/conf/walkers.example
* /accumulo/branches/1.5/trace/pom.xml
","11/Apr/13 21:04;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #184 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/184/])
    ACCUMULO-1265, ACCUMULO-1250, ACCUMULO-1244, ACCUMULO-1063 merged to trunk from 1.5 branch (Revision 1467036)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/scripts/generate-thrift.sh
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
","11/Apr/13 21:12;hudson;Integrated in Accumulo-Trunk #826 (See [https://builds.apache.org/job/Accumulo-Trunk/826/])
    ACCUMULO-1265, ACCUMULO-1250, ACCUMULO-1244, ACCUMULO-1063 merged to trunk from 1.5 branch (Revision 1467036)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/core
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/core/src/main/scripts/generate-thrift.sh
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/pom.xml
* /accumulo/trunk/fate/pom.xml
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/src
* /accumulo/trunk/start/pom.xml
* /accumulo/trunk/test/pom.xml
* /accumulo/trunk/trace/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
unexpected PERMISSION DENIED in random walk test,ACCUMULO-1238,12640759,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,04/Apr/13 12:40,05/Apr/13 16:05,13/Mar/19 22:01,05/Apr/13 16:05,,,,,,,,1.5.0,,,tserver,,,,,,0,15_qa_bug,,,,"This error has happened multiple times.

{noformat}
04 02:31:53,606 [randomwalk.Framework] ERROR: Error during random walk
java.lang.Exception: Error running node Concurrent.xml
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Framework.run(Framework.java:65)
        at org.apache.accumulo.test.randomwalk.Framework.main(Framework.java:125)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:101)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node ct.CloneTable
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:285)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED for user root - User does not have permission to perform this action
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:292)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:274)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.clone(TableOperationsImpl.java:675)
        at org.apache.accumulo.test.randomwalk.concurrent.CloneTable.visit(CloneTable.java:47)
        at org.apache.accumulo.test.randomwalk.Module.visit(Module.java:254)
        ... 9 more
Caused by: ThriftSecurityException(user:root, code:PERMISSION_DENIED)
        at org.apache.accumulo.core.master.thrift.MasterClientService$executeTableOperation_result$executeTableOperation_resultStandardScheme.read(MasterClientService.java:16120)
        at org.apache.accumulo.core.master.thrift.MasterClientService$executeTableOperation_result$executeTableOperation_resultStandardScheme.read(MasterClientService.java:16106)
        at org.apache.accumulo.core.master.thrift.MasterClientService$executeTableOperation_result.read(MasterClientService.java:16048)
        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Client.recv_executeTableOperation(MasterClientService.java:499)
        at org.apache.accumulo.core.master.thrift.MasterClientService$Client.executeTableOperation(MasterClientService.java:480)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.executeTableOperation(TableOperationsImpl.java:230)
        at org.apache.accumulo.core.client.admin.TableOperationsImpl.doTableOperation(TableOperationsImpl.java:283)
        ... 13 more

{noformat}",10-node test cluster running random walk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-04 15:13:20.556,,,no_permission,,,,,,,,,,,,321218,,,Thu Apr 04 16:10:18 UTC 2013,,,,,,0|i1jf8v:,321563,,,,,,,,"04/Apr/13 15:13;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #62 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/62/])
    ACCUMULO-1238 throw a better error than permission denied when a table has just been deleted (Revision 1464582)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/tableOps/CreateTable.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/security/handler/ZKPermHandler.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/CloneTable.java
","04/Apr/13 15:18;hudson;Integrated in Accumulo-1.5 #64 (See [https://builds.apache.org/job/Accumulo-1.5/64/])
    ACCUMULO-1238 throw a better error than permission denied when a table has just been deleted (Revision 1464582)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/master/tableOps/CreateTable.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/security/handler/ZKPermHandler.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/CloneTable.java
","04/Apr/13 16:07;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #174 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/174/])
    ACCUMULO-1238 throw a better error than permission denied when a table has just been deleted (Revision 1464586)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/CreateTable.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/security/handler/ZKPermHandler.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/CloneTable.java
","04/Apr/13 16:10;hudson;Integrated in Accumulo-Trunk #815 (See [https://builds.apache.org/job/Accumulo-Trunk/815/])
    ACCUMULO-1238 throw a better error than permission denied when a table has just been deleted (Revision 1464586)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/tableOps/CreateTable.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/security/handler/ZKPermHandler.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/CloneTable.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move thift generation into 'thrift' profile.,ACCUMULO-1191,12638137,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,medined,medined,medined,21/Mar/13 01:11,05/Apr/13 03:27,13/Mar/19 22:01,21/Mar/13 01:14,,,,,,,,1.5.0,,,,,,,,,0,,,,,"For obvious reasons, the generate-thrift shell script will not work under Windows. Nor are the thrift files regenerated frequently. Therefore, the generate-thrift script should only be invoked when a 'thrift' profile is specified. For example:

  mvn clean compile -DskipTests -P thrift",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-21 05:00:53.853,,,no_permission,,,,,,,,,,,,318615,,,Fri Apr 05 03:25:02 UTC 2013,,,,,,0|i1iz5j:,318956,,,,,,,,"21/Mar/13 01:14;medined;SVN#1459115. This change affected the pom.xml files in the trace, core, and proxy modules.","21/Mar/13 01:37;medined;I just confirmed that with this change, Accumulo can be compiled under Windows. Many of the tests are not passing though.","21/Mar/13 05:00;hudson;Integrated in Accumulo-Trunk #791 (See [https://builds.apache.org/job/Accumulo-Trunk/791/])
    ACCUMULO-1191: Move thift generation into 'thrift' profile. (Revision 1459115)

     Result = SUCCESS
medined : 
Files : 
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/trace/pom.xml
","21/Mar/13 05:59;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #150 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/150/])
    ACCUMULO-1191: Move thift generation into 'thrift' profile. (Revision 1459115)

     Result = UNSTABLE
medined : 
Files : 
* /accumulo/trunk/core/pom.xml
* /accumulo/trunk/proxy/pom.xml
* /accumulo/trunk/trace/pom.xml
","05/Apr/13 03:23;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #64 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/64/])
    ACCUMULO-924 Updated plugin versions for build,
  applied latest apache parent pom,
  applied dependency pedantics based on dependency:analyze,
  add sorting/style standards to POM,
  simplified checking for licenses,
  fix brokenness with sealed jars,
  eliminated snapshot dependencies,
  used properties to support release plugin better
ACCUMULO-1063 verified previous fix on dependency conflicts
ACCUMULO-1122 incorporated Benson's changes to trunk for site
  plugin (to make it easier to merge back to trunk... site
  isn't currently being published anyway)
ACCUMULO-1201 incorporate David's changes to trunk to make merge
  back to trunk easier
ACCUMULO-1191 incorporate David's changes to trunk to make merge
  back to trunk easier (Revision 1464817)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/CHANGES
* /accumulo/branches/1.5/assemble/deb/accumulo/conffile
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/1GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/1GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/1GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/1GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/1GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/2GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/2GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/2GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/2GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/2GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/3GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/3GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/3GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/3GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/3GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/512MB/standalone/gc
* /accumulo/branches/1.5/conf/examples/512MB/standalone/masters
* /accumulo/branches/1.5/conf/examples/512MB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/512MB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/512MB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/vfs-classloader/accumulo-site.xml
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/core/src/test/resources/log4j.properties
* /accumulo/branches/1.5/docs/README_UBUNTU
* /accumulo/branches/1.5/examples/pom.xml
* /accumulo/branches/1.5/examples/simple/pom.xml
* /accumulo/branches/1.5/examples/simple/src/test/resources/log4j.properties
* /accumulo/branches/1.5/fate/pom.xml
* /accumulo/branches/1.5/fate/src/test/resources/log4j.properties
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/proxy/pom.xml
* /accumulo/branches/1.5/proxy/proxy.properties
* /accumulo/branches/1.5/proxy/src/test/resources/log4j.properties
* /accumulo/branches/1.5/server/pom.xml
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
* /accumulo/branches/1.5/server/src/test/resources/log4j.properties
* /accumulo/branches/1.5/start/pom.xml
* /accumulo/branches/1.5/start/src/test/resources/log4j.properties
* /accumulo/branches/1.5/test/compat/japi-compliance/japi-accumulo-1.4.xml
* /accumulo/branches/1.5/test/compat/japi-compliance/japi-accumulo-1.5.xml
* /accumulo/branches/1.5/test/pom.xml
* /accumulo/branches/1.5/test/src/main/resources/log4j.properties
* /accumulo/branches/1.5/test/src/test/resources/log4j.properties
* /accumulo/branches/1.5/test/system/auto/simple/__init__.py
* /accumulo/branches/1.5/test/system/auto/stress/__init__.py
* /accumulo/branches/1.5/test/system/continuous/batch_walkers.txt.example
* /accumulo/branches/1.5/test/system/continuous/ingesters.txt.example
* /accumulo/branches/1.5/test/system/continuous/scanners.txt.example
* /accumulo/branches/1.5/test/system/continuous/walkers.txt.example
* /accumulo/branches/1.5/test/system/randomwalk/conf/walkers.example
* /accumulo/branches/1.5/trace/pom.xml
","05/Apr/13 03:25;hudson;Integrated in Accumulo-1.5 #66 (See [https://builds.apache.org/job/Accumulo-1.5/66/])
    ACCUMULO-924 Updated plugin versions for build,
  applied latest apache parent pom,
  applied dependency pedantics based on dependency:analyze,
  add sorting/style standards to POM,
  simplified checking for licenses,
  fix brokenness with sealed jars,
  eliminated snapshot dependencies,
  used properties to support release plugin better
ACCUMULO-1063 verified previous fix on dependency conflicts
ACCUMULO-1122 incorporated Benson's changes to trunk for site
  plugin (to make it easier to merge back to trunk... site
  isn't currently being published anyway)
ACCUMULO-1201 incorporate David's changes to trunk to make merge
  back to trunk easier
ACCUMULO-1191 incorporate David's changes to trunk to make merge
  back to trunk easier (Revision 1464817)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/branches/1.5/CHANGES
* /accumulo/branches/1.5/assemble/deb/accumulo/conffile
* /accumulo/branches/1.5/assemble/pom.xml
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/1GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/1GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/1GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/1GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/1GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/1GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/2GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/2GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/2GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/2GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/2GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/2GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/3GB/standalone/gc
* /accumulo/branches/1.5/conf/examples/3GB/standalone/masters
* /accumulo/branches/1.5/conf/examples/3GB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/3GB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/3GB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/gc
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/masters
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/monitor
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/slaves
* /accumulo/branches/1.5/conf/examples/512MB/native-standalone/tracers
* /accumulo/branches/1.5/conf/examples/512MB/standalone/gc
* /accumulo/branches/1.5/conf/examples/512MB/standalone/masters
* /accumulo/branches/1.5/conf/examples/512MB/standalone/monitor
* /accumulo/branches/1.5/conf/examples/512MB/standalone/slaves
* /accumulo/branches/1.5/conf/examples/512MB/standalone/tracers
* /accumulo/branches/1.5/conf/examples/vfs-classloader/accumulo-site.xml
* /accumulo/branches/1.5/core/pom.xml
* /accumulo/branches/1.5/core/src/test/resources/log4j.properties
* /accumulo/branches/1.5/docs/README_UBUNTU
* /accumulo/branches/1.5/examples/pom.xml
* /accumulo/branches/1.5/examples/simple/pom.xml
* /accumulo/branches/1.5/examples/simple/src/test/resources/log4j.properties
* /accumulo/branches/1.5/fate/pom.xml
* /accumulo/branches/1.5/fate/src/test/resources/log4j.properties
* /accumulo/branches/1.5/pom.xml
* /accumulo/branches/1.5/proxy/pom.xml
* /accumulo/branches/1.5/proxy/proxy.properties
* /accumulo/branches/1.5/proxy/src/test/resources/log4j.properties
* /accumulo/branches/1.5/server/pom.xml
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/trace/Basic.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/server/src/test/java/org/apache/accumulo/server/tabletserver/InMemoryMapTest.java
* /accumulo/branches/1.5/server/src/test/resources/log4j.properties
* /accumulo/branches/1.5/start/pom.xml
* /accumulo/branches/1.5/start/src/test/resources/log4j.properties
* /accumulo/branches/1.5/test/compat/japi-compliance/japi-accumulo-1.4.xml
* /accumulo/branches/1.5/test/compat/japi-compliance/japi-accumulo-1.5.xml
* /accumulo/branches/1.5/test/pom.xml
* /accumulo/branches/1.5/test/src/main/resources/log4j.properties
* /accumulo/branches/1.5/test/src/test/resources/log4j.properties
* /accumulo/branches/1.5/test/system/auto/simple/__init__.py
* /accumulo/branches/1.5/test/system/auto/stress/__init__.py
* /accumulo/branches/1.5/test/system/continuous/batch_walkers.txt.example
* /accumulo/branches/1.5/test/system/continuous/ingesters.txt.example
* /accumulo/branches/1.5/test/system/continuous/scanners.txt.example
* /accumulo/branches/1.5/test/system/continuous/walkers.txt.example
* /accumulo/branches/1.5/test/system/randomwalk/conf/walkers.example
* /accumulo/branches/1.5/trace/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
race condition looking at zookeeper nodes,ACCUMULO-1233,12640369,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,02/Apr/13 20:16,03/Apr/13 02:07,13/Mar/19 22:01,02/Apr/13 21:24,,,,,,,,1.5.0,,,master,tserver,,,,,0,15_qa_bug,,,,"There's a common pattern used with zookeeper:

{noformat}
for (String child : zk.getChildren(path)) {
   byte[] content = zk.getData(path + ""/"" + child, null, null);
   doSomething(content);
}
{noformat}

The problem is that between the getChildren() call and the getData() call, the child node has gone away.

We'll typically retry these operations, but it puts big scary messages in the logs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-02 21:47:39.021,,,no_permission,,,,,,,,,,,,320832,,,Wed Apr 03 02:07:29 UTC 2013,,,,,,0|i1jcu7:,321173,,,,,,,,"02/Apr/13 20:46;ecn;Running:

{noformat}
./bin/accumulo org.apache.accumulo.server.fate.Admin print
{noformat}

often fails with a NoNode exception during the random walk test.","02/Apr/13 21:47;hudson;Integrated in Accumulo-Trunk #811 (See [https://builds.apache.org/job/Accumulo-Trunk/811/])
    ACCUMULO-1233 retry znode child scans (Revision 1463735)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/trunk/src
","02/Apr/13 21:52;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #170 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/170/])
    ACCUMULO-1233 retry znode child scans (Revision 1463735)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
* /accumulo/trunk/src
","03/Apr/13 01:58;hudson;Integrated in Accumulo-1.5 #61 (See [https://builds.apache.org/job/Accumulo-1.5/61/])
    ACCUMULO-1233 retry znode child scans (Revision 1463734)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
","03/Apr/13 02:07;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #59 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/59/])
    ACCUMULO-1233 retry znode child scans (Revision 1463734)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/MetadataTable.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Thrift ProxyServer is not throwing TableNotFoundException in createScanner & createBatchScanner,ACCUMULO-1189,12637892,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,sonixbp,sonixbp,sonixbp,20/Mar/13 04:45,23/Mar/13 14:49,13/Mar/19 22:01,23/Mar/13 14:49,,,,,,,,1.5.0,,,proxy,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20/Mar/13 05:49;sonixbp;ACCUMULO-1189.patch;https://issues.apache.org/jira/secure/attachment/12574491/ACCUMULO-1189.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-03-20 14:06:25.968,,,no_permission,,,,,,,,,,,,318372,,,Wed Mar 20 15:09:49 UTC 2013,,,,,,0|i1ixnj:,318713,,,,,,,,20/Mar/13 04:46;sonixbp;I'm going to try to fix this without having to re-generate the thrift server. I'll make the change to the thrift file though.,20/Mar/13 05:49;sonixbp;TableNotFoundException added to createScanner and createBatchScanner methods in proxy.thrift. new AccumuloProxy.java generated. Verified fix through functional test.,"20/Mar/13 14:06;ecn;It looks like almost anything that takes a table name should throw TableNotFoundException.  
Also, the list of exceptions are ordered inconsistently to make this obvious by inspection.

Thanks for clearing this up!



","20/Mar/13 14:28;sonixbp;Hey Eric,

I definitely agree with you. I looked through the tableOperations() and other methods on the scanner in the core API and it looked like there were some methods I would have thought should have thrown TableNotFoundException but they did not. 

Let me know if you want anything more from me- I can update the thrift again and resubmit a patch if you'd like.","20/Mar/13 14:45;hudson;Integrated in Accumulo-1.5 #43 (See [https://builds.apache.org/job/Accumulo-1.5/43/])
    ACCUMULO-1189 fix up exceptions (Revision 1458837)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
","20/Mar/13 14:45;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #41 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/41/])
    ACCUMULO-1189 fix up exceptions (Revision 1458837)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/branches/1.5/proxy/src/main/thrift/proxy.thrift
","20/Mar/13 15:05;hudson;Integrated in Accumulo-Trunk #787 (See [https://builds.apache.org/job/Accumulo-Trunk/787/])
    ACCUMULO-1189 fix up exceptions (Revision 1458839)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/server
* /accumulo/trunk/src
","20/Mar/13 15:09;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #146 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/146/])
    ACCUMULO-1189 fix up exceptions (Revision 1458839)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java
* /accumulo/trunk/proxy/src/main/thrift/proxy.thrift
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""du"" on a table without files does not report",ACCUMULO-1192,12638295,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kevin.faro,ecn,ecn,21/Mar/13 16:36,22/Mar/13 16:10,13/Mar/19 22:01,22/Mar/13 14:16,1.4.3,,,,,,,1.5.0,,,shell,,,,,,0,,,,,"{noformat}
shell> createtable t
shell> du t
shell>
{noformat}

expected:

{noformat}
shell> du t
             0 t
shell>
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,22/Mar/13 14:01;kevin.faro;ACCUMULO-1192.patch;https://issues.apache.org/jira/secure/attachment/12575011/ACCUMULO-1192.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-03-22 14:01:31.701,,,no_permission,,,,,,,,,,,,318771,,,Fri Mar 22 16:10:00 UTC 2013,,,,,,0|i1j047:,319112,,,,,,,,22/Mar/13 14:01;kevin.faro;patch for reporting du for tables that have not been flushed to disk yet and do not have any files associated with them,22/Mar/13 14:16;ecn;Patch applied.  Thanks!,"22/Mar/13 14:21;hudson;Integrated in Accumulo-Trunk #795 (See [https://builds.apache.org/job/Accumulo-Trunk/795/])
    ACCUMULO-1192 applying Kevin Faro's patch to fix du on an empty table (Revision 1459789)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/TableDiskUsage.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","22/Mar/13 16:02;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #48 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/48/])
    ACCUMULO-1192 applying Kevin Faro's patch to fix du on an empty table (Revision 1459788)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/TableDiskUsage.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
","22/Mar/13 16:07;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #155 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/155/])
    ACCUMULO-1192 applying Kevin Faro's patch to fix du on an empty table (Revision 1459789)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/TableDiskUsage.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","22/Mar/13 16:10;hudson;Integrated in Accumulo-1.5 #50 (See [https://builds.apache.org/job/Accumulo-1.5/50/])
    ACCUMULO-1192 applying Kevin Faro's patch to fix du on an empty table (Revision 1459788)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/TableDiskUsage.java
* /accumulo/branches/1.5/core/src/test/java/org/apache/accumulo/core/util/shell/ShellTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ProxyServer does not set column information on BatchScanner,ACCUMULO-1183,12637475,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,sonixbp,sonixbp,sonixbp,18/Mar/13 02:50,21/Mar/13 21:23,13/Mar/19 22:01,18/Mar/13 12:14,,,,,,,,1.5.0,,,proxy,,,,,,0,,,,,"The createScanner method uses the options from the thrift request to call fetchColumn() and fetchColumnFamily(). The createBatchScanner should be doing have the same feature, though the statements are absent from the code.",,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,18/Mar/13 03:49;sonixbp;ACCUMULO-1183.diff;https://issues.apache.org/jira/secure/attachment/12574108/ACCUMULO-1183.diff,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-03-18 12:14:47.199,,,no_permission,,,,,,,,,,,,317966,,,Thu Mar 21 21:23:49 UTC 2013,,,,,,0|i1iv5b:,318307,,,,,,,,18/Mar/13 03:49;sonixbp;Code insert + appropriate unit tests created.,"18/Mar/13 12:14;ecn;Committed patch, added Corey to the contributors.  Thanks!","18/Mar/13 13:04;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #34 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/34/])
    ACCUMULO-1183 applying patch from Corey Nolet (Revision 1457724)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/TestProxyReadWrite.java
","18/Mar/13 13:11;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #139 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/139/])
    ACCUMULO-1183 applying patch from Corey Nolet (Revision 1457726)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/TestProxyReadWrite.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","18/Mar/13 13:12;hudson;Integrated in Accumulo-1.5 #36 (See [https://builds.apache.org/job/Accumulo-1.5/36/])
    ACCUMULO-1183 applying patch from Corey Nolet (Revision 1457724)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/TestProxyReadWrite.java
","18/Mar/13 13:13;hudson;Integrated in Accumulo-Trunk #780 (See [https://builds.apache.org/job/Accumulo-Trunk/780/])
    ACCUMULO-1183 applying patch from Corey Nolet (Revision 1457726)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/TestProxyReadWrite.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","21/Mar/13 21:19;sonixbp;Haha, sorry Keith- I'll have to stop filling out the ""Affects Version/s"" fields.","21/Mar/13 21:23;kturner;NP, thanks to you the bug will not affect 1.5.0.   I try to keep the version #s in bugs somewhat sane so that a year from now I can make sense of it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Discussion of versioning iterator should mention how to disable it completely,ACCUMULO-1039,12630747,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kturner,mberman,mberman,04/Feb/13 20:53,21/Mar/13 04:15,13/Mar/19 22:01,20/Mar/13 20:09,1.4.2,,,,,,,1.5.0,,,docs,,,,,,0,,,,,"On the ""Table Configuration"" doc page, in the section ""VERSIONING ITERATORS AND TIMESTAMPS"" (at http://accumulo.apache.org/1.4/user_manual/Table_Configuration.html#Iterators), there is no mention of how to disable the iterator completely.  It would be a nice addition.  For tables created programmatically, this can be achieved by using TableOperations.create(tableName, false).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-20 21:05:41.553,,,no_permission,,,,,,,,,,,,311243,,,Thu Mar 21 04:15:23 UTC 2013,,,,,,0|i1hpov:,311589,,,,,,,,"20/Mar/13 21:05;hudson;Integrated in Accumulo-1.5 #44 (See [https://builds.apache.org/job/Accumulo-1.5/44/])
    ACCUMULO-1039 Added info about table creation and versioning iterator to docs. (Revision 1459011)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/docs/src/user_manual/chapters/table_configuration.tex
","20/Mar/13 22:16;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #42 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/42/])
    ACCUMULO-1039 Added info about table creation and versioning iterator to docs. (Revision 1459011)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/branches/1.5/docs/src/user_manual/chapters/table_configuration.tex
","20/Mar/13 23:29;hudson;Integrated in Accumulo-Trunk #790 (See [https://builds.apache.org/job/Accumulo-Trunk/790/])
    ACCUMULO-896 Added some info about automatic splitting to user manual.
ACCUMULO-1039 Added info about table creation and versioning iterator to docs.
ACCUMULO-1040 fixed code in documentation
ACCUMULO-804 another FileNotFoundException being thrown: going to keep it, though (Revision 1459026)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java
* /accumulo/trunk/src
","21/Mar/13 04:15;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #149 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/149/])
    ACCUMULO-896 Added some info about automatic splitting to user manual.
ACCUMULO-1039 Added info about table creation and versioning iterator to docs.
ACCUMULO-1040 fixed code in documentation
ACCUMULO-804 another FileNotFoundException being thrown: going to keep it, though (Revision 1459026)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/HadoopLogCloser.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryManager.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reset security broken with jcommander additions,ACCUMULO-1184,12637551,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,vines,vines,vines,18/Mar/13 15:17,18/Mar/13 16:52,13/Mar/19 22:01,18/Mar/13 15:39,,,,,,,,1.5.0,,,,,,,,,0,,,,,"The switch to jcommander seems to have broken the ability to run reset security, due to a new variable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-18 16:25:46.914,,,no_permission,,,,,,,,,,,,318042,,,Mon Mar 18 16:52:40 UTC 2013,,,,,,0|i1ivm7:,318383,,,,,,,,"18/Mar/13 16:25;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #140 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/140/])
    ACCUMULO-1184 - simple fix for reset security bug (Revision 1457820)

     Result = FAILURE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
","18/Mar/13 16:30;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #35 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/35/])
    ACCUMULO-1184 - simple fix for reset security bug (Revision 1457818)

     Result = FAILURE
vines : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
","18/Mar/13 16:47;hudson;Integrated in Accumulo-Trunk #781 (See [https://builds.apache.org/job/Accumulo-Trunk/781/])
    ACCUMULO-1184 - simple fix for reset security bug (Revision 1457820)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
","18/Mar/13 16:52;hudson;Integrated in Accumulo-1.5 #37 (See [https://builds.apache.org/job/Accumulo-1.5/37/])
    ACCUMULO-1184 - simple fix for reset security bug (Revision 1457818)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Increase metadata table split threshold,ACCUMULO-1172,12636449,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kturner,kturner,kturner,11/Mar/13 20:55,16/Mar/13 00:51,13/Mar/19 22:01,15/Mar/13 15:14,1.4.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"The metadata table split threshold is initialized to 4M.  This is very small and can cause a system to have alots of metadata table tablets.  This was set small a long time ago when tablets did not have read parallelism.  That has not been the case for a long time, but this threshold is still small.  I propose increasing it to 64M or 128M.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-12 18:48:38.341,,,no_permission,,,,,,,,,,,,316941,,,Sat Mar 16 00:51:23 UTC 2013,,,,,,0|i1iotz:,317283,,,,,,,,12/Mar/13 18:37;kturner;any objections to increasing this to 128M for 1.5?,12/Mar/13 18:48;ecn;Make the datablock cache default the same size so it's in memory in the default case.,"12/Mar/13 19:25;kturner;bq. Make the datablock cache default the same size so it's in memory in the default case.

Good point.  Also the cache holds uncompressed blocks.  So maybe set splits size to 64M and  cache size to 128M by default.","15/Mar/13 23:50;hudson;Integrated in Accumulo-Trunk #778 (See [https://builds.apache.org/job/Accumulo-Trunk/778/])
    #ACCUMULO-1172 increased default metadata table split threshold (Revision 1456984)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
* /accumulo/trunk/src
","16/Mar/13 00:03;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #32 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/32/])
    #ACCUMULO-1172 increased default metadata table split threshold (Revision 1456983)

     Result = UNSTABLE
kturner : 
Files : 
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
","16/Mar/13 00:51;hudson;Integrated in Accumulo-1.5 #34 (See [https://builds.apache.org/job/Accumulo-1.5/34/])
    #ACCUMULO-1172 increased default metadata table split threshold (Revision 1456983)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/branches/1.5/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/branches/1.5/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
","16/Mar/13 00:51;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #137 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/137/])
    #ACCUMULO-1172 increased default metadata table split threshold (Revision 1456984)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Initialize.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in tracer on zookeeper disconnect,ACCUMULO-1173,12636603,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,12/Mar/13 16:43,14/Mar/13 21:22,13/Mar/19 22:01,14/Mar/13 21:22,1.4.2,,,,,,,1.4.3,1.5.0,,trace,,,,,,0,,,,,"{noformat}
java.lang.IllegalArgumentException: Path cannot be null
	java.lang.IllegalArgumentException: Path cannot be null
		at org.apache.zookeeper.common.PathUtils.validatePath(PathUtils.java:45)
		at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1020)
		at org.apache.accumulo.fate.zookeeper.ZooReader.exists(ZooReader.java:75)
		at org.apache.accumulo.server.trace.TraceServer.process(TraceServer.java:274)
		at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:519)
		at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:495)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-12 18:26:50.589,,,no_permission,,,,,,,,,,,,317095,,,Wed Mar 13 16:31:10 UTC 2013,,,,,,0|i1iprr:,317436,,,,,,,,"12/Mar/13 18:26;hudson;Integrated in Accumulo-1.5 #30 (See [https://builds.apache.org/job/Accumulo-1.5/30/])
    ACCUMULO-1173 ensure that threads serving requests are Daemonized (Revision 1455641)
ACCUMULO-1173 disconnect events do not set a path (Revision 1455614)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/src

ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/src
","12/Mar/13 18:38;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #28 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/28/])
    ACCUMULO-1173 ensure that threads serving requests are Daemonized (Revision 1455641)
ACCUMULO-1173 disconnect events do not set a path (Revision 1455614)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/src

ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/src
","12/Mar/13 18:50;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #133 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/133/])
    ACCUMULO-1173 ensure that threads serving requests are Daemonized (Revision 1455642)
ACCUMULO-1173 disconnect events do not set a path (Revision 1455616)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/trunk/src
","12/Mar/13 18:50;hudson;Integrated in Accumulo-Trunk #774 (See [https://builds.apache.org/job/Accumulo-Trunk/774/])
    ACCUMULO-1173 ensure that threads serving requests are Daemonized (Revision 1455642)
ACCUMULO-1173 disconnect events do not set a path (Revision 1455616)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/trunk/src
",13/Mar/13 15:01;ecn;Cannot set daemon state like this: reverting.,"13/Mar/13 16:14;hudson;Integrated in Accumulo-1.4.x #283 (See [https://builds.apache.org/job/Accumulo-1.4.x/283/])
    ACCUMULO-1173 reverting setting thread state (Revision 1455980)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
","13/Mar/13 16:21;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #29 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/29/])
    ACCUMULO-1173 reverting setting thread state (Revision 1455984)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/src
","13/Mar/13 16:23;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #134 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/134/])
    ACCUMULO-1173 reverting setting thread state (Revision 1455985)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/proxy.properties
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/trunk/src
* /accumulo/trunk/test/system/continuous/ingesters.txt.example
","13/Mar/13 16:23;hudson;Integrated in Accumulo-Trunk #775 (See [https://builds.apache.org/job/Accumulo-Trunk/775/])
    ACCUMULO-1173 reverting setting thread state (Revision 1455985)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/proxy.properties
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/trunk/src
* /accumulo/trunk/test/system/continuous/ingesters.txt.example
","13/Mar/13 16:31;hudson;Integrated in Accumulo-1.5 #31 (See [https://builds.apache.org/job/Accumulo-1.5/31/])
    ACCUMULO-1173 reverting setting thread state (Revision 1455984)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5
* /accumulo/branches/1.5/assemble
* /accumulo/branches/1.5/core
* /accumulo/branches/1.5/examples
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/branches/1.5/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/branches/1.5/server
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/trace/TraceServer.java
* /accumulo/branches/1.5/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
org.apache.accumulo.test.randomwalk.bulk.Verify#main needs to be CLIed or purged,ACCUMULO-1164,12635908,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,vines,vines,07/Mar/13 22:44,08/Mar/13 16:19,13/Mar/19 22:01,08/Mar/13 15:28,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"Cleaning up getConnector calls and I stumbled across this code. I noticed it's not using the new CLI stuff, but I'm wondering if it's still useful. A grep of the codebase shows no scripts reference it, but it looks like it might be used for manual verification of results? Either we should purge it or update it to use the CLI.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-08 13:45:24.047,,,no_permission,,,,,,,,,,,,316400,,,Fri Mar 08 16:19:02 UTC 2013,,,,,,0|i1ilhz:,316743,,,,,,,,"08/Mar/13 13:45;ecn;I think it is used for post-failure analysis.  That is, this test fails. Later, as you are trying to figure out where the import failed, you can run this code to get a better idea of the failure pattern. I would port it to the new CLI code.","08/Mar/13 16:08;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #128 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/128/])
    ACCUMULO-1164 use cli utilities (Revision 1454425)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/bulk/Verify.java
","08/Mar/13 16:11;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #22 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/22/])
    ACCUMULO-1164 use cli utilities (Revision 1454423)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/bulk/Verify.java
","08/Mar/13 16:15;hudson;Integrated in Accumulo-Trunk #769 (See [https://builds.apache.org/job/Accumulo-Trunk/769/])
    ACCUMULO-1164 use cli utilities (Revision 1454425)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/bulk/Verify.java
","08/Mar/13 16:19;hudson;Integrated in Accumulo-1.5 #24 (See [https://builds.apache.org/job/Accumulo-1.5/24/])
    ACCUMULO-1164 use cli utilities (Revision 1454423)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/randomwalk/bulk/Verify.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
noisy logs during random walk,ACCUMULO-1117,12634242,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,26/Feb/13 20:36,05/Mar/13 15:14,13/Mar/19 22:01,05/Mar/13 15:14,,,,,,,,1.5.0,,,master,tserver,,,,,0,15_qa_bug,,,,"Many events generate many ugly errors that display on the monitor:

 * an error is reported to the master when a tserver is told to unload a closing tablet
 * when the master doesn't have a connection for a server, it logs an NPE
 * merge warns if a merge isn't in progress
 * if a tablet server isn't serving a tablet, and is asked to split, a warning is logged
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-02 04:16:15.481,,,no_permission,,,,,,,,,,,,314735,,,Sat Mar 02 09:24:02 UTC 2013,,,,,,0|i1ib8f:,315079,,,,,,,,"02/Mar/13 04:16;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #114 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/114/])
    ACCUMULO-1117 do not log a stack trace for a simple communications failure (Revision 1451666)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/Writer.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","02/Mar/13 04:20;hudson;Integrated in Accumulo-Trunk #755 (See [https://builds.apache.org/job/Accumulo-Trunk/755/])
    ACCUMULO-1117 do not log a stack trace for a simple communications failure (Revision 1451666)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/Writer.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
","02/Mar/13 09:20;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #9 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/9/])
    ACCUMULO-1117 do not log a stack trace for a simple communications failure (Revision 1451665)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/Writer.java
","02/Mar/13 09:24;hudson;Integrated in Accumulo-1.5 #10 (See [https://builds.apache.org/job/Accumulo-1.5/10/])
    ACCUMULO-1117 do not log a stack trace for a simple communications failure (Revision 1451665)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/impl/Writer.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Parse Exception During Run of Maven Changes Report Plugin,ACCUMULO-858,12616655,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,medined,medined,medined,18/Nov/12 21:27,28/Feb/13 02:31,13/Mar/19 22:01,27/Feb/13 03:03,1.5.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"[INFO] Generating ""JIRA Report"" report    --- Maven Changes Report Plugin 2.7.1
Nov 18, 2012 3:32:53 PM org.apache.commons.httpclient.HttpMethodBase
getResponseBody
WARNING: Going to buffer response body of large or unknown size. Using
getResponseBodyAsStream instead is recommended.
[ERROR] maven-changes-plugin: invalid statusId closed
[ERROR] maven-changes-plugin: invalid statusId resolved
[INFO] Downloading from JIRA at:
https://issues.apache.org/jira/secure/IssueNavigator.jspa?view=rss&pid=12312121&resolutionIds=1&sorter/field=created&sorter/order=DESC&sorter/field=priority&sorter/order=DESC&tempMax=10000&reset=true&decorator=none
[WARNING]
org.apache.maven.plugin.MojoExecutionException: Failed to parse JIRA XML.
        at org.apache.maven.plugin.jira.JiraXML.parse(JiraXML.java:132)
        at org.apache.maven.plugin.jira.JiraXML.parseXML(JiraXML.java:108)
        at org.apache.maven.plugin.jira.AbstractJiraDownloader.getIssueList(AbstractJiraDownloader.java:755)
        at org.apache.maven.plugin.jira.JiraMojo.executeReport(JiraMojo.java:347)
        at org.apache.maven.reporting.AbstractMavenReport.generate(AbstractMavenReport.java:190)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.apache.maven.plugins.site.ReportDocumentRenderer.generateMultiPage(ReportDocumentRenderer.java:302)
        at org.apache.maven.plugins.site.ReportDocumentRenderer.renderDocument(ReportDocumentRenderer.java:221)
        at org.apache.maven.doxia.siterenderer.DefaultSiteRenderer.renderModule(DefaultSiteRenderer.java:317)
        at org.apache.maven.doxia.siterenderer.DefaultSiteRenderer.render(DefaultSiteRenderer.java:134)
        at org.apache.maven.plugins.site.SiteMojo.renderLocale(SiteMojo.java:175)
        at org.apache.maven.plugins.site.SiteMojo.execute(SiteMojo.java:138)
        at org.apache.maven.plugin.DefaultPluginManager.executeMojo(DefaultPluginManager.java:490)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:694)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalWithLifecycle(DefaultLifecycleExecutor.java:556)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoal(DefaultLifecycleExecutor.java:535)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalAndHandleFailures(DefaultLifecycleExecutor.java:387)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeTaskSegments(DefaultLifecycleExecutor.java:348)
        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.execute(DefaultLifecycleExecutor.java:180)
        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:328)
        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:138)
        at org.apache.maven.cli.MavenCli.main(MavenCli.java:362)
        at org.apache.maven.cli.compat.CompatibleMain.main(CompatibleMain.java:60)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.codehaus.classworlds.Launcher.launchEnhanced(Launcher.java:315)
        at org.codehaus.classworlds.Launcher.launch(Launcher.java:255)
        at org.codehaus.classworlds.Launcher.mainWithExitCode(Launcher.java:430)
        at org.codehaus.classworlds.Launcher.main(Launcher.java:375)
Caused by: org.xml.sax.SAXParseException; lineNumber: 11;
columnNumber: 88; The entity name must immediately follow the '&' in
the entity reference.
        at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown
Source)
        at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)
        at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
        at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
        at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)
        at org.apache.xerces.impl.XMLScanner.reportFatalError(Unknown Source)
        at org.apache.xerces.impl.XMLScanner.scanAttributeValue(Unknown Source)
        at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanAttribute(Unknown
Source)
        at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanStartElement(Unknown
Source)
        at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown
Source)
        at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown
Source)
        at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
        at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
        at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
        at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
        at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
        at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
        at org.apache.maven.plugin.jira.JiraXML.parse(JiraXML.java:128)
        ... 33 more",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-18 21:30:15.02,,,no_permission,,,,,,,,,,,,258511,,,Thu Feb 28 02:31:20 UTC 2013,,,,,,0|i0ktu7:,119652,,,,,,,,"18/Nov/12 21:30;bmargulies;David, this needs to be a JIRA on MCHANGES at jira.codehaus.org.
","19/Nov/12 01:42;medined;Are you a member there?

On Sun, Nov 18, 2012 at 4:30 PM, Benson Margulies (JIRA)
","19/Nov/12 01:44;bmargulies;THe Apache Maven project, for historical reasons, has most of its JIRA projects at codehaus. I'm a maven committer and occasional maintainer and release manager of the maven-changes-plugin.
","27/Feb/13 02:45;medined;I do not have an account at codehaus.org. Benson, can you create the ticket please?","27/Feb/13 03:03;medined;SVN#1450586 - This issue was resolved by adding ""<useJql>true</useJql>"" to the pom.xml","28/Feb/13 01:36;hudson;Integrated in Accumulo-Trunk #748 (See [https://builds.apache.org/job/Accumulo-Trunk/748/])
    merging changes from 1.5

ACCUMULO-1118 - updating cli's default password to be empty, and some of the tests appropriately
ACCUMULO-1104, ACCUMULO-1093, ACCUMULO-1094, ACCUMULO-1095, ACCUMULO-1099, ACCUMULO-1097, ACCUMULO-1102 - Improve documentation
ACCUMULO-858: Parse Exception During Run of Maven Changes Report Plugin
ACCUMULO-1120 - credentials now getting properly read (Revision 1451008)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_design.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/dirlist/CountTest.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
","28/Feb/13 02:31;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #107 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/107/])
    merging changes from 1.5

ACCUMULO-1118 - updating cli's default password to be empty, and some of the tests appropriately
ACCUMULO-1104, ACCUMULO-1093, ACCUMULO-1094, ACCUMULO-1095, ACCUMULO-1099, ACCUMULO-1097, ACCUMULO-1102 - Improve documentation
ACCUMULO-858: Parse Exception During Run of Maven Changes Report Plugin
ACCUMULO-1120 - credentials now getting properly read (Revision 1451008)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/cli/TestClientOpts.java
* /accumulo/trunk/docs/src/user_manual/chapters/clients.tex
* /accumulo/trunk/docs/src/user_manual/chapters/design.tex
* /accumulo/trunk/docs/src/user_manual/chapters/shell.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_configuration.tex
* /accumulo/trunk/docs/src/user_manual/chapters/table_design.tex
* /accumulo/trunk/examples
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/dirlist/CountTest.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check Existence of Zookeeper Recovery Node Before Reading It.,ACCUMULO-635,12560563,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kturner,medined,medined,13/Jun/12 21:48,09/Feb/13 04:32,13/Mar/19 22:01,09/Feb/13 02:11,,,,,,,,1.5.0,,,,,,,,,0,,,,,"I don't know why but my errors have started to display the following message. I tracked down the source. Basically the Zookeeper node is being read without first making sure that it exists.

{code}
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode
 = NoNode for /accumulo/b519799c-3a51-4c9b-af21-96d577e2c11f/recovery
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
        at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1448)
        at org.apache.accumulo.core.zookeeper.ZooReader.getChildren(ZooReader.java:62)
        at org.apache.accumulo.server.master.Master.run(Master.java:2071)
        at org.apache.accumulo.server.master.Master.main(Master.java:2173)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-06-15 20:26:40.004,,,no_permission,,,,,,,,,,,,246431,,,Sat Feb 09 04:32:11 UTC 2013,,,,,,0|i07lzj:,42328,,,,,,,,"13/Jun/12 21:50;medined;This is the original code:

{code}
  ZooReaderWriter.getInstance().getChildren(zroot + Constants.ZRECOVERY, new Watcher() {
    @Override
    public void process(WatchedEvent event) {
      nextEvent.event(""Noticed recovery changes"", event.getType());
    }
  });
{code}",15/Jun/12 20:26;kturner;I made a change to create the node in zookeeper when init is run.  I still need to create the node when upgrading from 1.4 to 1.5,"24/Jul/12 02:00;medined;Keith, did you get a chance to update the upgrading code?","09/Feb/13 04:24;hudson;Integrated in Accumulo-Trunk #719 (See [https://builds.apache.org/job/Accumulo-Trunk/719/])
    ACCUMULO-635 ACCUMULO-1010 got basic upgrade and upgrade test script working... (Revision 1444313)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/Constants.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/test/system/upgrade_test.sh
","09/Feb/13 04:32;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #77 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/77/])
    ACCUMULO-635 ACCUMULO-1010 got basic upgrade and upgrade test script working... (Revision 1444313)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/Constants.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/test/system/upgrade_test.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consistent CamelCase for ZooKeeper,ACCUMULO-1034,12630671,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kturner,jklucar,jklucar,04/Feb/13 16:57,08/Feb/13 22:57,13/Mar/19 22:01,08/Feb/13 22:57,,,,,,,,1.5.0,,,test,,,,,,1,,,,,I was using the MiniAccumuloCluster and noticed it had a method named getZookeeper. Other places in the code base it is cased as ZooKeeper. I suggest changing the MiniAccumuloCluster method and standardizing how we camel case ZooKeeper across the code base. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-05 21:56:45.913,,,no_permission,,,,,,,,,,,,311167,,,Tue Feb 05 23:44:33 UTC 2013,,,,,,0|i1hp87:,311514,,,,,,,,"05/Feb/13 21:56;ctubbsii;I assigned to Keith, so he can look at this for 1.5.0, since MiniAccumuloCluster is a new feature and should be checked before release. [~jklucar], if you can identify any other places where this is inconsistent, we can address them too.","05/Feb/13 23:40;hudson;Integrated in Accumulo-Trunk #709 (See [https://builds.apache.org/job/Accumulo-Trunk/709/])
    ACCUMULO-1034 switched camel case of zookeeper in mini accumulo cluster to be consistent w/ zookeeper project (Revision 1442777)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/examples/instamo/src/main/java/org/apache/accumulo/instamo/MapReduceExample.java
* /accumulo/trunk/examples/instamo/src/test/java/org/apache/accumulo/instamo/ExampleAccumuloUnitTest.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate/zookeeper/ZooLockTest.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MiniAccumuloClusterTest.java
","05/Feb/13 23:44;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #67 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/67/])
    ACCUMULO-1034 switched camel case of zookeeper in mini accumulo cluster to be consistent w/ zookeeper project (Revision 1442777)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/examples/instamo/src/main/java/org/apache/accumulo/instamo/MapReduceExample.java
* /accumulo/trunk/examples/instamo/src/test/java/org/apache/accumulo/instamo/ExampleAccumuloUnitTest.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/Proxy.java
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/fate/zookeeper/ZooLockTest.java
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/MiniAccumuloClusterTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DebugIterator could debug a little better,ACCUMULO-986,12629213,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,elserj,elserj,elserj,25/Jan/13 02:34,26/Jan/13 05:55,13/Mar/19 22:01,26/Jan/13 05:11,,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"DebugIterator could use a next() method, as well as a non-null prefix when added to a stack of iterators.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-26 05:44:34.707,,,no_permission,,,,,,,,,,,,309057,,,Sat Jan 26 05:55:19 UTC 2013,,,,,,0|i1dyov:,289717,,,,,,,,"26/Jan/13 05:11;elserj;I just fixed it in 1.5.0 anyways, ""oops""","26/Jan/13 05:44;hudson;Integrated in Accumulo-Trunk #676 (See [https://builds.apache.org/job/Accumulo-Trunk/676/])
    ACCUMULO-986 Override next(), implement OptionDescriber for the shell, and default `prefix` to this.hashCode if it's not set by the time init() gets called. (Revision 1438849)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/DebugIterator.java
","26/Jan/13 05:55;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #34 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/34/])
    ACCUMULO-986 Override next(), implement OptionDescriber for the shell, and default `prefix` to this.hashCode if it's not set by the time init() gets called. (Revision 1438849)

     Result = SUCCESS
elserj : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/DebugIterator.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The TableLoadBalancer.getTableOperations method should not rely on Zookeeper.,ACCUMULO-928,12625966,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ctubbsii,medined,medined,04/Jan/13 03:13,25/Jan/13 22:04,13/Mar/19 22:01,25/Jan/13 22:04,1.5.0,,,,,,,1.5.0,,,,,,,,,0,,,,,"The method uses ""HdfsZooInstance.getInstance()"" instead of ""configuration.getInstance()"". Using the class variable enables dependency injection which enables unit tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-923,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-25 07:46:25.254,,,no_permission,,,,,,,,,,,,302548,,,Fri Jan 25 07:48:04 UTC 2013,,,,,,0|i173vz:,249597,,,,,,,,"25/Jan/13 07:46;hudson;Integrated in Accumulo-Trunk #668 (See [https://builds.apache.org/job/Accumulo-Trunk/668/])
    ACCUMULO-928 Use the ServerConfiguration object where available, instead of directly calling HdfsZooInstance
ACCUMULO-923 Made error messages more descriptive (Revision 1438335)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/balancer/TableLoadBalancer.java
","25/Jan/13 07:48;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #26 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/26/])
    ACCUMULO-928 Use the ServerConfiguration object where available, instead of directly calling HdfsZooInstance
ACCUMULO-923 Made error messages more descriptive (Revision 1438335)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/Accumulo.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/balancer/TableLoadBalancer.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MapReduce API should not use Configuration to set Job state at submission time (ambiguous semantics),ACCUMULO-769,12608497,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ctubbsii,ctubbsii,ctubbsii,20/Sep/12 17:31,25/Jan/13 22:00,13/Mar/19 22:01,25/Jan/13 22:00,1.4.0,1.4.1,,,,,,1.5.0,,,client,,,,,,0,,,,,"ACCUMULO-267 made this change, but I think it was the wrong way to go about it.

From the comments on ACCUMULO-267:

This is the wrong way to go about doing this fix. The reason why it took a JobContext is so that it could accept a ""Job"" object. This was modeled after the pattern Hadoop was using for FileOutputFormat, which is somewhat the standard for conventions in configuring MR jobs.

While JobContext does specifically state that's what it's purpose is, it is a base class, and Job extends JobContext, and includes a comment that describes it as holding the state of the job at submission time. This API should really be taking a ""Job"" object, rather than a ""JobContext"" object. Further, because Job is the only JobContext that actually works as intended here, the change from JobContext to Job does not require any deprecation, because Job will still work, and any other JobContext that isn't a Job will still fail. (We would have to deprecate the ones that were added in 1.4 that took a Configuration object, though... because those were never ""correct"", if we are going off of the conventions set by Hadoop's provided OutputFormats).

It is somewhat annoying to deprecate something in 1.5 that was added in 1.4... especially since it allows people to go back to what they were doing before. But, I think it might be worth it to be consistent with the established conventions, and to clarify the semantics of the methods (we are, after all, modifying the state of a job we are about to submit, and not just an arbitrary configuration, which is used for all sorts of things).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-09-20 18:08:19.123,,,no_permission,,,,,,,,,,,,246307,,,Tue Jan 22 19:00:44 UTC 2013,,,,,,0|i07l7z:,42204,,,,,,,,"20/Sep/12 18:08;kturner;I am not a big fan of the churn in the API this change would make.  However I do agree with the goal of this ticket.  This leaves me a bit conflicted on this issue.  Passing in a Job removes the possibility that the user will do something wrong.  With the new API in 1.4 the user can write the following code that is incorrect.  

{code:java}
  @Override
  public int run(String[] args) throws Exception {

    Configuration conf = getConf();
    Job job = new Job(conf, ""Test MR 1"");
      .
      .
      .
    job.setOutputFormatClass(AccumuloOutputFormat.class);
    AccumuloOutputFormat.setOutputInfo(conf, ""root"", ""secret"".getBytes(), false, ""nodes"");  //WRONG, modifying conf will not setup the job
  }
{code}

Instead the user needs to write the following with the new API

{code:java}
  @Override
  public int run(String[] args) throws Exception {

    Configuration conf = getConf();
    Job job = new Job(conf, ""Test MR 1"");
      .
      .
      .
    job.setOutputFormatClass(AccumuloOutputFormat.class);
    AccumuloOutputFormat.setOutputInfo(job.getConfiguration(), ""root"", ""secret"".getBytes(), false, ""nodes"");  //CORRECT, modifying the job conf will setup the job
  }
{code}

If the user just passed in the job object they would not have to think about it and understand that job creates a copy of the config they passed.    

","12/Dec/12 20:45;billie.rinaldi;I'm not thrilled about the API churn, either.  There's another point of concern related to ACCUMULO-695: the ""old"" MapReduce API is no longer deprecated and is still considered the stable version.  The old API uses Configuration in its static methods.",12/Dec/12 21:33;billie.rinaldi;I guess it is kind of weird that AccumuloFileOutputFormat has some static methods that take a Configuration and some that take a Job.  Does that mean we should create separate classes for the mapred and mapreduce APIs with static methods that match those APIs?,"12/Dec/12 21:45;ctubbsii;[~billie.rinaldi] - I agree that the API churn is frustrating, but I think if we're going to support the ""new"" API, we should do it in a way that is consistent and sensible for users familiar with this API, and I think this is consistent with the design intent, documentation, and examples in the ""new"" API. I think it makes sense to consider ACCUMULO-695 's solution separately, in the context of the ""old"" API, with a goal of consistency with that API's design intent, documentation, and examples.","12/Dec/12 21:48;ctubbsii;[~billie.rinaldi] - Yes, I think we should have separate classes for the ""old"" API, as users familiar with one and not the other, should not be bombarded with available API methods that aren't suitable to the framework of their choice.","13/Dec/12 02:03;hudson;Integrated in Accumulo-Trunk #576 (See [https://builds.apache.org/job/Accumulo-Trunk/576/])
    ACCUMULO-467 Change the behavior of AccumuloFileOutputFormat to carry Accumulo properties in an AccumuloConfiguration object, to remove the side-effect behavior of RFileOperations permitting Hadoop configuration to override AccumuloConfiguration in all cases.
ACCUMULO-769 The new methods that were added were done so in a way that is consistent with Hadoop's context-oriented MapReduce framework. (Revision 1421044)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/file/rfile/RFileOperations.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ContextFactory.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormatTest.java
","13/Dec/12 19:13;hudson;Integrated in Accumulo-Trunk #577 (See [https://builds.apache.org/job/Accumulo-Trunk/577/])
    ACCUMULO-467, ACCUMULO-769 Partially revert edits that cause strange compilation errors on the build server, and remove createJob() from the ContextFactory, as it isn't needed. (Revision 1421416)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ContextFactory.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormatTest.java
","13/Dec/12 21:24;hudson;Integrated in Accumulo-Trunk #578 (See [https://builds.apache.org/job/Accumulo-Trunk/578/])
    ACCUMULO-769 Updated partitioners to reflect the only valid, mutable JobContext, which is simply Job; This change is API-compatible with current code that isn't broken, because Job is a JobContext, so no deprecation is needed (though code that uses this may need to be recompiled). (Revision 1421521)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/partition/KeyRangePartitioner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/partition/RangePartitioner.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/lib/partition/RangePartitionerTest.java
","16/Jan/13 01:33;hudson;Integrated in Accumulo-Trunk #639 (See [https://builds.apache.org/job/Accumulo-Trunk/639/])
    ACCUMULO-769 Deprecated and replaced 1.4.x Mapreduce APIs and updated javadocs for all Mapreduce classes and updated referencing classes. (Revision 1433745)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOnDefaultTable.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOnRequiredTable.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/user/VersioningIterator.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormatTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormatTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormatTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormatTest.java
* /accumulo/trunk/examples/simple/src/main/java/org/apache/accumulo/examples/simple/mapreduce/RegexExample.java
* /accumulo/trunk/examples/simple/src/main/java/org/apache/accumulo/examples/simple/mapreduce/RowHash.java
* /accumulo/trunk/examples/simple/src/main/java/org/apache/accumulo/examples/simple/mapreduce/TableToFile.java
* /accumulo/trunk/examples/simple/src/main/java/org/apache/accumulo/examples/simple/mapreduce/TeraSortIngest.java
* /accumulo/trunk/examples/simple/src/main/java/org/apache/accumulo/examples/simple/mapreduce/UniqueColumns.java
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/filedata/ChunkInputFormatTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/metanalysis/IndexMeta.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/continuous/ContinuousMoru.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/continuous/ContinuousVerify.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/randomwalk/multitable/CopyTool.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/randomwalk/sequential/MapRedVerifyTool.java
","17/Jan/13 20:17;billie.rinaldi;The trunk changes broke the hadoop 2.0 build due to the use of the TaskAttemptContext constructor.  However, the two methods marked as deprecated that instantiate TaskAttemptContext, initialize(InputSplit inSplit, Configuration conf) and getSplits(Configuration conf), are actually new in trunk and can be removed instead of deprecated.  We should check over 1.5.0 before release and make sure nothing else is both new and deprecated.",18/Jan/13 13:54;billie.rinaldi;I think we should continue to standardize on Configuration internally (protected / private methods) while matching the MR API for public methods.,"18/Jan/13 15:31;ctubbsii;[~billie.rinaldi] Yes, I think you're probably right. To get that benefit, while still reducing confusion for end users due to the clutter of overloaded methods, I'm thinking it best to put the methods that take Configuration in a separate Configurator utility class.","18/Jan/13 15:47;billie.rinaldi;I'd be in favor of that.  Plus then if we have mapred and mapreduce InputFormats, they can share configuration code.  We should clearly mark the utility class as not part of the public API, not to be used for manually configuring things.","18/Jan/13 17:33;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #6 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/6/])
    ACCUMULO-769 Fix Hadoop 2.0 breakage by removing methods marked as deprecated that didn't exist in prior version.
ACCUMULO-975 Fix proxy pom.xml to support Hadoop 2.0 (Revision 1435230)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/proxy/pom.xml
","18/Jan/13 17:38;hudson;Integrated in Accumulo-Trunk #648 (See [https://builds.apache.org/job/Accumulo-Trunk/648/])
    ACCUMULO-769 Fix Hadoop 2.0 breakage by removing methods marked as deprecated that didn't exist in prior version.
ACCUMULO-975 Fix proxy pom.xml to support Hadoop 2.0 (Revision 1435230)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/proxy/pom.xml
",18/Jan/13 22:38;billie.rinaldi;Are we going to try to get this done for 1.5.0?  Do you need any help with that?,18/Jan/13 23:38;ctubbsii;I'm finishing it up now.,"22/Jan/13 18:49;hudson;Integrated in Accumulo-Trunk #653 (See [https://builds.apache.org/job/Accumulo-Trunk/653/])
    ACCUMULO-769 Modify mapreduce API to use the Hadoop static configurator conventions, but done in a way that allows us to standardize and reuse configurator code to support multiple frameworks. (Revision 1437073)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOnDefaultTable.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOnRequiredTable.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util/ConfiguratorBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util/FileOutputConfigurator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util/InputConfigurator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util/OutputConfigurator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util/package-info.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormatTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormatTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormatTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormatTest.java
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/filedata/ChunkInputFormatTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/metanalysis/IndexMeta.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/randomwalk/multitable/CopyTool.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/randomwalk/sequential/MapRedVerifyTool.java
","22/Jan/13 19:00;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #11 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/11/])
    ACCUMULO-769 Modify mapreduce API to use the Hadoop static configurator conventions, but done in a way that allows us to standardize and reuse configurator code to support multiple frameworks. (Revision 1437073)

     Result = SUCCESS
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOnDefaultTable.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOnRequiredTable.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormat.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputFormatBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util/ConfiguratorBase.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util/FileOutputConfigurator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util/InputConfigurator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util/OutputConfigurator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/util/package-info.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloFileOutputFormatTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloInputFormatTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloOutputFormatTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mapreduce/AccumuloRowInputFormatTest.java
* /accumulo/trunk/examples/simple/src/test/java/org/apache/accumulo/examples/simple/filedata/ChunkInputFormatTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/metanalysis/IndexMeta.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/randomwalk/multitable/CopyTool.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/test/randomwalk/sequential/MapRedVerifyTool.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Zookeeper session ids created as unsigned long, parsed in ZooUtils.java as signed long",ACCUMULO-965,12627529,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ralberth,ralberth,14/Jan/13 23:24,16/Jan/13 16:19,13/Mar/19 22:01,15/Jan/13 16:11,1.4.2,,,,,,,1.4.3,1.5.0,,start,,,,,,0,,,,,"Seems like this may be a bug.  I looked at
LiveTServerSet.assignTablet() it eventually calls Long.toHexString().
The javadoc for toHexString() says the following.
{code}Returns a string representation of the <code>long</code>
argument as an unsigned integer in base 16.
{code}

However, the method we are using to parse the Long can not handle
unsigned longs greater than MAX_LONG.  There does not seem to be a
method in long that can parse the output of  toHexString().  For
example the following will fail, any negative number will fail.

{code}Long.parseLong(Long.toHexString(-1), 16);{code}

Original Stack Dump:
{code}
java.lang.NumberFormatException: For input string: ""b53c3a3610ce0001""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)
	at java.lang.Long.parseLong(Long.java:422)
	at org.apache.accumulo.core.zookeeper.ZooUtil$LockID.<init>(ZooUtil.java:64)
	at org.apache.accumulo.server.tabletserver.TabletServer$ThriftClientHandler.checkPermission(TabletServer.java:1794)
	at org.apache.accumulo.server.tabletserver.TabletServer$ThriftClientHandler.loadTablet(TabletServer.java:1814)
	at org.apache.accumulo.core.tabletserver.thrift.TabletClientService$Processor.process(TabletClientService.java:2037)
	at org.apache.accumulo.server.util.TServerUtils$TimedProcessor.process(TServerUtils.java:154)
	at org.apache.thrift.server.TNonblockingServer$FrameBuffer.invoke(TNonblockingServer.java:631)
	at org.apache.accumulo.server.util.TServerUtils$THsHaServer$Invocation.run(TServerUtils.java:202)
{code}","Hadoop 0.20, ZooKeeper 3.4.3, CentOS 2.6, x64 CPU, Java 1.6.0_24",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-15 16:11:31.006,,,no_permission,,,,,,,,,,,,304313,,,Wed Jan 16 16:19:23 UTC 2013,,,,,,0|i17ljz:,252461,,,,,,,,"15/Jan/13 16:11;ecn;I'm still a little worried that we've never seen a negative session id before, but if we do, the code will handle it.
","15/Jan/13 16:43;hudson;Integrated in Accumulo-Trunk #638 (See [https://builds.apache.org/job/Accumulo-Trunk/638/])
    ACCUMULO-965 handle negative zookeeper session ids (Revision 1433477)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooUtil.java
","15/Jan/13 16:58;ecn;Digging into the zookeeper code, it looks like session ids consist of 8 bits of myid, time shifted 16 bits left.

The problem is that time is now 41 bits... and they shift those bits left 24, then right 8.  The shift right is an arithmetic shift, so sign extension is possible.  The myid bits are or'd into the upper most bits, so if sign extension happens, they will all be set to 1's.  The current time, in hex, looks like this:

0x13c3f143771

It would be very strange to have a time value where the upper bit of the second hex digit would be set. That will be 0x18000000000 (April, 2022), or 0xffffffffff (November, 2004)

Or, we could be using a myid up in the range of 0x80.  If someone was to put the zookeeper port number (2181, or 0x885) into the myid file, that might cause this problem.
","15/Jan/13 17:06;ecn;The bits 0x3c3a3610ce in your session id correspond to the time of 0x13c3a3610ce, which is 01/14/2013 at 1PM EST.

The bits ""b5"" come from the myid file.  Can you verify that your myid file contains a small number?

","15/Jan/13 18:09;hudson;Integrated in Accumulo-1.4.x #267 (See [https://builds.apache.org/job/Accumulo-1.4.x/267/])
    ACCUMULO-965 merge to 1.4 (Revision 1433481)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooUtil.java
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src
","16/Jan/13 13:55;ralberth;> The bits ""b5"" come from the myid file. Can you verify that your myid file contains a small number?

Confirmed!  Namenode is 180, data nodes are 181 and 182.  0xb5=181 base 10.  Works out right.","16/Jan/13 16:19;ecn;It's traditional to use an arbitrarily assigned, but small number for each zookeeper node.  Like ""1"" or ""2"" or ""3"".
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master fails to shutdown,ACCUMULO-621,12559434,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,05/Jun/12 19:52,10/Jan/13 16:16,13/Mar/19 22:01,10/Jan/13 16:16,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,master,,,,,,0,,,,,"The functional test ""AdminStopDuringStart"" found a rare issue with shutdown.

 * master starts
 * assigns root tablet
 * goal state is switch to CLEAN_STOP
 * master assigns non-root METADATA tablets
 * master transitions into UNLOAD_NON_ROOT_METADATA
 * master sees the METADATA tablets are not loaded
 * master transitions into UNLOAD_ROOT_TABLET
 * tablet server loads the METADATA tablets
 * master unloads the root tablet
 * tablet server cannot change the state of the METADATA tables
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246445,,,Thu Jan 10 16:16:24 UTC 2013,,,,,,0|i07m2n:,42342,,,,,,,,"05/Jun/12 19:57;ecn;There are three loops that migrate the tablets to the offline state.  The root tablet, the non-root metadata tablets, and all the rest.  Each loop needs to wait for the next to be be stopped before they can begin offlining their tablets.
",10/Jan/13 16:16;ecn;I think this is fixed with the changes for ACCUMULO-676,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
empty log fails recovery,ACCUMULO-797,12611053,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,09/Oct/12 20:07,09/Jan/13 21:06,13/Mar/19 22:01,09/Jan/13 20:25,1.3.6,,,,,,,1.5.0,,,logger,,,,,,0,,,,,"Found a reference to a log, which existed, but was empty (zero bytes). Theoretically, this can happen with an extremely well-timed crash/kill of the tserver.  Log recovery should deal with this gracefully, instead of failing.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-09 21:06:42.665,,,no_permission,,,,,,,,,,,,246486,,,Wed Jan 09 21:06:42 UTC 2013,,,,,,0|i07pvr:,42959,,,,,,,,09/Jan/13 20:25;ecn;fixed with revision 1431042.,"09/Jan/13 21:06;hudson;Integrated in Accumulo-Trunk #622 (See [https://builds.apache.org/job/Accumulo-Trunk/622/])
    ACCUMULO-797: ignore empty wal files (Revision 1431042)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/log/SortedLogRecovery.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mock does not implement locality groups or merging,ACCUMULO-843,12614993,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,cmccubbin,cmccubbin,06/Nov/12 16:58,09/Jan/13 20:10,13/Mar/19 22:01,09/Jan/13 16:32,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"The Mock Instance does not implement locality groups and throws an exception if one attempts to set them. It would be useful for the unit tests that I am writing for the Accumulo proxy to have at least minimal locality group functionality in the Mock instance, for example simply storing the groups and returning the stored groups when asked for.

*Edit: Tablet merging would be useful as well.",,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-09 16:32:18.026,,,no_permission,,,,,,,,,,,,255512,,,Wed Jan 09 20:10:04 UTC 2013,,,,,,0|i0esfz:,84372,,,,,,,,09/Jan/13 16:32;ecn;fixed with rev 1430938,"09/Jan/13 17:10;hudson;Integrated in Accumulo-Trunk #619 (See [https://builds.apache.org/job/Accumulo-Trunk/619/])
    ACCUMULO-843 implement deleteRows in MockAccumulo, fake locality groups, ignore merge requests (Revision 1430938)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockTable.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mock/MockTableOperationsTest.java
","09/Jan/13 20:10;hudson;Integrated in Accumulo-Trunk #621 (See [https://builds.apache.org/job/Accumulo-Trunk/621/])
    ACCUMULO-843 throw the same exceptions as TableOperationsImpl (Revision 1431018)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"average queue time and average time for major compactions are identical, which is unlikely",ACCUMULO-641,12595089,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,19/Jun/12 11:31,09/Jan/13 19:26,13/Mar/19 22:01,09/Jan/13 18:17,1.4.0,,,,,,,1.5.0,,,monitor,,,,,,0,,,,,"Poking around the monitor, I noticed the average queue time and the average time for major compactions were identical, and that is very unlikely.  Perhaps these are not being calculated properly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-09 19:17:22.349,,,no_permission,,,,,,,,,,,,246426,,,Wed Jan 09 19:26:05 UTC 2013,,,,,,0|i07lyf:,42323,,,,,,,,09/Jan/13 18:17;ecn;fixed with 1430997 and 1430998,"09/Jan/13 19:17;hudson;Integrated in Accumulo-1.4.x #264 (See [https://builds.apache.org/job/Accumulo-1.4.x/264/])
    ACCUMULO-641 merge to 1.4 branch (Revision 1430998)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletStatsKeeper.java
","09/Jan/13 19:26;hudson;Integrated in Accumulo-Trunk #620 (See [https://builds.apache.org/job/Accumulo-Trunk/620/])
    ACCUMULO-641 fix queue time stat (Revision 1430997)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletStatsKeeper.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
simple.gc.GCLotsOfCandidatesTest fails with OOM,ACCUMULO-945,12626586,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,,ecn,ecn,08/Jan/13 17:56,08/Jan/13 22:07,13/Mar/19 22:01,08/Jan/13 22:07,,,,,,,,,,,,,,,,,0,,,,,"it's configured to be very tight, but it fails with OOM before it gets a chance to run",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-08 18:10:29.607,,,no_permission,,,,,,,,,,,,303193,,,Tue Jan 08 18:10:29 UTC 2013,,,,,,0|i178kf:,250356,,,,,,,,"08/Jan/13 18:10;hudson;Integrated in Accumulo-Trunk #616 (See [https://builds.apache.org/job/Accumulo-Trunk/616/])
    ACCUMULO-945 tweak tight size for gc-under-memory-pressure test (Revision 1430411)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/test/system/auto/simple/gc.py
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
both accumulo and accumulo-native contain native libs,ACCUMULO-872,12617449,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,vines,ecn,ecn,23/Nov/12 15:23,02/Jan/13 19:57,13/Mar/19 22:01,02/Jan/13 18:29,1.4.2,,,,,,,1.4.3,1.5.0,,build,,,,,,0,,,,,I'm surprised to see the native libs in the accumulo deb file; and they seem to be in a non-standard place in the accumulo-native file.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-23 20:06:51.675,,,no_permission,,,,,,,,,,,,291890,,,Wed Jan 02 19:57:03 UTC 2013,,,,,,0|i0rhc7:,158452,,,,,,,,"23/Nov/12 20:06;vines;Hmm... oops. Neither should actually contain the files, the accumulo-native builds from scratch.","02/Jan/13 19:57;hudson;Integrated in Accumulo-Trunk #598 (See [https://builds.apache.org/job/Accumulo-Trunk/598/])
    ACCUMULO-872 - accumulo base will not include the native libraries at all (Revision 1427892)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/assemble
* /accumulo/trunk/assemble/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TimestampFilter should serialize start and end as longs in the IteratorSetting,ACCUMULO-776,12609277,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,marciosilva,marciosilva,26/Sep/12 17:37,02/Jan/13 17:20,13/Mar/19 22:01,02/Jan/13 17:20,1.4.1,,,,,,,1.4.3,1.5.0,,client,,,,,,0,,,,,"Although the TimestampFilter supports using longs to set the start or end timestamp, it formats them as strings using SimpleDateFormat when storing or retrieving them in the IteratorSetting.

This results in exceptions when the timestamps being used aren't able to be formatted as _yyyyMMddHHmmssz_. For example, try {{setEnd(253402300800001,true)}}

Instead, {{setStart()}} and {{setEnd()}} could just as easily use {{String.valueOf(long i)}} to store the values, and {{init()}} could retrieve them using {{Long.valueOf(String s)}}.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,07/Nov/12 01:49;billie.rinaldi;ACCUMULO-776.patch;https://issues.apache.org/jira/secure/attachment/12552396/ACCUMULO-776.patch,05/Nov/12 20:38;billie.rinaldi;ACCUMULO-776.patch;https://issues.apache.org/jira/secure/attachment/12552158/ACCUMULO-776.patch,08/Nov/12 17:11;billie.rinaldi;ACCUMULO-776_1.4.patch;https://issues.apache.org/jira/secure/attachment/12552674/ACCUMULO-776_1.4.patch,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,2012-11-05 20:38:07.36,,,no_permission,,,,,,,,,,,,246300,,,Tue Dec 18 18:37:08 UTC 2012,,,,,,0|i07l6f:,42197,,,,,,,,"05/Nov/12 20:38;billie.rinaldi;Do people think I should apply this patch to the 1.4 branch, or just to trunk?","05/Nov/12 20:43;vines;I'm concerned about the implications of the transition, regardless of version. Not having viewed, does this patch handle backwards compatability?

On a higher level about this ticket though, one of the reasons we used a formated Date is to prevent issues of clients and servers being in different timezone configurations, particularly the client and the actual server. Again, not having viewed the patch, I do not know if there is anything done here to handle it, but there needs to be some sort of consideration here.","05/Nov/12 20:45;vines;Patch was smaller than I thought. I have no issues with a proper patch being rolled into 1.4.x, but we need to have backwards compatibility with the old system for both 1.4.x and 1.5.0. My other issue from the comment above about time zones still stands as well.","05/Nov/12 20:57;kturner;I agree with John, if patched into 1.4 need to handle  backwards compatability in some way.  For example if someone is running a 1.4.1 client against a 1.4.3 server with this bug fix.  May not be as much of an issue for 1.5, since a 1.4 client and 1.5 server probably will not talk to each other.","05/Nov/12 21:01;vines;Well, regardless of version you need backwards compatibility. We don't want things from suddenly break for users because they upgraded and were using a TimestampFilter as a configured iterator.","05/Nov/12 21:02;billie.rinaldi;I guess the question is whether the following procedure returns the same timestamp on all systems regardless of timezone.  Before the patch, the tablet server would have executed this code, and after the patch the client executes this code.
{code:java}
SimpleDateFormat dateParser = new SimpleDateFormat(""yyyyMMddHHmmssz"");
dateParser.setTimeZone(TimeZone.getTimeZone(""GMT""));
long timestamp = dateParser.parse(dateString).getTime();
{code}
This date format requires the timezone to be set explicitly, e.g. ""19990101000000GMT"".

The TimestampFilter static set methods have units tests that passed before and after the patch.  I added the test that Marcio suggested, and it works only after the patch is applied.",05/Nov/12 21:04;billie.rinaldi;Good point about running different client and server code.  That makes me think we should only make the change in trunk.,"05/Nov/12 21:05;kturner;bq. Well, regardless of version you need backwards compatibility. We don't want things from suddenly break for users because they upgraded and were using a TimestampFilter as a configured iterator.

Oh right, I totally spaced on that.  I was only thinking of using it as scan time iterator, because that the only way I have used it.","05/Nov/12 21:14;vines;{quote} I guess the question is whether the following procedure returns the same timestamp on all systems regardless of timezone. Before the patch, the tablet server would have executed this code, and after the patch the client executes this code.
 SimpleDateFormat dateParser = new SimpleDateFormat(""yyyyMMddHHmmssz"");
 dateParser.setTimeZone(TimeZone.getTimeZone(""GMT""));
 long timestamp = dateParser.parse(dateString).getTime();
{quote} 

As long as the time is always converted to the same timezone, then timezone issues are not a problem, I would say. I would say that's a non-issue.


bq. The TimestampFilter static set methods have units tests that passed before and after the patch. I added the test that Marcio suggested, and it works only after the patch is applied.

Which is fine, but we need a test where a TimestampFilter is set as the old storage format with validation that it can be successfully read with the revised Filter.","05/Nov/12 21:14;billie.rinaldi;Yikes, does that mean we'd have to include timestamp format conversion for configured TimestampFilters in our upgrade from 1.4 to 1.5?

What if we just limited the max timestamp to years less than 10000 and threw an error when you tried to set a larger timestamp (instead of just erroring out on the server, like it does now)?  Did this ticket get opened because someone needed a year >= 10000?","05/Nov/12 21:28;vines;I think you bring up a larger question of what date 253402300800001 is supposed to be. That's either microsecond based time or it's past 10,000 AD. While I have faith in our software, I'm not sure if humanity will be around that long...","05/Nov/12 21:33;kturner;bq. Yikes, does that mean we'd have to include timestamp format conversion for configured TimestampFilters in our upgrade from 1.4 to 1.5?
This could be done in the TimestampFilter code that reads the config rather than as part of the upgrade process.  I think we can identify the old persistent format because it ends with alpha chars and distinguish that from the new format which all numeric chars?  Unless there is a completely numeric timezone?  

bq.   Did this ticket get opened because someone needed a year >= 10000?
I suppose any long is valid in the timestamp, so the filter should probably handle it.","05/Nov/12 21:37;kturner;I suppose we can serialize the new persistent format however we want.  For example we could prefix it with LONG inorder to preclude any ambiguity with the old persistent format.  We could also use a different option name, but then would need to handle the case where the old and new option exists.  So to simplify I would rather the current option support two different persistent formats.","05/Nov/12 21:41;vines;Agreed, just integrate some sort of versioning into the format. Especially useful if we, for some reason, need to do this again.","05/Nov/12 22:18;marciosilva;bq. Did this ticket get opened because someone needed a year >= 10000

This issue is problematic for use-cases where the version value is being used to store a different concept than the epoch time (e.g. Facebook's use of the version value in HBase in their inbox search application).",05/Nov/12 22:22;vines;I'm not familiar with Facebook's use of version value. Do you have a resource I can read?,"06/Nov/12 01:26;marciosilva;It's described briefly on page 374 of Lars George's [HBase: The Definitive Guide|http://www.hbasebook.com/] and the schema used for inbox search is also described in this slide deck from QCon London [HBase @ Facebook|http://qconlondon.com/dl/qcon-london-2011/slides/KannanMuthukkaruppan_HBaseFacebook.pdf]

The basic idea is they build per-user search indices in a single HBase row using the version to store the message ids.","06/Nov/12 02:11;vines;Interesting, that's a neat application of the visibilities.

I looked over the patch again, and I'm wondering if we have a compatability issue after all. I don't think anything is being changed in how things are being stored in ZK. So the only issue is the wire compatability which Keith mentioned before, which is nowhere as severe of an issue IMO.","06/Nov/12 02:52;kturner;bq.  I don't think anything is being changed in how things are being stored in ZK. 

No, I think your initial comments were correct.  The date encoded string will be stored in zookeeper, not a long.   To be sure I ran a little test.

{code:java}

    IteratorSetting is = new IteratorSetting(21, TimestampFilter.class);
    TimestampFilter.setStart(is, System.currentTimeMillis(), false);
    TimestampFilter.setEnd(is, System.currentTimeMillis() + 10000, false);
    conn.tableOperations().attachIterator(""foo"", is);

    Iterable<Entry<String,String>> propsIter = conn.tableOperations().getProperties(""foo"");
    for (Entry<String,String> entry : propsIter) {
      if (entry.getKey().contains(""Timestamp""))
        System.out.println(entry);
    }
{code}

This prints out the following :

{noformat}
table.iterator.majc.TimestampFilter.opt.start=20121106024224GMT
 .
 .
 .
{noformat}

I think if I had applied the patch, a long would be stored in ZK instead.","06/Nov/12 03:26;billie.rinaldi;bq. I think if I had applied the patch, a long would be stored in ZK instead.

Yes, that's right.  I like the idea of making it understand both by prefixing the long with LONG.  I'll try that out.",07/Nov/12 01:49;billie.rinaldi;Updated patch with support for both option types.,"07/Nov/12 20:02;kturner;I think the latest patch looks good.  The changes to validateOptions() are not tested by the unit test, but that method was not tested before.","07/Nov/12 20:19;vines;bq. I think the latest patch looks good. The changes to validateOptions() are not tested by the unit test, but that method was not tested before.

Agreed",08/Nov/12 16:40;billie.rinaldi;Committed patch with additional testing for validateOptions (which was good because I found and fixed an issue with it).,"08/Nov/12 17:10;billie.rinaldi;Keith pointed out there would still be issues with 1.4 compatibility, but that fast failing (client-side) for 1.4 would be helpful.","08/Nov/12 17:11;hudson;Integrated in Accumulo-Trunk #544 (See [https://builds.apache.org/job/Accumulo-Trunk/544/])
    ACCUMULO-776 made timestamp filter support longs greater than max date - merged to trunk (Revision 1407162)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/iterators/user/RegExFilterTest.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","08/Nov/12 17:11;hudson;Integrated in Accumulo-1.4.x #247 (See [https://builds.apache.org/job/Accumulo-1.4.x/247/])
    ACCUMULO-776 reverted 1.4 changes to timestamp filter (Revision 1407165)
ACCUMULO-776 made timestamp filter support longs greater than max date (Revision 1407157)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java
* /accumulo/branches/1.4/src/core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java

billie : 
Files : 
* /accumulo/branches/1.4/conf
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java
* /accumulo/branches/1.4/src/core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java
* /accumulo/branches/1.4/src/core/src/test/java/org/apache/accumulo/core/iterators/user/RegExFilterTest.java
","18/Dec/12 18:37;hudson;Integrated in Accumulo-1.4.x #254 (See [https://builds.apache.org/job/Accumulo-1.4.x/254/])
    ACCUMULO-776 added fast failure when unusable longs are set for 1.4 (Revision 1423565)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java
* /accumulo/branches/1.4/src/core/src/test/java/org/apache/accumulo/core/iterators/user/FilterTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,
Functional test simple.readwrite.LocalityGroupPerf is hanging,ACCUMULO-83,12529101,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,,ecn,ecn,27/Oct/11 18:14,18/Dec/12 18:39,13/Mar/19 22:01,27/Oct/11 19:13,,,,,,,,1.3.5-incubating,,,test,,,,,,0,,,,,"{noformat}
./test/system/auto/run.py -t localitygroupperf
{noformat}

Hangs indefinitely.
",linux accumulo-r1181848,,,,,,,,,,,,,,,,,,,,,,,600,600,,0%,600,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,214961,,,2011-10-27 18:14:30.0,,,,,,0|i07pbr:,42869,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unrecognized Property In Example Configuration (logger.sort.buffer.size),ACCUMULO-629,12559770,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,,medined,medined,07/Jun/12 22:35,18/Dec/12 18:39,13/Mar/19 22:01,09/Jul/12 19:04,,,,,,,,1.5.0,,,,,,,,,0,,,,,"When using the accumulo executable, I see this message ""[conf.ConfigSanityCheck] WARN : BAD CONFIG unrecognized property key (logger.sort.buffer.size)"". That property is in the accumulo-site.xml file.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-06-07 22:41:58.084,,,no_permission,,,,,,,,,,,,246437,,,Mon Jul 09 19:04:31 UTC 2012,,,,,,0|i07m0v:,42334,,,,,,,,07/Jun/12 22:41;jvines;which version? ,07/Jun/12 23:31;medined;Revision: 1347340 - v1.5 trunk,"08/Jun/12 20:06;billie.rinaldi;This is probably because the logger and related properties have been removed in trunk, but the example configurations still contain the logger.sort.buffer.size property.",12/Jun/12 19:07;billie.rinaldi;I removed the unneeded property from the example conf files.  Update the site xml file for your instance to stop seeing the error.,12/Jun/12 20:39;ecn;Still need to configure tserver.sort.buffer.size to fit in the advertised memory footprint.,"13/Jun/12 13:22;billie.rinaldi;Eric, does this look ok now?",26/Jun/12 18:12;jvines;Functional tests still use bad configurations,06/Jul/12 16:14;jvines;I think that's it.,"09/Jul/12 16:56;jvines;Sigh, more borked tests",09/Jul/12 19:04;jvines;Think we're in the clear now,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add aggregator adds versioning iterator to the iterator tree.,ACCUMULO-158,12531938,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,vines,jvines,18/Nov/11 13:59,18/Dec/12 18:38,13/Mar/19 22:01,18/Nov/11 13:59,1.3.5-incubating,,,,,,,1.4.0,,,client,,,,,,0,,,,,"Due to a small foible, add aggregator will also add versioning iterators to the iterator tree. This has already been fixed in 1.4, but this is a note that it's a minor issue in 1.3.5 that we're going to let go. There are work arounds in place should it be an issue. If we end up going to 1.3.6, we can talk about it, but as far as I'm concerned, the issue is documented and resolved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,217674,,,2011-11-18 13:59:08.0,,,,,,0|i07ovb:,42795,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shell 'help' should wrap more cleanly,ACCUMULO-333,12539007,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,vines,jvines,19/Jan/12 18:04,18/Dec/12 18:38,13/Mar/19 22:01,02/Mar/12 20:47,1.4.0,,,,,,,1.4.0,1.5.0,,client,,,,,,0,,,,,"In the shell, if your window is not wide enough the lines will wrap with the help command. This is fine, but it makes it harder to read. We should instead the line on wrapping to make the start of the next command more clear.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,224509,,,2012-01-19 18:04:17.0,,,,,,0|i07ntb:,42624,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make monitor servlet JSON output JSON spec compliant,ACCUMULO-903,12623595,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,crohling88,jasontrost,jasontrost,12/Dec/12 17:46,18/Dec/12 15:23,13/Mar/19 22:01,18/Dec/12 15:23,,,,,,,,1.5.0,,,monitor,,,,,,0,json,monitor,,,"While trying to ingrate the monitor page JSON output into our internal monitoring system, we noticed that the json generated is not compliant with the JSON spec (http://www.json.org/). Specifically, it uses single quotes rather that double quotes.  This caused issues in most of the JSON libs we tried (python's anyjson, simplejson, and json).

We are preparing a fix for this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,13/Dec/12 20:01;crohling88;ACCUMULO-903;https://issues.apache.org/jira/secure/attachment/12560840/ACCUMULO-903,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-12-12 19:08:53.663,,,no_permission,,,,,,,,,,,,297313,,,Mon Dec 17 16:37:05 UTC 2012,,,,,,0|i14ntr:,235325,,,,,,,,12/Dec/12 19:08;crohling88;Replacing single quotes in the JSON output with double quotes.,"12/Dec/12 20:39;crohling88;The diff provided here is simply a quick patch to fix the JSON formatting issue, but does not solve the issue of generating JSON by hand. Has there been consideration for actually leveraging an existing JSON library to complete this task? I am willing to do that work.",12/Dec/12 20:47;billie.rinaldi;We haven't thought about using a library to generate the JSON.  Did you have any in mind?,"12/Dec/12 20:57;crohling88;We have used http://jackson.codehaus.org/ in the past, it seems to work well enough.","12/Dec/12 21:05;billie.rinaldi;Does anyone have an opinion on adding a jackson dependency?  I could go either way.  What we're currently doing is not pretty, but also this one class is the only place we generate any JSON.","12/Dec/12 21:10;jasontrost;my pref is using a library for this.  It ensures that the data coming from the servlet is JSON compliant.  Also, it will make this code a little cleaner.",12/Dec/12 23:40;ecn;+1 for a library... but I would like to see us move away from internal monitoring and making all the data available to a better external monitoring system; probably using JMX,"13/Dec/12 14:10;medined;I think that http://code.google.com/p/json-simple/ is the JSON library
that google uses?

",13/Dec/12 15:37;crohling88;I was under the impression that they had developed and used http://code.google.com/p/google-gson/ ,13/Dec/12 16:25;elserj;+1 for GSON,13/Dec/12 16:27;mdrob;+1 GSON,13/Dec/12 20:01;crohling88;Adding a patch to include GSON as the JSON library used for the monitor.,17/Dec/12 14:38;jasontrost;This patch looks good to me.  Unless there are any objections I will integrate it and push to trunk.,17/Dec/12 14:56;ecn;Thanks Jason and Christian! Looks good to me.,"17/Dec/12 14:59;billie.rinaldi;I read over it and it looks ok.  It would be good if someone took a look at the Server Activity on the Accumulo monitor page and makes sure it appears to be working.  Server Activity uses the JSON.  Christian, thanks for the patch!  I've added you to our contributors list in JIRA.","17/Dec/12 15:18;jasontrost;I just confirmed, the Server Activity page is working with this change.",17/Dec/12 15:23;jasontrost;Committed revision 1422979,"17/Dec/12 16:37;hudson;Integrated in Accumulo-Trunk #581 (See [https://builds.apache.org/job/Accumulo-Trunk/581/])
    ACCUMULO-903

Integrating patch from Christian Rohling (crohling88 at gmail dot com) that add GSON json lib and makes the JSON Servlet output JSON spec compliant data. (Revision 1422979)

     Result = SUCCESS
jtrost : 
Files : 
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server/pom.xml
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/JSONServlet.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ava.lang.IllegalStateException: Locality group reader closed,ACCUMULO-854,12616063,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,medined,medined,14/Nov/12 13:42,13/Dec/12 16:27,13/Mar/19 22:01,13/Dec/12 16:27,,,,,,,,1.5.0,,,client,,,,,,0,,,,,"I am running the RFile program and getting the following result:
{noformat}
2/11/12 22:05:26 INFO compress.CodecPool: Got brand-new compressor
12/11/12 22:05:34 INFO compress.CodecPool: Got brand-new decompressor
Open time 2 21
0.185 540.5405405405405
12/11/12 22:05:37 INFO compress.CodecPool: Got brand-new decompressor
0.152 657.8947368421053
12/11/12 22:05:41 INFO compress.CodecPool: Got brand-new decompressor
0.146 684.9315068493152
0.143 699.3006993006993
0.194 515.4639175257731
Exception in thread ""main"" java.lang.IllegalStateException: Locality
group reader closed
        at org.apache.accumulo.core.file.rfile.RFile$LocalityGroupReader.seek(RFile.java:612)
        at org.apache.accumulo.core.file.rfile.RFile$Reader.seek(RFile.java:1047)
        at org.apache.accumulo.core.file.rfile.RFile.seekRandomly(RFile.java:1173)
        at org.apache.accumulo.core.file.rfile.RFile.main(RFile.java:1161)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-14 15:02:20.349,,,no_permission,,,,,,,,,,,,257764,,,Wed Dec 12 21:27:06 UTC 2012,,,,,,0|i0kdb3:,116973,,,,,,,,14/Nov/12 14:24;medined;I suggest that the RFile.java file be removed not fixed. Pull the needed stuff into BCFile or pull it out of an RFile in an Hadoop jar file.,"14/Nov/12 15:02;dlmarion;-1

RFile is an integral part of the system. I suggest that we just fix the problem.",14/Nov/12 15:03;dlmarion;Unless you are suggesting that we remove the RFile.java file and move the contents into BCFile.java as a static inner class :-),"14/Nov/12 15:04;elserj;Am I to read that as remove the main method from RFile, or do you really mean remove the entire java file?

If you did mean the latter: RFile is rather important for how Accumulo actually works and has a logical extension on top of BCFile. Why do you think it should be pulled into BCFile?",14/Nov/12 16:46;medined;Sorry. I confused RFile and TFile. It's the removal of TFile that I suggest as a thought experiment.,"14/Nov/12 17:02;kturner;bq. Sorry. I confused RFile and TFile. It's the removal of TFile that I suggest as a thought experiment.

The history behind this is that I wanted to use BCFile when writing RFile.  However BCFile was package private.  So I just copied the whole package.   TFile and BCFile are intertwined, I think they depend on each other.   I do not think its worthwhile removing TFile.  The copied BCfile was modified to support multi-level indexes in 1.4.

I think what should be removed is the main method from RFile.  This is just some really old test code from when I first wrote RFile.  It really should not be there.  The exception is expected because the code tries to use an RFile after it was closed.","12/Dec/12 20:17;ecn;BTW, I'm editing nearly every main() in my effort to clean up argument parsing of *everything* (ACCUMULO-745)","12/Dec/12 21:19;hudson;Integrated in Accumulo-Trunk #575 (See [https://builds.apache.org/job/Accumulo-Trunk/575/])
    ACCUMULO-854 removed main method from RFile (Revision 1420938)

     Result = SUCCESS
billie : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/file/rfile/RFile.java
","12/Dec/12 21:27;billie.rinaldi;Eric, does that mean you'd prefer this main to be there, or are you happy it's gone?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix mapr support in 1.5,ACCUMULO-688,12598647,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,12/Jul/12 23:38,23/Nov/12 20:01,13/Mar/19 22:01,23/Nov/12 18:11,,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"Using Accumulo on MapR could fail in 1.5 (unreleased) that we are logging directly to the distributed file system.  We need some way to make walogs read-only when detecting tserver failure and using MapR.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-23 20:01:00.38,,,no_permission,,,,,,,,,,,,246380,,,Fri Nov 23 20:01:00 UTC 2012,,,,,,0|i07lnz:,42276,,,,,,,,23/Nov/12 18:11;ecn;fixed with revision 1413007,"23/Nov/12 20:01;hudson;Integrated in Accumulo-Trunk #564 (See [https://builds.apache.org/job/Accumulo-Trunk/564/])
    ACCUMULO-688 make lease recovery configurable (Revision 1413007)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/MapRRecoverLease.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/recovery/RecoverLease.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Handle method.include calls consistently in TraceWrap class.,ACCUMULO-845,12615292,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,medined,medined,08/Nov/12 05:13,16/Nov/12 15:10,13/Mar/19 22:01,16/Nov/12 14:52,,,,,,,,1.5.0,,,,,,,,,0,,,,,"One call ignores exceptions and one call handles exceptions.
{noformat}
 if (args == null || args.length < 1 || args[0] == null || !(args[0] instanceof TInfo)) {
  return method.invoke(instance, args);
 }       
 Span span = Trace.trace((TInfo) args[0], method.getName());
 try {   
    return method.invoke(instance, args);
 } catch (InvocationTargetException ex) {
   throw ex.getCause();
 } finally {
   span.stop();
 }       
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-16 14:48:37.861,,,no_permission,,,,,,,,,,,,255897,,,Fri Nov 16 15:10:52 UTC 2012,,,,,,0|i0fvnr:,90727,,,,,,,,16/Nov/12 14:48;ecn;I'm going to fix this in trunk.  Do you think this should be back-ported to 1.4?,"16/Nov/12 15:10;hudson;Integrated in Accumulo-Trunk #555 (See [https://builds.apache.org/job/Accumulo-Trunk/555/])
    ACCUMULO-845 make error handling consistent in the Proxy (Revision 1410378)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/trace/src/main/java/org/apache/accumulo/cloudtrace/instrument/thrift/TraceWrap.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
thrift server responds slowly to large numbers of requests,ACCUMULO-834,12613653,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kturner,ecn,ecn,26/Oct/12 13:16,15/Nov/12 22:34,13/Mar/19 22:01,15/Nov/12 21:30,1.4.1,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"Testing on a large cluster, I found that the time to gather data from tablet servers got very long, resulting in ""blocky"" graphs in the monitor.  After instrumenting the master, I found that each request to a tablet server was taking longer, and there were many servers.  In the tserver logs, I saw lots of adjustments to the number of threads in the tablet server.  At a large scale, say, hundreds of servers, and hundreds of test ingesters, sometimes there will be hundreds of threads requesting service.  The thread pool grows slowly (one new thread per second when falling behind).  Requests from the master starve waiting for new threads to be created.

Possible fixes:
 * use a thread pool in the master to make status requests
 * use asynchronous messaging (the old ping/pong) to make status requests
 * modify the configuration to respond to large numbers of requests more quickly
 * increase the minimum number of threads available to service requests
 * replace the existing network infrastructure to use netty
 * modify the thread-pool checker to increase the number of threads more quickly when heavily loaded ",large scale cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-09 16:08:41.862,,,no_permission,,,,,,,,,,,,251255,,,Thu Nov 15 22:34:14 UTC 2012,,,,,,0|i0bc3z:,64074,,,,,,,,"09/Nov/12 16:08;hudson;Integrated in Accumulo-Trunk #545 (See [https://builds.apache.org/job/Accumulo-Trunk/545/])
    ACCUMULO-834 change thread name to improve debugging of slow status scans (Revision 1407493)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
",15/Nov/12 21:30;ecn;fixed with r1410025,"15/Nov/12 22:34;hudson;Integrated in Accumulo-Trunk #553 (See [https://builds.apache.org/job/Accumulo-Trunk/553/])
    ACCUMULO-834 adjust threadpool size quickly: storm events (like root tablet moves) cause lots of connections on large clusters (Revision 1410025)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/TServerUtils.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
monitor gets npe when the master is down,ACCUMULO-856,12616312,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,15/Nov/12 21:24,15/Nov/12 22:34,13/Mar/19 22:01,15/Nov/12 21:33,,,,,,,,1.5.0,,,monitor,,,,,,0,,,,,got an annoying NPE when the master wasn't running,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-15 22:34:14.019,,,no_permission,,,,,,,,,,,,258073,,,Thu Nov 15 22:34:14 UTC 2012,,,,,,0|i0kmcn:,118438,,,,,,,,15/Nov/12 21:33;ecn;fixed with r1410023,"15/Nov/12 22:34;hudson;Integrated in Accumulo-Trunk #553 (See [https://builds.apache.org/job/Accumulo-Trunk/553/])
    ACCUMULO-856 do not decode the fetched data if the master is down (Revision 1410023)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/Monitor.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
agitator maxkill/minkill issue,ACCUMULO-784,12610144,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,cmccubbin,cmccubbin,cmccubbin,03/Oct/12 21:30,16/Oct/12 14:02,13/Mar/19 22:01,16/Oct/12 14:02,1.4.1,,,,,,,1.4.2,1.5.0,,test,,,,,,0,,,,,"agitator.pl has a bug where if it is launched with a maxkill value and a minkill value, if the maxkill is lowered automatically by the script to the number of actual tservers, and the maxkill is then lower than the input minkill, the script can hang.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Oct/12 17:52;cmccubbin;accumulo784patch.diff;https://issues.apache.org/jira/secure/attachment/12547791/accumulo784patch.diff,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-10-15 20:01:33.391,,,no_permission,,,,,,,,,,,,240578,,,Mon Oct 15 20:24:38 UTC 2012,,,,,,0|i013nj:,4361,,,,,,,,04/Oct/12 18:05;cmccubbin;Attached is a patch that sets minkill to equal maxkill if maxkill gets lowered below minkill.,"15/Oct/12 20:01;kturner;I just did a search for tickets with Attachment count > 0 that were not in patch available state... found this and some other tickets

changing status to patch available....",15/Oct/12 20:24;billie.rinaldi;I believe the Accumulo Patches filter on the Accumulo Interest dashboard checks for attachment count or patch available status (in case anyone wants to see both in a unified view).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockTable doesn't obey useVersions parameter,ACCUMULO-795,12611011,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,drew.farris,drew.farris,drew.farris,09/Oct/12 16:03,13/Oct/12 19:45,13/Mar/19 22:01,13/Oct/12 19:45,1.4.1,1.5.0,,,,,,1.4.2,1.5.0,,test,,,,,,0,hackathon,,,,"The constructor for {{MockTable}} will call {{IteratorUtil.generateInitialTableProperties()}}, and thus set a versioning iterator on itself regardless of whether the useVersion parameter is set to true or false. 

I believe {{MockTable}}'s constructor should call IteratorUtil.generateInitialTableProperties() only if useVersions is true, otherwise, it should populate {{settings}} with a new {{TreeMap}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,13/Oct/12 18:24;drew.farris;ACCUMULO-795.patch;https://issues.apache.org/jira/secure/attachment/12549033/ACCUMULO-795.patch,13/Oct/12 15:09;drew.farris;ACCUMULO-795.patch;https://issues.apache.org/jira/secure/attachment/12549024/ACCUMULO-795.patch,11/Oct/12 00:27;drew.farris;ACCUMULO-795.patch;https://issues.apache.org/jira/secure/attachment/12548676/ACCUMULO-795.patch,10/Oct/12 23:58;drew.farris;ACCUMULO-795.patch;https://issues.apache.org/jira/secure/attachment/12548672/ACCUMULO-795.patch,09/Oct/12 16:05;drew.farris;ACCUMULO-795.patch;https://issues.apache.org/jira/secure/attachment/12548421/ACCUMULO-795.patch,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,2012-10-09 19:28:12.153,,,no_permission,,,,,,,,,,,,246182,,,Sat Oct 13 18:24:14 UTC 2012,,,,,,0|i07hzb:,41680,,,,,,,,09/Oct/12 19:28;kturner;I think the test should that creates a table w/o the versioning iterator should also insert some data that would normally be suppressed by the versioning iterator.   Do this before attaching the iterator.,10/Oct/12 23:58;drew.farris;Updated unit test to validate absence/presence of VersioningIterator via insert and assert methods.,"11/Oct/12 00:27;drew.farris;Shuffled things around a bit -- {{IteratorUtil.generateInitialTableProperties()}} now takes a boolean argument {{limitVersion}} what will cause the Versioning Iterator to be added to the table if true. 

This way, if we add additional default table properties, such as a Constraint that limits key size, we can add them here, and not worry about code calling {{generateInitialTableProperties}} or not. 

The general contract would be that {{generateInitialTableProperties}} is always called when a new table is created regardless of whether it is mock or real.","13/Oct/12 15:09;drew.farris;Uhh, with this unit tests in the patch this time.",13/Oct/12 17:59;drew.farris;Updated for latest revisions to 1.4.x,13/Oct/12 18:24;drew.farris;One more time...,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
splitting a tablet results in bogus warnings,ACCUMULO-774,12608909,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,24/Sep/12 17:54,13/Oct/12 19:22,13/Mar/19 22:01,13/Oct/12 19:06,,,,,,,,1.5.0,,,master,tserver,,,,,0,hackathon,,,,"Asking a tablet server to split a tablet can result in an unbalanced load.  When the balancer runs, it returns a plan to move the tablets. The next run of the state machine will send unload messages to tablet servers.  This, in turn, will result in waking up the master to re-run the state machine.  In this way, the master ends up queuing many requests to unload a tablet.  Eventually the tablet server will unload the tablet and then complain about being asked to unload a tablet that is no longer loaded.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246302,,,Sat Oct 13 19:06:30 UTC 2012,,,,,,0|i07l6v:,42199,,,,,,,,"13/Oct/12 19:06;ecn;fixed at the hackathon in Columbia, MD",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cobertura coverage not generated,ACCUMULO-801,12611163,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,10/Oct/12 12:45,10/Oct/12 13:13,13/Mar/19 22:01,10/Oct/12 13:13,1.4.1,,,,,,,1.4.2,1.5.0,,test,,,,,,0,coverage,jenkins,maven,,The cobertura coverage is no longer generated by the mvn cobertura:cobertura goal in Jenkins.  It needs to be moved the the pluginManagement section of builds (until such time as we get mvn site fixed).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246964,,,2012-10-10 12:45:18.0,,,,,,0|i07xgf:,44187,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Typo in User Manual on MapReduce Analytics,ACCUMULO-768,12608442,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,jshipper,jshipper,jshipper,20/Sep/12 13:02,21/Sep/12 19:30,13/Mar/19 22:01,21/Sep/12 19:30,1.4.0,,,,,,,1.4.2,1.5.0,,docs,,,,,,0,,,,,"This typo can be found on: http://accumulo.apache.org/1.4/user_manual/Analytics.html (also applies to older versions of manual)

The reduce function signature is incorrect.  Instead of:
public void reduce(WritableComparable key, Iterator<Text> values, Context c)

It should be:
public void reduce(WritableComparable key, Iterable<Text> values, Context c)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,21/Sep/12 17:36;jshipper;ACCUMULO-768.patch;https://issues.apache.org/jira/secure/attachment/12546069/ACCUMULO-768.patch,20/Sep/12 13:59;jshipper;ACCUMULO-768.patch;https://issues.apache.org/jira/secure/attachment/12545903/ACCUMULO-768.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2012-09-20 19:59:21.831,,,no_permission,,,,,,,,,,,,246308,,,Fri Sep 21 19:30:53 UTC 2012,,,,,,0|i07l87:,42205,,,,,,,,20/Sep/12 13:59;jshipper;Changed Iterator to Iterable on 1.4's user manual's Analytics page,"20/Sep/12 19:59;billie.rinaldi;Jay, thanks for the patch.  I've added you to our contributors group in JIRA.","21/Sep/12 12:04;jshipper;Sorry for the rookie question, but can I apply the patch or does a committer have to do it?  If I can do it, what's the process for that?  Just a simple svn commit?","21/Sep/12 16:45;billie.rinaldi;A committer will still have to apply the patch.  I haven't done this yet because there is another place where the error must be corrected, in the latex manual (docs/src/user_manual).  There is actually a process for generating the web manual from the latex manual, though someday I would like to make the web manual the canonical version and just generate a pdf manual from it.",21/Sep/12 17:36;jshipper;Updated to include change in latex manual,21/Sep/12 19:30;billie.rinaldi;Thanks for the updated patch!  I applied it to 1.4 and trunk as well as the site.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"large values, complex iterator stacks, and RFile readers can consume a surprising amount of memory",ACCUMULO-665,12596454,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,29/Jun/12 21:17,07/Sep/12 01:19,13/Mar/19 22:01,06/Sep/12 23:09,1.4.0,,,,,,,1.4.1,,,tserver,,,,,,0,,,,,"On a production cluster, with a complex iterator tree, a large value (~350M) was causing a 4G tserver to fail with out-of-memory.

There were several factors contributing to the problem:
# a bug: the query should not have been looking to the big data
# complex iterator tree, causing many copies of the data to be held at the same time
# RFile doubles the buffer it uses to load values, and continues to use that large buffer for future values

This ticket is for the last point.  If we know we're not even going to look at the value, we can read past it without storing it in memory.  It is surprising that skipping past a large value would cause the server to run out of memory, especially since it should fit into memory enough times to be returned to the caller.

The provided iterators inside core/org/apache/accumulo/iterators should be revisited to ensure that they properly set the seekColumnFamilies where necessary, specifically the IntersectingIterator.",large cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,03/Jul/12 02:52;elserj;ACCUMULO-665.patch;https://issues.apache.org/jira/secure/attachment/12534496/ACCUMULO-665.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-07-02 13:17:33.067,,,no_permission,,,,,,,,,,,,246402,,,Thu Sep 06 23:09:59 UTC 2012,,,,,,0|i07lsv:,42298,,,,,,,,"02/Jul/12 13:17;elserj;The big area that this can present itself is via the seekColumnFamilies on the SortedKeyValueIterator#seek() method. In the IntersectingIterator inside the core module, you could run into ""excessive"" memory usage.

Say you're intersecting over the two terms ""foo"" and ""bar"" and that you have some column ""documents"" which is directly before the term ""foo"". Assume the keys in the ""documents"" column are in their own locality group and have very large Values associated with them. The IntersectingIterator only uses any seek-column-families that are passed in but does not set any itself. Meaning, even though the ""documents"" column is in its own section of the RFile, by not specifically setting the seek column families for each term to just the term itself, the underlying Accumulo code will still open up all locality groups (the one for ""documents"" and the default locality group).

The javadoc for SortedKeyValueIterator should also be updated to inform other users of the implications that (not) setting the seekColumnFamilies has.","03/Jul/12 02:50;elserj;Taking a look at the OrIterator and IntersectingIterator, they are subject to the same faults this ticket describes. The attached patch corrects the usage of the columnFamilies passed to the seek() method, and makes the appropriate changes to the IndexDocIterator which extends the IntersectingIterator.","03/Jul/12 02:52;elserj;Update to SortedKeyValueIterator#seek javadoc. Changes to IntersectingIterator, OrIterator, and IndexedDocIterator to avoid confusion about the columnFamilies argument to the seek() method.","05/Jul/12 21:08;ecn;Josh, Isn't there something that needs to change in the AndIterator, in the wikisearch example, too?
","04/Sep/12 21:02;billie.rinaldi;Was this fixed in 1.4.1, or should we change the fix version of this ticket?","06/Sep/12 23:08;elserj;In regards to Eric's comment, it looks like the AndIterator in the wikisearch code is correct (r1359639).

Billie, as far as I can tell, this ticket is complete. I'll flip the version back to 1.4.1 and close it. We can re-open/rev-bump if we determine that it's not the case.",06/Sep/12 23:09;elserj;Patch applied by Eric.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
root tablet taken off line before non-root metadata tables,ACCUMULO-676,12597812,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,06/Jul/12 18:18,06/Sep/12 18:13,13/Mar/19 22:01,22/Aug/12 15:55,1.4.0,,,,,,,1.4.2,1.5.0,,master,,,,,,0,,,,,"
{noformat}
$ bin/accumulo admin stop localhost
{noformat}

This takes all tablets offline at the same time, which can take the root tablet offline before taking the metadata tablet offline, which will cause the tserver to fail to take the metadata tablet offline, and the system will fail to shutdown.
",single tserver instance (desk testing),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-08-22 15:11:52.182,,,no_permission,,,,,,,,,,,,246391,,,Wed Aug 22 15:55:57 UTC 2012,,,,,,0|i07lqf:,42287,,,,,,,,"06/Jul/12 18:23;ecn;Also noticed that if the master loses its lock, the Fate operation that is waiting for the tablet servers to unload their tablets will complete successfully, without the tablet server being halted.
",06/Jul/12 18:23;ecn;Note: this is only a problem when there are no other tablet servers.,"22/Aug/12 15:11;vines;1.4.2 Snapshot, single node install. I call admin stop localhost and it brings down the tserver and unregisters the logger fine. But then it gets stuck on a scan of the !METADATA table to validate that everything is correctly deallocated from that logger. We should tweak this so that if there are no tservers left, we don't check the !METADATA table.

This should not be an issue in trunk.","22/Aug/12 15:55;vines;As I said, tweaked it to NOT scan the !METADATA table if there are no tserver.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooZap Usage Message Does Not Mention -tracers,ACCUMULO-631,12559772,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,,medined,medined,07/Jun/12 22:44,06/Sep/12 18:13,13/Mar/19 22:01,10/Jul/12 11:54,,,,,,,,1.5.0,,,client,,,,,,0,,,,,The summary says it all.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246435,,,2012-06-07 22:44:34.0,,,,,,0|i07m0f:,42332,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Close InputStream instead finally clause in FileIngestData.insertFileData method.,ACCUMULO-738,12604556,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,medined,medined,medined,23/Aug/12 03:54,06/Sep/12 17:58,13/Mar/19 22:01,23/Aug/12 03:57,,,,,,,,1.5.0,,,,,,,,,0,,,,,FileInputStream's are opened and then closed outside of a finally clause.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246336,,,Thu Aug 23 03:57:49 UTC 2012,,,,,,0|i07lef:,42233,,,,,,,,23/Aug/12 03:57;medined;SVN#1376359.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The PrintInfo.printMetaBlockInfo method does not close a BCFile.Reader,ACCUMULO-737,12604553,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,medined,medined,medined,23/Aug/12 03:23,06/Sep/12 17:58,13/Mar/19 22:01,23/Aug/12 03:27,,,,,,,,1.5.0,,,,,,,,,0,,,,,"A Reader is opened:

{noformat}
BCFile.Reader bcfr = new BCFile.Reader(fsin, fs.getFileStatus(path).getLen(), conf);
{noformat}

but not closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246337,,,Thu Aug 23 03:27:22 UTC 2012,,,,,,0|i07len:,42234,,,,,,,,23/Aug/12 03:27;medined;SVN#1376356,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
java.lang.ClassCastException: com.mapr.fs.MapRFileSystem cannot be cast to org.apache.hadoop.hdfs.DistributedFileSystem,ACCUMULO-476,12547238,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,toddstavish,toddstavish,20/Mar/12 17:06,08/Aug/12 15:43,13/Mar/19 22:01,20/Mar/12 19:52,,,,,,,,1.4.0,,,logger,master,tserver,,,,0,,,,,"From Keith Turner on the accumulo user group:

I looked at the code and its just simply cast to a
DistributedFileSystem inorder to check if HDFS is in safe mode.  It
should do an instanceof operation and then do the case.  Would you
mind opening a ticket about this?",Accumulo 1.4 rc 2 on mapr m5.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,08/Aug/12 15:43;calmo;ASF.LICENSE.NOT.GRANTED--AccumuloOverview-ClassCastException.jpg;https://issues.apache.org/jira/secure/attachment/12539879/ASF.LICENSE.NOT.GRANTED--AccumuloOverview-ClassCastException.jpg,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-03-20 17:24:11.603,,,no_permission,,,,,,,,,,,,232396,,,Wed Aug 08 15:43:55 UTC 2012,,,,,,0|i07myf:,42485,,,,,,,,20/Mar/12 17:24;kturner;I will try to create a functional test that uses the LocalFileSystem instead of DistributedFileSystem.  Hopefully that will reproduce this and maybe find other issues.,"08/Aug/12 15:37;calmo;Verified same error is occurring in v1.4.1, with MapR M5 v2.0beta.

{quote}
     java.lang.ClassCastException: com.mapr.fs.MapRFileSystem cannot be cast to org.apache.hadoop.hdfs.DistributedFileSystem
	at org.apache.accumulo.server.monitor.servlets.DefaultServlet.doHdfsTable(DefaultServlet.java:297)
	at org.apache.accumulo.server.monitor.servlets.DefaultServlet.pageBody(DefaultServlet.java:207)
	at org.apache.accumulo.server.monitor.servlets.BasicServlet.doGet(BasicServlet.java:62)
	at org.apache.accumulo.server.monitor.servlets.DefaultServlet.doGet(DefaultServlet.java:146)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:324)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)
	at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)
{quote}",08/Aug/12 15:43;calmo;showing stack trace for bug,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tablet server shutdown may not work through a master failure,ACCUMULO-678,12598048,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,09/Jul/12 16:19,10/Jul/12 16:40,13/Mar/19 22:01,10/Jul/12 16:40,1.4.0,,,,,,,1.4.2,1.5.0,,master,,,,,,0,,,,,"Also noticed that if the master loses its lock, the Fate operation that is waiting for the tablet servers to unload their tablets will complete successfully, without the tablet server being halted.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246389,,,2012-07-09 16:19:23.0,,,,,,0|i07lpz:,42285,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ArrayByteSequence needs to be Serializable,ACCUMULO-659,12596135,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,ecn,ecn,27/Jun/12 18:34,28/Jun/12 18:22,13/Mar/19 22:01,28/Jun/12 18:22,1.4.0,,,,,,,1.4.1,,,client,,,,,,0,,,,,"Authorizations is Serializable, and points to a set of ByteSequence, which is implemented ArrayByteSequence.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246408,,,2012-06-27 18:34:20.0,,,,,,0|i07lu7:,42304,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
512Mb Configuration Example - JVM Memory Too Small.,ACCUMULO-632,12560427,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,medined,medined,medined,13/Jun/12 02:32,18/Jun/12 22:37,13/Mar/19 22:01,18/Jun/12 22:37,,,,,,,,1.5.0,,,,,,,,,0,configuration,,,,"In conf/examples/512MB/native-standalone/accumulo-env.sh, it says:

 ACCUMULO_TSERVER_OPTS=""${POLICY} -Xmx48m -Xms48m -Xss128k""

And in the accumulo-site.xml in the same directory, it sets:

  tserver.memory.maps.max: 80M
  tserver.cache.index.size: 20M

This combination of value prevents tserver from starting. In order to get running, I set the JVM values to 128M.

Please correct one or both of these settings so that the tserver will start.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-06-13 02:41:38.118,,,no_permission,,,,,,,,,,,,246434,,,Mon Jun 18 22:37:41 UTC 2012,,,,,,0|i07m07:,42331,,,,,,,,"13/Jun/12 02:41;jvines;that configuration example is to be used with the native maps, which use memory outside of the jvm. If you are not using them, then use the standalone examples or compile the native map.",18/Jun/12 22:37;medined;John explained the issue. I checked that the 512MB standalone files were correct.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
default walog copy/sort uses replication of 1,ACCUMULO-509,12549320,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kturner,ecn,ecn,03/Apr/12 12:32,29/May/12 18:34,13/Mar/19 22:01,29/May/12 18:34,,,,,,,,1.4.1,1.5.0,,logger,,,,,,0,,,,,"During recovery, the logger copied/sorted a recovery walog to hdfs.  The copy was ok, but there was a checksum error when replaying the data.  The system did not recover without manual intervention.  The work-around was to find the datanode serving the back block, and stop it.  Then I removed the bad recovery file and restarted the master.  The copy/sort took place again, and used a different datanode.  Recovery proceeded successfully.

We need to use a higher replication and/or a more sophisticated approach to verifying and restarting recoveries.",medium size cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,234311,,,2012-04-03 12:32:37.0,,,,,,0|i07mrb:,42453,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Key hashCode should include timestamp,ACCUMULO-450,12545551,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kturner,kturner,kturner,07/Mar/12 19:54,04/May/12 23:15,13/Mar/19 22:01,04/May/12 23:15,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,,,,,,,0,,,,,"The hashCode function for the Key class does not include the timestamp.  If someone were to create a HashSet or HashMap of keys were only the timestamp differed, then performance would be O(N).  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-03-08 14:32:35.272,,,no_permission,,,,,,,,,,,,230737,,,Thu Mar 08 14:32:35 UTC 2012,,,,,,0|i07n47:,42511,,,,,,,,08/Mar/12 14:32;jvines;I'm just worried about the impact of making this sort of change mid-release. I think it should be done in a .0 release.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""% of Used DFS"" is overflowing on a large cluster",ACCUMULO-505,12548850,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,30/Mar/12 17:08,27/Apr/12 12:31,13/Mar/19 22:01,27/Apr/12 12:31,,,,,,,,1.4.1,1.5.0,,,,,,,,0,,,,,"monitor is displaying ""% of Used DFS 65429710200.91%"" -- size of hdfs is large, so something is probably overflowing an int.",large cluster testing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,233947,,,Fri Apr 27 12:31:28 UTC 2012,,,,,,0|i07ms7:,42457,,,,,,,,27/Apr/12 12:31;ecn;Was measuring total space and space under /accumulo using two different mechanisms.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
assigned tablets are not considered offline,ACCUMULO-520,12550499,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,11/Apr/12 11:48,25/Apr/12 13:36,13/Mar/19 22:01,25/Apr/12 13:36,1.3.5-incubating,1.4.0,,,,,,1.4.1,,,master,,,,,,0,,,,,"Presently (1.3.5, 1.4.0) if a tablet is assigned, but not loaded, it is considered online for display purposes.  This provides no indication that a tablet is unavailable.  Change the definition of offline to included assigned tablets that have not been loaded.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235363,,,2012-04-11 11:48:25.0,,,,,,0|i07mp3:,42443,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
migrations to unresponsive tablet server cancelled for the wrong reason,ACCUMULO-529,12550680,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,12/Apr/12 13:57,12/Apr/12 18:47,13/Mar/19 22:01,12/Apr/12 18:47,1.3.5-incubating,,,,,,,1.3.6,,,master,,,,,,0,,,,,"While looking at another bug, I saw strange reports of a thousand tablets being cancelled because the tablets ""no longer exist, probably due to a split.""  The tablets do still exist, and the migrations should not have been cancelled.
",large deployed cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235544,,,Thu Apr 12 18:47:08 UTC 2012,,,,,,0|i07mn3:,42434,,,,,,,,12/Apr/12 18:47;ecn;This bug does not exist in 1.4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
examples functional test is using the wrong class name,ACCUMULO-521,12550505,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,11/Apr/12 12:23,11/Apr/12 17:22,13/Mar/19 22:01,11/Apr/12 17:22,1.4.0,,,,,,,1.4.1,,,test,,,,,,0,,,,,"Reported by Keys Botzum:

simple.examples.Examples was failing with a class loader issue. By examining simple/examples.py I was able to determine that the package names were not correct when referring to certain subtests, such as RandomBatchScanner. Specifically it referred to org.apache.accumulo.examples.client.RandomBatchScanner rather than the appropriate org.apache.accumulo.examples.*simple*.client.RandomBatchScanner. The same is true for RandomBatchWriter.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235369,,,2012-04-11 12:23:17.0,,,,,,0|i07mov:,42442,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DEFAULT_MAX_LATENCY in AccumuloOutputFormat wrong units,ACCUMULO-512,12549436,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,patrods1,patrods1,04/Apr/12 01:12,04/Apr/12 13:54,13/Mar/19 22:01,04/Apr/12 13:54,,,,,,,,1.4.1,,,client,,,,,,0,,,,,"In org.apache.accumulo.core.client.mapreduce.AccumuloOutputFormat, the DEFAULT_MAX_LATENCY (line 88) is defined as:

private static final int DEFAULT_MAX_LATENCY = 60; // 1 minute

However, at line 233 that default value (assuming the key isn't set by the user) is provided as an argument to createMultiTableBatchWriter().  The latency parameter there is documented as milliseconds.  The DEFAULT_MAX_LATENCY should be set to 60000 if the desired default latency value is 1 minute.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,234427,,,2012-04-04 01:12:16.0,,,,,,0|i07mqv:,42451,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
update documentation and prompt for the initial configuration of the trace table,ACCUMULO-184,12532545,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,mnguyen,mnguyen,23/Nov/11 23:32,01/Feb/12 20:49,13/Mar/19 22:01,01/Feb/12 20:49,1.3.5-incubating,,,,,,,1.4.0,,,trace,,,,,,0,,,,,"Getting this error (over and over again) in tracer.log:

tracer_server1.bericotechnologies.com.log:23 17:34:25,785 [trace.TraceServer] INFO : waiting to checking/create the trace table: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_CREDENTIALS - Username or Password is Invalid

I'm not sure what credentials are being used, I can verify via the accumulo shell that the root user and my generated user have the right passwords.  ","CentOS release 5.6
single node Accumulo setup",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-11-24 15:39:24.794,,,no_permission,,,,,,,,,,,,218278,,,Thu Nov 24 18:20:41 UTC 2011,,,,,,0|i07opr:,42770,,,,,,,,"24/Nov/11 15:39;ecn;The username/password for the tracer is configurable.  You'll need to make entries in accumulo-site.xml:

{noformat}

 <property>
    <name>trace.user</name>
    <value>root</value>
 </property>

 <property>
    <name>trace.password</name>
    <value>YourPasswordHere</value>
 </property>

{noformat}


If you use a different user, be sure to grant the user the ability to create tables, or create the table ""trace"" and grant the trace user the ability to write to the table.

edit: fixed typo
","24/Nov/11 18:20;mnguyen;The changes worked.  Just as an FYI, there is a small typo, though, with missing ""</value>"" tags in the example XML.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
button color is too dark,ACCUMULO-346,12539750,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,srinu k,srinu k,25/Jan/12 11:49,25/Jan/12 11:52,13/Mar/19 22:01,25/Jan/12 11:52,1.3.5-incubating,,,,,,,1.4.0,,,client,monitor,,,,,0,newbie,,,,in login page button color is too dark,"windos xp,.net,oracle",,,,,,,,,,,,,,,,,,,,,,,14400,14400,,0%,14400,14400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,225253,,,Wed Jan 25 11:52:41 UTC 2012,,,,,,0|i07nqf:,42611,,,,,,,,25/Jan/12 11:52;srinu k;problem is solved,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
master does not rebalance after a node fails,ACCUMULO-202,12533625,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,02/Dec/11 13:52,13/Jan/12 14:12,13/Mar/19 22:01,13/Jan/12 14:12,1.3.5-incubating,,,,,,,1.3.6,,,master,,,,,,0,,,,,"The master seems to be trying to contact a dead tablet server.  The master will not re-balance if the metrics it has for a tablet server are out-of-date.  Tablets seem to be assigned properly; just not balanced.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-12-30 21:28:29.22,,,no_permission,,,,,,,,,,,,219352,,,Tue Jan 10 20:39:17 UTC 2012,,,,,,0|i07olr:,42752,,,,,,,,05/Dec/11 17:25;ecn;This problem was already fixed in Accumulo 1.3.5.,08/Dec/11 18:23;ecn;Verified the issue still exists in 1.3; need a bigger cluster to reproduce.,"30/Dec/11 21:28;acordova;I believe we are seeing this issue in a 1.3.5 cluster of 200 EC2 nodes

How can I verify that the bug is there or not?","01/Jan/12 16:56;ecn;The bug is definitely in 1.3.5. If you take down an arbitrary node, and the monitor displays a notice that the node is unresponsive for more than 30 seconds, you are seeing this bug. To recover, restart the master.  [r1212020|http://svn.apache.org/viewvc?view=rev&rev=1212020] should fix 1.3.5.","10/Jan/12 20:39;ecn;Failing in the 1.4 branch:

 - running the wikisearch example
 - during ingest
 - ./bin/accumulo admin stop hostname
 - ./bin/start-here.sh
 - system did not rebalance",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ArrayIndexOutOfBoundsException running examples.shard.ContinuousQuery.,ACCUMULO-281,12537553,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,kturner,medined,medined,06/Jan/12 17:47,10/Jan/12 21:14,13/Mar/19 22:01,10/Jan/12 21:14,,,,,,,,1.4.0,,,docs,,,,,,0,,,,,"If no iteration count is passed to the ContinousQuery program, the following exception is thrown:
{noformat}
Thread ""org.apache.accumulo.examples.shard.ContinuousQuery"" died null
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.accumulo.start.Main$1.run(Main.java:89)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 7
	at org.apache.accumulo.examples.shard.ContinuousQuery.main(ContinuousQuery.java:61)
	... 6 more
{noformat}

The program works if an iteration count is provided.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,223059,,,2012-01-06 17:47:10.0,,,,,,0|i07o4f:,42674,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tracer continues to get errors writing to an online trace table,ACCUMULO-215,12534787,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,12/Dec/11 14:09,27/Dec/11 18:41,13/Mar/19 22:01,27/Dec/11 18:41,,,,,,,,1.4.0,,,trace,,,,,,0,,,,,"I took the trace table offline.  The tracer gets exceptions writing to it, which is to be expected.  However, after I brought the table online, I continued to get errors.

{noformat}
Unable to write mutation to table: org.apache.accumulo.core.data.Mutation@0
	org.apache.accumulo.core.client.MutationsRejectedException: # constraint violations : 0  # authorization failures : 0  # server errors 0 # exceptions 10
		at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.checkForFailures(TabletServerBatchWriter.java:456)
		at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.addMutation(TabletServerBatchWriter.java:198)
		at org.apache.accumulo.core.client.impl.BatchWriterImpl.addMutation(BatchWriterImpl.java:40)
		at org.apache.accumulo.server.trace.TraceServer$Receiver.span(TraceServer.java:128)
		at cloudtrace.thrift.SpanReceiver$Processor$span.process(SpanReceiver.java:174)
		at cloudtrace.thrift.SpanReceiver$Processor.process(SpanReceiver.java:154)
		at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:176)
		at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
		at java.lang.Thread.run(Thread.java:662)
	Caused by: org.apache.accumulo.core.client.TableOfflineException: Table trace (1) is offline
		at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.binMutations(TabletServerBatchWriter.java:571)
		at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$MutationWriter.addMutations(TabletServerBatchWriter.java:602)
		at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.startProcessing(TabletServerBatchWriter.java:182)
		at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.addFailedMutations(TabletServerBatchWriter.java:473)
		at org.apache.accumulo.core.client.impl.TabletServerBatchWriter.access$700(TabletServerBatchWriter.java:96)
		at org.apache.accumulo.core.client.impl.TabletServerBatchWriter$FailedMutations.run(TabletServerBatchWriter.java:525)
		at java.util.TimerThread.mainLoop(Timer.java:512)
		at java.util.TimerThread.run(Timer.java:462)
{noformat}
",trunk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-12-12 15:44:20.568,,,no_permission,,,,,,,,,,,,220471,,,Mon Dec 12 15:44:20 UTC 2011,,,,,,0|i07oj3:,42740,,,,,,,,"12/Dec/11 15:44;kturner;This is probably the batch writer.  Once it has seen any type of exception that it does not automatically recover from, it continues to fail and will never work again.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RegExFilter deepCopy NullPointerException,ACCUMULO-189,12532974,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,jasontrost,jasontrost,jasontrost,28/Nov/11 20:09,05/Dec/11 21:10,13/Mar/19 22:01,05/Dec/11 21:10,,,,,,,,1.4.0,1.5.0,,client,tserver,,,,,0,patch,,,,"If any of the regex matcher objects are null (i.e. for example, if you only specify a regex for the column family), the deepCopy call will throw a NullPointerException.
",,,,,,,,,,,,,,,,,,,,,,,,0,0,,0%,0,0,,,,,,,,,,,,,,,,,,,,,,,02/Dec/11 22:50;jasontrost;RegExFilter-patch-updated.patch;https://issues.apache.org/jira/secure/attachment/12505939/RegExFilter-patch-updated.patch,28/Nov/11 20:10;jasontrost;RegExFilter-test.patch;https://issues.apache.org/jira/secure/attachment/12505386/RegExFilter-test.patch,28/Nov/11 20:10;jasontrost;RegExFilter.patch;https://issues.apache.org/jira/secure/attachment/12505385/RegExFilter.patch,02/Dec/11 22:50;jasontrost;RegExFilterTest-patch-updated.patch;https://issues.apache.org/jira/secure/attachment/12505940/RegExFilterTest-patch-updated.patch,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,2011-11-28 20:24:38.911,,,no_permission,,,,,,,,,,,,218706,,,Fri Dec 02 22:50:19 UTC 2011,,,,,,0|i07oon:,42765,,,,,,,,"28/Nov/11 20:10;jasontrost;see attached patches
","28/Nov/11 20:10;jasontrost;patches attached.
","28/Nov/11 20:24;kturner;I changed the affects version.  This bug will be fixed for 1.5 and probably 1.4, so it will not affect those versions when released. If its not fixed for 1.4, then the affects version should be set to 1.4 ","28/Nov/11 20:54;billie.rinaldi;Jason, thanks for the patches and for finding this bug.  I very, very recently made some changes to the RegExFilter and some other user iterators that involved removing their constructors and using their static configuration methods for testing (see ACCUMULO-167).  For example:

    RegExFilter rei = new RegExFilter();
    IteratorSetting is = new IteratorSetting(1, RegExFilter.class);
    RegExFilter.setRegexs(is, "".*2"", null, null, null, false);
    rei.init(new SortedMapIterator(tm), is.getProperties(), new DefaultIteratorEnvironment());

Also, I moved the RegExFilterTest to the ...iterators.user package.  Could you do an svn update and recreate your patches, using the new syntax above for the test?","02/Dec/11 14:16;billie.rinaldi;If you'd prefer that I make the changes based on your existing patch, let me know.","02/Dec/11 22:50;jasontrost;updated patch
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in shell when trying to get help for non-existant command,ACCUMULO-170,12532257,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,kturner,kturner,22/Nov/11 02:42,30/Nov/11 20:46,13/Mar/19 22:01,30/Nov/11 20:46,,,,,,,,1.4.0,,,client,,,,,,0,,,,,"Saw this while running 1.4 branch, not sure if affects 1.3.

{noformat}
root@uptest> help dcan
21 21:40:03,274 [shell.Shell] ERROR: java.lang.NullPointerException
root@uptest>
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,217990,,,2011-11-22 02:42:45.0,,,,,,0|i07osv:,42784,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZooKeeperInstance should use site configuration for ZK timeout,ACCUMULO-126,12530713,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,08/Nov/11 13:03,30/Nov/11 20:22,13/Mar/19 22:01,30/Nov/11 20:22,1.3.5-incubating,,,,,,,1.4.0,,,,,,,,,0,,,,,"The  public constructor for ZooKeeperInstance hard codes the zk timeout to the default found via DefaultConfiguration. Instead, it should use SiteConfiguration in case the local configuration differs.

This is a single line change.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,216451,,,Tue Nov 08 14:21:59 UTC 2011,,,,,,0|i07p27:,42826,,,,,,,,"08/Nov/11 14:21;ecn;Hm... no, we can't use the SiteConfiguration in client code because clients don't have access to the accumulo-site.xml configuration file.  But we should expose the constructor that allows the client to set their own timeout value.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
key.followingKey(PartialKey.ROW_COLFAM_COLQUAL_COLVIS) can produce a key with an invalid COLVIS,ACCUMULO-193,12533243,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,afuchs,afuchs,30/Nov/11 05:27,30/Nov/11 20:04,13/Mar/19 22:01,30/Nov/11 20:04,1.3.5-incubating,,,,,,,1.4.0,,,client,,,,,,0,,,,,"Need a new algorithm for calculating the next biggest column visibility, because tagging \0 to the end creates an invalid column visibility. We might be able to minimize the timestamp for this (i.e. set timestamp to Long.MIN_VALUE, but keep column and row elements the same).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-11-30 14:46:49.007,,,no_permission,,,,,,,,,,,,218971,,,Wed Nov 30 16:33:05 UTC 2011,,,,,,0|i07onr:,42761,,,,,,,,30/Nov/11 14:46;billie.rinaldi;Just changing the timestamp would make it inconsistent with the rest of the followingKey algorithms; the returned Key would have to be treated as inclusive rather than exclusive.,"30/Nov/11 15:52;afuchs;That's true that the timestamp solution is imperfect: keys that actually use a timestamp of Long.MIN_VALUE would be left out. However, this is probably a moot discussion because Billie traced this down to the Key.toString() function. Basically, for ""fake"" keys used for specifying ranges we should never be validating the column visibility. Removing this validation from Key.toString() should solve the problem.","30/Nov/11 16:33;billie.rinaldi;As much as I enjoy there existing a Key that is perfectly usable until you call toString() on it, I suppose we should fix this issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Install script is missing,ACCUMULO-179,12532514,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,mnguyen,mnguyen,23/Nov/11 18:37,28/Nov/11 20:27,13/Mar/19 22:01,23/Nov/11 19:48,1.3.5-incubating,,,,,,,1.4.0,,,docs,,,,,,0,,,,,docs/administration.html mentions a script (bin/install) that automates all of the install and configuration steps.  This script is not located under bin/.  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-11-23 19:47:29.873,,,no_permission,,,,,,,,,,,,218247,,,Wed Nov 23 19:47:29 UTC 2011,,,,,,0|i07oqv:,42775,,,,,,,,"23/Nov/11 19:47;ecn;The install script has been removed... so I've removed the references to it.  The amount of effort needed to do this properly should not be underestimated.  Thanks for pointing out the reference.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
listscans in the shell attempts to contact tablet servers that do not hold locks,ACCUMULO-93,12529274,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,28/Oct/11 15:57,18/Nov/11 14:50,13/Mar/19 22:01,28/Oct/11 16:02,,,,,,,,1.3.5-incubating,1.4.0,,client,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,600,600,,0%,600,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215134,,,2011-10-28 15:57:18.0,,,,,,0|i07p9j:,42859,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
instance name listing suggestion doesn't work,ACCUMULO-122,12530608,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,billie.rinaldi,afuchs,afuchs,07/Nov/11 18:35,07/Nov/11 19:27,13/Mar/19 22:01,07/Nov/11 19:24,,,,,,,,1.3.5-incubating,,,client,,,,,,0,,,,,"Exception in thread ""main"" java.lang.RuntimeException: Instance name 1.3.5-incubating-RC4 does not exist in zookeeper.  Run ""accumulo accumulo.server.util.ListInstances"" to see a list.
	at org.apache.accumulo.core.client.ZooKeeperInstance.getInstanceID(ZooKeeperInstance.java:134)
	at org.apache.accumulo.core.client.ZooKeeperInstance.<init>(ZooKeeperInstance.java:93)
	at org.apache.accumulo.core.client.ZooKeeperInstance.<init>(ZooKeeperInstance.java:74)
	at org.apache.accumulo.core.client.mapreduce.AccumuloOutputFormat.getInstance(AccumuloOutputFormat.java:159)
	at org.apache.accumulo.core.client.mapreduce.AccumuloOutputFormat.checkOutputSpecs(AccumuloOutputFormat.java:345)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:830)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:791)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:791)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:465)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:494)
	at org.apache.accumulo.examples.mapreduce.WordCount.run(WordCount.java:110)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.accumulo.examples.mapreduce.WordCount.main(WordCount.java:121)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:156)


> accumulo accumulo.server.util.ListInstances
Classname accumulo.server.util.ListInstances not found.  Please make sure you use the wholly qualified package name.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,216346,,,2011-11-07 18:35:23.0,,,,,,0|i07p33:,42830,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockConnector does not implement createMultiTableBatchWriter,ACCUMULO-95,12529277,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,28/Oct/11 16:09,28/Oct/11 16:31,13/Mar/19 22:01,28/Oct/11 16:31,,,,,,,,1.3.5-incubating,1.4.0,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215137,,,2011-10-28 16:09:39.0,,,,,,0|i07p93:,42857,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
monitor doesn't provide web service if zookeeper is down,ACCUMULO-54,12527934,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,ecn,ecn,20/Oct/11 14:48,26/Oct/11 17:08,13/Mar/19 22:01,26/Oct/11 17:08,,,,,,,,1.4.0,,,monitor,,,,,,0,,,,,Users become frustrated if the monitor page doesn't tell them that things are down.,start accumulo without zookeeper running; nothing tells you that zookeeper is unavailable,,,,,,,,,,,,,,,,,,,,,,,86400,86400,,0%,86400,86400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,92345,,,2011-10-20 14:48:25.0,,,,,,0|i07pi7:,42898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in zookeeper trace callback,ACCUMULO-66,12528560,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Minor,Fixed,ecn,kturner,kturner,24/Oct/11 21:21,25/Oct/11 19:15,13/Mar/19 22:01,25/Oct/11 19:15,,,,,,,,,,,trace,,,,,,0,,,,,"Saw the following when starting the shell.  Seems like the callback executed before zoo was set (or flushed from CPU cache).

{noformat}
java.lang.NullPointerException
	at cloudtrace.instrument.receivers.ZooSpanClient.process(ZooSpanClient.java:91)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:530)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:506)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,214420,,,2011-10-24 21:21:30.0,,,,,,0|i07pfj:,42886,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ColumnVisibility parse tree nodes do not have correct location offsets for AND and OR nodes,ACCUMULO-1730,12669509,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,jstoneham,jstoneham,19/Sep/13 18:42,03/Jun/16 17:38,13/Mar/19 22:01,22/Oct/13 17:32,1.4.0,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,,1.6.0,,,client,,,,,,0,,,,,"Trying to do some transformations on visibility strings and running into issues working with the parse tree:

Clojure 1.5.1
user=> (import [org.apache.accumulo.core.security ColumnVisibility])
org.apache.accumulo.core.security.ColumnVisibility
user=> (def vis (ColumnVisibility. ""(W)|(U|V)""))
#'user/vis
user=> (.getTermStart (first (.getChildren (.getParseTree vis))))
1
user=> (.getTermEnd (first (.getChildren (.getParseTree vis))))
2
user=> (.getTermStart (second (.getChildren (.getParseTree vis))))
0
user=> (.getTermEnd (second (.getChildren (.getParseTree vis))))
8

Shouldn't those last two be 5 and 8?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16/Oct/13 01:36;jstoneham;0001-ACCUMULO-1730-Reinsert-changes-inadvertently-lost-in.patch;https://issues.apache.org/jira/secure/attachment/12608630/0001-ACCUMULO-1730-Reinsert-changes-inadvertently-lost-in.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-09-19 18:56:43.736,,,no_permission,,,,,,,,,,,,349441,,,Tue Oct 22 17:32:50 UTC 2013,,,,,,0|i1o94v:,349739,,,,,,,,19/Sep/13 18:56;vines;I believe the fourth would be 5 and 8 as it's an inorder tree traversal,19/Sep/13 19:11;jstoneham;It builds out the tree. There's only two children of the top node.,"20/Sep/13 19:05;ctubbsii;Is this really a bug? If so, can you provide a unit test that highlights the bug?
I suspect it's not so much a bug, as it is non-intuitive API semantics for internal parsing code, or a non-optimal implementation.","20/Sep/13 19:08;ctubbsii;Also, I recommend Java pseudo-code to report bugs for a Java application :) You can be sure we know Java... but it's not necessarily safe to say we know Clojure (though, the above is reasonably easy to figure out).","23/Sep/13 15:34;ecn;This code
{noformat}
import org.apache.accumulo.core.security.ColumnVisibility;
import org.apache.accumulo.core.security.ColumnVisibility.Node;


public class Test {
  
  static void printTree(int indent, String v, Node node) {
    for (int i = 0; i < indent; i++)
      System.out.print(' ');
    System.out.println(node.getType() + "" "" + v.substring(node.getTermStart(), node.getTermEnd()) + "" "" + node.getTermStart() + "" "" + node.getTermEnd());
    for (Node child : node.getChildren()) {
      printTree(indent + 1, v, child);
    }
  }
  
  public static void main(String[] args) {
    String s = ""(W)|(U|V)"";
    ColumnVisibility v = new ColumnVisibility(s);
    System.out.println(s);
    printTree(0, s, v.getParseTree());
  }
  
}
{noformat}

prints this:

{noformat}
(W)|(U|V)
OR  0 0
 TERM W 1 2
 OR (W)|(U|V 0 8
  TERM U 5 6
  TERM V 7 8
{noformat}
","23/Sep/13 15:57;jira-bot;Commit a25e3af8876f2118fb8370c3c4e3794ffc69989f in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a25e3af ]

ACCUMULO-1730 set offsets for AND and OR parse nodes
","23/Sep/13 15:57;jira-bot;Commit c091b545a7f79efb3dc9b8b279cfb4465b476ecc in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=c091b54 ]

ACCUMULO-1730 set offsets for AND and OR parse nodes
","02/Oct/13 14:56;jstoneham;This mentions it was fixed in 1.4.5 and 1.5.1, but it appears that no commit was actually pushed to any of the backport branches.

Appears that c091b54 was intended for 1.4.5, and a25e3af was intended for 1.5.1.

I've got some further commits that fix the offsets for the AND and OR nodes in such a way as they are useful for substringing the actual expression. Will provide pull requests on GitHub.","02/Oct/13 15:20;jstoneham;Pull request for 1.4.5-SNAPSHOT at https://github.com/apache/accumulo/pull/1
Pull request for 1.5.1-SNAPSHOT at https://github.com/apache/accumulo/pull/2","02/Oct/13 15:22;jstoneham;And, sorry about the Clojure sample code. I already had it in the REPL so just pasted it.","09/Oct/13 18:49;ctubbsii;Pull request 2 is insufficient as explained here: https://github.com/apache/accumulo/pull/2#issuecomment-25997371
Additionally, I'm not sure these non-bugfix improvements to this important code are worth the risk of backporting. (See comment linked above).","10/Oct/13 21:09;ctubbsii;[~ctubbsii] wrote on [GitHub|https://github.com/apache/accumulo/pull/2#issuecomment-26084687]:
{quote}Out of curiosity, why is this needed? I'm really hesitant to backport this change, since it's not really a bug, and because of the risks.{quote}

[~jstoneham] wrote on [GitHub|https://github.com/apache/accumulo/pull/2#issuecomment-26086903]:
{quote}I was writing a MapReduce job to re-normalize the visibility strings in our database because the format we want to use has changed. This is easy enough on most visibility strings - parse them the old way, then re-write them out the new way. The issue I had was dealing with complex visibility strings with top-level ORs, such as (A&B)|(C&(D|E)). I wanted to use the parse tree to find the substrings of the top-level visibilities, since we can't safely just split on the | character. But the node offsets were wrong.

I understand the risk of the backport, and making a call on whether or not to add it the 1.4 baseline based on that. I'm still not sure why it doesn't ""count as a bug"", though.{quote}

(Since this is our issue tracker, I moved the conversation here.)

I see. That's an interesting use case. I'd be reluctant to recommend relying on this code for that case. Originally, this code was written as a state machine. It was transformed to look more like a parse tree, to make it easier to fix some bugs at the time, but that cost us some efficiency. We addressed that loss by caching the results of visibility expression parsing in the visibility filter in the iterator stack with an LRUMap, but we've always considered this code to be ""internal"", and subject to change back to a much more efficient state machine or something else, as needed.

The reason why it's technically an improvement rather than a bug, is because the behavior you're expecting is based on assumptions about the semantics of an inner class intended for internal use... assumptions that were incorrect. Until you (effectively) requested those narrower semantics by filing this JIRA issue, that class existed solely to evaluate visibility expressions, not to provide a parse tree for users. However, it can do both, and that's why [~ecn] added it as an improvement in 1.6.

If you think this is a ""must have"", I can backport it to 1.4.5 and 1.5.1, but I'm unwilling to accept the maintenance costs/risks for doing so if it's a ""might be nice"". (Perhaps another commiter would be willing, though.) I did check your updated pull request, but I couldn't get it to merge cleanly. There might have been some other updates in the 1.4.5-SNAPSHOT and 1.5.1-SNAPSHOT branches that made the merge problematic.
","10/Oct/13 21:13;jstoneham;Makes sense. I though of the ParseTree as a public API, but sounds like it wasn't originally intended to be that way.

I don't need this immediately. I'll close the pull requests and open a new one against master. Thanks.",11/Oct/13 05:41;ctubbsii;I thought it was fixed in master.,11/Oct/13 18:45;jstoneham;Eric's commit is in master. It addresses the offsets for the terms themselves. My additional commits address the nodes representing the logical operators.,11/Oct/13 19:35;ctubbsii;Ah.,"15/Oct/13 17:42;jira-bot;Commit 9ceb320e1742a7b0fbb3bd753d28453e9313f517 in branch refs/heads/master from [~jstoneham]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9ceb320 ]

ACCUMULO-1730 Rename variable for clarity.
","15/Oct/13 17:42;jira-bot;Commit 33118cb721b9598af5cbe26cd4048ecb7189f0a0 in branch refs/heads/master from [~jstoneham]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=33118cb ]

ACCUMULO-1730 Correct ParseTree start/end markers for logical connector nodes.
","15/Oct/13 17:42;jira-bot;Commit 876c5ce5ee9a039d56c8e4c7ca04d0401a47cdac in branch refs/heads/master from [~jstoneham]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=876c5ce ]

ACCUMULO-1730 Expose ColumnVisibility normalize/stringify methods.
","15/Oct/13 21:07;jira-bot;Commit 611463972a52feab96156012c4a9d75c8df3d882 in branch refs/heads/master from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6114639 ]

ACCUMULO-1751 Fixing off by one error.
ACCUMULO-1730 Missing ) in test
",15/Oct/13 21:08;sonixbp;It looks like there's some test failures here.,15/Oct/13 21:27;jstoneham;Which tests? I compiled and ran them.,15/Oct/13 22:59;sonixbp;https://builds.apache.org/job/Accumulo-Master-Hadoop-2/480/,16/Oct/13 01:09;jstoneham;I hereby assign copyright of the code submitted for this issue to the ASF to be licensed as they see fit.,16/Oct/13 01:36;jstoneham;Patch for lines lost in broken cherry-pick and push. Fixes tests and behavior.,16/Oct/13 01:37;jstoneham;Sorry about that. I ran the tests after the cherry-pick but must have done something out of order or pushed the wrong commits. Attached patch 0001 fixes tests and behavior.,"16/Oct/13 01:44;jira-bot;Commit 872b6db372bba953e3c435fcfcb1c64c0713ff49 in branch refs/heads/master from [~jstoneham]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=872b6db ]

ACCUMULO-1730 Reinsert changes inadvertently lost in cherry-pick
","16/Oct/13 01:45;ecn;I don't know, either.  I absolutely ran the test after doing the pull.  ","16/Oct/13 01:49;ecn;For some reason the patch does not apply clean:

{noformat}
$ git apply ~/Downloads/0001-ACCUMULO-1730-Reinsert-changes-inadvertently-lost-in.patch 
error: patch failed: core/src/main/java/org/apache/accumulo/core/security/ColumnVisibility.java:302
error: core/src/main/java/org/apache/accumulo/core/security/ColumnVisibility.java: patch does not apply
error: patch failed: core/src/test/java/org/apache/accumulo/core/security/ColumnVisibilityTest.java:152
error: core/src/test/java/org/apache/accumulo/core/security/ColumnVisibilityTest.java: patch does not apply
{noformat}
",16/Oct/13 01:59;jstoneham;Corey Nolet was having the same problem for a while. Then it worked. It's in now.,16/Oct/13 02:00;jstoneham;Perhaps you were trying to reapply on top of his apply?,22/Oct/13 17:19;ecn;[~jstoneham] is this ticket done?,22/Oct/13 17:32;jstoneham;Fixed on master.,,,,,,,,,,,,,,,,,,,,,
while statement used as if statement,ACCUMULO-2131,12687246,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,bthorman,ecn,ecn,03/Jan/14 21:01,09/Apr/15 22:57,13/Mar/19 22:01,09/Apr/15 21:33,,,,,,,,1.7.0,,,tserver,,,,,,0,newbie,,,,"Going through PMD output, and this looks a little sketchy in SourceSwitchingIterator.java:

{noformat}
  private boolean switchSource() throws IOException {
    while (!source.isCurrent()) {
      source = source.getNewDataSource();
      iter = source.iterator();
      if (iflag != null)
        ((InterruptibleIterator) iter).setInterruptFlag(iflag);
      
      return true;
    }
    
    return false;
  }
{noformat}

I'm wondering if that ""while"" should be ""if""",,"Commit aac619c969abf0b76dbaf88744a0408516d3c655 in accumulo's branch refs/heads/master from [~bthorman]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=aac619c ]

ACCUMULO-2131 while statement used as if statement. Changed the while to an if.

Signed-off-by: Christopher Tubbs <ctubbsii@apache.org>
;09/Apr/15 21:31;jira-bot;600",,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,09/Apr/15 00:32;ctubbsii;0001-ACCUMULO-2131-Ensure-source-is-re-checked-for-being-.patch;https://issues.apache.org/jira/secure/attachment/12724078/0001-ACCUMULO-2131-Ensure-source-is-re-checked-for-being-.patch,06/Apr/15 14:55;bthorman;ACCUMULO-2131.patch;https://issues.apache.org/jira/secure/attachment/12723358/ACCUMULO-2131.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2014-02-04 00:00:13.34,,,no_permission,,,,,,,,,,,,366244,,,Thu Apr 09 22:57:20 UTC 2015,,,,,,0|i1r4q7:,366555,,,,,,,,04/Feb/14 00:00;vines;I'm wondering if this bug is a good case of 'let sleeping dogs lie'...,10/Feb/14 20:29;kturner;source changes in the loop.   After {{source = source.getNewDataSource();}} is executed the new source will be checked to see if its still current.,"10/Feb/14 20:36;mdrob;While source changes, the loop condition will never be checked again after the {{return true}}.","10/Feb/14 20:57;kturner;bq. While source changes, the loop condition will never be checked again after the return true.

oh yeah,  well that was not my intent.  I wanted it to recheck.   However for correctness, the source does not need to be rechecked.  If after getting the new source it becomes invalid then either one key or a row will be read before switching.   Its just not switching as soon as it could in this special case.  

My thinking was that getting the iterator could take a bit of time because it may involve I/O.  Therefore the new datasource could be invalidated by other concurrent actions (like bulk import or compactions).   I am not really sure if its worth handling this special case.   I would not be opposed to just changing to an if.",06/Apr/15 14:55;bthorman;ACCUMULO-2131 fixed by changing while to an if,06/Apr/15 14:55;bthorman;ACCUMULO-2131 changed while to an if,"09/Apr/15 00:32;ctubbsii;Attached [^0001-ACCUMULO-2131-Ensure-source-is-re-checked-for-being-.patch].

This new patch matches the re-check behavior that [~kturner] described was intended. Keith, could you check this?","09/Apr/15 20:56;elserj;Uhh, what's going on here, [~ctubbsii]? Bob had submitted a patch already.","09/Apr/15 21:30;ctubbsii;Yes, but it's not clear which is the preferred solution, based on Keith's comments. Bob's patch ""fixes"" the problem one way, and mine ""fixes"" it the other way. I submitted my patch to get feedback from Keith on which would be better.

After discussing with him, I'm going to do the least risky thing, and apply Bob's patch, which does not change the behavior, and leave my patch here, in case this issue needs to be revisited (for example, if the current behavior results in a bug that the loop would fix).","09/Apr/15 21:33;ctubbsii;Applied [~bthorman]'s patch. Thanks, Bob!

(Leaving second patch available here, for future reference, in case this issue needs to be revisted and the behavior of the switchSource method needs to change to match Keith's description above.)","09/Apr/15 22:09;elserj;bq. Yes, but it's not clear which is the preferred solution, based on Keith's comments. Bob's patch ""fixes"" the problem one way, and mine ""fixes"" it the other way. I submitted my patch to get feedback from Keith on which would be better.

Yes, but it's _very_ inappropriate attach a patch when someone else is working on it and hasn't asked for help. At the very least, you should have worked through Bob as he already staked his claim. I know you were just trying to be helpful, but please be mindful of this in the future.","09/Apr/15 22:17;ctubbsii;bq. Yes, but it's very inappropriate attach a patch when someone else is working on it and hasn't asked for help.

I think I disagree with this pretty strongly. Anybody can provide more information on an issue at any time, and they should be encouraged to do so. I think this is true, regardless of whether it is a comment or an attached file (perhaps a diagram, a design document, a stack trace, or as in this case, code).

Attaching additional information, and even code, does not obligate the code to be used, nor should it be interpreted to supercede any other patches or code which has been attached to the issue. It does not replace or invalidate the other work done, or convey any intention that the previous work will be ignored.","09/Apr/15 22:24;elserj;Providing a snippet of code is something completely different than providing a patch which wholly replaces a user's contribution. When unprompted, providing ""work"" that someone else said they were going to do doesn't make me happy. Let's not clutter this issue more; we can move it elsewhere if you still want to discuss it further.

Thanks, Bob, for your patch.","09/Apr/15 22:55;ctubbsii;Well, I still disagree that it is substantively different. The idea that it undermines their contribution I think is incorrectly inferred on insufficient information.

However, I will concede that my comment which accompanied my patch was insufficient, and I should have clarified that it was being attached *solely* as a convenience for me to request Keith (whom I consider an expert on this code) to review and compare which approach should be applied. The fact that it was a patch instead of pseudo-code was simply because the change was trivial for me to create as a patch, for him to review.

In the future, I will make more of an effort to explicitly anticipate somebody misconstruing my intentions as stepping on people's toes, and will expend more time and effort to provide sufficient detail in my comments so that the occurrence of such misunderstandings will be (hopefully) less probable. In exchange, I politely request that others take greater efforts to not jump to the conclusion that I'm ignoring or undermining somebody else's efforts, on incomplete information. (In other words, please [""assume good intentions""|https://www.apache.org/foundation/policies/conduct.html#specific-guidelines].)",09/Apr/15 22:57;elserj;Thanks!,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"GarbageCollectorIT runs with miniDfs, only not really",ACCUMULO-2370,12695253,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,,ecn,ecn,14/Feb/14 18:05,12/Mar/15 17:48,13/Mar/19 22:01,14/Feb/14 18:26,,,,,,,,1.6.0,,,test,,,,,,0,,,,,,"{{useMiniDfs()}} is a getter, not a setter.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-14 18:06:44.141,,,no_permission,,,,,,,,,,,,373761,,,Tue Feb 18 14:58:28 UTC 2014,,,,,,0|i1serr:,374061,,,,,,,,"14/Feb/14 18:06;jira-bot;Commit b0a1f6d61eedc8e78b2100f6c750ee7ec3fc3df3 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b0a1f6d ]

ACCUMULO-2370 remove useless call
","18/Feb/14 14:58;jira-bot;Commit b0a1f6d61eedc8e78b2100f6c750ee7ec3fc3df3 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b0a1f6d ]

ACCUMULO-2370 remove useless call
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
display the exact number of tablet servers in the monitor,ACCUMULO-1140,12635036,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,03/Mar/13 20:04,15/Dec/14 17:34,13/Mar/19 22:01,14/Mar/13 20:54,,,,,,,,1.5.0,,,monitor,,,,,,0,,,,,"The monitor displays numbers with human-friendly short-hands like ""K"" and ""M"".  This is great for things like bytes of storage.  But, it is really nice to know if you lose a few tablet servers, even if you have a lot of 'em.  Tablet server counts should be displayed with complete accuracy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-04 22:45:49.378,,,no_permission,,,,,,,,,,,,315529,,,Tue Mar 05 03:48:58 UTC 2013,,,,,,0|i1ig4v:,315873,,,,,,,,"04/Mar/13 22:45;vines;FYI, if anyone has issues with PreciseNumberType in their IDE after commit 1452494, try reimporting the project. I was able to build in maven just fine, but eclipse couldn't figure it out. I dropped the project and reimported and that finally fixed it (and yes, I had tried updating the maven project and cleaning).","05/Mar/13 03:25;hudson;Integrated in Accumulo-Trunk #757 (See [https://builds.apache.org/job/Accumulo-Trunk/757/])
    ACCUMULO-1140 display actual number of tservers using precise whole numbers
ACCUMULO-1041 ACCUMULO-1129 - purging instance.getConnector(Credential) (Revision 1452602)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/Instance.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/ZooKeeperInstance.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/OfflineScanner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/InputConfigurator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockInstance.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/PasswdCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/TraceCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/UserCommand.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/impl/TabletLocatorImplTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mock/MockTableOperationsTest.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/HdfsZooInstance.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/balancer/TableLoadBalancer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/MasterServlet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/PreciseNumberType.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/problems/ProblemReports.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/security/SecurityConstants.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Admin.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/CheckForMetadataProblems.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/FindOfflineTablets.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/VerifyTabletAssignments.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/QueryMetadataTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/WrongTabletTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/performance/scan/CollectTabletStats.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/State.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/AlterTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/AlterTablePerm.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/Authenticate.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/ChangePass.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/CreateTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/CreateUser.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/DropTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/DropUser.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/SetAuths.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/Validate.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","05/Mar/13 03:30;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #116 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/116/])
    ACCUMULO-1140 display actual number of tservers using precise whole numbers
ACCUMULO-1041 ACCUMULO-1129 - purging instance.getConnector(Credential) (Revision 1452602)

     Result = FAILURE
vines : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/Instance.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/ZooKeeperInstance.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/OfflineScanner.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/InputConfigurator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/mock/MockInstance.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/PasswdCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/TraceCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/UserCommand.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/impl/TabletLocatorImplTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mock/MockTableOperationsTest.java
* /accumulo/trunk/proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/HdfsZooInstance.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/balancer/TableLoadBalancer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/MasterServlet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/PreciseNumberType.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/problems/ProblemReports.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/security/SecurityConstants.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Admin.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/CheckForMetadataProblems.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/FindOfflineTablets.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/VerifyTabletAssignments.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/QueryMetadataTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/WrongTabletTest.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/performance/scan/CollectTabletStats.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/State.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/AlterTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/AlterTablePerm.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/Authenticate.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/ChangePass.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/CreateTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/CreateUser.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/DropTable.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/DropUser.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/SetAuths.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/TableOp.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/Validate.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
","05/Mar/13 03:35;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #12 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/12/])
    ACCUMULO-1140 display actual number of tservers using precise whole numbers (Revision 1452494)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/MasterServlet.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/PreciseNumberType.java
","05/Mar/13 03:48;hudson;Integrated in Accumulo-1.5 #13 (See [https://builds.apache.org/job/Accumulo-1.5/13/])
    ACCUMULO-1140 display actual number of tservers using precise whole numbers (Revision 1452494)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/MasterServlet.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/monitor/servlets/PreciseNumberType.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
update ScaleTest presentation,ACCUMULO-1178,12637033,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,14/Mar/13 14:52,28/Apr/14 23:03,13/Mar/19 22:01,14/Mar/13 15:24,1.4.3,1.5.0,,,,,,1.5.0,,,docs,,,,,,0,,,,,"This old talk needs to be updated with the name ""Apache Accumulo"" and the status of the randomwalk test.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-14 16:04:58.188,,,no_permission,,,,,,,,,,,,317525,,,Tue Mar 19 14:15:50 UTC 2013,,,,,,0|i1isfb:,317866,,,,,,,,"14/Mar/13 16:04;hudson;Integrated in Accumulo-1.5 #32 (See [https://builds.apache.org/job/Accumulo-1.5/32/])
    ACCUMULO-1178 update presentation (Revision 1456461)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/test/system/continuous/ScaleTest.odp
","14/Mar/13 16:08;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #30 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/30/])
    ACCUMULO-1178 update presentation (Revision 1456461)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/test/system/continuous/ScaleTest.odp
","14/Mar/13 16:12;hudson;Integrated in Accumulo-Trunk #776 (See [https://builds.apache.org/job/Accumulo-Trunk/776/])
    ACCUMULO-1178 revert unintential check-in (Revision 1456467)
ACCUMULO-1178 update presentation (Revision 1456462)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/trace/src/main/thrift/trace.thrift

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/continuous/ScaleTest.odp
* /accumulo/trunk/trace/src/main/thrift/trace.thrift
","14/Mar/13 16:21;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #135 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/135/])
    ACCUMULO-1178 revert unintential check-in (Revision 1456467)
ACCUMULO-1178 update presentation (Revision 1456462)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/trace/src/main/thrift/trace.thrift

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/system/continuous/ScaleTest.odp
* /accumulo/trunk/trace/src/main/thrift/trace.thrift
","19/Mar/13 14:15;hudson;Integrated in Accumulo-1.4.x #286 (See [https://builds.apache.org/job/Accumulo-1.4.x/286/])
    ACCUMULO-1178 update old presentation (Revision 1458273)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/test/system/continuous/ScaleTest.odp
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Concurrent random walk test shutsdown accumulo way too often,ACCUMULO-1148,12635205,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,,ecn,ecn,04/Mar/13 20:44,25/Apr/14 18:56,13/Mar/19 22:01,05/Mar/13 15:16,,,,,,,,1.5.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,315698,,,2013-03-04 20:44:25.0,,,,,,0|i1ih5z:,316041,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Debian package controls should be in same directory as,ACCUMULO-1064,12632249,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,vines,vines,vines,13/Feb/13 18:16,25/Apr/14 18:56,13/Mar/19 22:01,13/Feb/13 19:41,,,,,,,,1.5.0,,,build,,,,,,0,,,,,We can simplify the root hierarchy a bit by collapsing the packages directory into assemble.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-02-13 20:19:25.618,,,no_permission,,,,,,,,,,,,312745,,,Wed Feb 13 20:47:36 UTC 2013,,,,,,0|i1hyyf:,313091,,,,,,,,"13/Feb/13 20:19;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #90 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/90/])
    ACCUMULO-1064 - migrated packages to assemble, updated assemble pom for jdeb (Revision 1445875)

     Result = UNSTABLE
vines : 
Files : 
* /accumulo/trunk/assemble/deb
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/packages
","13/Feb/13 20:47;hudson;Integrated in Accumulo-Trunk #732 (See [https://builds.apache.org/job/Accumulo-Trunk/732/])
    ACCUMULO-1064 - migrated packages to assemble, updated assemble pom for jdeb (Revision 1445875)

     Result = SUCCESS
vines : 
Files : 
* /accumulo/trunk/assemble/deb
* /accumulo/trunk/assemble/pom.xml
* /accumulo/trunk/packages
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Eclipse warns about unclosed resources,ACCUMULO-1362,12645366,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ctubbsii,mdrob,mdrob,30/Apr/13 04:06,16/Apr/14 22:03,13/Mar/19 22:01,16/Apr/14 22:03,,,,,,,,1.7.0,,,shell,,,,,,0,,,,,Eclipse gives several warnings about unclosed java.util.Scanner objects and potential leaks in the shell.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2179,ACCUMULO-2176,ACCUMULO-2187,ACCUMULO-905,,,,,,,,,,,,,,30/Apr/13 04:07;mdrob;ACCUMULO-1362.v1.patch;https://issues.apache.org/jira/secure/attachment/12581117/ACCUMULO-1362.v1.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-04-30 04:39:58.774,,,no_permission,,,,,,,,,,,,325728,,,Wed Apr 16 22:01:38 UTC 2014,,,,,,0|i1k71r:,326073,,,,,,,,"30/Apr/13 04:39;ctubbsii;FYI: These warnings occur because you're using JDK 1.7. Install a 1.6 JDK. It's probably harmless to apply these changes, but if the goal is to just remove the warnings, it isn't necessary.",30/Apr/13 16:14;ecn;[~mdrob] can you put the close calls in a finally block?,"16/Apr/14 22:01;jira-bot;Commit 082d43d690ef30dee79d3230ec5eba4ac795a361 in accumulo's branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=082d43d ]

ACCUMULO-1362 Ensure resources are closed and warnings removed
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"typo in PrintInfo: ""historgram""",ACCUMULO-1571,12657982,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,16/Jul/13 12:32,09/Apr/14 05:50,13/Mar/19 22:01,21/Jul/13 20:15,1.5.0,,,,,,,1.5.1,,,,,,,,,0,,,,,"The RFile PrintInfo utility's option to print a histogram of key-value sizes doesn't work properly

e.g.
{noformat}
$> ./bin/accumulo org.apache.accumulo.core.file.rfile.PrintInfo --histogram /path/to/rfile/example.rf
{noformat}

Workaround: use the misspelled argument name

{noformat}
$> ./bin/accumulo org.apache.accumulo.core.file.rfile.PrintInfo --historgram /path/to/rfile/example.rf
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-17 15:31:45.831,,,no_permission,,,,,,,,,,,,338176,,,Wed Jul 17 15:34:07 UTC 2013,,,,,,0|i1mbvj:,338497,,,,,,,,"17/Jul/13 15:31;jira-bot;Commit cfb01d4675a7e33082b5586f2418f3a96f998b3b in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cfb01d4 ]

ACCUMULO-1571
","17/Jul/13 15:34;jira-bot;Commit cfb01d4675a7e33082b5586f2418f3a96f998b3b in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=cfb01d4 ]

ACCUMULO-1571
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dirlist example documentation for 1.5 used 1.4 syntax,ACCUMULO-2141,12687548,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,arshak,arshak,06/Jan/14 23:08,06/Mar/14 23:12,13/Mar/19 22:01,06/Jan/14 23:40,1.5.0,,,,,,,1.5.1,,,docs,,,,,,0,examples,,,,"dirlist documentation(http://accumulo.apache.org/1.5/examples/dirlist.html) should be updated to the 1.5 syntax.

the line:

./bin/accumulo org.apache.accumulo.examples.simple.dirlist.FileCount instance zookeepers username password dirTable exampleVis exampleVis

should read:

./bin/accumulo org.apache.accumulo.examples.simple.dirlist.FileCount -i instance -z zookeepers -u username -p password -t dirTable --auths exampleVis

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-06 23:21:37.47,,,no_permission,,,,,,,,,,,,366549,,,Mon Jan 06 23:38:34 UTC 2014,,,,,,0|i1r6lr:,366860,,,,,,,,"06/Jan/14 23:21;jira-bot;Commit 4c9a6662b22a1fa7bd4b3559f3e07802cb611233 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4c9a666 ]

ACCUMULO-2141 updating docs to 1.5 option parsing
","06/Jan/14 23:24;ecn;I've updated the README.dirlist file, [~billie.rinaldi], how do we update the web pages?","06/Jan/14 23:27;mdrob;[~ecn] - you can use the [Apache CMS|http://www.apache.org/dev/cms.html#usage] to do it. Unless it's part of the user manual, in which case you need to get much more involved.","06/Jan/14 23:34;jira-bot;Commit 4c9a6662b22a1fa7bd4b3559f3e07802cb611233 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4c9a666 ]

ACCUMULO-2141 updating docs to 1.5 option parsing
","06/Jan/14 23:35;jira-bot;Commit a18e469e922f937716aa0d69e0570219614a2220 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a18e469 ]

ACCUMULO-2141 found a typo
","06/Jan/14 23:35;jira-bot;Commit a18e469e922f937716aa0d69e0570219614a2220 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a18e469 ]

ACCUMULO-2141 found a typo
","06/Jan/14 23:36;jira-bot;Commit 4c9a6662b22a1fa7bd4b3559f3e07802cb611233 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4c9a666 ]

ACCUMULO-2141 updating docs to 1.5 option parsing
","06/Jan/14 23:38;billie.rinaldi;The examples on the web page are actually ""generated"" from our READMEs.   In this case it just means copying README.dirlist to the appropriate page on the site, e.g. trunk/content/1.5/examples/dirlist.mdtext.","06/Jan/14 23:38;jira-bot;Commit 1556070 from [~ecn] in branch 'site/trunk'
[ https://svn.apache.org/r1556070 ]

ACCUMULO-2141 fixed typo and old syntax",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Continuous Verify job should find ranges on cloned table,ACCUMULO-2233,12690080,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,mdrob,busbey,busbey,21/Jan/14 18:34,04/Mar/14 19:27,13/Mar/19 22:01,04/Mar/14 19:27,1.4.4,1.5.0,,,,,,1.4.5,1.5.2,1.6.0,test,,,,,,0,newbie,,,,"Right now, when configured for offline mode, the verification job

* clones source table
* takes clone offline
* calculates ranges for job based on source table

Since the source table could change after the clone we should update the test to calculate the ranges on the clone prior to taking it offline.

(1.5.0 is only kind of impacted, since running hte verification job in offline mode is totally broken there, see ACCUMULO-2230)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-03-04 19:24:42.035,,,no_permission,,,,,,,,,,,,369037,,,Tue Mar 04 19:24:43 UTC 2014,,,,,,0|i1rlv3:,369342,,,,,,,,"04/Mar/14 19:24;jira-bot;Commit 4bdebdb1e5aaec75c678d91ff6b7d53ff65e3ec0 in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4bdebdb ]

ACCUMULO-2233 Get ranges from cloned table
","04/Mar/14 19:24;jira-bot;Commit 4bdebdb1e5aaec75c678d91ff6b7d53ff65e3ec0 in accumulo's branch refs/heads/1.5.2-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4bdebdb ]

ACCUMULO-2233 Get ranges from cloned table
","04/Mar/14 19:24;jira-bot;Commit 4bdebdb1e5aaec75c678d91ff6b7d53ff65e3ec0 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4bdebdb ]

ACCUMULO-2233 Get ranges from cloned table
","04/Mar/14 19:24;jira-bot;Commit 4bdebdb1e5aaec75c678d91ff6b7d53ff65e3ec0 in accumulo's branch refs/heads/master from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4bdebdb ]

ACCUMULO-2233 Get ranges from cloned table
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Building creates a src/lib directory with a log4j jar,ACCUMULO-2281,12692172,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,mdrob,vines,vines,29/Jan/14 23:07,04/Mar/14 13:37,13/Mar/19 22:01,03/Mar/14 17:11,1.4.0,,,,,,,1.4.5,,,build,,,,,,0,newbie,,,,Did a mvn clean package -DskipTests and I saw a src/lib/log4<version>.jar showed up for some reason.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-30 00:22:46.343,,,no_permission,,,,,,,,,,,,370763,,,Tue Mar 04 13:37:21 UTC 2014,,,,,,0|i1rwf3:,371071,,,,,,,,"30/Jan/14 00:22;busbey;I've noticed this for awhile and keep meaning to clean it up.

It's because our dependency copy (and jar plugin) specify a destination using a relative path instead of the top pom's project root.","03/Mar/14 17:11;jira-bot;Commit a8bbb916c2796d7f2bbc64ef82291034bbb3810d in accumulo's branch refs/heads/1.4.5-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a8bbb91 ]

ACCUMULO-2281 copy dependencies to correct dir

Use project.parent.basedir instead of relative paths for copying
dependencies for packaging and assembly.
","03/Mar/14 17:11;jira-bot;Commit a8bbb916c2796d7f2bbc64ef82291034bbb3810d in accumulo's branch refs/heads/1.5.1-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a8bbb91 ]

ACCUMULO-2281 copy dependencies to correct dir

Use project.parent.basedir instead of relative paths for copying
dependencies for packaging and assembly.
","04/Mar/14 13:37;jira-bot;Commit a8bbb916c2796d7f2bbc64ef82291034bbb3810d in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~mdrob@cloudera.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a8bbb91 ]

ACCUMULO-2281 copy dependencies to correct dir

Use project.parent.basedir instead of relative paths for copying
dependencies for packaging and assembly.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
replace empty loops in tests with simple count method,ACCUMULO-2418,12697732,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,27/Feb/14 16:27,27/Feb/14 17:32,13/Mar/19 22:01,27/Feb/14 17:32,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"While fixing ACCUMULO-2405, I created a simple method to eliminate a loop.  There are many tests that could use this method.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-27 17:14:44.784,,,no_permission,,,,,,,,,,,,376206,,,Thu Feb 27 17:32:25 UTC 2014,,,,,,0|i1stt3:,376502,,,,,,,,"27/Feb/14 17:14;jira-bot;Commit eab028a4894c363c112df051ceebbd5584075769 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=eab028a ]

ACCUMULO-2418 use utility method to count iterables
","27/Feb/14 17:14;jira-bot;Commit eab028a4894c363c112df051ceebbd5584075769 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=eab028a ]

ACCUMULO-2418 use utility method to count iterables
","27/Feb/14 17:22;mdrob;minor nit: you dropped the fail message from {{NoMutationRecoveryIT.java}} when it could have been part of the assert.
{noformat}
-    for (@SuppressWarnings(""unused"") Entry<Key, Value> refs : getLogRefs(conn, MetadataTable.NAME)) {
-      fail(""should not have any refs"");
-    }
+    assertEquals(0, FunctionalTestUtils.count(getLogRefs(conn, MetadataTable.NAME)));
{noformat}","27/Feb/14 17:31;jira-bot;Commit b9bc5e259dc990bd1e03e0decc8aa6510a91b290 in accumulo's branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b9bc5e2 ]

ACCUMULO-2418 add fail message back
","27/Feb/14 17:31;jira-bot;Commit b9bc5e259dc990bd1e03e0decc8aa6510a91b290 in accumulo's branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b9bc5e2 ]

ACCUMULO-2418 add fail message back
","27/Feb/14 17:32;ecn;Good catch, thanks!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stack trace in shell when using grep,ACCUMULO-2344,12694181,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,elserj,afuchs,afuchs,09/Feb/14 21:45,10/Feb/14 20:29,13/Mar/19 22:01,10/Feb/14 16:46,1.5.0,,,,,,,1.5.1,1.6.0,,shell,,,,,,0,,,,,"After getting a partial result set, I hit 'q' and got the following stack trace:
{code}
-------------------- hit any key to continue or 'q' to quit --------------------
2014-02-09 16:42:37,693 [util.UtilWaitThread] ERROR: sleep interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.accumulo.core.util.UtilWaitThread.sleep(UtilWaitThread.java:26)
	at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.processFailures(TabletServerBatchReaderIterator.java:310)
	at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator.access$1300(TabletServerBatchReaderIterator.java:77)
	at org.apache.accumulo.core.client.impl.TabletServerBatchReaderIterator$QueryTask.run(TabletServerBatchReaderIterator.java:400)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at org.apache.accumulo.trace.instrument.TraceRunnable.run(TraceRunnable.java:47)
	at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)
	at java.lang.Thread.run(Thread.java:695)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-02-09 22:33:07.545,,,no_permission,,,,,,,,,,,,372690,,,Mon Feb 10 20:29:52 UTC 2014,,,,,,0|i1s87j:,372994,,,,,,,,"09/Feb/14 22:33;elserj;I was about to say I couldn't reproduce it, but after trying a couple of different greps, I got the stacktrace too.","09/Feb/14 23:06;jira-bot;Commit 4cb92ca616fb2aeaa80b0c5b7d004b6e8b39aa6d in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cb92ca ]

ACCUMULO-2344 Avoid usage of UtilWaitThread because we want to exit gracefully on interrupt.
","09/Feb/14 23:06;jira-bot;Commit 4cb92ca616fb2aeaa80b0c5b7d004b6e8b39aa6d in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cb92ca ]

ACCUMULO-2344 Avoid usage of UtilWaitThread because we want to exit gracefully on interrupt.
","09/Feb/14 23:06;jira-bot;Commit 4cb92ca616fb2aeaa80b0c5b7d004b6e8b39aa6d in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=4cb92ca ]

ACCUMULO-2344 Avoid usage of UtilWaitThread because we want to exit gracefully on interrupt.
","10/Feb/14 16:15;kturner;The interrupt status of the thread should be reset if it will not cause problems.  In the catch block, I think you can call {{Thread.currentThread().interrupt()}} to do this.","10/Feb/14 16:23;elserj;[~kturner], yup, you're right. I forgot to include that.","10/Feb/14 16:46;jira-bot;Commit 78ba31d5a12ca0ed6e346133e263c2f5a5cf2f57 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=78ba31d ]

ACCUMULO-2344 interrupt the current thread when we catch the InterruptedException.
","10/Feb/14 16:46;jira-bot;Commit 78ba31d5a12ca0ed6e346133e263c2f5a5cf2f57 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=78ba31d ]

ACCUMULO-2344 interrupt the current thread when we catch the InterruptedException.
","10/Feb/14 16:46;jira-bot;Commit 78ba31d5a12ca0ed6e346133e263c2f5a5cf2f57 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=78ba31d ]

ACCUMULO-2344 interrupt the current thread when we catch the InterruptedException.
","10/Feb/14 16:46;elserj;Pass the interrupt along before returning. Thanks for the catch, [~kturner].","10/Feb/14 20:29;jira-bot;Commit 6730880dbc7e25574ab12a52ef7676f80f4e2985 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6730880 ]

ACCUMULO-2344 Whitespace altercation
","10/Feb/14 20:29;jira-bot;Commit 6730880dbc7e25574ab12a52ef7676f80f4e2985 in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6730880 ]

ACCUMULO-2344 Whitespace altercation
","10/Feb/14 20:29;jira-bot;Commit 6730880dbc7e25574ab12a52ef7676f80f4e2985 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6730880 ]

ACCUMULO-2344 Whitespace altercation
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""egrep: /home/user/accumulo-1.5.1/conf/gc: No such file or directory""",ACCUMULO-2329,12693457,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,elserj,ecn,ecn,05/Feb/14 22:31,10/Feb/14 19:09,13/Mar/19 22:01,10/Feb/14 19:09,,,,,,,,1.5.1,1.6.0,,scripts,,,,,,0,,,,,"Testing 1.5.1rc1, didn't create a gc file in conf, and I got this error on start-up.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-2153,,,,,,,,,,,,,,,,,,06/Feb/14 00:14;elserj;ACCUMULO-2329.diff;https://issues.apache.org/jira/secure/attachment/12627254/ACCUMULO-2329.diff,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-02-05 22:51:57.255,,,no_permission,,,,,,,,,,,,372042,,,Mon Feb 10 19:09:32 UTC 2014,,,,,,0|i1s48n:,372346,,,,,,,,"05/Feb/14 22:46;ecn;Also, it didn't start the gc.
",05/Feb/14 22:51;elserj;I didn't consider the lack of a 'gc' file.,"05/Feb/14 23:56;elserj;I read gc and thought monitor. I'm guessing that ACCUMULO-2015 might actually be to blame here but I have to revisit this ""standalone"" mode stuff.","06/Feb/14 00:02;elserj;Rather confusing myself now: according to config.sh, when {{ACCUMULO_VERIFY_ONLY}} is not set, config.sh says it will ""Ensure the presense of local role files (masters, slaves, gc, tracers)"". It does not appear to actually do this completely (only master, monitor and tracers).","06/Feb/14 00:14;elserj;This appears to fix things for me, [~ecn]. I think it's the correct fix to make given what's written in the scripts.",06/Feb/14 13:56;bhavanki;Does this also fix ACCUMULO-2153?,06/Feb/14 14:47;elserj;Sounds like it,"06/Feb/14 16:26;elserj;Ok, finally looked through the git-log enough. It seems like the initial introduction of ACCUMULO_VERIFY_ONLY is what actually is at fault here. The comments introduced there say that config.sh will perform validation on GC and set the env variable appropriately, but it does not.","06/Feb/14 21:34;vickyuec;The files containing the names of all servers are useful only for the start/stop scripts. Clients, e.g. don't need to know the list of masters while running shell. So would it be OK to move the section reading these files with host list to where they are actually needed (start-all.sh, stop-all.sh etc)?","06/Feb/14 22:05;elserj;You read my mind, [~vickyuec]. I was planning to file a ticket in 1.7 that we could try to address that would lift all of the ""host"" file verification (gc, masters, monitor, etc) into the {start,stop}-*.sh scripts and remove that logic from the accumulo script. This would make it much easier to use the accumulo script when you know what you're doing to start a service.",06/Feb/14 23:08;vickyuec;I've filed ACCUMULO-2335 for this improvent [~elserj].,"10/Feb/14 19:09;jira-bot;Commit bfa20dd07710c244140fd7fd8844b60739962c0e in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bfa20dd ]

ACCUMULO-2329 Infer the GC role from master when gc file is not present.
","10/Feb/14 19:09;jira-bot;Commit bfa20dd07710c244140fd7fd8844b60739962c0e in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bfa20dd ]

ACCUMULO-2329 Infer the GC role from master when gc file is not present.
","10/Feb/14 19:09;jira-bot;Commit bfa20dd07710c244140fd7fd8844b60739962c0e in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=bfa20dd ]

ACCUMULO-2329 Infer the GC role from master when gc file is not present.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MiniAccumulo cluster improperly configures classpaths,ACCUMULO-1472,12650063,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,elserj,kturner,kturner,30/May/13 00:14,03/Feb/14 20:50,13/Mar/19 22:01,03/Feb/14 20:50,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,mini,,,,,,0,,,,,"I used instamo to run an Accumulo shell against MiniAccumuloCluster.  I ran the classpath command and noticed it was referencing the hadoop jars from my local hadoop install.  It was also referencing the hadoop jars from maven.

I looked at the accumulo-site.xml generated MAC and saw the following :

{noformat}
<property><name>general.classpaths</name><value>null/lib/.*.jar,$ZOOKEEPER_HOME/zookeeper[^.].*.jar,$HADOOP_HOME/[^.].*.jar,$HADOOP_HOME/lib/[^.].*.jar,$HADOOP_PREFIX/share/hadoop/common/.*.jar,$HADOOP_PREFIX/share/hadoop/common/lib/.*.jar,$HADOOP_PREFIX/share/hadoop/hdfs/.*.jar,$HADOOP_PREFIX/share/hadoop/mapreduce/.*.jar</value></property>
{noformat}

I think this prop should be empty.  Below is what I saw when running classpath.  Also, I do not think it should print the warning.

{noformat}
root@miniInstance !METADATA> classpath
[main] WARN  org.apache.accumulo.start.classloader.vfs.AccumuloVFSClassLoader  - ignoring classpath entry file:///lib/ext/[^.].*.jar

Level 1: Java System Classloader (loads Java system resources) URL classpath items are:
    file:/home/kturner/software/jdk1.6.0_33/jre/lib/ext/dnsns.jar
    file:/home/kturner/software/jdk1.6.0_33/jre/lib/ext/localedata.jar
    file:/home/kturner/software/jdk1.6.0_33/jre/lib/ext/sunpkcs11.jar
    file:/home/kturner/software/jdk1.6.0_33/jre/lib/ext/sunjce_provider.jar

Level 2: Java Classloader (loads everything defined by java classpath) URL classpath items are:
    file:/home/kturner/instamo-example/target/classes/
    file:/home/kturner/.m2/repository/org/apache/accumulo/accumulo-core/1.5.0/accumulo-core-1.5.0.jar
    file:/home/kturner/.m2/repository/com/beust/jcommander/1.30/jcommander-1.30.jar
    file:/home/kturner/.m2/repository/jline/jline/1.0/jline-1.0.jar
    file:/home/kturner/.m2/repository/org/apache/commons/commons-vfs2/2.0/commons-vfs2-2.0.jar
    file:/home/kturner/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar
    file:/home/kturner/.m2/repository/org/apache/maven/scm/maven-scm-api/1.4/maven-scm-api-1.4.jar
    file:/home/kturner/.m2/repository/org/codehaus/plexus/plexus-utils/1.5.6/plexus-utils-1.5.6.jar
    file:/home/kturner/.m2/repository/org/apache/maven/scm/maven-scm-provider-svnexe/1.4/maven-scm-provider-svnexe-1.4.jar
    file:/home/kturner/.m2/repository/org/apache/maven/scm/maven-scm-provider-svn-commons/1.4/maven-scm-provider-svn-commons-1.4.jar
    file:/home/kturner/.m2/repository/regexp/regexp/1.3/regexp-1.3.jar
    file:/home/kturner/.m2/repository/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar
    file:/home/kturner/.m2/repository/commons-lang/commons-lang/2.5/commons-lang-2.5.jar
    file:/home/kturner/.m2/repository/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar
    file:/home/kturner/.m2/repository/org/apache/httpcomponents/httpcore/4.1.3/httpcore-4.1.3.jar
    file:/home/kturner/.m2/repository/org/apache/accumulo/accumulo-fate/1.5.0/accumulo-fate-1.5.0.jar
    file:/home/kturner/.m2/repository/org/apache/accumulo/accumulo-server/1.5.0/accumulo-server-1.5.0.jar
    file:/home/kturner/.m2/repository/com/google/code/gson/gson/2.2.2/gson-2.2.2.jar
    file:/home/kturner/.m2/repository/org/apache/accumulo/accumulo-test/1.5.0/accumulo-test-1.5.0.jar
    file:/home/kturner/.m2/repository/org/apache/accumulo/accumulo-minicluster/1.5.0/accumulo-minicluster-1.5.0.jar
    file:/home/kturner/.m2/repository/org/apache/accumulo/accumulo-start/1.5.0/accumulo-start-1.5.0.jar
    file:/home/kturner/.m2/repository/org/apache/accumulo/accumulo-trace/1.5.0/accumulo-trace-1.5.0.jar
    file:/home/kturner/.m2/repository/org/apache/zookeeper/zookeeper/3.3.6/zookeeper-3.3.6.jar
    file:/home/kturner/.m2/repository/log4j/log4j/1.2.15/log4j-1.2.15.jar
    file:/home/kturner/.m2/repository/javax/mail/mail/1.4/mail-1.4.jar
    file:/home/kturner/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar
    file:/home/kturner/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar
    file:/home/kturner/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar
    file:/home/kturner/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar
    file:/home/kturner/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar
    file:/home/kturner/.m2/repository/org/apache/hadoop/hadoop-core/1.0.4/hadoop-core-1.0.4.jar
    file:/home/kturner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar
    file:/home/kturner/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
    file:/home/kturner/.m2/repository/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar
    file:/home/kturner/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar
    file:/home/kturner/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar
    file:/home/kturner/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar
    file:/home/kturner/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar
    file:/home/kturner/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar
    file:/home/kturner/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar
    file:/home/kturner/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar
    file:/home/kturner/.m2/repository/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar
    file:/home/kturner/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar
    file:/home/kturner/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar
    file:/home/kturner/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar
    file:/home/kturner/.m2/repository/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar
    file:/home/kturner/.m2/repository/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar
    file:/home/kturner/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar
    file:/home/kturner/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar
    file:/home/kturner/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar
    file:/home/kturner/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar
    file:/home/kturner/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar
    file:/home/kturner/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar
    file:/home/kturner/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar
    file:/home/kturner/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar
    file:/home/kturner/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar
    file:/home/kturner/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar
    file:/home/kturner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.0.1/jackson-mapper-asl-1.0.1.jar
    file:/home/kturner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.0.1/jackson-core-asl-1.0.1.jar

Level 3: Accumulo Classloader (loads everything defined by general.classpaths) URL classpath items are:
    file:/home/kturner/software/zookeeper/zookeeper-3.3.5.jar
    file:/home/kturner/software/hadoop/hadoop-client-1.0.3.jar
    file:/home/kturner/software/hadoop/hadoop-ant-1.0.3.jar
    file:/home/kturner/software/hadoop/hadoop-core-1.0.3.jar
    file:/home/kturner/software/hadoop/hadoop-test-1.0.3.jar
    file:/home/kturner/software/hadoop/hadoop-tools-1.0.3.jar
    file:/home/kturner/software/hadoop/hadoop-minicluster-1.0.3.jar
    file:/home/kturner/software/hadoop/hadoop-examples-1.0.3.jar
    file:/home/kturner/software/hadoop/lib/commons-collections-3.2.1.jar
    file:/home/kturner/software/hadoop/lib/commons-beanutils-1.7.0.jar
    file:/home/kturner/software/hadoop/lib/jasper-compiler-5.5.12.jar
    file:/home/kturner/software/hadoop/lib/jasper-runtime-5.5.12.jar
    file:/home/kturner/software/hadoop/lib/servlet-api-2.5-20081211.jar
    file:/home/kturner/software/hadoop/lib/slf4j-log4j12-1.4.3.jar
    file:/home/kturner/software/hadoop/lib/aspectjrt-1.6.5.jar
    file:/home/kturner/software/hadoop/lib/commons-logging-api-1.0.4.jar
    file:/home/kturner/software/hadoop/lib/mockito-all-1.8.5.jar
    file:/home/kturner/software/hadoop/lib/jackson-core-asl-1.8.8.jar
    file:/home/kturner/software/hadoop/lib/jsch-0.1.42.jar
    file:/home/kturner/software/hadoop/lib/jersey-core-1.8.jar
    file:/home/kturner/software/hadoop/lib/hadoop-fairscheduler-1.0.3.jar
    file:/home/kturner/software/hadoop/lib/kfs-0.2.2.jar
    file:/home/kturner/software/hadoop/lib/asm-3.2.jar
    file:/home/kturner/software/hadoop/lib/log4j-1.2.15.jar
    file:/home/kturner/software/hadoop/lib/jersey-json-1.8.jar
    file:/home/kturner/software/hadoop/lib/hsqldb-1.8.0.10.jar
    file:/home/kturner/software/hadoop/lib/jersey-server-1.8.jar
    file:/home/kturner/software/hadoop/lib/slf4j-api-1.4.3.jar
    file:/home/kturner/software/hadoop/lib/commons-httpclient-3.0.1.jar
    file:/home/kturner/software/hadoop/lib/commons-configuration-1.6.jar
    file:/home/kturner/software/hadoop/lib/junit-4.5.jar
    file:/home/kturner/software/hadoop/lib/commons-logging-1.1.1.jar
    file:/home/kturner/software/hadoop/lib/commons-beanutils-core-1.8.0.jar
    file:/home/kturner/software/hadoop/lib/commons-math-2.1.jar
    file:/home/kturner/software/hadoop/lib/core-3.1.1.jar
    file:/home/kturner/software/hadoop/lib/jetty-util-6.1.26.jar
    file:/home/kturner/software/hadoop/lib/jackson-mapper-asl-1.8.8.jar
    file:/home/kturner/software/hadoop/lib/hadoop-capacity-scheduler-1.0.3.jar
    file:/home/kturner/software/hadoop/lib/jets3t-0.6.1.jar
    file:/home/kturner/software/hadoop/lib/aspectjtools-1.6.5.jar
    file:/home/kturner/software/hadoop/lib/hadoop-thriftfs-1.0.3.jar
    file:/home/kturner/software/hadoop/lib/commons-digester-1.8.jar
    file:/home/kturner/software/hadoop/lib/xmlenc-0.52.jar
    file:/home/kturner/software/hadoop/lib/jdeb-0.8.jar
    file:/home/kturner/software/hadoop/lib/commons-daemon-1.0.1.jar
    file:/home/kturner/software/hadoop/lib/jetty-6.1.26.jar
    file:/home/kturner/software/hadoop/lib/commons-codec-1.4.jar
    file:/home/kturner/software/hadoop/lib/commons-el-1.0.jar
    file:/home/kturner/software/hadoop/lib/commons-io-2.1.jar
    file:/home/kturner/software/hadoop/lib/commons-cli-1.2.jar
    file:/home/kturner/software/hadoop/lib/commons-net-1.4.1.jar
    file:/home/kturner/software/hadoop/lib/oro-2.0.8.jar
    file:/home/kturner/software/hadoop/lib/commons-lang-2.4.jar

Level 4: Accumulo Dynamic Classloader (loads everything defined by general.dynamic.classpaths) VFS classpaths items are:
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-09 00:31:15.35,,,no_permission,,,,,,,,,,,,330390,,,Mon Feb 03 20:50:37 UTC 2014,,,,,,0|i1kzzz:,330724,,,,,,,,09/Jul/13 00:31;mdrob;[~kturner] - Is this still an issue?,09/Jul/13 22:05;mdrob;I spoke with Keith offline about this and he said that he does not intend to fix this for 1.4.4 with the release so close.,"03/Feb/14 16:02;elserj;The {{null/lib/*.jar}} in the {{general.classpaths}} value was bugging me. Turns out there's another small issue there -- we reference ACCUMULO_HOME from the current environment, but that value doesn't necessarily exist yet (if it does, it isn't the right one). When we exec out to the Accumulo processes, that where we turn the File from the MiniAccumuloConfig into the ACCUMULO_HOME env variable.","03/Feb/14 20:48;jira-bot;Commit 748276b5b4cd91cd860082a758ec55d013013c9e in branch refs/heads/1.4.5-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=748276b ]

ACCUMULO-1472 Rely solely on classpath from the invoking application and prevent extra warnings from being logged.

Create lib/ext so that the classloader doesn't WARN. Since the applications
will inherit the classpath from the invoking application, we shouldn't try
to pull jars from environment vars (as they will rarely be correct) and add
them to the classpath too. Sadly, we must set *something*, otherwise the
AccumuloClassLoader will revert back to some default and load things
we don't want.
","03/Feb/14 20:48;jira-bot;Commit 748276b5b4cd91cd860082a758ec55d013013c9e in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=748276b ]

ACCUMULO-1472 Rely solely on classpath from the invoking application and prevent extra warnings from being logged.

Create lib/ext so that the classloader doesn't WARN. Since the applications
will inherit the classpath from the invoking application, we shouldn't try
to pull jars from environment vars (as they will rarely be correct) and add
them to the classpath too. Sadly, we must set *something*, otherwise the
AccumuloClassLoader will revert back to some default and load things
we don't want.
","03/Feb/14 20:48;jira-bot;Commit 748276b5b4cd91cd860082a758ec55d013013c9e in branch refs/heads/1.6.0-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=748276b ]

ACCUMULO-1472 Rely solely on classpath from the invoking application and prevent extra warnings from being logged.

Create lib/ext so that the classloader doesn't WARN. Since the applications
will inherit the classpath from the invoking application, we shouldn't try
to pull jars from environment vars (as they will rarely be correct) and add
them to the classpath too. Sadly, we must set *something*, otherwise the
AccumuloClassLoader will revert back to some default and load things
we don't want.
","03/Feb/14 20:48;jira-bot;Commit 748276b5b4cd91cd860082a758ec55d013013c9e in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=748276b ]

ACCUMULO-1472 Rely solely on classpath from the invoking application and prevent extra warnings from being logged.

Create lib/ext so that the classloader doesn't WARN. Since the applications
will inherit the classpath from the invoking application, we shouldn't try
to pull jars from environment vars (as they will rarely be correct) and add
them to the classpath too. Sadly, we must set *something*, otherwise the
AccumuloClassLoader will revert back to some default and load things
we don't want.
","03/Feb/14 20:50;elserj;Don't include classpath entries from  ACCUMULO_HOME, HADOOP_HOME or HADOOP_PREFIX as they likely aren't what is anticipated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Typo in TabletServer.java's copyright,ACCUMULO-2265,12691583,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,vines,vickyuec,vickyuec,28/Jan/14 08:48,28/Jan/14 17:16,13/Mar/19 22:01,28/Jan/14 15:30,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Second line has ""77"" in it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-28 15:29:54.105,,,no_permission,,,,,,,,,,,,370328,,,Tue Jan 28 17:16:01 UTC 2014,,,,,,0|i1rtqn:,370629,,,,,,,,"28/Jan/14 15:29;jira-bot;Commit 3c3911dd59d4326a7c95e0f353186b208f1b25da in branch refs/heads/1.6.0-SNAPSHOT from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3c3911d ]

ACCUMULO-2265 fixing copyright notice
","28/Jan/14 17:16;jira-bot;Commit 3c3911dd59d4326a7c95e0f353186b208f1b25da in branch refs/heads/master from [~vines]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3c3911d ]

ACCUMULO-2265 fixing copyright notice
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Backport ACCUMULO-684 to 1.4.x,ACCUMULO-2252,12691087,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,bhavanki,bhavanki,bhavanki,24/Jan/14 18:21,24/Jan/14 20:27,13/Mar/19 22:01,24/Jan/14 20:27,1.4.4,,,,,,,1.4.5,,,test,,,,,,0,randomwalk,test,,,"During a Security randomwalk on 1.4.4, ran into the error that was fixed in ACCUMULO-684.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-24 20:26:03.218,,,no_permission,,,,,,,,,,,,369830,,,Fri Jan 24 20:27:40 UTC 2014,,,,,,0|i1rqpj:,370132,,,,,,,,"24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:27;bhavanki;Since the backport is only to 1.4.5-SNAPSHOT, 1.4.5 is the only version fixed. The original fix was made in 1.5.x.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
npe during randomwalk test,ACCUMULO-684,12598266,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,10/Jul/12 20:23,24/Jan/14 20:26,13/Mar/19 22:01,11/Jul/12 14:25,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"Running a Concurrent test on the 10 node test cluster:

{noformat}

java.lang.Exception: Error running node Concurrent.xml
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:259)
        at org.apache.accumulo.server.test.randomwalk.Framework.run(Framework.java:61)
        at org.apache.accumulo.server.test.randomwalk.Framework.main(Framework.java:116)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.accumulo.start.Main$1.run(Main.java:87)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.Exception: Error running node ct.CreateUser
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:259)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
        ... 8 more
Caused by: org.apache.accumulo.core.client.AccumuloException: java.lang.NullPointerException
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.execute(SecurityOperationsImpl.java:61)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.createUser(SecurityOperationsImpl.java:111)
        at org.apache.accumulo.server.test.randomwalk.concurrent.CreateUser.visit(CreateUser.java:43)
        at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:251)
        ... 9 more
Caused by: java.lang.NullPointerException
        at org.apache.accumulo.fate.zookeeper.ZooUtil.getLockData(ZooUtil.java:226)
        at org.apache.accumulo.core.client.impl.ServerClient.getConnection(ServerClient.java:136)
        at org.apache.accumulo.core.client.impl.ServerClient.getConnection(ServerClient.java:122)
        at org.apache.accumulo.core.client.impl.ServerClient.executeRaw(ServerClient.java:104)
        at org.apache.accumulo.core.client.admin.SecurityOperationsImpl.execute(SecurityOperationsImpl.java:49)
        ... 12 more
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-24 20:26:04.334,,,no_permission,,,,,,,,,,,,246384,,,Fri Jan 24 20:26:15 UTC 2014,,,,,,0|i07lov:,42280,,,,,,,,"24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
","24/Jan/14 20:26;jira-bot;Commit 6593a9f5466e465ea7b8d46edfdef0544c42ada9 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6593a9f ]

ACCUMULO-2252 Backport ACCUMULO-684 to 1.4.x

A one-line manual backport of the one-line fix in ACCUMULO-684. The ZooUtil class
modified here is the one residing under the fate component in later releases.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"mapred-setup.sh emits error, still works",ACCUMULO-2237,12690319,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,22/Jan/14 17:13,22/Jan/14 17:15,13/Mar/19 22:01,22/Jan/14 17:15,,,,,,,,1.6.0,,,test,,,,,,0,,,,,"Running verification step, I get this error:
{noformat}
...continuous/mapred-setup.sh: line 27: /conf/accumulo-env.sh: No such file or directory
{noformat}

Everything works, this line is just unnecessary.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-22 17:14:35.407,,,no_permission,,,,,,,,,,,,369272,,,Wed Jan 22 17:14:43 UTC 2014,,,,,,0|i1rnav:,369577,,,,,,,,"22/Jan/14 17:14;jira-bot;Commit 383bf6dd3e4ee99b6c26f8e5ac5989bf720726d6 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=383bf6d ]

ACCUMULO-2237 eliminate warning
","22/Jan/14 17:14;jira-bot;Commit 383bf6dd3e4ee99b6c26f8e5ac5989bf720726d6 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=383bf6d ]

ACCUMULO-2237 eliminate warning
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Compilation error in 1.4.5-SNAPSHOT from ACCUMULO-2184,ACCUMULO-2201,12689088,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,bhavanki,bhavanki,bhavanki,15/Jan/14 21:05,15/Jan/14 21:33,13/Mar/19 22:01,15/Jan/14 21:33,,,,,,,,1.4.5,,,monitor,,,,,,0,,,,,"Simple compilation error in 1.4.5-SNAPSHOT introduced in ACCUMULO-2184:

{noformat}
src/server/src/main/java/org/apache/accumulo/server/monitor/servlets/DefaultServlet.java:[274,70] error: cannot find symbol
{noformat}

An exception variable is defined as {{e}} but referred to as {{ex}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-15 21:10:00.441,,,no_permission,,,,,,,,,,,,368055,,,Wed Jan 15 21:33:28 UTC 2014,,,,,,0|i1rfu7:,368361,,,,,,,,"15/Jan/14 21:10;jira-bot;Commit 5fdecd72e10bb3531797d365946e657b154ffca7 in branch refs/heads/1.4.5-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5fdecd7 ]

ACCUMULO-2201 Fix compilation error in 1.4.x.
","15/Jan/14 21:10;jira-bot;Commit 5fdecd72e10bb3531797d365946e657b154ffca7 in branch refs/heads/1.5.1-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5fdecd7 ]

ACCUMULO-2201 Fix compilation error in 1.4.x.
","15/Jan/14 21:10;jira-bot;Commit 5fdecd72e10bb3531797d365946e657b154ffca7 in branch refs/heads/1.6.0-SNAPSHOT from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5fdecd7 ]

ACCUMULO-2201 Fix compilation error in 1.4.x.
","15/Jan/14 21:10;jira-bot;Commit 5fdecd72e10bb3531797d365946e657b154ffca7 in branch refs/heads/master from [~bhavanki]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=5fdecd7 ]

ACCUMULO-2201 Fix compilation error in 1.4.x.
",15/Jan/14 21:33;bhavanki;boom,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CreateTableCommand#execute() should close Scanner,ACCUMULO-2179,12688397,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,yuzhihong@gmail.com,yuzhihong@gmail.com,yuzhihong@gmail.com,11/Jan/14 16:43,13/Jan/14 15:30,13/Mar/19 22:01,13/Jan/14 14:04,1.4.0,1.4.1,1.4.2,1.4.3,1.4.4,1.5.0,,1.4.5,1.5.0,1.6.0,,,,,,,0,,,,,"The Scanner, file, should be closed upon return from execute().",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11/Jan/14 16:43;yuzhihong@gmail.com;accumulo-2179.txt;https://issues.apache.org/jira/secure/attachment/12622505/accumulo-2179.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2014-01-13 14:01:45.727,,,no_permission,,,,,,,,,,,,367416,,,Mon Jan 13 14:04:22 UTC 2014,,,,,,0|i1rbxr:,367725,,,,,,,,"13/Jan/14 14:01;jira-bot;Commit 1431d3485ff0d54356d29e7b4ebee925ff254616 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1431d34 ]

ACCUMULO-2179 close the scanner
","13/Jan/14 14:02;jira-bot;Commit 1431d3485ff0d54356d29e7b4ebee925ff254616 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1431d34 ]

ACCUMULO-2179 close the scanner
","13/Jan/14 14:02;jira-bot;Commit aa5c92189791210de35739b69044defbbb8895d9 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=aa5c921 ]

ACCUMULO-2179 close the scanner
","13/Jan/14 14:03;jira-bot;Commit 1431d3485ff0d54356d29e7b4ebee925ff254616 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1431d34 ]

ACCUMULO-2179 close the scanner
","13/Jan/14 14:03;jira-bot;Commit aa5c92189791210de35739b69044defbbb8895d9 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=aa5c921 ]

ACCUMULO-2179 close the scanner
","13/Jan/14 14:03;jira-bot;Commit 1431d3485ff0d54356d29e7b4ebee925ff254616 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=1431d34 ]

ACCUMULO-2179 close the scanner
","13/Jan/14 14:04;jira-bot;Commit aa5c92189791210de35739b69044defbbb8895d9 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=aa5c921 ]

ACCUMULO-2179 close the scanner
",13/Jan/14 14:04;ecn;Fixed!  Thanks.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix minor typos and spelling in ARS,ACCUMULO-2124,12687029,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,02/Jan/14 19:45,02/Jan/14 21:28,13/Mar/19 22:01,02/Jan/14 20:23,,,,,,,,1.6.0,,,docs,,,,,,0,,,,,"There are some nice comments in the Accumulo Reservation System example.  Clean them up with trivial formatting, punctuation and spelling.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2014-01-02 19:46:53.945,,,no_permission,,,,,,,,,,,,366024,,,Thu Jan 02 21:28:30 UTC 2014,,,,,,0|i1r3cv:,366331,,,,,,,,"02/Jan/14 19:46;jira-bot;Commit 9bfef59ffe75ccea174222f6b000b6009e611f65 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9bfef59 ]

ACCUMULO-2124 minor updates to comments
","02/Jan/14 19:47;jira-bot;Commit 9bfef59ffe75ccea174222f6b000b6009e611f65 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=9bfef59 ]

ACCUMULO-2124 minor updates to comments
","02/Jan/14 21:14;jira-bot;Commit a56b76602767c062cd80e93f0437758dab02a266 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a56b766 ]

ACCUMULO-2124 [~kturner] found another typo
","02/Jan/14 21:28;jira-bot;Commit a56b76602767c062cd80e93f0437758dab02a266 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a56b766 ]

ACCUMULO-2124 [~kturner] found another typo
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"The FileDataIngest example creates MD5 hash keys, but the javadoc says it creates SHA1 hash keys.",ACCUMULO-1968,12682827,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ctubbsii,cncarrino,cncarrino,05/Dec/13 04:00,05/Dec/13 17:34,13/Mar/19 22:01,05/Dec/13 16:57,1.4.4,1.5.0,,,,,,1.4.5,1.5.1,1.6.0,client,,,,,,0,documentation,,,,"In file org.apache.accumulo.examples.simple.filedata.FileDataIngest the javadoc comment says ""Takes a list of files and archives them into Accumulo keyed on the SHA1 hashes of the files.""  But the code on line 64 creates an MD5 hash using MessageDigest.getInstance(""MD5"").

So either the ""SHA1"" in javadoc should be changed to ""MD5"", or the ""MD5"" in the MessageDigest.getInstance() method argument should be changed to ""SHA1"".

",,,,,,,,,,,,,,,,,,,,,,,,120,120,,0%,120,120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-12-05 16:56:54.732,,,no_permission,,,,,,,,,,,,362084,,,Thu Dec 05 17:34:40 UTC 2013,,,,,,0|i1qexz:,362379,,,,,,,,"05/Dec/13 11:51;cncarrino;I just realized another documentation page is affected as well:  http://accumulo.apache.org/1.5/examples/filedata.html.  The ""SHA1"" text should probably be changed to ""MD5"", unless the code itself is changed to generate SHA1 keys. ","05/Dec/13 16:56;jira-bot;Commit 513f4d22c5dfe39e5dd372528edb6c2ce6c7525d in branch refs/heads/1.4.5-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=513f4d2 ]

ACCUMULO-1968 Update incorrect example documentation
","05/Dec/13 16:57;jira-bot;Commit 513f4d22c5dfe39e5dd372528edb6c2ce6c7525d in branch refs/heads/1.5.1-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=513f4d2 ]

ACCUMULO-1968 Update incorrect example documentation
","05/Dec/13 16:57;jira-bot;Commit 513f4d22c5dfe39e5dd372528edb6c2ce6c7525d in branch refs/heads/1.6.0-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=513f4d2 ]

ACCUMULO-1968 Update incorrect example documentation
","05/Dec/13 17:34;jira-bot;Commit 513f4d22c5dfe39e5dd372528edb6c2ce6c7525d in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=513f4d2 ]

ACCUMULO-1968 Update incorrect example documentation
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
lots of simple warnings in 1.4 branch,ACCUMULO-1934,12681392,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,26/Nov/13 20:50,26/Nov/13 21:07,13/Mar/19 22:01,26/Nov/13 21:07,,,,,,,,1.4.5,,,,,,,,,0,,,,,"I'm going to clean up unused imports, dead code, etc.  It would be nice if these simple warnings didn't hide some of the more interesting ones.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-26 21:06:02.814,,,no_permission,,,,,,,,,,,,360657,,,Tue Nov 26 21:06:16 UTC 2013,,,,,,0|i1q66n:,360956,,,,,,,,"26/Nov/13 21:06;jira-bot;Commit 8d39b09b212a67ad0e8379ddf18cf3624d9d2152 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8d39b09 ]

ACCUMULO-1934 cleaning up imports, dead code, unused vars
","26/Nov/13 21:06;jira-bot;Commit 8d39b09b212a67ad0e8379ddf18cf3624d9d2152 in branch refs/heads/1.4.5-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8d39b09 ]

ACCUMULO-1934 cleaning up imports, dead code, unused vars
","26/Nov/13 21:06;jira-bot;Commit 8d39b09b212a67ad0e8379ddf18cf3624d9d2152 in branch refs/heads/1.5.1-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8d39b09 ]

ACCUMULO-1934 cleaning up imports, dead code, unused vars
","26/Nov/13 21:06;jira-bot;Commit 8d39b09b212a67ad0e8379ddf18cf3624d9d2152 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8d39b09 ]

ACCUMULO-1934 cleaning up imports, dead code, unused vars
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zookeeper polled too frequently,ACCUMULO-1911,12680378,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,,ecn,ecn,20/Nov/13 21:26,22/Nov/13 21:26,13/Mar/19 22:01,22/Nov/13 21:26,1.4.4,1.5.1,,,,,,1.6.0,,,monitor,,,,,,0,,,,,I noticed the monitor pulls stat data from zookeeper every second.  It should pull this data less frequently.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-22 21:26:01.907,,,no_permission,,,,,,,,,,,,359643,,,Fri Nov 22 21:26:02 UTC 2013,,,,,,0|i1pzyn:,359942,,,,,,,,"22/Nov/13 21:26;jira-bot;Commit 40d491807dfc473b396c8444772b91e5f1057288 in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=40d4918 ]

ACCUMULO-1911 increase the zookeeper poll rate to 5 seconds
","22/Nov/13 21:26;jira-bot;Commit 40d491807dfc473b396c8444772b91e5f1057288 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=40d4918 ]

ACCUMULO-1911 increase the zookeeper poll rate to 5 seconds
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
randomwalk test fails: unable to find accumulo-server.jar,ACCUMULO-1922,12680810,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,22/Nov/13 20:57,22/Nov/13 21:00,13/Mar/19 22:01,22/Nov/13 21:00,,,,,,,,1.6.0,,,test,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-11-22 20:59:19.581,,,no_permission,,,,,,,,,,,,360075,,,Fri Nov 22 20:59:22 UTC 2013,,,,,,0|i1q2lz:,360374,,,,,,,,"22/Nov/13 20:59;jira-bot;Commit 435b5c721ca585f68b7b2f5217d5cbb128ab71df in branch refs/heads/1.6.0-SNAPSHOT from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=435b5c7 ]

ACCUMULO-1922 accomodate new jar structure
","22/Nov/13 20:59;jira-bot;Commit 435b5c721ca585f68b7b2f5217d5cbb128ab71df in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=435b5c7 ]

ACCUMULO-1922 accomodate new jar structure
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix JS error in jquery.flot.js,ACCUMULO-1837,12676940,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,mberman,mberman,mberman,31/Oct/13 19:47,31/Oct/13 21:21,13/Mar/19 22:01,31/Oct/13 21:21,,,,,,,,1.6.0,,,,,,,,,0,,,,,"It doesn't affect correctness, but it does produce an annoying red X in the Eclipse problems view.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31/Oct/13 19:49;mberman;ACCUMULO-1837.patch;https://issues.apache.org/jira/secure/attachment/12611464/ACCUMULO-1837.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-10-31 21:21:04.234,,,no_permission,,,,,,,,,,,,356316,,,Thu Oct 31 21:21:04 UTC 2013,,,,,,0|i1pfdb:,356604,,,,,,,,31/Oct/13 19:49;mberman;Patch attached,"31/Oct/13 21:21;jira-bot;Commit b8b1b96a15dab0b17bda163d47b048a6199ed7db in branch refs/heads/master from [~mberman]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b8b1b96 ]

ACCUMULO-1837: fix JS error

Signed-off-by: John Vines <jvines@gmail.com>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
remove references to com.yahoo.zookeeper from logging configuration files,ACCUMULO-1683,12666882,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,vines,ecn,ecn,04/Sep/13 13:33,25/Oct/13 23:05,13/Mar/19 22:01,25/Oct/13 23:05,,,,,,,,1.6.0,,,,,,,,,0,,,,,Zookeeper uses different packages now.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-25 23:05:49.566,,,no_permission,,,,,,,,,,,,346819,,,Fri Oct 25 23:05:49 UTC 2013,,,,,,0|i1nszr:,347119,,,,,,,,"25/Oct/13 23:05;jira-bot;Commit aa0dcf25352e97bf50996ad8bfe2284167aa9565 in branch refs/heads/master from [~jvines@gmail.com]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=aa0dcf2 ]

ACCUMULO-1683 - Replacing com.yahoo.zookeeper in conf examples with org.apache.zookeeper
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testFilesAreGarbageCollected sometimes fails,ACCUMULO-1813,12675505,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,24/Oct/13 15:09,24/Oct/13 15:14,13/Mar/19 22:01,24/Oct/13 15:13,,,,,,,,,,,test,,,,,,0,,,,,Seeing the test fail sporadically.  Increase the wait time for the final test. ,apache build environment,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-24 15:14:07.73,,,no_permission,,,,,,,,,,,,355082,,,Thu Oct 24 15:14:07 UTC 2013,,,,,,0|i1p7rr:,355370,,,,,,,,"24/Oct/13 15:14;jira-bot;Commit 821ecec331e6f6be70eb93d750f9e0b5fe029133 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=821ecec ]

ACCUMULO-1813 increase wait time for GC to work
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
continuous ingest seeing log message and stack trace about log file closure,ACCUMULO-1812,12675504,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,,ecn,ecn,24/Oct/13 15:05,24/Oct/13 15:07,13/Mar/19 22:01,24/Oct/13 15:07,,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,Getting a ClosedChannelException when a thread decides to close a log and another is trying to use it.  Catch it and treat this as a normal retry condition.,hadoop 2.2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-24 15:07:45.431,,,no_permission,,,,,,,,,,,,355081,,,Thu Oct 24 15:07:45 UTC 2013,,,,,,0|i1p7rj:,355369,,,,,,,,"24/Oct/13 15:07;jira-bot;Commit b2adcaa3e405041ce300dc5b157c473cf91211fb in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b2adcaa ]

ACCUMULO-1812 translate ClosedChannelException into LogClosedException
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
filename in compaction start error,ACCUMULO-1811,12675352,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,23/Oct/13 22:41,23/Oct/13 22:42,13/Mar/19 22:01,23/Oct/13 22:42,,,,,,,,,,,tserver,,,,,,0,,,,,"I get this error when running continuous ingest with agitation.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-23 22:42:17.65,,,no_permission,,,,,,,,,,,,354972,,,Wed Oct 23 22:42:17 UTC 2013,,,,,,0|i1p73j:,355261,,,,,,,,"23/Oct/13 22:42;jira-bot;Commit 7e04aefe36089ec5654f9676197278eb33b26f3d in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7e04aef ]

ACCUMULO-1811 demote message, and make the message more informative
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MAC start() method should timeout when it can't connect to Zookeeper,ACCUMULO-1752,12672517,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,sonixbp,sonixbp,sonixbp,06/Oct/13 12:31,17/Oct/13 01:55,13/Mar/19 22:01,17/Oct/13 01:55,,,,,,,,1.6.0,,,,,,,,,0,,,,,"If the Zookeeper process fails to start for some reason, the MAC goes into an infinite loop looking for Zookeeper to start. It would be preferable to have it timeout after some number of seconds so that it can give an appropriate error message that Zookeeper was not started.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-17 01:55:07.409,,,no_permission,,,,,,,,,,,,352140,,,Thu Oct 17 01:55:07 UTC 2013,,,,,,0|i1opov:,352428,,,,,,,,"17/Oct/13 01:55;jira-bot;Commit 929279c79907d7f87b208290de0859cca61ccb96 in branch refs/heads/master from [~sonixbp]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=929279c ]

ACCUMULO-1752 Added 10 second timeout if Zookeeper process fails during MAC start
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
load average on monitor page is an integer,ACCUMULO-1536,12654955,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,26/Jun/13 15:41,11/Oct/13 20:28,13/Mar/19 22:01,11/Oct/13 20:28,,,,,,,,1.6.0,,,monitor,,,,,,0,,,,,"the load average is presently being displayed as an integer, and not a floating point value, as it was in 1.5",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-11 20:15:37.688,,,no_permission,,,,,,,,,,,,335232,,,Fri Oct 11 20:15:37 UTC 2013,,,,,,0|i1ltqv:,335556,,,,,,,,"11/Oct/13 20:15;jira-bot;Commit d10ec173d874f73588fa44a7cc811a66a42add70 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d10ec17 ]

ACCUMULO-1536 fixed load average presentation
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DevNull iterator documentation is incorrect,ACCUMULO-1774,12673462,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,11/Oct/13 17:04,11/Oct/13 17:19,13/Mar/19 22:01,11/Oct/13 17:05,,,,,,,,1.6.0,,,,,,,,,0,,,,,"Document states:

{noformat}
config -t ci -s table.iterator.minc.devnull=21,accumulo.core.iterators.DevNull
{noformat}

But the package for the DevNull iterator is {{org.apache.core.iterators}}.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-10-11 17:05:41.28,,,no_permission,,,,,,,,,,,,353085,,,Fri Oct 11 17:05:41 UTC 2013,,,,,,0|i1ovhz:,353372,,,,,,,,"11/Oct/13 17:05;jira-bot;Commit d88be6c12d768ce1626a5ec6a1a039e1a83503c1 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=d88be6c ]

ACCUMULO-1774 fixed package name in docs
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bin/accumulo should follow symbolic links,ACCUMULO-1492,12650947,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,elserj,kbotzum,kbotzum,04/Jun/13 18:03,22/Sep/13 22:56,13/Mar/19 22:01,22/Sep/13 22:56,1.5.0,,,,,,,1.5.1,1.6.0,,scripts,,,,,,0,,,,,"The accumulo script runs the find command on $HADOOP_PREFIX/lib to look for a log4j jar file. In some environments (such as with MapR) there may be symbolic links in the Accumulo configuration. Thus we need 'find' to follow links. So add the -H option:

    LOG4J_JAR=$(find -H $HADOOP_PREFIX/lib $HADOOP_PREFIX/share/hadoop/common/lib -name 'log4j*.jar' -print 2>/dev/null | head -1)
",MapR 2.1.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-09-22 19:08:53.256,,,no_permission,,,,,,,,,,,,331274,,,Sun Sep 22 19:12:48 UTC 2013,,,,,,0|i1l5fz:,331607,,,,,,,,"22/Sep/13 19:08;jira-bot;Commit 51dcfd8c257283e638d02399949868af95e2b2f3 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=51dcfd8 ]

ACCUMULO-1492 Add the -H option to `find` to follow symlinks when looking for
the log4j jar.
","22/Sep/13 19:12;jira-bot;Commit 51dcfd8c257283e638d02399949868af95e2b2f3 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=51dcfd8 ]

ACCUMULO-1492 Add the -H option to `find` to follow symlinks when looking for
the log4j jar.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"property GENERAL_MAX_MESSAGE_SIZE is configured as ""tserver.server.message.size.max""",ACCUMULO-1523,12653565,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,bhavanki,ecn,ecn,18/Jun/13 20:33,19/Sep/13 18:08,13/Mar/19 22:01,19/Sep/13 18:08,1.5.0,,,,,,,1.6.0,,,gc,master,tserver,,,,0,newbie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,19/Sep/13 17:35;bhavanki;0001-ACCUMULO-1523-Split-misnamed-GENERAL_MAX_MESSAGE_SIZ.patch;https://issues.apache.org/jira/secure/attachment/12604069/0001-ACCUMULO-1523-Split-misnamed-GENERAL_MAX_MESSAGE_SIZ.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-06-18 21:19:35.553,,,no_permission,,,,,,,,,,,,333842,,,Thu Sep 19 18:08:53 UTC 2013,,,,,,0|i1ll87:,334169,,,,,,,,"18/Jun/13 21:19;ctubbsii;What is the intended scope of this property? Per-tserver (in which case the enum is misnamed), or generally affecting the behavior of all thrift services (in which case, the configuration key is incorrect)?","19/Sep/13 16:32;bhavanki;I propose

* changing the key to ""general.server.message.size.max"" since it is used currently by the gc, master, and tablet server
* creating a new TSERVER_MAX_MESSAGE_SIZE property with key ""tserver.server.message.size.max"" that can specifically apply to the tablet server

In the interests of backward compatibility, the tablet server can first heed the TSERVER property, but use the GENERAL property if the TSERVER property isn't set.","19/Sep/13 17:36;bhavanki;Correction: The new property is TSERV_MAX_MESSAGE_SIZE, not TSERVER_... .","19/Sep/13 18:07;jira-bot;Commit b4ce6f88eb5db3c9a58e9a2d298447cdd2c44287 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b4ce6f8 ]

ACCUMULO-1523 applying Bill Havanki's patch
",19/Sep/13 18:08;ecn;Patch applied.  Thanks!  Please let me know how you want your information to appear on the accumulo contributors' page.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mikstake in 1.5 Manual section 7.3 Indexing,ACCUMULO-1673,12665928,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,_alexm,blueraiu,blueraiu,28/Aug/13 14:27,19/Sep/13 17:43,13/Mar/19 22:01,19/Sep/13 17:43,,,,,,,,1.5.1,1.6.0,,docs,,,,,,0,documentaion,newbie,,,"HashSet<Text> matchingRows = new HashSet<Text>();
...
    matchingRows.add(new Text(entry.getKey().getColumnQualifier()));
...
bscan.fetchFamily(""attributes"");
...
for(Entry<Key,Value> entry : scan)

Should read:

HashSet<Range> matchingRows = new HashSet<Range>();
...
    matchingRows.add(new Range(entry.getKey().getColumnQualifier()));
...
bscan.fetchColumnFamily(""attributes""); // api change?
...
for(Entry<Key,Value> entry : bscan)


// Now this line will work, since it accepts a collection of range not text 
bscan.setRanges(matchingRows);",,,,,,,,,,,,,,,,,,,,,,,,300,300,,0%,300,300,,,,,,,,,,,,,,,,,,,,,,,19/Sep/13 15:59;_alexm;ACCUMULO-1673.patch.txt;https://issues.apache.org/jira/secure/attachment/12604054/ACCUMULO-1673.patch.txt,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-09-19 15:58:44.588,,,no_permission,,,,,,,,,,,,345867,,,Thu Sep 19 17:43:01 UTC 2013,,,,,,0|i1nn5b:,346168,,,,,,,,19/Sep/13 15:58;_alexm;Patch for 1.5.1-SNAPSHOT.,"19/Sep/13 17:22;jira-bot;Commit 3c4f4f065a099a01c8c27e367db00cd6ed19bc96 in branch refs/heads/1.5.1-SNAPSHOT from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3c4f4f0 ]

ACCUMULO-1673 fetchColumnFamily only takes a Text, not a String or
CharSequence.
","19/Sep/13 17:22;jira-bot;Commit baf134c836dd90d581a71484544d5ced64a7e35a in branch refs/heads/1.5.1-SNAPSHOT from [~_alexm]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=baf134c ]

ACCUMULO-1673 fix 1.5 manual indexing example

Signed-off-by: Josh Elser <elserj@rpi.edu>
","19/Sep/13 17:42;jira-bot;Commit 3c4f4f065a099a01c8c27e367db00cd6ed19bc96 in branch refs/heads/master from [~elserj]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=3c4f4f0 ]

ACCUMULO-1673 fetchColumnFamily only takes a Text, not a String or
CharSequence.
","19/Sep/13 17:42;jira-bot;Commit baf134c836dd90d581a71484544d5ced64a7e35a in branch refs/heads/master from [~_alexm]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=baf134c ]

ACCUMULO-1673 fix 1.5 manual indexing example

Signed-off-by: Josh Elser <elserj@rpi.edu>
","19/Sep/13 17:43;elserj;Applied! Thanks, Alex.

I did modify the fetchColumnFamilies method from a String to Text to match the 1.5 API changes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CloudStone tests broken for < 1.5,ACCUMULO-1519,12653362,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,mdrob,chrisbennight,chrisbennight,18/Jun/13 01:28,07/Aug/13 23:10,13/Mar/19 22:01,07/Jul/13 15:41,1.4.3,,,,,,,1.4.4,,,shell,test,,,,,0,,,,,"Summary: 
force option for deletetable shell operation added in 1.5, CloudStone python benchmark change ported to 1.4.3 which tries to call the -f option, but results in error.



Longer:
Force command (""f"" was added to the deletetable shell command @ 
https://github.com/apache/accumulo/commit/6abb3e5ccb533adff0ae715dc3eb0c4a56ed4874#L9L67
1.4.3 tagged version is 
https://github.com/apache/accumulo/blob/1.4.3/src/core/src/main/java/org/apache/accumulo/core/util/shell/commands/DeleteTableCommand.java

The CloudStone python scripts in versions < 1.5 send the force command, which results in [shell.Shell] ERROR: org.apache.commons.cli.UnrecognizedOptionException: Unrecognized option: -f

This appears to have been the result of Accumulo-897 - https://github.com/apache/accumulo/commit/736c230ad1f3e106fa1713323545ee568251033f#test/system/bench/lib/IngestBenchmark.py

",Accumulo 1.4.3 (and presumably ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-07 15:37:12.183,,,no_permission,,,,,,,,,,,,333640,,,Sun Jul 07 15:37:12 UTC 2013,,,,,,0|i1ljzj:,333968,,,,,,,,"07/Jul/13 15:37;jira-bot;Commit 1500455 from [~mdrob]
[ https://svn.apache.org/r1500455 ]

ACCUMULO-1519 removing force flag from deletetable commands in cloudstone tests",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
pom.xml scm section should point at git,ACCUMULO-1646,12662469,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,mdrob,mdrob,mdrob,07/Aug/13 19:39,07/Aug/13 20:09,13/Mar/19 22:01,07/Aug/13 20:09,1.4.3,,,,,,,1.4.4,,,build,,,,,,0,,,,,"The scm section in the pom still points to the old svn repository, not the new git one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1500,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-08-07 20:03:12.81,,,no_permission,,,,,,,,,,,,342472,,,Wed Aug 07 20:03:15 UTC 2013,,,,,,0|i1n29b:,342777,,,,,,,,07/Aug/13 19:44;mdrob;scm urls have already been fixed in 1.5 and newer branches.,"07/Aug/13 20:03;jira-bot;Commit 27e8021b79fe4acc0b79b16d241860182360b3b2 in branch refs/heads/1.4.4-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27e8021 ]

ACCUMULO-1646 updating pom scm to use git
","07/Aug/13 20:03;jira-bot;Commit 6a03b419956ebdc7a6a38738e80f335394cdd5d1 in branch refs/heads/1.5.1-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6a03b41 ]

ACCUMULO-1646 Merge branch '1.4.4-SNAPSHOT' into 1.5.1-SNAPSHOT
","07/Aug/13 20:03;jira-bot;Commit 27e8021b79fe4acc0b79b16d241860182360b3b2 in branch refs/heads/1.5.1-SNAPSHOT from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27e8021 ]

ACCUMULO-1646 updating pom scm to use git
","07/Aug/13 20:03;jira-bot;Commit 6a03b419956ebdc7a6a38738e80f335394cdd5d1 in branch refs/heads/master from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=6a03b41 ]

ACCUMULO-1646 Merge branch '1.4.4-SNAPSHOT' into 1.5.1-SNAPSHOT
","07/Aug/13 20:03;jira-bot;Commit 27e8021b79fe4acc0b79b16d241860182360b3b2 in branch refs/heads/master from [~mdrob]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=27e8021 ]

ACCUMULO-1646 updating pom scm to use git
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RAT check fails to ignore .git directory,ACCUMULO-1500,12651497,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ctubbsii,ctubbsii,ctubbsii,06/Jun/13 21:48,07/Aug/13 19:44,13/Mar/19 22:01,06/Jun/13 21:52,,,,,,,,1.5.1,1.6.0,,,,,,,,0,,,,,"RAT-126 is fixed in 0.9, but Apache parent POM version 13 (latest as of now) uses Apache Rat 0.8.

We just need to update RAT to 0.9, overriding the version in the parent POM (until they update).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-06 21:52:14.724,,,no_permission,,,,,,,,,,,,331823,,,Wed Jul 24 02:31:02 UTC 2013,,,,,,0|i1l8t3:,332152,,,,,,,,"06/Jun/13 21:52;jira-bot;Commit 1490456 from [~ctubbsii]
[ https://svn.apache.org/r1490456 ]

ACCUMULO-1500 update to newer rat plugin to ignore .git/","24/Jul/13 01:53;jira-bot;Commit 96bed81360da4fcc49e0a09a5c575158b35afa32 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=96bed81 ]

ACCUMULO-1500 Merge branch '1.5.1-SNAPSHOT'

Conflicts:
	pom.xml
","24/Jul/13 01:53;jira-bot;Commit a7bc9375bb27149d1cc570cd3e6d530667786674 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a7bc937 ]

ACCUMULO-1500 Fix rat for switch to git, and other git and url fixes
","24/Jul/13 01:54;jira-bot;Commit a7bc9375bb27149d1cc570cd3e6d530667786674 in branch refs/heads/1.5.1-SNAPSHOT from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a7bc937 ]

ACCUMULO-1500 Fix rat for switch to git, and other git and url fixes
","24/Jul/13 02:31;jira-bot;Commit a7bc9375bb27149d1cc570cd3e6d530667786674 in branch refs/heads/1.5.1-SNAPSHOT-1.4.4-SNAPSHOT-merged from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=a7bc937 ]

ACCUMULO-1500 Fix rat for switch to git, and other git and url fixes
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
remove code related to mlock: it is no longer supported,ACCUMULO-1595,12659138,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,22/Jul/13 17:05,06/Aug/13 16:58,13/Mar/19 22:01,23/Jul/13 15:17,1.5.0,,,,,,,1.6.0,,,tserver,,,,,,0,,,,,"We once had a native library call to lock the tablet server JVM into RAM; the native code has been removed, so the supporting code should also be removed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-22 18:25:08.132,,,no_permission,,,,,,,,,,,,339331,,,Tue Aug 06 16:58:05 UTC 2013,,,,,,0|i1mizr:,339651,,,,,,,,"22/Jul/13 18:25;jira-bot;Commit 93f741e7efe761c980eda74b7fb679bd015838f3 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=93f741e ]

ACCUMULO-1595 remove mlock config entry
","22/Jul/13 18:25;jira-bot;Commit b3f1155962ead8af40b63c83103120ca0b82b3f2 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=b3f1155 ]

ACCUMULO-1595 remove code to lock jvm to ram
","06/Aug/13 16:58;jira-bot;Commit 7c2eed5849891a361d413be52ef6179ad848f6e2 in branch refs/heads/master from [~ctubbsii]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=7c2eed5 ]

ACCUMULO-1595 Remove MLock.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"IZooReaderWriter interface is defined with Mutate, which lives in the concrete implementation",ACCUMULO-1596,12659144,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,22/Jul/13 17:43,23/Jul/13 14:55,13/Mar/19 22:01,23/Jul/13 14:55,,,,,,,,,,,fate,,,,,,0,,,,,Hoist the Mutate interface up to IZooReaderWriter,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-07-22 18:25:06.535,,,no_permission,,,,,,,,,,,,339337,,,Mon Jul 22 18:25:07 UTC 2013,,,,,,0|i1mj13:,339657,,,,,,,,"22/Jul/13 18:25;jira-bot;Commit 85451233c6a00352daaf460fb668d02d76bdd953 in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=8545123 ]

ACCUMULO-1596 moved Mutator interface up to IZooReaderWriter
","22/Jul/13 18:25;jira-bot;Commit 734cd505d37f229d9c7204276059f33d3a7707ce in branch refs/heads/master from [~ecn]
[ https://git-wip-us.apache.org/repos/asf?p=accumulo.git;h=734cd50 ]

ACCUMULO-1596 moved Mutator interface up to IZooReaderWriter
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
minor typo in continuous-env.sh.example and run-verify.sh,ACCUMULO-1552,12656395,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,jmhsieh,jmhsieh,jmhsieh,05/Jul/13 16:29,08/Jul/13 13:47,13/Mar/19 22:01,08/Jul/13 13:47,1.4.3,1.5.0,,,,,,1.4.4,1.5.1,,test,,,,,,0,,,,,A variable name was misspelt VERFIY_OUT -> VERIFY_OUT,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,05/Jul/13 16:31;jmhsieh;accumulo-1552.patch;https://issues.apache.org/jira/secure/attachment/12591022/accumulo-1552.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-07-08 13:36:03.027,,,no_permission,,,,,,,,,,,,336618,,,Mon Jul 08 13:47:16 UTC 2013,,,,,,0|i1m2a7:,336941,,,,,,,,05/Jul/13 16:33;jmhsieh;Patch attached. Applies cleanly to 1.5 and trunk.,"08/Jul/13 13:36;jira-bot;Commit 1500718 from [~ecn]
[ https://svn.apache.org/r1500718 ]

ACCUMULO-1552 applying Jonathan Hsieh's patch to fix the typo","08/Jul/13 13:39;jira-bot;Commit 1500719 from [~ecn]
[ https://svn.apache.org/r1500719 ]

ACCUMULO-1552 applying Jonathan Hsieh's patch to fix the typo","08/Jul/13 13:41;jira-bot;Commit 1500723 from [~ecn]
[ https://svn.apache.org/r1500723 ]

ACCUMULO-1552 applying Jonathan Hsieh's patch to fix the typo",08/Jul/13 13:47;ecn;Thanks for the patch!,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZOOKEEPER_HOME needs to be set for the functional tests,ACCUMULO-522,12550506,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,,ecn,ecn,11/Apr/12 12:26,20/Jun/13 20:42,13/Mar/19 22:01,11/Apr/12 17:22,,,,,,,,,,,test,,,,,,0,,,,,"Reported by Keys Botzum:

simple.mapreduce.MapReduceTest fails because it assumes ZOOKEEPER_HOME is set as an environment variable. Most of the other scripts appear to get this information from TestUtils.py. The workaround is simply to set that variable before using run.py.

stress.weird.LateLastContact fails with a ZOOKEEPER_HOME reference just like MapReduceTest.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-06-20 20:42:52.853,,,no_permission,,,,,,,,,,,,235370,,,Thu Jun 20 20:42:52 UTC 2013,,,,,,0|i07mon:,42441,,,,,,,,20/Jun/13 20:42;jmhsieh;fixed in 1.4.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"logger.dir.walog description should say that the WAL is stored on the ""HDFS filesystem""",ACCUMULO-1470,12649994,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,kturner,aarongmldt,aarongmldt,29/May/13 20:02,29/May/13 21:55,13/Mar/19 22:01,29/May/13 21:55,1.5.0,,,,,,,1.5.1,1.6.0,,docs,,,,,,0,,,,,"Currently description for logger.dir.walog:

    <description>The directory used to store write-ahead logs on the local filesystem. It is possible to specify a comma-separated list of directories.
    </description>

I read ""local filesystem"" as it is NOT being written to the HDFS filesystem
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-29 20:19:52.788,,,no_permission,,,,,,,,,,,,330321,,,Wed May 29 21:51:56 UTC 2013,,,,,,0|i1kzkv:,330655,,,,,,,,"29/May/13 20:17;aarongmldt;This is based on, from what I can tell, the WAL being written into the ""/accumulo"" on the DFS.  However, what is weird, is that even though I had the default (walogs), the DIR that was created was ""wal.""

In looking over the code, the LOGGER_DIR property does have the default set to ""walogs"", but when looking at org.apache.accumulo.core.Constants:

  /**
   * @param conf
   * @return The write-ahead log directory.
   */
  public static String getWalDirectory(final AccumuloConfiguration conf) {
    return getBaseDir(conf) + ""/wal"";
  }

which is where I BELIEVE (not sure) that being used instead of the LOGGER_DIR.  
","29/May/13 20:19;vines;This is actually a vestigial configuration from the old local disk based walogs. I believe it's still there for backwards compatibility, but I cannot say for certain. [~ecn] would know that one.","29/May/13 20:24;ecn;The setting is still required for upgrades.  Any 1.3 WALogs will be put into HDFS on start-up.
",29/May/13 21:07;kturner;The docs probably need to be updated.  I'll update them.,"29/May/13 21:32;jira-bot;Commit 1487649 from kturner
[ https://svn.apache.org/r1487649 ]

ACCUMULO-1470 updated documentation for logger.dir.walog","29/May/13 21:51;jira-bot;Commit 1487650 from kturner
[ https://svn.apache.org/r1487650 ]

ACCUMULO-1470 updated documentation for logger.dir.walog",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
the master column on the master status page has no documentation,ACCUMULO-1287,12642961,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,sonixbp,ecn,ecn,17/Apr/13 15:56,16/May/13 20:53,13/Mar/19 22:01,16/May/13 16:38,1.5.0,,,,,,,1.6.0,,,monitor,,,,,,0,,,,,"Open up the ""Show Legend"" link, and you'll see there's nothing there for the ""Masters"" column.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-05-16 20:47:49.357,,,no_permission,,,,,,,,,,,,323371,,,Thu May 16 20:53:16 UTC 2013,,,,,,0|i1jsin:,323716,,,,,,,,"16/May/13 20:47;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #232 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/232/])
    ACCUMULO-1393 Removed all code that assumes TSERVER/MASTER don't have port attached to address in metadata table and zookeeper
ACCUMULO-1287 Add ""Master"" column on Master Server monitor page to the legend (Revision 1483437)

     Result = FAILURE
cjnolet : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/MasterClient.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ServerClient.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReaderIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchWriter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftTransportKey.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftTransportPool.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/AddressUtil.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ServerServices.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/AddressUtilTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/GarbageCollectWriteAheadLogs.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/state/TabletStateChangeIterator.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/MasterServlet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/AddressUtil.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Admin.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/StopTabletServer.java
","16/May/13 20:53;hudson;Integrated in Accumulo-Trunk #874 (See [https://builds.apache.org/job/Accumulo-Trunk/874/])
    ACCUMULO-1393 Removed all code that assumes TSERVER/MASTER don't have port attached to address in metadata table and zookeeper
ACCUMULO-1287 Add ""Master"" column on Master Server monitor page to the legend (Revision 1483437)

     Result = SUCCESS
cjnolet : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/InstanceOperationsImpl.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/MasterClient.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ServerClient.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchReaderIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/TabletServerBatchWriter.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftTransportKey.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftTransportPool.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/AddressUtil.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ServerServices.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/ThriftUtil.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/AddressUtilTest.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/GarbageCollectWriteAheadLogs.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/LiveTServerSet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/state/TabletStateChangeIterator.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/MasterServlet.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/AddressUtil.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/Admin.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/StopTabletServer.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
proxy SimpleTest fails trying to get a port,ACCUMULO-1365,12645490,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,30/Apr/13 19:14,01/May/13 18:18,13/Mar/19 22:01,30/Apr/13 19:51,,,,,,,,1.4.4,1.5.0,,test,,,,,,0,,,,,SimpleTest fails assigning a random port to the proxy.  Use the better method in MiniAccumuloCluster.,running on the apache build machines,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-30 19:35:13.759,,,no_permission,,,,,,,,,,,,325852,,,Wed May 01 18:18:38 UTC 2013,,,,,,0|i1k7tb:,326197,,,,,,,,30/Apr/13 19:35;sonixbp;Should this be changed in 1.4.4 as well?,30/Apr/13 19:43;elserj;Yup!,"30/Apr/13 19:46;ecn;Let me merge it (or attempt it).
","30/Apr/13 23:08;hudson;Integrated in Accumulo-Trunk #847 (See [https://builds.apache.org/job/Accumulo-Trunk/847/])
    ACCUMULO-1365 use the MAC mechanism for finding a random port (Revision 1477783)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","30/Apr/13 23:13;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #205 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/205/])
    ACCUMULO-1365 use the MAC mechanism for finding a random port (Revision 1477783)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","01/May/13 00:23;hudson;Integrated in Accumulo-1.5 #95 (See [https://builds.apache.org/job/Accumulo-1.5/95/])
    ACCUMULO-1365 use the MAC mechanism for finding a random port (Revision 1477782)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","01/May/13 00:52;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #94 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/94/])
    ACCUMULO-1365 use the MAC mechanism for finding a random port (Revision 1477782)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","01/May/13 01:53;hudson;Integrated in Accumulo-1.4.x #298 (See [https://builds.apache.org/job/Accumulo-1.4.x/298/])
    ACCUMULO-1365 use the MAC mechanism for finding a random port (Revision 1477797)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/zookeeper/ZooLock.java
* /accumulo/branches/1.4/src/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","01/May/13 16:41;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #95 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/95/])
    ACCUMULO-1365 move getRandomFreePort() out of MAC API (Revision 1478005)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/PortUtils.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","01/May/13 18:01;hudson;Integrated in Accumulo-1.4.x #299 (See [https://builds.apache.org/job/Accumulo-1.4.x/299/])
    ACCUMULO-1365 move getRandomFreePort() out of MAC API (Revision 1478018)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.4
* /accumulo/branches/1.4/src
* /accumulo/branches/1.4/src/core
* /accumulo/branches/1.4/src/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/branches/1.4/src/server
* /accumulo/branches/1.4/src/server/src
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/util/PortUtils.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/zookeeper/ZooLock.java
* /accumulo/branches/1.4/src/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","01/May/13 18:05;hudson;Integrated in Accumulo-1.5 #96 (See [https://builds.apache.org/job/Accumulo-1.5/96/])
    ACCUMULO-1365 move getRandomFreePort() out of MAC API (Revision 1478005)

     Result = FAILURE
kturner : 
Files : 
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/PortUtils.java
* /accumulo/branches/1.5/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","01/May/13 18:18;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #206 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/206/])
    ACCUMULO-1321 set constant to original value and provide comment describing reason for original value
ACCUMULO-1365 move getRandomFreePort() out of MAC API (Revision 1478032)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/PortUtils.java
* /accumulo/trunk/src
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/vfs/AccumuloReloadingVFSClassLoader.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
","01/May/13 18:18;hudson;Integrated in Accumulo-Trunk #848 (See [https://builds.apache.org/job/Accumulo-Trunk/848/])
    ACCUMULO-1321 set constant to original value and provide comment describing reason for original value
ACCUMULO-1365 move getRandomFreePort() out of MAC API (Revision 1478032)

     Result = ABORTED
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/PortUtils.java
* /accumulo/trunk/src
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/vfs/AccumuloReloadingVFSClassLoader.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/MiniAccumuloCluster.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CleanZookeeper requires password with ""accumulo:"" prefix",ACCUMULO-1333,12644163,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,23/Apr/13 17:43,23/Apr/13 20:12,13/Mar/19 22:01,23/Apr/13 17:49,,,,,,,,1.5.0,,,client,,,,,,0,,,,,"When prompted for the system password, the password that is required needs the accumulo prefix, which is a little too much to ask the average user.

Automatically pre-pend ""accumulo:"" to the password given by the user.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-23 19:54:25.555,,,no_permission,,,,,,,,,,,,324530,,,Tue Apr 23 20:12:42 UTC 2013,,,,,,0|i1jznr:,324875,,,,,,,,"23/Apr/13 19:54;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #87 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/87/])
    ACCUMULO-1333 prepend the user password with ""accumulo:"" so the user does not have to know this convention (Revision 1471067)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/CleanZookeeper.java
","23/Apr/13 19:56;hudson;Integrated in Accumulo-Trunk #841 (See [https://builds.apache.org/job/Accumulo-Trunk/841/])
    ACCUMULO-1333 prepend the user password with ""accumulo:"" so the user does not have to know this convention (Revision 1471068)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/CleanZookeeper.java
* /accumulo/trunk/src
","23/Apr/13 20:03;hudson;Integrated in Accumulo-1.5 #88 (See [https://builds.apache.org/job/Accumulo-1.5/88/])
    ACCUMULO-1333 prepend the user password with ""accumulo:"" so the user does not have to know this convention (Revision 1471067)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/CleanZookeeper.java
","23/Apr/13 20:12;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #199 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/199/])
    ACCUMULO-1333 prepend the user password with ""accumulo:"" so the user does not have to know this convention (Revision 1471068)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/util/CleanZookeeper.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
'bin/accumulo init' with a bad JAVA_HOME gives a misleading message,ACCUMULO-1072,12632646,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,vines,benpopp,benpopp,15/Feb/13 20:14,18/Apr/13 19:41,13/Mar/19 22:01,18/Apr/13 19:41,1.4.2,,,,,,,1.5.0,,,scripts,,,,,,0,,,,,"I mis-set my JAVA_HOME in accumulo-env.sh during an install.

I then ran 'bin/accumulo init'

Expected behavior: The script tells me that my JAVA_HOME is not a valid JAVA_HOME

Actual behavior: 'JAVA_HOME is not set. Please make sure it's set globally or in conf/accumulo-env.sh'",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-18 19:41:04.494,,,no_permission,,,,,,,,,,,,313142,,,Thu Apr 18 19:41:04 UTC 2013,,,,,,0|i1i1ev:,313488,,,,,,,,18/Apr/13 19:41;vines;The script refactoring done seems to address this.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"monitor displays GC status using 12-hour time, not 24",ACCUMULO-1059,12631754,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,supun,ecn,ecn,11/Feb/13 17:31,17/Apr/13 19:43,13/Mar/19 22:01,17/Apr/13 15:11,1.4.3,,,,,,,1.4.4,1.5.0,,monitor,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16/Apr/13 17:02;supun;ACCUMULO-1059.patch;https://issues.apache.org/jira/secure/attachment/12578959/ACCUMULO-1059.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-04-15 23:56:44.125,,,no_permission,,,,,,,,,,,,312250,,,Wed Apr 17 19:43:06 UTC 2013,,,,,,0|i1hvwf:,312596,,,,,,,,"15/Apr/13 23:56;supun;Does this Jira need a quick fix for changing the date time to 24 hour time? I would like to contribute a patch to this Jira if someone isn't looking at it already.

Thanks,
Supun..","16/Apr/13 00:02;elserj;[~supun] if memory serves, if there's no assignee for a ticket, feel free to assume no one is working on it. If someone is marked as assigned, asking is a good idea :)

A patch would be great!",16/Apr/13 17:02;supun;Attaching a simple patch. Please let me know if it needs any more changes.,"16/Apr/13 23:47;billie.rinaldi;Thanks for the patch, Supun!  I've added you to our contributors in JIRA, and will add you to our people page as well.  I'd like Eric to weigh in on the particular date/time format before we check in the patch; I don't know if he had something particular in mind.","16/Apr/13 23:56;ecn;I will apply the patch tomorrow... got stuck behind a few other issues today.

I don't really care about the format, but I like Supun's initiative.

","17/Apr/13 16:01;hudson;Integrated in Accumulo-Trunk #834 (See [https://builds.apache.org/job/Accumulo-Trunk/834/])
    ACCUMULO-1059 applying Supun Kamburugamuva's patch to use 24-hour time (Revision 1468961)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/servlets/GcStatusServlet.java
* /accumulo/trunk/src
","17/Apr/13 19:43;hudson;Integrated in Accumulo-1.4.x #294 (See [https://builds.apache.org/job/Accumulo-1.4.x/294/])
    ACCUMULO-1059 applying Supun Kamburugamuva's patch to use 24-hour time (Revision 1468958)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/monitor/servlets/GcStatusServlet.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
new configuration test in random walk sets timeout values much too high,ACCUMULO-1283,12642939,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,vines,ecn,ecn,17/Apr/13 14:23,17/Apr/13 16:01,13/Mar/19 22:01,17/Apr/13 14:31,,,,,,,,1.5.0,,,test,,,,,,0,15_qa_bug,,,,"The {{Config}} node in the concurrent random walk tests sets delay values from 0 to 10000.  These are read as whole seconds, so they are much too long.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-17 16:01:44.585,,,no_permission,,,,,,,,,,,,323349,,,Wed Apr 17 16:01:44 UTC 2013,,,,,,0|i1jsdr:,323694,,,,,,,,"17/Apr/13 16:01;hudson;Integrated in Accumulo-Trunk #834 (See [https://builds.apache.org/job/Accumulo-Trunk/834/])
    ACCUMULO-1283 use better ranges for timeout values (Revision 1468928)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/SimpleGarbageCollector.java
* /accumulo/trunk/src
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/concurrent/Config.java
* /accumulo/trunk/test/src/main/java/org/apache/accumulo/test/randomwalk/security/WalkingSecurity.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"garbage collector is reporting ""0 files deleted"" even though it deleted many files",ACCUMULO-1285,12642948,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,17/Apr/13 14:52,17/Apr/13 16:01,13/Mar/19 22:01,17/Apr/13 14:53,,,,,,,,,,,gc,,,,,,0,,,,,Does not report the number of WAL files deleted.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-17 16:01:44.815,,,no_permission,,,,,,,,,,,,323358,,,Wed Apr 17 16:01:44 UTC 2013,,,,,,0|i1jsfr:,323703,,,,,,,,"17/Apr/13 16:01;hudson;Integrated in Accumulo-Trunk #834 (See [https://builds.apache.org/job/Accumulo-Trunk/834/])
    ACCUMULO-1285 account for files deleted regardless of how they are trashed/deleted (Revision 1468949)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/gc/GarbageCollectWriteAheadLogs.java
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
strange updates to metadata table,ACCUMULO-1257,12641858,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,kturner,ecn,ecn,10/Apr/13 16:22,15/Apr/13 17:12,13/Mar/19 22:01,15/Apr/13 14:47,,,,,,,,1.5.0,,,tserver,,,,,,0,,,,,"While testing, I took a very close look at the write-ahead log for one !METADATA tablet.  I saw a series of strange updates:

{noformat}
MANY_MUTATIONS 1 3
1 mutations:
  m9<
      srv:time [system]:181690 [] M1365448749945
      srv:lock [system]:181690 [] tservers/10.0.0.1:9997/zlock-0000000012$33dea1f3e44032a

MANY_MUTATIONS 1 3
1 mutations:
  m9<
      srv:time [system]:181691 [] M1365448749945
      srv:lock [system]:181691 [] tservers/10.0.0.1:9997/zlock-0000000012$33dea1f3e44032a

MANY_MUTATIONS 1 3
1 mutations:
  m9<
      srv:time [system]:181692 [] M1365448749974
      srv:lock [system]:181692 [] tservers/10.0.0.1:9997/zlock-0000000012$33dea1f3e44032a

MANY_MUTATIONS 1 3
1 mutations:
  m9<
      srv:time [system]:181703 [] M1365448751735
      srv:lock [system]:181703 [] tservers/10.0.0.1:9997/zlock-0000000012$33dea1f3e44032a
{noformat}

It seems to me that these updates aren't necessary.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-15 17:01:10.661,,,no_permission,,,,,,,,,,,,322273,,,Mon Apr 15 17:12:20 UTC 2013,,,,,,0|i1jlqv:,322618,,,,,,,,"15/Apr/13 17:01;hudson;Integrated in Accumulo-1.5 #78 (See [https://builds.apache.org/job/Accumulo-1.5/78/])
    ACCUMULO-1257 stopped updating time for bulk import when there are no files (Revision 1468098)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
","15/Apr/13 17:05;hudson;Integrated in Accumulo-Trunk #831 (See [https://builds.apache.org/job/Accumulo-Trunk/831/])
    ACCUMULO-1257 stopped updating time for bulk import when there are no files (Revision 1468100)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
* /accumulo/trunk/src
","15/Apr/13 17:10;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #189 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/189/])
    ACCUMULO-1257 stopped updating time for bulk import when there are no files (Revision 1468100)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
* /accumulo/trunk/src
","15/Apr/13 17:12;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #77 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/77/])
    ACCUMULO-1257 stopped updating time for bulk import when there are no files (Revision 1468098)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
setscaniter can cause iterator class warning to appear in monitor,ACCUMULO-1234,12640499,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,bfloss,bfloss,03/Apr/13 12:48,04/Apr/13 01:43,13/Mar/19 22:01,03/Apr/13 20:33,1.4.3,,,,,,,1.5.0,,,,,,,,,0,,,,,"When using the shell, if I attempt to set a scan iterator for the shell session only using the setscaniter command, a warning appears in the monitor if the iterator class cannot be loaded.  The class warning in this case should probably be limited to just the user's shell since they are the only one impacted by the problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-04 01:18:18.131,,,no_permission,,,,,,,,,,,,320959,,,Thu Apr 04 01:43:17 UTC 2013,,,,,,0|i1jdmf:,321300,,,,,,,,"04/Apr/13 01:18;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #61 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/61/])
    ACCUMULO-1234 do a local check for classes that are only used locally (Revision 1464194)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetIterCommand.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetScanIterCommand.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetShellIterCommand.java
","04/Apr/13 01:26;hudson;Integrated in Accumulo-1.5 #63 (See [https://builds.apache.org/job/Accumulo-1.5/63/])
    ACCUMULO-1234 do a local check for classes that are only used locally (Revision 1464194)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetIterCommand.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetScanIterCommand.java
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetShellIterCommand.java
","04/Apr/13 01:35;hudson;Integrated in Accumulo-Trunk #814 (See [https://builds.apache.org/job/Accumulo-Trunk/814/])
    ACCUMULO-1234 do a local check for classes that are only used locally (Revision 1464196)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetIterCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetScanIterCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetShellIterCommand.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","04/Apr/13 01:43;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #173 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/173/])
    ACCUMULO-1234 do a local check for classes that are only used locally (Revision 1464196)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetIterCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetScanIterCommand.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetShellIterCommand.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
running FindOfflineTablets with no arguments throws NPE,ACCUMULO-1231,12640307,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,02/Apr/13 14:07,03/Apr/13 02:07,13/Mar/19 22:01,02/Apr/13 14:32,,,,,,,,1.5.0,,,client,,,,,,0,,,,,"For convenience, this utility should always use System credentials.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-04-03 01:58:16.17,,,no_permission,,,,,,,,,,,,320770,,,Wed Apr 03 02:07:29 UTC 2013,,,,,,0|i1jcgf:,321111,,,,,,,,"03/Apr/13 01:58;hudson;Integrated in Accumulo-1.5 #61 (See [https://builds.apache.org/job/Accumulo-1.5/61/])
    ACCUMULO-1231 use system credentials all the time (Revision 1463553)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/FindOfflineTablets.java
","03/Apr/13 02:07;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #59 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/59/])
    ACCUMULO-1231 use system credentials all the time (Revision 1463553)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/util/FindOfflineTablets.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Proxy SimpleTest fails reading stale zookeeper data,ACCUMULO-1214,12639293,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,27/Mar/13 12:31,03/Apr/13 02:07,13/Mar/19 22:01,02/Apr/13 13:51,1.4.3,,,,,,,1.5.0,,,master,tserver,,,,,0,,,,,"During the nightly tests, changing table.split.threshhold from 1G to 500M did not read back properly.  The change had not propagated out yet.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-27 14:26:37.996,,,no_permission,,,,,,,,,,,,319763,,,Wed Apr 03 02:07:28 UTC 2013,,,,,,0|i1j68n:,320104,,,,,,,,"27/Mar/13 14:26;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #162 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/162/])
    ACCUMULO-1214 fix method name conflict (Revision 1461569)
ACCUMULO-1214 invalidate the zookeeper cache when returning results to clients (Revision 1461556)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/conf/TableConfiguration.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/AccumuloConfiguration.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/conf/ZooConfiguration.java
* /accumulo/trunk/src
","27/Mar/13 14:35;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #54 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/54/])
    ACCUMULO-1214 fix method name conflict (Revision 1461567)
ACCUMULO-1214 invalidate the zookeeper cache when returning results to clients (Revision 1461555)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/conf/TableConfiguration.java

ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/AccumuloConfiguration.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/conf/ZooConfiguration.java
","27/Mar/13 14:40;hudson;Integrated in Accumulo-1.5 #57 (See [https://builds.apache.org/job/Accumulo-1.5/57/])
    ACCUMULO-1214 fix method name conflict (Revision 1461567)
ACCUMULO-1214 invalidate the zookeeper cache when returning results to clients (Revision 1461555)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/conf/TableConfiguration.java

ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/conf/AccumuloConfiguration.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/conf/ZooConfiguration.java
","27/Mar/13 14:44;hudson;Integrated in Accumulo-Trunk #803 (See [https://builds.apache.org/job/Accumulo-Trunk/803/])
    ACCUMULO-1214 fix method name conflict (Revision 1461569)
ACCUMULO-1214 invalidate the zookeeper cache when returning results to clients (Revision 1461556)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/conf/TableConfiguration.java
* /accumulo/trunk/src

ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/AccumuloConfiguration.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/ClientServiceHandler.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/conf/ZooConfiguration.java
* /accumulo/trunk/src
","28/Mar/13 14:34;kturner;If we want to offer this level of consistency, clearing zoocache may not be enough.  May need to sync before reading from zookeeper.","02/Apr/13 13:45;ecn;There isn't a specific node to sync on. I agree that it does not provide a guarantee that the data is loaded on all zookeeper servers, but this change has stabilized the test.  I'll document it in the API.","02/Apr/13 14:06;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #167 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/167/])
    ACCUMULO-1214 document delay between set/get properties; loosen the test to allow for the delay (Revision 1463547)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
* /accumulo/trunk/server
* /accumulo/trunk/src
","03/Apr/13 01:58;hudson;Integrated in Accumulo-1.5 #61 (See [https://builds.apache.org/job/Accumulo-1.5/61/])
    ACCUMULO-1214 document delay between set/get properties; loosen the test to allow for the delay (Revision 1463546)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
","03/Apr/13 02:07;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #59 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/59/])
    ACCUMULO-1214 document delay between set/get properties; loosen the test to allow for the delay (Revision 1463546)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java
* /accumulo/branches/1.5/proxy/src/test/java/org/apache/accumulo/proxy/SimpleTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
remove stray println in ClientOpts,ACCUMULO-1210,12639157,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,26/Mar/13 18:35,27/Mar/13 02:47,13/Mar/19 22:01,26/Mar/13 18:37,,,,,,,,1.5.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-27 02:33:53.384,,,no_permission,,,,,,,,,,,,319627,,,Wed Mar 27 02:47:30 UTC 2013,,,,,,0|i1j5ef:,319968,,,,,,,,"27/Mar/13 02:33;hudson;Integrated in Accumulo-Trunk #802 (See [https://builds.apache.org/job/Accumulo-Trunk/802/])
    ACCUMULO-1210 remove stray println (Revision 1461260)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java
","27/Mar/13 02:37;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #53 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/53/])
    ACCUMULO-1210 remove stray println (Revision 1461259)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
","27/Mar/13 02:47;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #161 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/161/])
    ACCUMULO-1210 remove stray println (Revision 1461260)

     Result = UNSTABLE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/src
* /accumulo/trunk/test/src/test/java/org/apache/accumulo/test/ShellServerTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ThriftScanner ScanState.tableName is really the tableId,ACCUMULO-1144,12635178,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,kevin.faro,kevin.faro,kevin.faro,04/Mar/13 18:41,20/Mar/13 20:12,13/Mar/19 22:01,20/Mar/13 16:37,1.4.0,,,,,,,1.6.0,,,,,,,,,0,,,,,"During work on ACCUMULO-1018, I ran into the ThriftScanner$ScanState.tableName really being the tableId.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Mar/13 20:01;kevin.faro;ACCUMULO-1144.patch;https://issues.apache.org/jira/secure/attachment/12571940/ACCUMULO-1144.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-03-20 16:37:10.068,,,no_permission,,,,,,,,,,,,315671,,,Wed Mar 20 20:12:11 UTC 2013,,,,,,0|i1igzz:,316014,,,,,,,,04/Mar/13 20:01;kevin.faro;slight refactoring by changing the tableName property when it refers to a tableId.,04/Mar/13 20:01;kevin.faro;ACCUMULO-1144.patch,"20/Mar/13 16:37;kturner;Thanks Kevin, I merged the patch.","20/Mar/13 20:04;hudson;Integrated in Accumulo-Trunk #789 (See [https://builds.apache.org/job/Accumulo-Trunk/789/])
    ACCUMULO-1144 merged patch from Kevin Faro (Revision 1458933)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ScannerIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftScanner.java
","20/Mar/13 20:12;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #148 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/148/])
    ACCUMULO-1144 merged patch from Kevin Faro (Revision 1458933)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ScannerIterator.java
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/impl/ThriftScanner.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stray warning about missing recovery files,ACCUMULO-1147,12635203,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,,ecn,ecn,04/Mar/13 20:37,05/Mar/13 03:48,13/Mar/19 22:01,04/Mar/13 20:39,,,,,,,,1.5.0,,,,,,,,,0,,,,,"When removing WALogs, we cleanup any recovery files.  Usually, there are none, which causes the tserver to emit a warning.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-03-05 03:25:32.959,,,no_permission,,,,,,,,,,,,315696,,,Tue Mar 05 03:48:59 UTC 2013,,,,,,0|i1ih5j:,316039,,,,,,,,"05/Mar/13 03:25;hudson;Integrated in Accumulo-Trunk #757 (See [https://builds.apache.org/job/Accumulo-Trunk/757/])
    ACCUMULO-1147 remove missing file warning (Revision 1452498)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/src
","05/Mar/13 03:30;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #116 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/116/])
    ACCUMULO-1147 remove missing file warning (Revision 1452498)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/ZooStore.java
* /accumulo/trunk/fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooSession.java
* /accumulo/trunk/server
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
* /accumulo/trunk/src
","05/Mar/13 03:35;hudson;Integrated in Accumulo-1.5-Hadoop-2.0 #12 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/12/])
    ACCUMULO-1147 remove missing file warning (Revision 1452496)

     Result = FAILURE
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
","05/Mar/13 03:48;hudson;Integrated in Accumulo-1.5 #13 (See [https://builds.apache.org/job/Accumulo-1.5/13/])
    ACCUMULO-1147 remove missing file warning (Revision 1452496)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Authorizations has inconsistent serialization,ACCUMULO-1051,12631364,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,kevin.faro,ctubbsii,ctubbsii,08/Feb/13 00:41,21/Feb/13 04:27,13/Mar/19 22:01,20/Feb/13 23:41,,,,,,,,1.6.0,,,client,,,,,,0,newbie,,,,"The same set of authorizations may not serialize to the same value each time, if specified in a different order when constructed (like new Authorizations(""a"", ""b"") and new Authorizations(""b"", ""a"")), because serialization reproducibility depends on the insert order in the underlying HashSet.

So, one could get the following to happen:
{code:java}
true == auths1.equals(auths2) && !auths1.serialize().equals(auths2.serialize());
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ACCUMULO-1066,,,,,,,,,,,,,,,,,,,,14/Feb/13 00:50;kevin.faro;accumulo-1051.patch;https://issues.apache.org/jira/secure/attachment/12569293/accumulo-1051.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2013-02-08 02:05:11.916,,,no_permission,,,,,,,,,,,,311860,,,Thu Feb 21 04:27:24 UTC 2013,,,,,,0|i1hthz:,312206,,,,,,,,"08/Feb/13 02:05;afuchs;Interesting, but when do we care about comparing the serialization of
authorizations?

","08/Feb/13 15:05;ctubbsii;We might not care at all. I only ran into this when I was writing some unit tests for mapreduce, and was surprised by it.",08/Feb/13 15:23;bills;I think having some consistent serialization would be nice. Log mining applications might find it useful to have a raw comparator option if they consider Authorizations objects.,"08/Feb/13 17:05;ctubbsii;I don't know how useful it is in the general case to have consistent serialization, but for Authorizations, it's a trivial change, and could be useful.","13/Feb/13 21:33;kevin.faro;I wasn't able to recreate the failing test case since I think the underlying HashMap was consistently hashing the keys a and b, however the HashSet API indicates that the Iterator will not return keys in any particular order.  So I went ahead and added the test case and changed the implementation of auths to use a TreeSet so it will always iterate over the keys consistently regardless of insertion order.","13/Feb/13 22:07;vines;Won't there be a sizable performance impact by switching it to a TreeSet, given how we check users Authorizations as we iterate over key value pairs?","13/Feb/13 22:10;bills;That will depend on the length of each individual authorization, the similarity of each byte in each authorization, and the number of individual visibilities being checked against the authorizations. In real world scenarios, probably not.","13/Feb/13 22:13;ctubbsii;I doubt it, but if so, we could choose another implementation (like throw it into an array and sort it during serialize() method).","13/Feb/13 22:39;kturner;bq. Won't there be a sizable performance impact by switching it to a TreeSet, given how we check users Authorizations as we iterate over key value pairs?

Looked in the code, the set is directly used by the VisibilityEvaluator. O(log n) is probably ok for small auths sets.  But I think it would be faster to switch back to a HashSet than do performance tests :)   I say just sort on serialize and switch back to hashset.","13/Feb/13 23:14;vines;Additionally, this test is causing build failures for me.","13/Feb/13 23:58;kevin.faro;Good point ... sorry I am still trying to get my hands around the code.  

Would it be better to sort auths in checkAuths and store the authorizations in sorted order in the authList?  Then in serialize, just iterate over the authList instead of auths.  It would take slightly longer for object creation, but then the sort would only happen once.

John ... what class/classes are failing to build?","14/Feb/13 00:04;vines;The testAuths is. Unfortunately I didn't get to look into it yet though.

Sent from my phone, please pardon the typos and brevity.

","14/Feb/13 00:29;hudson;Integrated in Accumulo-Trunk #733 (See [https://builds.apache.org/job/Accumulo-Trunk/733/])
    ACCUMULO-1051 Applied patch from Kevin Faro ([~kevin.faro]) to consistently serialize Authorizations (Revision 1445954)

     Result = UNSTABLE
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/Authorizations.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/AuthorizationsTest.java
","14/Feb/13 00:47;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #91 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/91/])
    ACCUMULO-1051 Applied patch from Kevin Faro ([~kevin.faro]) to consistently serialize Authorizations (Revision 1445954)

     Result = UNSTABLE
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/Authorizations.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/AuthorizationsTest.java
","14/Feb/13 00:49;kevin.faro;I left auths to be a HashSet, changed the checkAuths method to sort the authorizations before storing them in the authsList (so it only sorts once) and then serialize() iterates over the authsList instead of auths.

Also, this now passes the ShellTest.authsTest that was failing in Hudson.

What do you think?","14/Feb/13 01:11;ctubbsii;Yes, sorry. I only ran the unit tests that were added when I committed, and not the whole suite (admittedly a stupid idea). I'll revert the commit, until it is fixed (because I don't have time to fix it at the moment), but essentially the failure is because the shell tests are relying on the iteration order of the HashSet. The shell should be showing them in sorted order, regardless of the serialization, anyway, but that's a separate issue (but related).","14/Feb/13 01:56;kevin.faro;Nope, that is my bad.  I should have done that.  Sorry dude.

The new patch should compile and pass all the tests (fingers crossed).  Not sure it is what you guys are looking for though - feel free to comment.
","14/Feb/13 04:06;hudson;Integrated in Accumulo-Trunk #734 (See [https://builds.apache.org/job/Accumulo-Trunk/734/])
    ACCUMULO-1051 reverted previous change, which broke unit tests. Awaiting updated patch based on test failures and ticket discussions. (Revision 1446013)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/Authorizations.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/AuthorizationsTest.java
","14/Feb/13 04:06;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #92 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/92/])
    ACCUMULO-1051 reverted previous change, which broke unit tests. Awaiting updated patch based on test failures and ticket discussions. (Revision 1446013)

     Result = FAILURE
ctubbsii : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/Authorizations.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/AuthorizationsTest.java
",19/Feb/13 14:17;kevin.faro;now sorting auths in check auths,"21/Feb/13 04:25;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #98 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/98/])
    ACCUMULO-1051 checking in patch from Kevin Faro (Revision 1448472)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/Authorizations.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/AuthorizationsTest.java
","21/Feb/13 04:27;hudson;Integrated in Accumulo-Trunk #740 (See [https://builds.apache.org/job/Accumulo-Trunk/740/])
    ACCUMULO-1051 checking in patch from Kevin Faro (Revision 1448472)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/security/Authorizations.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/security/AuthorizationsTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stderr: Warning: $HADOOP_HOME is deprecated,ACCUMULO-645,12595096,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,19/Jun/12 12:13,12/Feb/13 19:56,13/Mar/19 22:01,14/Jan/13 19:07,1.4.0,,,,,,,1.5.0,,,scripts,,,,,,0,,,,,"Getting tired of looking at the message.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-08-01 21:02:18.722,,,no_permission,,,,,,,,,,,,246422,,,Tue Feb 12 19:56:05 UTC 2013,,,,,,0|i07lxj:,42319,,,,,,,,01/Aug/12 21:02;medined;Please clarify what work needs to be done for this ticket.,01/Aug/12 21:06;jvines;Find out what aspect of the hadoop scripts do this check and work around it would be my guess.,09/Jan/13 20:43;ecn;fixed with revision 1431051,"09/Jan/13 21:06;hudson;Integrated in Accumulo-Trunk #622 (See [https://builds.apache.org/job/Accumulo-Trunk/622/])
    ACCUMULO-645 switch to using HADOOP_PREFIX and HADOOP_CONF_DIR (Revision 1431051)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/conf/examples/1GB/native-standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/1GB/standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/2GB/native-standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/2GB/standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/512MB/native-standalone/accumulo-env.sh
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-env.sh
","10/Jan/13 21:25;hudson;Integrated in Accumulo-Trunk #626 (See [https://builds.apache.org/job/Accumulo-Trunk/626/])
    ACCUMULO-645: found more references to HADOOP_HOME (Revision 1431596)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/bin/tool.sh
","11/Jan/13 19:47;vines;Fresh pull, ran the script. I was using the old config, so things broke. Not sure if we want to fix it, but the checks in config.sh seem a bit strange to me.

{code}if [ -z ""$HADOOP_PREFIX"" ]
then
   HADOOP_HOME=""`which hadoop`""
   if [ -z ""$HADOOP_PREFIX"" ]
   then
      echo ""You must set HADOOP_PREFIX""
      exit 1
   fi
   HADOOP_HOME=`dirname $HADOOP_PREFIX`
   HADOOP_HOME=`dirname $HADOOP_PREFIX`
fi
{code
We check hadoop prefix, set hadoop home, make no changes to hadoop prefix, check it again with the exact same check, and then exit. Shouldn't we either just fail outright here (blech) or try to set HADOOP_PREFIX to HADOOP_HOME if not set (getting HADOOP_HOME figured out by `which hadop` if we can?",14/Jan/13 19:06;ecn;Good catch... I've cleaned that up.,"14/Jan/13 20:41;hudson;Integrated in Accumulo-Trunk #636 (See [https://builds.apache.org/job/Accumulo-Trunk/636/])
    ACCUMULO-645 found another HADOOP_HOME reference (Revision 1433102)
ACCUMULO-645 found another HADOOP_HOME reference (Revision 1433058)
ACCUMULO-645 found and removed many other references to HADOOP_HOME (Revision 1433049)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/conf/examples/1GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/1GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/2GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/3GB/standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/native-standalone/accumulo-site.xml
* /accumulo/trunk/conf/examples/512MB/standalone/accumulo-site.xml

ecn : 
Files : 
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java

ecn : 
Files : 
* /accumulo/trunk/bin/accumulo
* /accumulo/trunk/bin/bootstrap_hdfs.sh
* /accumulo/trunk/bin/config.sh
* /accumulo/trunk/start/src/main/java/org/apache/accumulo/start/classloader/AccumuloClassLoader.java
* /accumulo/trunk/test/system/auto/TestUtils.py
","12/Feb/13 19:48;hudson;Integrated in Accumulo-Trunk #728 (See [https://builds.apache.org/job/Accumulo-Trunk/728/])
    ACCUMULO-645 fixed bootstrap_hdfs.sh (Revision 1445320)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/bin/bootstrap_hdfs.sh
","12/Feb/13 19:56;hudson;Integrated in Accumulo-Trunk-Hadoop-2.0 #86 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/86/])
    ACCUMULO-645 fixed bootstrap_hdfs.sh (Revision 1445320)

     Result = SUCCESS
kturner : 
Files : 
* /accumulo/trunk/bin/bootstrap_hdfs.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
number of Fate threads in the master is not configurable,ACCUMULO-778,12609453,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,27/Sep/12 21:06,18/Jan/13 16:10,13/Mar/19 22:01,10/Jan/13 20:30,,,,,,,,1.5.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-10 21:25:10.519,,,no_permission,,,,,,,,,,,,246298,,,Fri Jan 18 16:10:38 UTC 2013,,,,,,0|i07l5z:,42195,,,,,,,,10/Jan/13 20:30;ecn;added config item in 1431616,"10/Jan/13 21:25;hudson;Integrated in Accumulo-Trunk #626 (See [https://builds.apache.org/job/Accumulo-Trunk/626/])
    ACCUMULO-778: made the number of fate threads configurable (Revision 1431616)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
","18/Jan/13 16:10;hudson;Integrated in Accumulo-1.4.x #268 (See [https://builds.apache.org/job/Accumulo-1.4.x/268/])
    ACCUMULO-778 (Configurable FATE threads in master) backport to 1.4 branch (Revision 1435198)

     Result = SUCCESS
drew : 
Files : 
* /accumulo/branches/1.4/src/core/src/main/java/org/apache/accumulo/core/conf/Property.java
* /accumulo/branches/1.4/src/server/src/main/java/org/apache/accumulo/server/master/Master.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
No appenders for logger in TransactionWatcherTest,ACCUMULO-689,12598656,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,medined,medined,13/Jul/12 02:13,14/Jan/13 20:41,13/Mar/19 22:01,14/Jan/13 20:09,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"I ran ""mvn clean package -P assemble"" and looked at the output. I noticed the following message: 

188 Running org.apache.accumulo.fate.zookeeper.TransactionWatcherTest
189 log4j:WARN No appenders could be found for logger (org.apache.accumulo.fate.zookeeper.TransactionWatcher).
190 log4j:WARN Please initialize the log4j system properly.
191 log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
",Ubuntu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-07-13 19:59:24.436,,,no_permission,,,,,,,,,,,,246379,,,Mon Jan 14 20:41:42 UTC 2013,,,,,,0|i07lnr:,42275,,,,,,,,"13/Jul/12 19:59;jvines;Argh, logging examples again!",14/Jan/13 20:09;ecn;fixed with revision 1433090.,"14/Jan/13 20:41;hudson;Integrated in Accumulo-Trunk #636 (See [https://builds.apache.org/job/Accumulo-Trunk/636/])
    ACCUMULO-689 provide log4j initialization properties for the unit tests (Revision 1433090)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/fate/src/test/resources
* /accumulo/trunk/fate/src/test/resources/log4j.properties
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add description of the BatchWriter behavior,ACCUMULO-733,12603959,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,18/Aug/12 17:04,10/Jan/13 16:37,13/Mar/19 22:01,10/Jan/13 16:28,,,,,,,,1.5.0,,,docs,,,,,,0,,,,,"Keith Turner wrote up a nice description of the BatchWriter on the gora mailing list. I think it deserves to be in the BatchWriter documentation:

{quote}
When the user creates a
BatchWriter to write to Accumulo they specify how much memory and how
many threads it should use.  As the user adds mutations to the batch
writer it buffers them.  Once the buffered mutations have used half of
the user specified, the mutations are dumped into the background to be
written by a thread pool.  If the user specified memory completely
fills up, then writes are held.  When a user calls flush, it does not
return until all buffered mutations are written.
{quote}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-10 16:37:50.83,,,no_permission,,,,,,,,,,,,246341,,,Thu Jan 10 16:37:50 UTC 2013,,,,,,0|i07lfj:,42238,,,,,,,,10/Jan/13 16:28;ecn;added documentation with revision 1431485,"10/Jan/13 16:37;hudson;Integrated in Accumulo-Trunk #624 (See [https://builds.apache.org/job/Accumulo-Trunk/624/])
    ACCUMULO-733 added description to BatchWriter documentation (Revision 1431485)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/BatchWriter.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
race between log file recovery and fate initialization,ACCUMULO-950,12626831,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,09/Jan/13 19:32,09/Jan/13 20:10,13/Mar/19 22:01,09/Jan/13 19:38,,,,,,,,,,,master,,,,,,0,,,,,"{noformat}
Error processing table state for store Root Tablet
	java.lang.NullPointerException
		at org.apache.accumulo.server.master.Master.recoverLogs(Master.java:2107)
		at org.apache.accumulo.server.master.Master$TabletGroupWatcher.run(Master.java:1396
{noformat}

Fate needs to be initialized before recovery can be started.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-09 20:10:03.764,,,no_permission,,,,,,,,,,,,303450,,,Wed Jan 09 20:10:03 UTC 2013,,,,,,0|i17b93:,250791,,,,,,,,"09/Jan/13 20:10;hudson;Integrated in Accumulo-Trunk #621 (See [https://builds.apache.org/job/Accumulo-Trunk/621/])
    ACCUMULO-950 start fate before logs can be recovered (Revision 1431021)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/master/Master.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ignore JetBrains .idea and .iml files,ACCUMULO-929,12625969,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,medined,medined,medined,04/Jan/13 03:27,04/Jan/13 04:15,13/Mar/19 22:01,04/Jan/13 03:29,1.5.0,,,,,,,1.5.0,,,,,,,,,0,,,,,I am trying JetBrains and would not want to accidentally upload its configuration files to the code repository.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2013-01-04 04:15:38.847,,,no_permission,,,,,,,,,,,,302551,,,Fri Jan 04 04:15:38 UTC 2013,,,,,,0|i173wn:,249600,,,,,,,,04/Jan/13 03:29;medined;SVN#1428709,"04/Jan/13 04:15;hudson;Integrated in Accumulo-Trunk #607 (See [https://builds.apache.org/job/Accumulo-Trunk/607/])
    ACCUMULO-929: Ignore JetBrains .idea and .iml files (Revision 1428709)

     Result = SUCCESS
medined : 
Files : 
* /accumulo/trunk
* /accumulo/trunk/.gitignore
* /accumulo/trunk/assemble
* /accumulo/trunk/core
* /accumulo/trunk/examples
* /accumulo/trunk/examples/instamo
* /accumulo/trunk/examples/simple
* /accumulo/trunk/fate
* /accumulo/trunk/server
* /accumulo/trunk/start
* /accumulo/trunk/test
* /accumulo/trunk/trace
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix deprecation warnings due to upgrade to a more recent version of junit,ACCUMULO-857,12616418,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,16/Nov/12 15:06,16/Nov/12 16:20,13/Mar/19 22:01,16/Nov/12 15:09,,,,,,,,1.5.0,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-11-16 16:20:37.628,,,no_permission,,,,,,,,,,,,258199,,,Fri Nov 16 16:20:37 UTC 2012,,,,,,0|i0knpr:,118659,,,,,,,,"16/Nov/12 16:20;hudson;Integrated in Accumulo-Trunk #556 (See [https://builds.apache.org/job/Accumulo-Trunk/556/])
    ACCUMULO-857 fix deprecation warnings (Revision 1410388)

     Result = SUCCESS
ecn : 
Files : 
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/client/mock/MockConnectorTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/iterators/user/IntersectingIteratorTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/LocalityGroupUtilTest.java
* /accumulo/trunk/core/src/test/java/org/apache/accumulo/core/util/shell/command/FormatterCommandTest.java
* /accumulo/trunk/fate/src/test/java/org/apache/accumulo/fate/zookeeper/DistributedReadWriteLockTest.java
* /accumulo/trunk/fate/src/test/java/org/apache/accumulo/fate/zookeeper/TransactionWatcherTest.java
* /accumulo/trunk/pom.xml
* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/monitor/ZooKeeperStatus.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/client/BulkImporterTest.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/gc/TestConfirmDeletes.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/master/balancer/DefaultLoadBalancerTest.java
* /accumulo/trunk/server/src/test/java/org/apache/accumulo/server/master/balancer/TableLoadBalancerTest.java
* /accumulo/trunk/trace/src/test/java/org/apache/accumulo/cloudtrace/instrument/CountSamplerTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move README_UBUNTU to docs directory.,ACCUMULO-781,12610024,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,medined,medined,medined,03/Oct/12 03:11,18/Oct/12 03:11,13/Mar/19 22:01,03/Oct/12 03:14,,,,,,,,1.5.0,,,docs,,,,,,0,,,,,Reference email exchange with Keith from Aug 2. Move Ubuntu readme to docs directory and add a description of which release was used.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-10-18 03:11:06.494,,,no_permission,,,,,,,,,,,,246296,,,Thu Oct 18 03:11:06 UTC 2012,,,,,,0|i07l5b:,42193,,,,,,,,03/Oct/12 03:14;medined;SVN#1393270,"18/Oct/12 03:11;hudson;Integrated in Accumulo-Trunk #526 (See [https://builds.apache.org/job/Accumulo-Trunk/526/])
    ACCUMULO-781: Move README_UBUNTU to docs directory. (the file came back...let's hope it stays gone.) (Revision 1399505)

     Result = SUCCESS
medined : 
Files : 
* /accumulo/trunk/README_UBUNTU
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
timing too tight on LargeRowTest functional test,ACCUMULO-815,12612039,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,,ecn,ecn,16/Oct/12 14:13,16/Oct/12 14:14,13/Mar/19 22:01,16/Oct/12 14:14,,,,,,,,1.4.2,,,,,,,,,0,,,,,"Test is working properly, but does not wait long enough for the tablet to split.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,248992,,,2012-10-16 14:13:30.0,,,,,,0|i0a3cf:,56815,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CheckBalance in randomwalk tests is too sensitive,ACCUMULO-643,12595091,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,,ecn,ecn,19/Jun/12 11:55,15/Oct/12 14:08,13/Mar/19 22:01,15/Oct/12 14:08,1.4.1,,,,,,,1.4.2,,,test,,,,,,0,,,,,"A few randomwalks failed with failed CheckBalance.  After inspecting the code, it is ensuring that no tablet server is hosting more or less than the average number of tablets.  This is a little tight since the table load balancer allows for a little more uneven distribution of tablets, and there will be moments of unbalance during merges and agitation.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246424,,,2012-06-19 11:55:00.0,,,,,,0|i07lxz:,42321,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
randomwalk won't run out of a codebase served on a shared filesystem,ACCUMULO-644,12595094,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,,ecn,ecn,19/Jun/12 12:09,15/Oct/12 13:59,13/Mar/19 22:01,15/Oct/12 13:59,1.4.0,,,,,,,1.4.2,,,test,,,,,,0,,,,,"Tried to run randomwalk out of a codebase distributed by NFS on a small test cluster.  The test fails when it tries to unpack the configuration since it already exists because another walker already pulled it down and unpacked it.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246423,,,2012-06-19 12:09:36.0,,,,,,0|i07lxr:,42320,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
large ParNew can cause long-term stop-the-world java GC,ACCUMULO-798,12611054,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,09/Oct/12 20:12,10/Oct/12 19:44,13/Mar/19 22:01,10/Oct/12 19:44,1.4.1,,,,,,,1.4.2,,,tserver,,,,,,0,,,,,"While running a tserver with 16G of JVM memory, under continuous ingest, a ParNew collection took longer than 40 seconds.  This happened on two different servers (out of 40) after performing continuous ingest for more than 20 hours.

Limiting the ParNew generation to 2G, and never saw this failure again.

Recommend this setting in the examples, even though none of the examples approaches this memory size.",running a tserver with a very large memory foot-print (16G),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246488,,,Wed Oct 10 19:44:23 UTC 2012,,,,,,0|i07pw7:,42961,,,,,,,,10/Oct/12 19:44;ecn;fixed in r1396758 for 1.4 and r1396760 in 1.5 (trunk),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BatchVerify randomwalk test does not close its scanner,ACCUMULO-642,12595090,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,dlmarion,ecn,ecn,19/Jun/12 11:43,09/Sep/12 20:58,13/Mar/19 22:01,09/Sep/12 20:58,1.4.1,,,,,,,1.4.2,,,test,,,,,,0,test,,,,"Emitted during the test:

{noformat}
18 16:26:47,283 [impl.TabletServerBatchReader] WARN : TabletServerBatchReader not shutdown; did you forget to call close()?
18 16:27:12,865 [impl.TabletServerBatchReader] WARN : TabletServerBatchReader not shutdown; did you forget to call close()?
18 16:27:12,867 [impl.TabletServerBatchReader] WARN : TabletServerBatchReader not shutdown; did you forget to call close()?
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,08/Sep/12 22:48;dlmarion;ACCUMULO-642-1.patch;https://issues.apache.org/jira/secure/attachment/12544370/ACCUMULO-642-1.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-09-08 22:48:25.245,,,no_permission,,,,,,,,,,,,246425,,,Sun Sep 09 20:58:50 UTC 2012,,,,,,0|i07ly7:,42322,,,,,,,,08/Sep/12 22:48;dlmarion;Closed scanner in a finally block,"09/Sep/12 20:58;elserj;r1382566: Applied patch to 1.4
r1382578: Merge 1.4 into trunk

Thanks for the patch, Dave.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
WrappingIterator's seenSeek should be protected,ACCUMULO-675,12597689,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,bills,bills,bills,06/Jul/12 03:37,07/Sep/12 01:19,13/Mar/19 22:01,23/Jul/12 21:23,1.4.0,1.4.1,,,,,,1.4.2,1.5.0,,tserver,,,,,,0,,,,,"In 1.3, the WrappingIterator was pretty much some boilerplate code. In 1.4 on, a package private boolean called seenSeek was added to help enforce the iterator contract.

This causes some issues with iterators written for 1.3 and before, because the seenSeek property can't be set by an iterator outside of the core.iterators package, which is locked down. This means that sub iterators must always delegate up to the WrappingIterator's seek() method, even if implementors want to completely override seek().

I would like to provide more documentation on the WrappingIterator and make the seenSeek property protected so implementors don't need conditional logic to make the call to super.seek().","OSX, Linux",,,,,,,,,,,,,,,,,,,,,,,60,60,,0%,60,60,,,,,,,,,,,,,,,,,,,,,,,06/Jul/12 03:42;bills;wrapping-iterator-mod.patch;https://issues.apache.org/jira/secure/attachment/12535311/wrapping-iterator-mod.patch,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,2012-07-09 17:49:45.959,,,no_permission,,,,,,,,,,,,246392,,,Sun Jul 22 01:39:27 UTC 2012,,,,,,0|i07lqn:,42288,,,,,,,,06/Jul/12 03:42;bills;Added documentation to WrappingIterator and made seenSeek's visibility protected.,09/Jul/12 17:49;billie.rinaldi;I'm not convinced it's necessary to make seenSeek protected; it seems like it will just make it easier for iterators to circumvent the checking that is done to ensure the proper iterator lifecycle is observed.  Do you have a specific use case where you can't call super.seek instead?,"09/Jul/12 19:13;bills;Because the WrappingIterator just ends up calling source.seek(...) there really isn't a use case that excludes that. It was just a surprise for me to find that `getSource().seek(...)` and `super.seek(...)` are longer equivalent, so backwards compatibility with 1.3 was broken.

If WrappingIterator's seek will only ever delegate to the source's seek method, then you're right, there really isn't an issue. But, the checks in place can be just as easily circumvented by overriding any of the other methods. At the very least making seenSeek protected will allow clients to make an effort to properly adhere to the contract, rather than simply avoiding the checks by overriding methods.","10/Jul/12 16:06;billie.rinaldi;I'm in favor of the javadocs explaining how the usage of WrappingIterator has changed.  If subclasses are allowed to change seenSeek, I could see people getting an error when they do something like findTop() in the init method, and just setting seenSeek to true to get rid of the error without learning about the iterator lifecycle.  Perhaps this is misguided, but I think at this stage we want to draw as much attention as possible to the fact that we're trying to define the iterator lifecycle more clearly.  I could see backing this off at some point once people have become familiar with the lifecycle.  We could even consider removing these checks from WrappingIterator eventually, although they've been useful for making sure our internal iterators are doing the right things.

What do you think about the following?

{noformat}
/**
 * A convenience class for implementing iterators that select, but do not modify, entries read from a source iterator. Default implementations exist for all
 * methods, but {@link #deepCopy} will throw an <code>UnsupportedOperationException</code>.
 * 
 * This iterator has some checks in place to enforce the iterator contract. Specifically, it verifies that it has a source iterator and that {@link #seek} has
 * been called before any data is read. If either of these conditions does not hold true, an <code>IllegalStateException</code> will be thrown. In particular,
 * this means that <code>getSource().seek</code> and <code>super.seek</code> no longer perform identical actions. Implementors should take note of this and if
 * <code>seek</code> is overridden, ensure that <code>super.seek</code> is called before data is read.
 */
{noformat}
",22/Jul/12 01:39;bills;Looks good to me.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
run the functional tests with the typical jvm args,ACCUMULO-541,12551087,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,16/Apr/12 16:59,06/Sep/12 18:13,13/Mar/19 22:01,01/May/12 17:33,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,test,,,,,,0,qa-ft-1.5.0,,,,the options configuring the jvm gc are not used when running the functional tests,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235951,,,2012-04-16 16:59:29.0,,,,,,0|i07mkf:,42422,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
typo in user manual for 1.3 on aggregating iterators,ACCUMULO-661,12596245,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,,ecn,ecn,28/Jun/12 11:48,28/Jun/12 11:50,13/Mar/19 22:01,28/Jun/12 11:50,1.3.5-incubating,,,,,,,1.3.6,,,,,,,,,0,,,,,"Reported by Priya M:
{noformat}
http://accumulo.apache.org/user_manual_1.3-incubating/Table_Configuration.html#Aggregating_Iterators

Is the aggregate value for row2 counted incorrectly, since the rowKey for the last two rows seem to be different.

user@myinstance perDayCounts> insert row1 day 20080101 1
user@myinstance perDayCounts> insert row1 day 20080101 1
user@myinstance perDayCounts> insert row1 day 20080103 1
user@myinstance perDayCounts> insert row2 day 20080101 1
user@myinstance perDayCounts> insert row3 day 20080101 1

user@myinstance perDayCounts> scan
row1 day:20080101 [] 2
row1 day:20080103 [] 1
row2 day:20080101 [] 2
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246406,,,2012-06-28 11:48:49.0,,,,,,0|i07ltr:,42302,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MockAccumulo throws NPE if table doesn't exist,ACCUMULO-634,12560542,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,13/Jun/12 18:04,22/Jun/12 20:23,13/Mar/19 22:01,22/Jun/12 20:23,1.3.5-incubating,1.4.0,,,,,,1.5.0,,,client,,,,,,0,mock,,,,"When you create a batch writer for a table doesn't exist, MockAccumulo throws NPE instead of TableNotFoundException.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246432,,,2012-06-13 18:04:42.0,,,,,,0|i07lzr:,42329,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
accumulo runs fine on Hadoop 1.0,ACCUMULO-615,12559251,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,04/Jun/12 19:01,18/Jun/12 18:08,13/Mar/19 22:01,18/Jun/12 18:08,,,,,,,,1.3.6,1.4.1,,scripts,,,,,,0,,,,,The check for hadoop 0.20 is causing more problems than it solves now.  Remove the check.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,246451,,,2012-06-04 19:01:21.0,,,,,,0|i07m3z:,42348,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dirlist example README is a little inconsistent,ACCUMULO-570,12553665,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,02/May/12 20:45,02/May/12 20:48,13/Mar/19 22:01,02/May/12 20:48,1.4.0,,,,,,,1.4.1,1.5.0,,docs,,,,,,0,,,,,"The README.dirlist sometimes shows the authorizations as ""auths"" and sometimes as exampleVis.  The new ""-e"" shell option could help explain how to give the auths to a user.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,237858,,,2012-05-02 20:45:23.0,,,,,,0|i07mdz:,42393,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
deprecate/remove the option on bulkImport that prevents the GC from deleting the files,ACCUMULO-555,12552159,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,23/Apr/12 16:37,01/May/12 19:06,13/Mar/19 22:01,01/May/12 19:06,1.4.1,,,,,,,1.5.0,,,client,,,,,,0,,,,,"This ""feature"" is a hold-over from the days when bulk import and the GC had problems coordinating their actions.  Now it just confuses users.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-04-23 16:45:40.883,,,no_permission,,,,,,,,,,,,237686,,,Mon Apr 23 16:45:40 UTC 2012,,,,,,0|i07mhb:,42408,,,,,,,,23/Apr/12 16:45;kturner;This feature was not because bulk import and GC had issues coordinating.  It was a user requested feature.  The user wanted the option to keep their original data.  Not sure if was ever really used though.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test creates a core/null directory,ACCUMULO-568,12553494,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,billie.rinaldi,billie.rinaldi,billie.rinaldi,01/May/12 15:16,01/May/12 15:18,13/Mar/19 22:01,01/May/12 15:18,,,,,,,,1.5.0,,,test,,,,,,0,,,,,"When ACCUMULO_HOME isn't set, AccumuloFileOutputFormatTest creates a directory called ""null"" and doesn't clean it up.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,237658,,,2012-05-01 15:16:26.0,,,,,,0|i07mef:,42395,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"monitor should display zero tablet servers as red, even if there's only one tablet server configured",ACCUMULO-566,12553368,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,30/Apr/12 13:59,30/Apr/12 16:26,13/Mar/19 22:01,30/Apr/12 16:26,1.3.6,1.4.0,,,,,,1.4.1,1.5.0,,monitor,,,,,,0,,,,,didn't realize my tablet server had crashed in my development environment: zero tablet servers is always a problem.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,237522,,,2012-04-30 13:59:26.0,,,,,,0|i07mev:,42397,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
enabling tracing in clients requires access to an accumulo-site.xml configuration file,ACCUMULO-559,12552635,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,25/Apr/12 12:39,26/Apr/12 16:49,13/Mar/19 22:01,26/Apr/12 16:49,1.3.5-incubating,,,,,,,1.3.6,,,client,,,,,,0,,,,,"DistributedTrace.enable() uses the site configuration to find zookeeper, and it should use the provided instance.getZooKeepers().",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,236856,,,Thu Apr 26 16:49:35 UTC 2012,,,,,,0|i07mgf:,42404,,,,,,,,26/Apr/12 16:49;ecn;Inadvertently used the wrong ticket number on the merge to 1.4 and trunk. See revision #1330946 and #1330944.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix warning about deprecated md5 module when running functional tests,ACCUMULO-539,12551057,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,16/Apr/12 13:16,16/Apr/12 17:02,13/Mar/19 22:01,16/Apr/12 13:18,1.4.0,,,,,,,1.5.0,,,test,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,235921,,,2012-04-16 13:16:49.0,,,,,,0|i07mkv:,42424,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
low-memory warning message is incorrect,ACCUMULO-468,12547011,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,19/Mar/12 12:14,19/Mar/12 14:25,13/Mar/19 22:01,19/Mar/12 14:25,,,,,,,,1.4.1,,,,,,,,,0,,,,,"The tablet server allocated 6g, and never grew larger, however there were many warnings about getting low on memory.",testing on a large cluster with tablet server configured with -Xmx12g -Xms6g,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,232169,,,2012-03-19 12:14:16.0,,,,,,0|i07n07:,42493,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
monitor page warns if the number of tablets goes into the hundreds of thousands: this is no longer a significant limitation to scalability,ACCUMULO-300,12537967,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,10/Jan/12 21:10,09/Feb/12 14:05,13/Mar/19 22:01,09/Feb/12 14:05,,,,,,,,1.4.0,,,monitor,,,,,,0,,,,,"Master used to hold all tablets in memory, which limited the total number of tablets that the system could have.  Now the state is saved in the METADATA table, so this is no longer an issue.  Turn off the warning display.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2012-01-10 21:52:05.728,,,no_permission,,,,,,,,,,,,223473,,,Tue Jan 10 23:10:12 UTC 2012,,,,,,0|i07o07:,42655,,,,,,,,10/Jan/12 21:52;billie.rinaldi;Should we instead warn if the number of tablets is more than a couple of thousand per tablet server?,"10/Jan/12 22:37;ecn;Or 10K?  We have many clusters already over the 2K/server range, and they seem to be working just fine.  And tablet merging (in 1.4) lowers the need to worry too much about this.",10/Jan/12 23:10;afuchs;I think this is a perfect place to throw in some nice flame graphics. Or maybe just some Speed Racer fonts (http://assets.huluim.com/shows/key_art_speed_racer.jpg).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need a simple way to add tracing to clients,ACCUMULO-194,12533278,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,30/Nov/11 12:25,05/Jan/12 22:42,13/Mar/19 22:01,30/Nov/11 18:51,,,,,,,,1.4.0,,,client,,,,,,0,,,,,There are 3 lines of code that turn on tracing in the shell.  Create a simple utility method that all clients can use.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-11-30 15:43:29.407,,,no_permission,,,,,,,,,,,,219006,,,Wed Nov 30 18:50:58 UTC 2011,,,,,,0|i07onj:,42760,,,,,,,,"30/Nov/11 13:08;ecn;Should this be added to the client library, should it be accessed via Instance?  Should we provide a mock instance?",30/Nov/11 15:43;kturner; Could it be a static method in cloudtrace?  Not familiar enough w/ what needs to be done to know if this is a good option.,30/Nov/11 18:50;ecn;Use existing convenience method that I forgot I wrote.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
servers are exiting without logging an unexpected exception,ACCUMULO-113,12529907,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,02/Nov/11 17:26,27/Dec/11 18:43,13/Mar/19 22:01,27/Dec/11 18:43,,,,,,,,1.4.0,,,logger,master,tserver,,,,0,,,,,"If an unexpected exception causes one of the servers to stop, it should log the exception.
",Badly configured tserver under functional test would exit and not log the exception making it difficult to debug,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215766,,,2011-11-02 17:26:32.0,,,,,,0|i07p53:,42839,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
spell check the documentation,ACCUMULO-165,12532147,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,21/Nov/11 13:04,30/Nov/11 20:05,13/Mar/19 22:01,30/Nov/11 20:05,1.3.5-incubating,,,,,,,1.3.6,1.4.0,,docs,,,,,,0,,,,,"""garuantees"" in the isolation documentation.  Should try to go through any recent documentation and give it a quick scan.
",,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,217883,,,2011-11-21 13:04:37.0,,,,,,0|i07otz:,42789,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
config.html not built properly for accumulo-1.3.4rc4,ACCUMULO-124,12530620,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,07/Nov/11 19:24,30/Nov/11 18:56,13/Mar/19 22:01,30/Nov/11 18:56,,,,,,,,1.3.5-incubating,,,docs,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,216358,,,2011-11-07 19:24:31.0,,,,,,0|i07p2n:,42828,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"if accumulo is run as a non-hadoop user, the monitor says the NameNode is down",ACCUMULO-192,12533165,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,29/Nov/11 18:32,29/Nov/11 18:37,13/Mar/19 22:01,29/Nov/11 18:37,1.3.5-incubating,,,,,,,1.4.0,,,monitor,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,218893,,,2011-11-29 18:32:17.0,,,,,,0|i07onz:,42762,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Off-by-one error in FamilyIntersectingIterator,ACCUMULO-178,12532511,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,jasontrost,jasontrost,jasontrost,23/Nov/11 18:21,28/Nov/11 20:29,13/Mar/19 22:01,24/Nov/11 15:30,1.3.5-incubating,,,,,,,1.3.6,1.4.0,,tserver,,,,,,0,patch,,,,In the buildDocKey() function within the FamilyIntersectingIterator there is a bug that shortens the docID by 1.  This causes the wrong doc's data to be returned in the results of a query using this Iterator.,,,,,,,,,,,,,,,,,,,,,,,,60,60,,0%,60,60,,,,,,,,,,,,,,,,,,,,,,,24/Nov/11 03:42;jasontrost;family-iterator-with-tests.patch;https://issues.apache.org/jira/secure/attachment/12504976/family-iterator-with-tests.patch,23/Nov/11 18:29;jasontrost;family-iterator.patch;https://issues.apache.org/jira/secure/attachment/12504904/family-iterator.patch,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,2011-11-23 19:43:03.943,,,no_permission,,,,,,,,,,,,218244,,,Thu Nov 24 03:42:25 UTC 2011,,,,,,0|i07or3:,42776,,,,,,,,23/Nov/11 18:29;jasontrost;see attached patch.,"23/Nov/11 19:43;ecn;Thanks Jason!  Could I trouble you to add to the FamilyIntersectingIteratorTest so that the bug is demonstrated/detected?

",24/Nov/11 03:42;jasontrost;See attached patch.  These test cases now look for the correct value associated with the docID.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
subheading text falls outside header border,ACCUMULO-176,12532487,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,23/Nov/11 16:17,23/Nov/11 16:21,13/Mar/19 22:01,23/Nov/11 16:21,,,,,,,,1.4.0,,,monitor,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,300,300,,0%,300,300,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,218220,,,2011-11-23 16:17:23.0,,,,,,0|i07orj:,42778,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"the digest used to protect data in zookeeper is ""cb:password""; change this to ""accumulo:password""",ACCUMULO-60,12528033,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,20/Oct/11 21:35,18/Nov/11 15:03,13/Mar/19 22:01,20/Oct/11 21:50,,,,,,,,1.4.0,,,,,,,,,0,,,,,"If users need to modify zookeeper values from the zkCli.sh utility, they will need to

{noformat}
[zk: zoohost:2181(CONNECTED) 0] setauth digest accumulo:somePassword
{noformat}

It would be confusing to leave it as ""cb"".  Be prepared to wipe your zookeeper, because this will make all your users' passwords unreadable.",,,,,,,,,,,,,,,,,,,,,,,,300,300,,0%,300,300,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,95663,,,Thu Oct 20 21:37:22 UTC 2011,,,,,,0|i07pgv:,42892,,,,,,,,"20/Oct/11 21:37;ecn;Oh, looks like I already changed it to ""acu""... unnecessarily abbreviated; changing it to ""accumulo"" anyhow.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
developer's manual is out of date,ACCUMULO-71,12528742,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,25/Oct/11 19:17,18/Nov/11 14:59,13/Mar/19 22:01,27/Oct/11 19:26,,,,,,,,1.3.5-incubating,1.4.0,,docs,,,,,,0,,,,," * still has reference to map-reduce for log recoveries; this is no longer true
 * lists the load balancer API, which changed from 1.2 -> 1.3",,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,2011-10-25 19:27:29.772,,,no_permission,,,,,,,,,,,,214602,,,Tue Oct 25 19:27:29 UTC 2011,,,,,,0|i07pef:,42881,,,,,,,,25/Oct/11 19:27;kturner;The users manual also mentions map reduce for log recovery,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
all files in the tarball are executable.,ACCUMULO-117,12530042,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,03/Nov/11 13:41,18/Nov/11 14:41,13/Mar/19 22:01,08/Nov/11 20:13,,,,,,,,1.3.5-incubating,1.4.0,,build,,,,,,0,,,,,"Maybe we can tweak something in the assembly instructions to prevent the files from being marked as rwxr-xr-x.

",unpack the release candidate: everything is executable,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215901,,,2011-11-03 13:41:48.0,,,,,,0|i07p47:,42835,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
more 1.3.5 release issues,ACCUMULO-125,12530630,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,07/Nov/11 21:00,18/Nov/11 14:40,13/Mar/19 22:01,10/Nov/11 20:20,,,,,,,,1.3.5-incubating,,,docs,,,,,,0,,,,," * PDF had upside-down question marks for '>'
 * references to classpaths did not have ""org.apache""
 * links to api docs did not have ""org/apache/"" 
 * .so shared libs were packed in the src tree",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,216368,,,2011-11-07 21:00:08.0,,,,,,0|i07p2f:,42827,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
accumulo_sample/ingest/bin/ingest.sh is not executable,ACCUMULO-130,12530882,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,09/Nov/11 14:59,18/Nov/11 14:22,13/Mar/19 22:01,14/Nov/11 20:51,,,,,,,,1.4.0,,,,,,,,,0,,,,,"Following the accumulo_sample instructions, ingest/bin/ingest.sh is not executable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,216620,,,2011-11-09 14:59:37.0,,,,,,0|i07p1b:,42822,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
distributed documentation is not complete: missing the line to find the tracers,ACCUMULO-99,12529379,Bug,Resolved,ACCUMULO,Accumulo,software,mjwall,"Accumulo is a sorted, distributed key/value store based on Google's BigTable design. It is built on top of Apache Hadoop, Zookeeper, and Thrift. It features a few novel improvements on the BigTable design in the form of cell-level access labels and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.",https://accumulo.apache.org/,Trivial,Fixed,ecn,ecn,ecn,29/Oct/11 19:09,29/Oct/11 20:14,13/Mar/19 22:01,29/Oct/11 20:14,,,,,,,,,,,docs,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,no_permission,,,,,,,,,,,,215239,,,2011-10-29 19:09:10.0,,,,,,0|i07p87:,42853,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
