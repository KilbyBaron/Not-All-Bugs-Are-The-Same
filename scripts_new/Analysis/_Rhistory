t6_results[1,] <- c("Project", "Features", "Y #Bugs", "Y ChgLines", "Y Exp", "Y Priority")
i <- 2
#Calculate contributions for each dependent variable of each project
for (current_project in c("accumulo","bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket"))
{
print(current_project)
#Extract project data and standardize indep. & dep. variables
p_df <- filter(df, project == current_project)
p_df[c("LOC","CC","churn","exp","bfs","num_bugs","priority")] <- lapply(p_df[c("LOC","CC","churn","exp","bfs","num_bugs","priority")], function(x) c(scale(x, center= min(x), scale=diff(range(x)))))
#Build generalized linear models for each dependent variable
m_exp <- lm(exp ~ LOC+CC+churn, data=p_df, x=T, y=T)
#print(summary(fit_exp))
m_bfs <- lm(bfs ~ LOC+CC+churn, data=p_df, x=T, y=T)
#print(summary(fit_bfs))
m_bugs <- lm(num_bugs ~ LOC+CC+churn, data=p_df, x=T, y=T)
#print(summary(m_bugs))
m_priority <- lm(priority ~ LOC+CC+churn, data=p_df, x=T, y=T)
## RCS WAS CAUSING ERROR, FIND OUT WHY
print(1)
#Build generalized linear models for each dependent variable
#m_exp <- lm(exp ~ LOC+CC+rcs(churn,3), data=p_df, x=T, y=T)
#m_bfs <- lm(bfs ~  LOC+CC+rcs(churn,3), data=p_df, x=T, y=T)
#m_bugs <- lm(num_bugs ~ LOC+CC+rcs(churn,3), data=p_df, x=T, y=T)
print(2)
#Calculate R^2
#lmg is the R^2 contribution averaged over orderings among regressors
lmg_exp <- calc.relimp(m_exp, type="lmg", rela=TRUE)@lmg
lmg_bfs <- calc.relimp(m_bfs, type="lmg", rela=TRUE)@lmg
lmg_bugs <- calc.relimp(m_bugs, type="lmg", rela=TRUE)@lmg
lmg_priority <- calc.relimp(m_priority, type="lmg", rela=TRUE)@lmg
print(3)
#Add results to maxtrix
t6_results[i,] <- c(current_project, "X LOC", lmg_bugs['LOC'], lmg_bfs['LOC'], lmg_exp['LOC'], lmg_priority['LOC'])
t6_results[i+1,] <- c(current_project, "X CC", lmg_bugs['CC'], lmg_bfs['CC'], lmg_exp['CC'], lmg_priority['CC'])
t6_results[i+2,] <- c(current_project, "X churn", lmg_bugs['churn'], lmg_bfs['churn'], lmg_exp['churn'], lmg_priority['churn'])
## RCS ERROR DOWN HERE TOO!!! AHHHHHH
#t6_results[i+2,] <- c(current_project, "X churn", lmg_bugs['rcs(churn, 3).churn'], lmg_bfs['rcs(churn, 3).churn'], lmg_exp['rcs(churn, 3).churn'])
i <- i+3
}
write.csv(t6_results, file = "/home/kjbaron/Documents/NABATS/intermediate_files/t6_results.csv",row.names=FALSE,na="")
###########################################
#
# FILE LEVEL CORRELATION TEST
#
###########################################
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/final_dataset.csv", header = TRUE)
file_data <- filter(file_data, num_post > 0)
#Since bfs, priority, and exp are all sumations, I calculate the averages before calculating the correlation
file_data$avg_exp <- with(file_data, ifelse(num_bugs==0, 0, exp/num_bugs))
file_data$avg_pri <- with(file_data, ifelse(num_bugs==0, 0, priority/num_bugs))
library("ggpubr")
ggscatter(file_data, x = "avg_pri", y = "avg_exp",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "Priority", ylab = "Experience")
# -1 indicates a strong negative correlation : this means that every time x increases, y decreases (left panel figure)
#  0 means that there is no association between the two variables (x and y) (middle panel figure)
#  1 indicates a strong positive correlation : this means that y increases with x (right panel figure)
res <- cor.test(file_data$priority, file_data$exp, method = "pearson")
res
res$p.value
res$estimate
file_data <- filter(file_data, num_post > 0)
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/final_dataset.csv", header = TRUE)
file_data <- filter(file_data, num_post > 0)
colnames(file_data)
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/final_dataset.csv", header = TRUE)
file_data <- filter(file_data, "num_post" > 0)
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/final_dataset.csv", header = TRUE)
file_data <- filter(file_data, "num_post" > 0)
#Since bfs, priority, and exp are all sumations, I calculate the averages before calculating the correlation
file_data$avg_exp <- with(file_data, ifelse(num_bugs==0, 0, exp/num_bugs))
file_data$avg_pri <- with(file_data, ifelse(num_bugs==0, 0, priority/num_bugs))
library("ggpubr")
ggscatter(file_data, x = "avg_pri", y = "avg_exp",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "Priority", ylab = "Experience")
# -1 indicates a strong negative correlation : this means that every time x increases, y decreases (left panel figure)
#  0 means that there is no association between the two variables (x and y) (middle panel figure)
#  1 indicates a strong positive correlation : this means that y increases with x (right panel figure)
res <- cor.test(file_data$priority, file_data$exp, method = "pearson")
res
res$p.value
res$estimate
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/final_dataset.csv", header = TRUE)
file_data <- filter(file_data, num_post > 0)
file_data <- filter(file_data, priority > 0)
#install.packages(c("dplyr","scales","relaimpo","rms","e1071","Hmisc"))
#install.packages("rms")
#install.packages("mvtnorm")
library(dplyr)
library(scales)
require(relaimpo)
library(rms)
library(e1071)
library(Hmisc)
###########################################
#
# BUG LEVEL CORRELATION TEST
#
###########################################
#Read in CSV
bug_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/target_bfcs.csv", header = TRUE)
#bug_data <- filter(bug_data, project == "CXF")
boxplot(author_exp~priority,data=bug_data, main="Correlation between Priority and Exp",
xlab="Priority", ylab="Experience")
# -1 indicates a strong negative correlation : this means that every time x increases, y decreases (left panel figure)
#  0 means that there is no association between the two variables (x and y) (middle panel figure)
#  1 indicates a strong positive correlation : this means that y increases with x (right panel figure)
res <- cor.test(bug_data$priority, bug_data$author_exp, method = "pearson")
res$p.value
res$estimate
###########################################
#
# FILE LEVEL CORRELATION TEST
#
###########################################
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/final_dataset.csv", header = TRUE)
file_data <- filter(file_data, priority > 0)
#Since bfs, priority, and exp are all sumations, I calculate the averages before calculating the correlation
file_data$avg_exp <- with(file_data, ifelse(num_bugs==0, 0, exp/num_bugs))
file_data$avg_pri <- with(file_data, ifelse(num_bugs==0, 0, priority/num_bugs))
library("ggpubr")
ggscatter(file_data, x = "avg_pri", y = "avg_exp",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "Priority", ylab = "Experience")
# -1 indicates a strong negative correlation : this means that every time x increases, y decreases (left panel figure)
#  0 means that there is no association between the two variables (x and y) (middle panel figure)
#  1 indicates a strong positive correlation : this means that y increases with x (right panel figure)
res <- cor.test(file_data$priority, file_data$exp, method = "pearson")
res
res$p.value
res$estimate
#install.packages(c("dplyr","scales","relaimpo","rms","e1071","Hmisc"))
#install.packages("rms")
#install.packages("mvtnorm")
library(dplyr)
library(scales)
require(relaimpo)
library(rms)
library(e1071)
library(Hmisc)
#Read in CSV
df <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/final_dataset2.csv", header = TRUE)
#df <- filter(df, num_bugs > 0)
#df <- na.omit(df) #remove rows with na values
#df <- filter(df, num_post > 0)
################################################################################
# (MC-1) Estimate budget for degrees of freedom
################################################################################
#Since we plan to fit using ordinary least squares, we use the below rule of
# thumb to estimate our budget
print( floor(min(nrow(df[df$exp > 0,]), nrow(df[df$exp == 0,]) )/15))
print(floor(min(nrow(df[df$bfs > 0,]), nrow(df[df$bfs == 0,]) )/15))
print(floor(min(nrow(df[df$num_bugs > 0,]), nrow(df[df$num_bugs == 0,]) )/15))
################################################################################
# (MC -2) Normality adjustment
################################################################################
# Normalize indep. & dep. variables with min-max
df[c("LOC","CC","churn","exp","bfs","num_bugs","priority")] <- lapply(df[c("LOC","CC","churn","exp","bfs","num_bugs","priority")], function(x) c(scale(x, center= min(x), scale=diff(range(x)))))
#Set independent variable names
ind_vars = c("LOC","CC","churn")
################################################################################
# (MC -3) Correlation analysis
################################################################################
#Calculate spearman's correlation between independent variables
vc <- varclus(~ ., data=df[,ind_vars], trans="abs")
#Plot hierarchical clusters and the spearman's correlation threshold of 0.7
plot(vc)
threshold <- 0.7
abline(h=1-threshold, col = "red", lty = 2)
################################################################################
# (MC -4) Redundancy analysis
################################################################################
red <- redun(~ ., data=df[,ind_vars], nk=0)
print(red)
sp <- spearman2(formula(paste("num_bugs" ," ~ ",paste0(ind_vars, collapse=" + "))), data= df, p=2)
plot(sp)
print(sp)
################################################################################
# (MC -5) Fit regression model
################################################################################
#Create a matrix to fill with R^2 values
r2_results <- matrix(ncol=5, nrow=12)
r2_results[1,] <- c("Project", "Y #Bugs", "Y ChgLines", "Y Exp", "Y Priority")
i <- 2
num_iter = 1000
#RMS package requires a data distribution when building a model
for (current_project in c("accumulo","bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket"))
{
print(current_project)
#Extract project
p_df <- filter(df, project == current_project)
p_df[c("LOC","CC","churn","exp","bfs","num_bugs","priority")] <- lapply(p_df[c("LOC","CC","churn","exp","bfs","num_bugs","priority")], function(x) c(scale(x, center= min(x), scale=diff(range(x)))))
#RMS package requires a data distribution when building a model
print(dim(p_df[,c("exp",ind_vars)]))
dd_exp <- datadist(p_df[,c("exp",ind_vars)])
options(datadist = "dd_exp")
dd_bfs <- datadist(p_df[,c("bfs",ind_vars)])
options(datadist = "dd_bfs")
dd_bugs <- datadist(p_df[,c("num_bugs",ind_vars)])
options(datadist = "dd_bugs")
dd_priority <- datadist(p_df[,c("priority",ind_vars)])
options(datadist = "dd_priority")
#Build generalized linear models for each dependent variable
fit_exp <- lm(exp ~ LOC+CC+churn, data=p_df, x=T, y=T)
#print(summary(fit_exp))
fit_bfs <- lm(bfs ~ LOC+CC+churn, data=p_df, x=T, y=T)
#print(summary(fit_bfs))
fit_bugs <- lm(num_bugs ~ LOC+CC+churn, data=p_df, x=T, y=T)
#print(summary(fit_bugs))
fit_priority <- lm(priority ~ LOC+CC+churn, data=p_df, x=T, y=T)
#Calculate R^2
#lmg is the R^2 contribution averaged over orderings among regressors\
# Metrics normalized to sum to 100% --> (rela=TRUE), otherwise --> (rela=FALSE)
r2_exp <- calc.relimp(fit_exp, type="lmg", rela=FALSE)@R2
r2_bfs <- calc.relimp(fit_bfs, type="lmg", rela=FALSE)@R2
r2_bugs <- calc.relimp(fit_bugs, type="lmg", rela=FALSE)@R2
r2_priority <- calc.relimp(fit_priority, type="lmg", rela=FALSE)@R2
print(1)
#Add results to maxtrix
r2_results[i,] <- c(current_project, r2_bugs, r2_bfs, r2_exp, r2_priority)
i <- i+1
}
write.csv(r2_results, file = "/home/kjbaron/Documents/NABATS/intermediate_files/r2_results.csv",row.names=FALSE,na="")
#  The code below is most the same as for Table 5, but rela=TRUE in the relimp calculation
#  -- just separated the code by table to keep it easy to read
#  --------------------------------------------------------------------------------------------------------------------------
#  TABLE 6 - Average contributions from each independent variable when different dependent variables are used
#  --------------------------------------------------------------------------------------------------------------------------
#Create a matrix to fill with values
t6_results <- matrix(ncol=6, nrow=34)
t6_results[1,] <- c("Project", "Features", "Y #Bugs", "Y ChgLines", "Y Exp", "Y Priority")
i <- 2
#Calculate contributions for each dependent variable of each project
for (current_project in c("accumulo","bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket"))
{
print(current_project)
#Extract project data and standardize indep. & dep. variables
p_df <- filter(df, project == current_project)
p_df[c("LOC","CC","churn","exp","bfs","num_bugs","priority")] <- lapply(p_df[c("LOC","CC","churn","exp","bfs","num_bugs","priority")], function(x) c(scale(x, center= min(x), scale=diff(range(x)))))
#Build generalized linear models for each dependent variable
m_exp <- lm(exp ~ LOC+CC+churn, data=p_df, x=T, y=T)
#print(summary(fit_exp))
m_bfs <- lm(bfs ~ LOC+CC+churn, data=p_df, x=T, y=T)
#print(summary(fit_bfs))
m_bugs <- lm(num_bugs ~ LOC+CC+churn, data=p_df, x=T, y=T)
#print(summary(m_bugs))
m_priority <- lm(priority ~ LOC+CC+churn, data=p_df, x=T, y=T)
## RCS WAS CAUSING ERROR, FIND OUT WHY
print(1)
#Build generalized linear models for each dependent variable
#m_exp <- lm(exp ~ LOC+CC+rcs(churn,3), data=p_df, x=T, y=T)
#m_bfs <- lm(bfs ~  LOC+CC+rcs(churn,3), data=p_df, x=T, y=T)
#m_bugs <- lm(num_bugs ~ LOC+CC+rcs(churn,3), data=p_df, x=T, y=T)
print(2)
#Calculate R^2
#lmg is the R^2 contribution averaged over orderings among regressors
lmg_exp <- calc.relimp(m_exp, type="lmg", rela=TRUE)@lmg
lmg_bfs <- calc.relimp(m_bfs, type="lmg", rela=TRUE)@lmg
lmg_bugs <- calc.relimp(m_bugs, type="lmg", rela=TRUE)@lmg
lmg_priority <- calc.relimp(m_priority, type="lmg", rela=TRUE)@lmg
print(3)
#Add results to maxtrix
t6_results[i,] <- c(current_project, "X LOC", lmg_bugs['LOC'], lmg_bfs['LOC'], lmg_exp['LOC'], lmg_priority['LOC'])
t6_results[i+1,] <- c(current_project, "X CC", lmg_bugs['CC'], lmg_bfs['CC'], lmg_exp['CC'], lmg_priority['CC'])
t6_results[i+2,] <- c(current_project, "X churn", lmg_bugs['churn'], lmg_bfs['churn'], lmg_exp['churn'], lmg_priority['churn'])
## RCS ERROR DOWN HERE TOO!!! AHHHHHH
#t6_results[i+2,] <- c(current_project, "X churn", lmg_bugs['rcs(churn, 3).churn'], lmg_bfs['rcs(churn, 3).churn'], lmg_exp['rcs(churn, 3).churn'])
i <- i+3
}
write.csv(t6_results, file = "/home/kjbaron/Documents/NABATS/intermediate_files/t6_results.csv",row.names=FALSE,na="")
View(r2_results)
#install.packages(c("dplyr","scales","relaimpo","rms","e1071","Hmisc"))
#install.packages("rms")
#install.packages("mvtnorm")
library(dplyr)
library(scales)
require(relaimpo)
library(rms)
library(e1071)
library(Hmisc)
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/bug_level_df.csv", header = TRUE)
# -1 indicates a strong negative correlation : this means that every time x increases, y decreases (left panel figure)
#  0 means that there is no association between the two variables (x and y) (middle panel figure)
#  1 indicates a strong positive correlation : this means that y increases with x (right panel figure)
res <- cor.test(file_data$priority, file_data$exp, method = "pearson")
################################################################################
# Fill Correlation Table
################################################################################
#Create a matrix to fill with correlation values
cor_mat <- matrix(ncol=3, nrow=4)
cor_mat[1,] <- c("M1","M2", "Correlation")
for (current_project in c("accumulo"))#,"bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket"))
{
print(current_project)
#Extract project
p_df <- filter(file_data, project == current_project)
p_df[c("exp","bfs","num_bugs","priority")] <- lapply(p_df[c("exp","bfs","num_bugs","priority")], function(x) c(scale(x, center= min(x), scale=diff(range(x)))))
pri_exp <- cor.test(file_data$avg_pri, file_data$avg_exp, method = "pearson")
bfs_exp <- cor.test(file_data$avg_bfs, file_data$avg_exp, method = "pearson")
bfs_pri <- cor.test(file_data$avg_bfs, file_data$avg_pri, method = "pearson")
#Add results to maxtrix
cor_mat[2,] <- c("Experience","Bug-Fix Size",bfs_exp$estimate)
cor_mat[3,] <- c("Experience","Priority",pri_exp$estimate)
cor_mat[4,] <- c("Priority","Bug-Fix Size",bfs_pri$estimate)
}
write.csv(cor_mat, file = "/home/kjbaron/Documents/NABATS/intermediate_files/dependent_variable_correlations.csv",row.names=FALSE,na="")
#install.packages(c("dplyr","scales","relaimpo","rms","e1071","Hmisc"))
#install.packages("rms")
#install.packages("mvtnorm")
library(dplyr)
library(scales)
require(relaimpo)
library(rms)
library(e1071)
library(Hmisc)
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/bug_level_df.csv", header = TRUE)
# -1 indicates a strong negative correlation : this means that every time x increases, y decreases (left panel figure)
#  0 means that there is no association between the two variables (x and y) (middle panel figure)
#  1 indicates a strong positive correlation : this means that y increases with x (right panel figure)
res <- cor.test(file_data$priority, file_data$exp, method = "pearson")
################################################################################
# Fill Correlation Table
################################################################################
#Create a matrix to fill with correlation values
cor_mat <- matrix(ncol=3, nrow=4)
cor_mat[1,] <- c("M1","M2", "Correlation")
for (current_project in c("accumulo"))#,"bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket"))
{
print(current_project)
#Extract project
p_df <- filter(file_data, project == current_project)
p_df[c("exp","bfs","priority")] <- lapply(p_df[c("exp","bfs","priority")], function(x) c(scale(x, center= min(x), scale=diff(range(x)))))
pri_exp <- cor.test(file_data$avg_pri, file_data$avg_exp, method = "pearson")
bfs_exp <- cor.test(file_data$avg_bfs, file_data$avg_exp, method = "pearson")
bfs_pri <- cor.test(file_data$avg_bfs, file_data$avg_pri, method = "pearson")
#Add results to maxtrix
cor_mat[2,] <- c("Experience","Bug-Fix Size",bfs_exp$estimate)
cor_mat[3,] <- c("Experience","Priority",pri_exp$estimate)
cor_mat[4,] <- c("Priority","Bug-Fix Size",bfs_pri$estimate)
}
write.csv(cor_mat, file = "/home/kjbaron/Documents/NABATS/intermediate_files/dependent_variable_correlations.csv",row.names=FALSE,na="")
View(p_df)
#install.packages(c("dplyr","scales","relaimpo","rms","e1071","Hmisc"))
#install.packages("rms")
#install.packages("mvtnorm")
library(dplyr)
library(scales)
require(relaimpo)
library(rms)
library(e1071)
library(Hmisc)
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/bug_level_df.csv", header = TRUE)
# -1 indicates a strong negative correlation : this means that every time x increases, y decreases (left panel figure)
#  0 means that there is no association between the two variables (x and y) (middle panel figure)
#  1 indicates a strong positive correlation : this means that y increases with x (right panel figure)
res <- cor.test(file_data$priority, file_data$exp, method = "pearson")
################################################################################
# Fill Correlation Table
################################################################################
#Create a matrix to fill with correlation values
cor_mat <- matrix(ncol=3, nrow=4)
cor_mat[1,] <- c("M1","M2", "Correlation")
for (current_project in c("accumulo"))#,"bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket"))
{
print(current_project)
#Extract project
p_df <- filter(file_data, project == current_project)
p_df[c("exp","bfs","priority")] <- lapply(p_df[c("exp","bfs","priority")], function(x) c(scale(x, center= min(x), scale=diff(range(x)))))
pri_exp <- cor.test(p_df$priority, p_df$exp, method = "pearson")
bfs_exp <- cor.test(p_df$bfs, p_df$exp, method = "pearson")
bfs_pri <- cor.test(p_df$bfs, p_df$priority, method = "pearson")
#Add results to maxtrix
cor_mat[2,] <- c("Experience","Bug-Fix Size",bfs_exp$estimate)
cor_mat[3,] <- c("Experience","Priority",pri_exp$estimate)
cor_mat[4,] <- c("Priority","Bug-Fix Size",bfs_pri$estimate)
}
write.csv(cor_mat, file = "/home/kjbaron/Documents/NABATS/intermediate_files/dependent_variable_correlations.csv",row.names=FALSE,na="")
#install.packages(c("dplyr","scales","relaimpo","rms","e1071","Hmisc"))
#install.packages("rms")
#install.packages("mvtnorm")
library(dplyr)
library(scales)
require(relaimpo)
library(rms)
library(e1071)
library(Hmisc)
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/bug_level_df.csv", header = TRUE)
# -1 indicates a strong negative correlation : this means that every time x increases, y decreases (left panel figure)
#  0 means that there is no association between the two variables (x and y) (middle panel figure)
#  1 indicates a strong positive correlation : this means that y increases with x (right panel figure)
res <- cor.test(file_data$priority, file_data$exp, method = "pearson")
################################################################################
# Fill Correlation Table
################################################################################
#Create a matrix to fill with correlation values
cor_mat <- matrix(ncol=13, nrow=4)
cor_mat[1,] <- c("M1","M2", "accumulo","bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket")
cor_mat[2,] <- c("Experience","Bug-Fix Size")
cor_mat[3,] <- c("Experience","Priority")
cor_mat[4,] <- c("Priority","Bug-Fix Size")
i <- 3
for (current_project in c("accumulo","bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket"))
{
print(current_project)
#Extract project
p_df <- filter(file_data, project == current_project)
p_df[c("exp","bfs","priority")] <- lapply(p_df[c("exp","bfs","priority")], function(x) c(scale(x, center= min(x), scale=diff(range(x)))))
pri_exp <- cor.test(p_df$priority, p_df$exp, method = "pearson")
bfs_exp <- cor.test(p_df$bfs, p_df$exp, method = "pearson")
bfs_pri <- cor.test(p_df$bfs, p_df$priority, method = "pearson")
#Add results to maxtrix
cor_mat[2,i] <- c("Experience","Bug-Fix Size",bfs_exp$estimate)
cor_mat[3,i] <- c("Experience","Priority",pri_exp$estimate)
cor_mat[4,i] <- c("Priority","Bug-Fix Size",bfs_pri$estimate)
i <- i+1
}
write.csv(cor_mat, file = "/home/kjbaron/Documents/NABATS/intermediate_files/dependent_variable_correlations.csv",row.names=FALSE,na="")
#install.packages(c("dplyr","scales","relaimpo","rms","e1071","Hmisc"))
#install.packages("rms")
#install.packages("mvtnorm")
library(dplyr)
library(scales)
require(relaimpo)
library(rms)
library(e1071)
library(Hmisc)
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/bug_level_df.csv", header = TRUE)
# -1 indicates a strong negative correlation : this means that every time x increases, y decreases (left panel figure)
#  0 means that there is no association between the two variables (x and y) (middle panel figure)
#  1 indicates a strong positive correlation : this means that y increases with x (right panel figure)
res <- cor.test(file_data$priority, file_data$exp, method = "pearson")
################################################################################
# Fill Correlation Table
################################################################################
#Create a matrix to fill with correlation values
cor_mat <- matrix(ncol=13, nrow=4)
cor_mat[1,] <- c("M1","M2", "accumulo","bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket")
cor_mat[2,] <- c("Experience","Bug-Fix Size")
cor_mat[3,] <- c("Experience","Priority")
cor_mat[4,] <- c("Priority","Bug-Fix Size")
i <- 3
for (current_project in c("accumulo","bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket"))
{
print(current_project)
#Extract project
p_df <- filter(file_data, project == current_project)
p_df[c("exp","bfs","priority")] <- lapply(p_df[c("exp","bfs","priority")], function(x) c(scale(x, center= min(x), scale=diff(range(x)))))
pri_exp <- cor.test(p_df$priority, p_df$exp, method = "pearson")
bfs_exp <- cor.test(p_df$bfs, p_df$exp, method = "pearson")
bfs_pri <- cor.test(p_df$bfs, p_df$priority, method = "pearson")
#Add results to maxtrix
cor_mat[2,i] <- bfs_exp$estimate
cor_mat[3,i] <- pri_exp$estimate
cor_mat[4,i] <- bfs_pri$estimate
i <- i+1
}
write.csv(cor_mat, file = "/home/kjbaron/Documents/NABATS/intermediate_files/dependent_variable_correlations.csv",row.names=FALSE,na="")
#install.packages(c("dplyr","scales","relaimpo","rms","e1071","Hmisc"))
#install.packages("rms")
#install.packages("mvtnorm")
library(dplyr)
library(scales)
require(relaimpo)
library(rms)
library(e1071)
library(Hmisc)
#Read in CSV
file_data <- read.csv("/home/kjbaron/Documents/NABATS/intermediate_files/bug_level_df.csv", header = TRUE)
# -1 indicates a strong negative correlation : this means that every time x increases, y decreases (left panel figure)
#  0 means that there is no association between the two variables (x and y) (middle panel figure)
#  1 indicates a strong positive correlation : this means that y increases with x (right panel figure)
res <- cor.test(file_data$priority, file_data$exp, method = "pearson")
################################################################################
# Fill Correlation Table
################################################################################
#Create a matrix to fill with correlation values
cor_mat <- matrix(ncol=13, nrow=4)
cor_mat[1,] <- c("M1","M2", "accumulo","bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket")
cor_mat[,1] <- c("M1","Exp","Exp","Priority")
cor_mat[,2] <- c("M2","BFS","Priority","BFS")
i <- 3
for (current_project in c("accumulo","bookkeeper","camel","cassandra","cxf","derby","felix","hive","openjpa","pig","wicket"))
{
print(current_project)
#Extract project
p_df <- filter(file_data, project == current_project)
p_df[c("exp","bfs","priority")] <- lapply(p_df[c("exp","bfs","priority")], function(x) c(scale(x, center= min(x), scale=diff(range(x)))))
pri_exp <- cor.test(p_df$priority, p_df$exp, method = "pearson")
bfs_exp <- cor.test(p_df$bfs, p_df$exp, method = "pearson")
bfs_pri <- cor.test(p_df$bfs, p_df$priority, method = "pearson")
#Add results to maxtrix
cor_mat[2,i] <- bfs_exp$estimate
cor_mat[3,i] <- pri_exp$estimate
cor_mat[4,i] <- bfs_pri$estimate
i <- i+1
}
write.csv(cor_mat, file = "/home/kjbaron/Documents/NABATS/intermediate_files/dependent_variable_correlations.csv",row.names=FALSE,na="")
